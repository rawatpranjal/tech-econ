[
  {
    "name": "LMSYS-Chat-1M",
    "description": "1M real-world conversations with 25 state-of-the-art LLMs spanning 154 languages",
    "category": "AI & LLM",
    "url": "https://huggingface.co/datasets/lmsys/lmsys-chat-1m",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "LLM",
      "conversations",
      "multilingual",
      "chatbot"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "huggingface-transformers",
      "text-preprocessing"
    ],
    "topic_tags": [
      "conversational-ai",
      "llm-evaluation",
      "multilingual-data",
      "chatbot-analysis",
      "natural-language"
    ],
    "summary": "A comprehensive dataset containing 1 million real conversations between users and 25 different state-of-the-art language models across 154 languages. This resource enables researchers and practitioners to analyze conversational patterns, evaluate LLM performance, and study multilingual chatbot interactions at scale.",
    "use_cases": [
      "Benchmarking chatbot performance across different languages and comparing response quality between LLM models",
      "Training conversation classifiers or building datasets for fine-tuning conversational AI systems"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large dataset of chatbot conversations for analysis",
      "multilingual LLM conversation data for research",
      "real user interactions with language models dataset",
      "conversational AI evaluation dataset with multiple models"
    ]
  },
  {
    "name": "DiQAD",
    "description": "100K real-world user dialogues with comprehensive 6-dimension quality assessment",
    "category": "AI & LLM",
    "url": "https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation",
    "docs_url": null,
    "github_url": "https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation",
    "tags": [
      "dialogue",
      "quality assessment",
      "NLP"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "natural-language-processing",
      "data-preprocessing"
    ],
    "topic_tags": [
      "dialogue-systems",
      "quality-metrics",
      "conversational-ai",
      "evaluation-datasets",
      "human-computer-interaction"
    ],
    "summary": "DiQAD is a large-scale dataset containing 100,000 real-world user dialogues with systematic quality ratings across six dimensions. It provides researchers and practitioners with ground truth data for training and evaluating dialogue quality assessment models. The dataset is particularly valuable for developing automated conversation evaluation systems and benchmarking chatbot performance.",
    "use_cases": [
      "Training automated dialogue quality scoring models for chatbot evaluation",
      "Benchmarking conversational AI systems against human-annotated quality standards"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "dialogue quality evaluation dataset",
      "real world conversation data with quality scores",
      "benchmark dataset for chatbot performance",
      "human annotated dialogue assessment data"
    ]
  },
  {
    "name": "USS (User Satisfaction Simulation)",
    "description": "6,800 dialogues with 5-level satisfaction scale labels across multiple domains",
    "category": "AI & LLM",
    "url": "https://github.com/sunnweiwei/user-satisfaction-simulation",
    "docs_url": null,
    "github_url": "https://github.com/sunnweiwei/user-satisfaction-simulation",
    "tags": [
      "user satisfaction",
      "dialogue",
      "simulation"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "classification-metrics",
      "dialogue-systems"
    ],
    "topic_tags": [
      "user-satisfaction",
      "dialogue-evaluation",
      "conversational-ai",
      "labeled-dataset"
    ],
    "summary": "A simulation dataset containing 6,800 dialogues labeled with user satisfaction scores on a 5-point scale across multiple domains. This dataset enables researchers and practitioners to train models for predicting user satisfaction in conversational AI systems. It's particularly valuable for evaluating chatbot performance and understanding factors that drive user engagement.",
    "use_cases": [
      "Training ML models to predict user satisfaction scores for chatbot interactions",
      "Benchmarking conversational AI systems against standardized satisfaction metrics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "user satisfaction dataset for chatbots",
      "dialogue satisfaction scoring data",
      "conversational AI evaluation dataset",
      "labeled user satisfaction dialogues"
    ]
  },
  {
    "name": "ConvAI Dataset",
    "description": "4,750 human-to-bot dialogues with thumbs up/down feedback plus quality scores",
    "category": "AI & LLM",
    "url": "http://convai.io/2017/data/dataset_description.pdf",
    "docs_url": "http://convai.io/2017/data/dataset_description.pdf",
    "github_url": null,
    "tags": [
      "chatbot",
      "human feedback",
      "dialogue quality"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-NLP"
    ],
    "topic_tags": [
      "dialogue-systems",
      "human-feedback",
      "conversational-AI",
      "quality-assessment",
      "training-data"
    ],
    "summary": "The ConvAI Dataset contains 4,750 human-to-bot conversations with quality ratings and thumbs up/down feedback from users. This dataset is commonly used for training and evaluating conversational AI systems, providing both dialogue examples and human preference signals. It's particularly valuable for researchers working on chatbot improvement and dialogue quality assessment.",
    "use_cases": [
      "Training a chatbot to generate more human-preferred responses using the feedback scores",
      "Benchmarking dialogue quality metrics against human ratings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "dataset for chatbot training with human feedback",
      "conversational AI data with quality scores",
      "human-bot dialogue dataset with ratings",
      "training data for dialogue systems evaluation"
    ]
  },
  {
    "name": "Arena Human Preference (55K)",
    "description": "55K+ real-world conversations with human preference labels from Chatbot Arena",
    "category": "AI & LLM",
    "url": "https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "human preference",
      "LLM evaluation",
      "chatbot arena"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "pytorch-transformers",
      "statistical-hypothesis-testing"
    ],
    "topic_tags": [
      "human-preference",
      "llm-evaluation",
      "chatbot-arena",
      "conversation-data",
      "preference-learning"
    ],
    "summary": "A large-scale dataset containing over 55,000 real-world conversations between users and chatbots, each labeled with human preference judgments from Chatbot Arena. This dataset provides ground truth for training preference models and evaluating conversational AI systems against human judgment. It's particularly valuable for researchers and practitioners working on LLM alignment and evaluation metrics.",
    "use_cases": [
      "Training reward models for RLHF to align language models with human preferences",
      "Benchmarking new LLM evaluation metrics against human judgment data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "human preference dataset for LLM evaluation",
      "chatbot arena conversation data with labels",
      "real world preference data for RLHF training",
      "dataset for comparing language model outputs"
    ]
  },
  {
    "name": "Brazilian eCommerce",
    "description": "100,000 orders (2016-2018) structured in 9 relational tables from Olist",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "orders",
      "Brazil",
      "relational data",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "data-visualization"
    ],
    "topic_tags": [
      "ecommerce-data",
      "relational-database",
      "customer-analytics",
      "order-analysis",
      "kaggle-dataset"
    ],
    "summary": "A comprehensive dataset containing 100,000 Brazilian eCommerce orders from Olist marketplace spanning 2016-2018, organized across 9 interconnected tables. This real-world relational dataset includes order details, customer information, product data, seller metrics, and payment information. Ideal for learning SQL joins, customer analytics, and eCommerce business intelligence practices.",
    "use_cases": [
      "Learning relational database analysis and SQL joins with realistic eCommerce schema",
      "Building customer segmentation and order analysis dashboards for portfolio projects"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "Brazilian ecommerce dataset for SQL practice",
      "relational database dataset for learning joins",
      "ecommerce order data for customer analysis",
      "Kaggle dataset with multiple tables for beginners"
    ]
  },
  {
    "name": "Open CDP",
    "description": "Omnichannel interaction tracking with AI-driven identity resolution",
    "category": "E-Commerce",
    "url": "https://rees46.com/en/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "omnichannel",
      "customer data",
      "identity resolution"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "SQL-joins",
      "python-pandas",
      "customer-segmentation"
    ],
    "topic_tags": [
      "customer-data-platform",
      "omnichannel-analytics",
      "identity-resolution",
      "e-commerce",
      "dataset"
    ],
    "summary": "Open CDP is a dataset containing omnichannel customer interaction data with AI-powered identity resolution capabilities. It enables analysts to track customer journeys across multiple touchpoints and channels. The dataset is particularly valuable for understanding cross-platform customer behavior and building unified customer profiles.",
    "use_cases": [
      "Building a unified customer journey analysis across web, mobile, and in-store touchpoints",
      "Training machine learning models to predict customer lifetime value using cross-channel behavioral data"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "customer data platform dataset for omnichannel analysis",
      "identity resolution dataset e-commerce",
      "cross-channel customer tracking data",
      "omnichannel customer journey dataset"
    ]
  },
  {
    "name": "JD.com 2020 (MSOM-20)",
    "description": "2.5M customers (457k purchasers) and 31,868 SKUs from JD.com",
    "category": "E-Commerce",
    "url": "https://connect.informs.org/msom/events/datadriven2020",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "customers",
      "SKUs",
      "INFORMS",
      "operations"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "retail-analytics"
    ],
    "topic_tags": [
      "customer-segmentation",
      "e-commerce-data",
      "retail-operations",
      "purchase-behavior",
      "SKU-analysis"
    ],
    "summary": "A comprehensive e-commerce dataset from JD.com containing transaction and customer data for 2.5 million customers and over 31,000 products. This dataset enables analysis of customer purchasing patterns, product performance, and operational metrics in one of China's largest online retail platforms. Originally featured in Management Science & Operations Management research, it's ideal for studying consumer behavior and retail operations at scale.",
    "use_cases": [
      "Analyzing customer lifetime value and segmentation patterns across different product categories",
      "Building demand forecasting models for inventory management using historical purchase data"
    ],
    "audience": [
      "Mid-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "JD.com customer purchase dataset",
      "e-commerce transaction data for customer segmentation",
      "retail operations dataset with SKU data",
      "Chinese e-commerce platform customer behavior data"
    ]
  },
  {
    "name": "Alibaba Ads (IJCAI-18)",
    "description": "6 billion display ad/click logs over 8 days from 100M users",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/147588",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "clicks",
      "large-scale",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "logistic-regression"
    ],
    "topic_tags": [
      "display-advertising",
      "click-prediction",
      "large-scale-data",
      "behavioral-modeling",
      "e-commerce-analytics"
    ],
    "summary": "This dataset contains 6 billion display advertisement impression and click records from Alibaba's platform, spanning 8 days and covering 100 million users. It's commonly used for developing and benchmarking click-through rate prediction models and studying large-scale user behavior in e-commerce advertising. The dataset provides real-world scale for testing recommendation systems and ad optimization algorithms.",
    "use_cases": [
      "Building click-through rate prediction models for display advertising campaigns",
      "Analyzing user engagement patterns across different product categories and ad formats"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale click prediction dataset",
      "Alibaba advertising data for CTR models",
      "billion-scale ad click logs dataset",
      "e-commerce display advertising benchmark data"
    ]
  },
  {
    "name": "Coveo Shopping (SIGIR-21)",
    "description": "30M+ browsing events with query and image vectors for e-commerce search",
    "category": "E-Commerce",
    "url": "https://github.com/coveooss/SIGIR-ecom-data-challenge",
    "docs_url": null,
    "github_url": "https://github.com/coveooss/SIGIR-ecom-data-challenge",
    "tags": [
      "browsing",
      "search",
      "embeddings",
      "SIGIR"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "vector-embeddings",
      "collaborative-filtering"
    ],
    "topic_tags": [
      "e-commerce-search",
      "query-embeddings",
      "browsing-behavior",
      "recommendation-systems",
      "SIGIR-dataset"
    ],
    "summary": "A large-scale dataset containing 30+ million browsing events from Coveo's e-commerce platform, featuring both textual queries and image embeddings. Published at SIGIR 2021, it provides real-world data for training and evaluating search ranking and recommendation models. The dataset is particularly valuable for researchers working on multimodal e-commerce search systems.",
    "use_cases": [
      "Training neural ranking models that combine text queries with product image features",
      "Benchmarking recommendation algorithms against real e-commerce browsing patterns"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale e-commerce search dataset",
      "SIGIR 2021 browsing data with embeddings",
      "multimodal search dataset queries and images",
      "Coveo shopping behavior dataset"
    ]
  },
  {
    "name": "Retail Rocket",
    "description": "2.76M events (views, carts, purchases) from 1.4M visitors",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "user events",
      "conversions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "basic-SQL"
    ],
    "topic_tags": [
      "event-tracking",
      "funnel-analysis",
      "e-commerce",
      "behavioral-data",
      "conversion-rates"
    ],
    "summary": "A large-scale e-commerce dataset containing 2.76M user interaction events (page views, add-to-cart, purchases) from 1.4M website visitors. This Kaggle dataset is ideal for learning user behavior analysis, conversion funnel optimization, and recommendation systems. The rich event sequence data makes it perfect for practicing data manipulation and exploring customer journey patterns.",
    "use_cases": [
      "Building a recommendation system to suggest products based on user browsing and purchase history",
      "Analyzing conversion funnels to identify drop-off points between viewing, adding to cart, and purchasing"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "e-commerce user behavior dataset for funnel analysis",
      "retail dataset with purchase events and user journeys",
      "Kaggle dataset for recommendation system practice",
      "large scale conversion tracking data for beginners"
    ]
  },
  {
    "name": "Google Merchandise",
    "description": "3 months obfuscated GA4 e-commerce data (Nov 2020-Jan 2021)",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/bigquery/google-analytics-sample",
    "docs_url": "https://support.google.com/analytics/answer/7586738",
    "github_url": null,
    "tags": [
      "Google Analytics",
      "GA4",
      "web analytics"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "SQL-basics",
      "python-pandas",
      "web-analytics-concepts"
    ],
    "topic_tags": [
      "google-analytics",
      "ecommerce-data",
      "web-analytics",
      "customer-behavior",
      "conversion-funnel"
    ],
    "summary": "This dataset contains 3 months of obfuscated Google Analytics 4 e-commerce data from November 2020 to January 2021. It provides real-world web analytics data for learning customer behavior analysis, conversion tracking, and e-commerce metrics without privacy concerns. The dataset is ideal for practicing GA4 data structure understanding and building analytics dashboards.",
    "use_cases": [
      "Learning to analyze e-commerce conversion funnels and customer journey patterns",
      "Building practice dashboards for web analytics and testing GA4 data visualization techniques"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Google Analytics 4 sample dataset for practice",
      "ecommerce web analytics data for learning",
      "GA4 dataset to practice conversion analysis",
      "sample Google merchandise store data"
    ]
  },
  {
    "name": "Shopee",
    "description": "Dataset from Shopee's 2020 Code League competition",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/c/shopee-code-league-2021",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Shopee",
      "competition",
      "Southeast Asia"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "e-commerce-data",
      "competition-dataset",
      "southeast-asia",
      "shopee",
      "retail-analytics"
    ],
    "summary": "Dataset from Shopee's 2020 Code League programming competition featuring real e-commerce data from Southeast Asia's largest shopping platform. Contains product listings, user interactions, and transaction data typical of online marketplace operations. Ideal for practicing data analysis skills on realistic e-commerce scenarios without dealing with data collection complexities.",
    "use_cases": [
      "Learning e-commerce analytics by exploring product categorization and user behavior patterns",
      "Building portfolio projects demonstrating skills in retail data analysis and Southeast Asian market insights"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Shopee competition dataset for e-commerce analysis",
      "Southeast Asia e-commerce data for practice",
      "retail marketplace dataset beginner friendly",
      "Shopee 2020 Code League data download"
    ]
  },
  {
    "name": "Flipkart",
    "description": "Sales dataset from Indian e-commerce platform Flipkart",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/iyumrahul/flipkartsalesdataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "India",
      "sales",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "e-commerce-data",
      "sales-analysis",
      "indian-market",
      "retail-dataset"
    ],
    "summary": "Sales dataset from Flipkart, one of India's largest e-commerce platforms, containing transaction and product information. This dataset is ideal for learning e-commerce analytics fundamentals and understanding Indian online retail patterns. Perfect for practicing data manipulation, exploratory analysis, and basic business intelligence techniques.",
    "use_cases": [
      "Learning e-commerce metrics like conversion rates, average order value, and customer segmentation",
      "Building predictive models for product demand forecasting in emerging markets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Flipkart sales data for learning",
      "Indian e-commerce dataset beginner friendly",
      "retail sales data from India",
      "e-commerce transaction dataset practice"
    ]
  },
  {
    "name": "Pakistan e-commerce",
    "description": "500k+ transactions (Mar 2016 - Aug 2018) from Pakistan's largest e-commerce",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Pakistan",
      "transactions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "e-commerce-analytics",
      "transaction-data",
      "emerging-markets",
      "customer-behavior",
      "dataset"
    ],
    "summary": "A comprehensive dataset of 500,000+ e-commerce transactions from Pakistan's largest online retailer spanning March 2016 to August 2018. This dataset provides rich transaction-level data including customer information, product categories, pricing, and temporal patterns from a major South Asian market. Ideal for learning e-commerce analytics fundamentals and exploring customer behavior patterns in emerging markets.",
    "use_cases": [
      "Analyzing customer purchasing patterns and seasonal trends in South Asian e-commerce markets",
      "Building customer segmentation models to understand buying behavior in emerging economies"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Pakistan e-commerce transaction dataset",
      "emerging markets customer behavior data",
      "e-commerce analytics practice dataset",
      "South Asian online retail transaction data"
    ]
  },
  {
    "name": "Instacart",
    "description": "3.4M orders, 206k+ users, 49k+ products with reorder behavior",
    "category": "Food & Delivery",
    "url": "https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "orders",
      "reorder prediction"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-sql",
      "logistic-regression"
    ],
    "topic_tags": [
      "market-basket-analysis",
      "customer-segmentation",
      "reorder-prediction",
      "e-commerce-analytics",
      "consumer-behavior"
    ],
    "summary": "The Instacart dataset contains 3.4 million grocery orders from over 206,000 users, including detailed product information and reorder patterns. It's widely used by data scientists learning recommendation systems and market basket analysis. The dataset is perfect for practicing customer segmentation, demand forecasting, and building reorder prediction models.",
    "use_cases": [
      "Building recommendation engines for grocery e-commerce platforms",
      "Analyzing customer purchase patterns to optimize inventory and marketing strategies"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "grocery store customer data for machine learning",
      "dataset for building recommendation systems",
      "e-commerce reorder prediction training data",
      "market basket analysis grocery dataset"
    ]
  },
  {
    "name": "Open E-Commerce 1.0 (MIT)",
    "description": "1.8M Amazon purchases with demographics (age, gender, location). Real household e-commerce behavior at scale",
    "category": "E-Commerce",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGAVK9",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "demographics",
      "purchases",
      "households",
      "MIT"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "consumer-behavior",
      "purchase-data",
      "demographic-analysis",
      "amazon-data",
      "household-economics"
    ],
    "summary": "Large-scale dataset containing 1.8 million Amazon purchase records linked to household demographics including age, gender, and location. This MIT-licensed dataset provides researchers and analysts with real consumer behavior data at unprecedented scale. Perfect for studying purchasing patterns, demographic segmentation, and e-commerce trends.",
    "use_cases": [
      "Analyzing how age and gender influence product category preferences and spending patterns",
      "Building customer segmentation models to understand regional differences in e-commerce behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Amazon purchase dataset with demographics",
      "large scale e-commerce consumer behavior data",
      "household purchasing patterns dataset",
      "demographic segmentation ecommerce data"
    ]
  },
  {
    "name": "Upworthy News Headlines",
    "description": "32,487 headline/image experiments on 538M assignments",
    "category": "Advertising",
    "url": "https://upworthy.natematias.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "headlines",
      "media",
      "experimentation"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "hypothesis-testing",
      "python-pandas",
      "statistical-significance"
    ],
    "topic_tags": [
      "ab-testing",
      "experimentation",
      "media-optimization",
      "headline-testing",
      "dataset"
    ],
    "summary": "A large-scale dataset containing 32,487 headline and image A/B test experiments from Upworthy, covering 538 million user assignments. This dataset provides real-world examples of digital media experimentation and is valuable for understanding how content optimization works in practice. Researchers and practitioners can use it to study A/B testing methodologies, effect sizes, and content performance patterns.",
    "use_cases": [
      "Analyzing A/B test effect sizes and statistical power in media experiments",
      "Training machine learning models to predict headline performance and engagement"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "upworthy headline A/B testing dataset",
      "real world A/B testing examples media",
      "content optimization experiment data",
      "headline performance testing dataset"
    ]
  },
  {
    "name": "ASSISTments Dataset",
    "description": "Data from online tutoring platform for educational data mining",
    "category": "Education",
    "url": "https://sites.google.com/site/las2016data/home",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "education",
      "tutoring",
      "learning analytics"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "educational-data-mining",
      "learning-analytics",
      "student-behavior",
      "tutoring-systems",
      "longitudinal-data"
    ],
    "summary": "The ASSISTments dataset contains student interaction data from an online tutoring platform, including problem-solving attempts, hints requested, and learning outcomes. It's widely used by education researchers and data scientists to study learning patterns, predict student performance, and evaluate tutoring effectiveness. The dataset provides rich longitudinal data perfect for understanding how students learn mathematics through digital platforms.",
    "use_cases": [
      "Predicting which students are at risk of failing based on their tutoring session patterns",
      "A/B testing different hint strategies to see which helps students learn more effectively"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "student learning dataset for machine learning",
      "educational data mining tutorial data",
      "online tutoring platform analytics dataset",
      "ASSISTments data for predicting student performance"
    ]
  },
  {
    "name": "Gamified Learning",
    "description": "Experiments on gamification in learning environments",
    "category": "Education",
    "url": "https://data.mendeley.com/datasets/7kgpn39m8w/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "gamification",
      "education",
      "experiments"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "randomized-controlled-trials",
      "python-pandas",
      "statistical-hypothesis-testing"
    ],
    "topic_tags": [
      "gamification",
      "education-technology",
      "experimental-design",
      "learning-outcomes",
      "behavioral-interventions"
    ],
    "summary": "This dataset contains experimental results from studies testing gamification elements (points, badges, leaderboards) in educational settings. It's commonly used by education researchers and product teams to understand how game mechanics affect student engagement and learning outcomes. The data enables analysis of treatment effects across different gamification strategies and learner populations.",
    "use_cases": [
      "Designing A/B tests for an educational app to determine which gamification features improve course completion rates",
      "Academic research on the effectiveness of different reward systems in online learning platforms"
    ],
    "audience": [
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "gamification experiments in education",
      "does gamification improve learning outcomes",
      "A/B testing results for educational games",
      "gamification effect on student engagement data"
    ]
  },
  {
    "name": "Stanford GSB Experiment Collection",
    "description": "Datasets for experimentation analysis from Stanford Graduate School of Business",
    "category": "Education",
    "url": "https://github.com/gsbDBI/ExperimentData",
    "docs_url": null,
    "github_url": "https://github.com/gsbDBI/ExperimentData",
    "tags": [
      "Stanford",
      "causal inference",
      "experiments"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "randomization-inference",
      "hypothesis-testing"
    ],
    "topic_tags": [
      "experimental-data",
      "randomized-trials",
      "academic-datasets",
      "causal-inference",
      "stanford"
    ],
    "summary": "A curated collection of real experimental datasets from Stanford Graduate School of Business research projects. These datasets include randomized controlled trials and quasi-experimental studies with clean documentation for learning causal inference methods. Ideal for practitioners wanting to practice experimental analysis techniques on high-quality academic data.",
    "use_cases": [
      "Learning experimental design by replicating published Stanford studies",
      "Testing causal inference packages on clean randomized trial data"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "stanford business school experiment datasets",
      "academic RCT data for causal inference practice",
      "clean experimental data for learning randomization",
      "stanford GSB randomized trial datasets"
    ]
  },
  {
    "name": "Athey's Course Datasets",
    "description": "Datasets related to causal inference and experimental design from Susan Athey",
    "category": "Education",
    "url": "https://github.com/itamarcaspi/experimentdatar",
    "docs_url": null,
    "github_url": "https://github.com/itamarcaspi/experimentdatar",
    "tags": [
      "causal inference",
      "experiments",
      "research"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "difference-in-differences",
      "regression-analysis"
    ],
    "topic_tags": [
      "causal-inference",
      "experimental-design",
      "athey-datasets",
      "academic-research",
      "educational-materials"
    ],
    "summary": "Educational datasets curated by Susan Athey for teaching causal inference and experimental design methods. These datasets are commonly used in academic courses and workshops to demonstrate key concepts like randomized controlled trials, natural experiments, and treatment effect estimation. They provide clean, well-documented examples perfect for learning and practicing causal inference techniques.",
    "use_cases": [
      "Learning causal inference methods through hands-on practice with real experimental data",
      "Teaching econometrics courses with standardized datasets that illustrate key concepts"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "Susan Athey causal inference datasets",
      "educational datasets for learning experimental design",
      "practice data for difference in differences",
      "Athey course materials datasets"
    ]
  },
  {
    "name": "PEP Experimental Research",
    "description": "Experimental research datasets from Partnership for Economic Policy",
    "category": "Education",
    "url": "https://www.pep-net.org/publications/datasets/experimental-research-datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "development",
      "RCT",
      "policy"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-statistics",
      "experiment-design"
    ],
    "topic_tags": [
      "randomized-controlled-trials",
      "development-economics",
      "policy-evaluation",
      "experimental-data",
      "dataset"
    ],
    "summary": "A collection of experimental research datasets from Partnership for Economic Policy focusing on randomized controlled trials in developing countries. These datasets are primarily used by researchers and analysts studying the impact of various policy interventions on economic and social outcomes. The data provides real-world examples of experimental design and implementation in development economics contexts.",
    "use_cases": [
      "Learning how to analyze RCT data by replicating published development economics studies",
      "Teaching experimental methods using real policy intervention datasets from developing countries"
    ],
    "audience": [
      "Early-PhD",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "development economics RCT datasets",
      "experimental data for policy evaluation",
      "randomized controlled trial data developing countries",
      "PEP partnership economic policy datasets"
    ]
  },
  {
    "name": "Computational Neuroscience",
    "description": "Experimental data from neural recordings and behavior",
    "category": "Education",
    "url": "https://crcns.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "neuroscience",
      "neural data",
      "behavior"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "signal-processing",
      "matplotlib"
    ],
    "topic_tags": [
      "neural-recordings",
      "behavioral-data",
      "neuroscience",
      "experimental-data",
      "spike-trains"
    ],
    "summary": "Collection of experimental datasets containing neural activity recordings (spike trains, LFP, etc.) paired with behavioral measurements from various neuroscience experiments. Used by researchers studying brain-behavior relationships and computational neuroscientists developing analysis methods. Includes data from different brain regions, species, and experimental paradigms.",
    "use_cases": [
      "Training machine learning models to decode motor intentions from neural signals",
      "Analyzing neural population dynamics during decision-making tasks"
    ],
    "audience": [
      "Early-PhD",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "neural recording datasets for machine learning",
      "spike train data behavioral experiments",
      "computational neuroscience practice datasets",
      "brain activity data motor cortex"
    ]
  },
  {
    "name": "ASOS Experiments",
    "description": "99 real e-commerce experiments with daily checkpoints from ASOS",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/marinazmieva/asos-digital-experiments-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "e-commerce",
      "fashion",
      "Kaggle"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "statistical-hypothesis-testing",
      "data-visualization"
    ],
    "topic_tags": [
      "ab-testing",
      "ecommerce-experiments",
      "fashion-retail",
      "kaggle-dataset",
      "experimental-design"
    ],
    "summary": "A collection of 99 real A/B testing experiments from ASOS with daily performance metrics and outcomes. This dataset provides hands-on experience with real e-commerce experimentation data, including control/treatment groups, daily checkpoints, and business metrics. Perfect for learning experimental analysis techniques and understanding how fashion retailers optimize their platforms.",
    "use_cases": [
      "Learning A/B test analysis by practicing on real e-commerce experiments with known outcomes",
      "Building experimentation dashboards and monitoring systems using actual daily checkpoint data"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "real A/B testing datasets for practice",
      "ASOS experiment data download",
      "e-commerce A/B test examples with daily metrics",
      "fashion retail experimentation case studies"
    ]
  },
  {
    "name": "Amazon Sessions (KDD Cup 23)",
    "description": "Sessions from 6 locales with 40k-500k products per locale",
    "category": "E-Commerce",
    "url": "https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "sessions",
      "multilingual",
      "KDD"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-preprocessing",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "e-commerce",
      "session-data",
      "multilingual",
      "recommender-systems",
      "user-behavior"
    ],
    "summary": "A large-scale dataset from Amazon containing user session data across 6 different locales, with each locale featuring 40k-500k products. This KDD Cup 2023 competition dataset is ideal for learning e-commerce analytics and building recommender systems. The multilingual nature makes it valuable for understanding cross-cultural shopping patterns and international e-commerce behavior.",
    "use_cases": [
      "Building product recommendation systems using session-based collaborative filtering",
      "Analyzing cross-locale differences in user shopping behavior and conversion patterns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Amazon session data for recommender systems",
      "multilingual e-commerce dataset",
      "KDD Cup 2023 Amazon data",
      "session-based recommendation dataset"
    ]
  },
  {
    "name": "JD.com Search",
    "description": "170,000 users' real search queries (2021-2022) from JD.com",
    "category": "E-Commerce",
    "url": "https://github.com/rucliujn/JDsearch",
    "docs_url": null,
    "github_url": "https://github.com/rucliujn/JDsearch",
    "tags": [
      "search queries",
      "e-commerce search",
      "China"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-chinese",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "search-behavior",
      "e-commerce-analytics",
      "user-queries",
      "chinese-market",
      "dataset"
    ],
    "summary": "A dataset containing 170,000 real user search queries from JD.com, China's second-largest e-commerce platform, collected between 2021-2022. This data provides insights into Chinese consumer search behavior and e-commerce patterns. Perfect for researchers studying search intent, query analysis, or Chinese market dynamics.",
    "use_cases": [
      "Analyzing search query patterns to understand Chinese consumer preferences and seasonal trends",
      "Building search recommendation systems or query suggestion models for e-commerce platforms"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "JD.com search query dataset",
      "Chinese e-commerce user search data",
      "real search queries dataset china",
      "e-commerce search behavior analysis data"
    ]
  },
  {
    "name": "JD-pretrain-data",
    "description": "Encoded search queries and item data for intent detection",
    "category": "E-Commerce",
    "url": "https://github.com/jdcomsearch/jd-pretrain-data",
    "docs_url": null,
    "github_url": "https://github.com/jdcomsearch/jd-pretrain-data",
    "tags": [
      "search",
      "intent detection",
      "embeddings"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "text-embeddings",
      "classification-models"
    ],
    "topic_tags": [
      "search-intent",
      "query-embeddings",
      "e-commerce-data",
      "behavioral-analytics"
    ],
    "summary": "A dataset containing encoded search queries and corresponding item data designed for training intent detection models in e-commerce contexts. The data includes pre-processed embeddings that can be used to classify user search behavior and predict purchase intent. This resource is valuable for data scientists working on search optimization and recommendation systems.",
    "use_cases": [
      "Training machine learning models to classify whether a search query indicates browsing vs purchase intent",
      "Building recommendation systems that surface relevant products based on encoded search patterns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "search intent classification dataset e-commerce",
      "encoded query embeddings for recommendation systems",
      "training data for search behavior prediction",
      "e-commerce search intent detection models"
    ]
  },
  {
    "name": "BestBuy",
    "description": "Mobile website clicks (~42k) for Xbox games from BestBuy",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/competitions/acm-sf-chapter-hackathon-big",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clicks",
      "mobile",
      "gaming",
      "hackathon"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-statistics"
    ],
    "topic_tags": [
      "clickstream-analysis",
      "mobile-commerce",
      "gaming-industry",
      "user-behavior",
      "e-commerce-data"
    ],
    "summary": "A dataset containing approximately 42,000 mobile website click events for Xbox games on BestBuy's platform. This dataset provides real-world e-commerce clickstream data ideal for learning web analytics and user behavior analysis techniques. It's commonly used in hackathons and educational settings to practice conversion funnel analysis and mobile user experience optimization.",
    "use_cases": [
      "Analyzing mobile conversion funnels for Xbox game purchases to identify drop-off points",
      "Building click-through rate models to optimize product page layouts for gaming products"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "mobile ecommerce clickstream dataset",
      "xbox gaming website analytics data",
      "bestbuy click data for conversion analysis",
      "hackathon dataset mobile user behavior"
    ]
  },
  {
    "name": "Rakuten SIGIR",
    "description": "E-commerce dataset for SIGIR workshop from Rakuten",
    "category": "E-Commerce",
    "url": "https://sigir-ecom.github.io/ecom2018/data-task.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "SIGIR",
      "e-commerce",
      "search"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "information-retrieval-basics",
      "A-B-testing"
    ],
    "topic_tags": [
      "e-commerce-search",
      "information-retrieval",
      "ranking-algorithms",
      "user-behavior",
      "dataset"
    ],
    "summary": "This is an e-commerce dataset from Rakuten created for the SIGIR workshop, containing search and user interaction data from their platform. It's designed for researchers and practitioners working on information retrieval problems in e-commerce contexts. The dataset enables experimentation with search ranking algorithms, user behavior analysis, and recommendation systems in retail settings.",
    "use_cases": [
      "Developing and benchmarking search ranking algorithms for e-commerce platforms",
      "Analyzing user search behavior patterns to improve product discovery and conversion rates"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "e-commerce search ranking dataset",
      "Rakuten SIGIR workshop data",
      "benchmark dataset for product search algorithms",
      "e-commerce user behavior data for research"
    ]
  },
  {
    "name": "Wayfair Search (WANDS)",
    "description": "233k human-annotated query-product judgments, 43k products",
    "category": "E-Commerce",
    "url": "https://github.com/wayfair/WANDS",
    "docs_url": null,
    "github_url": "https://github.com/wayfair/WANDS",
    "tags": [
      "search relevance",
      "annotations",
      "furniture"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "information-retrieval-basics",
      "data-preprocessing"
    ],
    "topic_tags": [
      "search-relevance",
      "e-commerce",
      "annotations",
      "furniture",
      "dataset"
    ],
    "summary": "WANDS is a large-scale dataset containing 233,000 human-annotated query-product judgments from Wayfair's search system, covering 43,000 furniture and home goods products. It provides ground truth relevance labels for search queries, making it valuable for training and evaluating search ranking algorithms. The dataset is particularly useful for researchers and practitioners working on e-commerce search relevance problems.",
    "use_cases": [
      "Training machine learning models to predict search result relevance for e-commerce platforms",
      "Benchmarking different search ranking algorithms against human-labeled ground truth data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "wayfair search relevance dataset",
      "e-commerce query product annotations",
      "furniture search ranking data",
      "human labeled search results dataset"
    ]
  },
  {
    "name": "Criteo Display Advertising",
    "description": "342GB total with 13 integer features, 26 hashed categorical features",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/ressources/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR prediction",
      "advertising",
      "large-scale"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "logistic-regression"
    ],
    "topic_tags": [
      "CTR-prediction",
      "advertising",
      "large-scale",
      "categorical-features",
      "dataset"
    ],
    "summary": "The Criteo Display Advertising dataset is a 342GB collection containing click-through rate data with 13 integer features and 26 hashed categorical features. It's widely used by data scientists and researchers for benchmarking CTR prediction models at scale. The dataset provides real-world advertising data for training and evaluating machine learning algorithms in computational advertising.",
    "use_cases": [
      "Benchmarking CTR prediction models for display advertising campaigns",
      "Training large-scale machine learning systems for real-time bid optimization"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "criteo dataset for CTR prediction",
      "large scale advertising click through rate data",
      "display advertising machine learning dataset",
      "criteo benchmark dataset download"
    ]
  },
  {
    "name": "Avazu",
    "description": "Dataset for click-through rate prediction on mobile ads",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/avazu-ctr-prediction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR",
      "mobile ads",
      "Kaggle competition"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "binary-classification"
    ],
    "topic_tags": [
      "click-through-rate",
      "mobile-advertising",
      "kaggle-dataset",
      "binary-classification",
      "ad-tech"
    ],
    "summary": "The Avazu dataset contains mobile ad click data from a popular Kaggle competition focused on predicting click-through rates. It includes anonymized features about users, devices, and ad placements with binary click outcomes. This dataset is widely used for learning CTR prediction techniques and benchmarking classification models in digital advertising contexts.",
    "use_cases": [
      "Learning CTR prediction modeling techniques for digital advertising applications",
      "Benchmarking binary classification algorithms on real-world mobile ad click data"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "mobile ad click prediction dataset",
      "CTR prediction training data",
      "Avazu Kaggle competition dataset",
      "click through rate modeling dataset"
    ]
  },
  {
    "name": "Yoyi",
    "description": "Computational advertising dataset from Chinese ad platform",
    "category": "Advertising",
    "url": "https://apex.sjtu.edu.cn/datasets/7",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "China",
      "computational ads"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "click-through-rate-modeling",
      "A-B-testing"
    ],
    "topic_tags": [
      "computational-advertising",
      "click-through-rate",
      "chinese-market",
      "ad-platform",
      "dataset"
    ],
    "summary": "Yoyi is a computational advertising dataset from a Chinese advertising platform containing user interactions, ad features, and campaign performance metrics. It provides real-world data for researchers and practitioners working on ad targeting, bidding strategies, and campaign optimization. The dataset is particularly valuable for understanding advertising dynamics in the Chinese market context.",
    "use_cases": [
      "Training click-through-rate prediction models for ad platforms",
      "Benchmarking bidding algorithms against real Chinese market data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Chinese advertising dataset for CTR prediction",
      "real world computational advertising data",
      "ad platform dataset for bidding optimization",
      "Yoyi advertising dataset download"
    ]
  },
  {
    "name": "Ele.me Search",
    "description": "Search log dataset from Ele.me (Chinese food delivery)",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/dataset/120281",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "food delivery",
      "search logs",
      "China"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "search-logs",
      "food-delivery",
      "user-behavior",
      "dataset",
      "china-market"
    ],
    "summary": "Search log dataset from Ele.me, one of China's largest food delivery platforms, containing user search queries and interactions. This dataset provides insights into Chinese consumer food preferences and search behavior patterns. It's valuable for understanding search optimization, recommendation systems, and market analysis in the food delivery domain.",
    "use_cases": [
      "Analyzing search query patterns to improve food delivery app search algorithms",
      "Understanding regional food preferences and dietary trends in Chinese markets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "food delivery search logs dataset",
      "chinese food delivery user behavior data",
      "ele.me search query analysis",
      "food app search optimization dataset"
    ]
  },
  {
    "name": "Ele.me Clickstream",
    "description": "Clickstream data from Ele.me food delivery platform",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/dataset/131047",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clickstream",
      "food delivery",
      "user behavior"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "web-analytics",
      "survival-analysis"
    ],
    "topic_tags": [
      "clickstream-analysis",
      "food-delivery",
      "user-behavior",
      "conversion-funnels",
      "session-data"
    ],
    "summary": "Clickstream dataset from Ele.me, a major Chinese food delivery platform, containing user navigation and interaction patterns. The data captures user journeys from browsing to ordering, making it valuable for understanding customer behavior in food delivery apps. Researchers and data scientists use this for conversion analysis, recommendation system evaluation, and user experience optimization.",
    "use_cases": [
      "Analyzing conversion funnels to identify drop-off points in the food ordering process",
      "Building recommendation systems for restaurants and dishes based on user browsing patterns"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "food delivery clickstream data",
      "Ele.me user behavior dataset",
      "restaurant recommendation system training data",
      "conversion funnel analysis food delivery"
    ]
  },
  {
    "name": "Alibaba Industrial Dump (150GB)",
    "description": "Large-scale industrial dataset from Alibaba (150GB)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/81505",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "large-scale",
      "industrial",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "distributed-computing",
      "SQL-joins"
    ],
    "topic_tags": [
      "alibaba-dataset",
      "e-commerce-data",
      "large-scale-dataset",
      "industrial-data",
      "recommendation-systems"
    ],
    "summary": "A massive 150GB industrial dataset from Alibaba containing real-world e-commerce transaction and user behavior data. This dataset provides researchers and practitioners with access to large-scale commercial data for developing and testing algorithms at industrial scale. It's particularly valuable for understanding user patterns, recommendation systems, and marketplace dynamics in one of the world's largest e-commerce platforms.",
    "use_cases": [
      "Training recommendation algorithms on real e-commerce user behavior and transaction data",
      "Benchmarking distributed computing frameworks and big data processing pipelines"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale e-commerce dataset for recommendation systems",
      "Alibaba industrial dataset download",
      "150GB e-commerce transaction data",
      "real world marketplace behavior dataset"
    ]
  },
  {
    "name": "Alibaba Fashion Combo",
    "description": "Fashion item combinations from Alibaba for outfit recommendation",
    "category": "Fashion & Apparel",
    "url": "https://tianchi.aliyun.com/dataset/131519",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "outfit",
      "recommendation"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "data-preprocessing"
    ],
    "topic_tags": [
      "fashion-recommendation",
      "outfit-matching",
      "e-commerce-data",
      "recommendation-systems",
      "retail-analytics"
    ],
    "summary": "A dataset containing fashion item combinations from Alibaba's platform, designed for building outfit recommendation systems. This resource is valuable for data scientists working in retail and e-commerce who want to understand how customers combine different fashion items. The dataset enables experimentation with recommendation algorithms and fashion compatibility modeling.",
    "use_cases": [
      "Building a 'complete the look' feature for an e-commerce fashion website",
      "Training models to suggest complementary items when customers view a specific clothing piece"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "fashion recommendation dataset for outfit suggestions",
      "Alibaba clothing combination data for ML",
      "dataset for building complete the look features",
      "fashion item pairing data for recommendation systems"
    ]
  },
  {
    "name": "Alibaba Brick and Mortar (IJCAI-16)",
    "description": "Online and offline check-ins/purchases from 1,000+ stores",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/53",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "O2O",
      "offline",
      "retail",
      "IJCAI"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "SQL-basics"
    ],
    "topic_tags": [
      "o2o-commerce",
      "retail-analytics",
      "customer-behavior",
      "location-data",
      "chinese-ecommerce"
    ],
    "summary": "A dataset containing online and offline customer check-ins and purchase behaviors from over 1,000 Alibaba-affiliated brick-and-mortar stores. This O2O (online-to-offline) commerce dataset enables analysis of omnichannel customer journeys and retail optimization strategies. It's particularly valuable for understanding how digital platforms integrate with physical retail experiences.",
    "use_cases": [
      "Analyzing customer conversion patterns between online browsing and offline purchases",
      "Building recommendation systems that bridge digital and physical shopping experiences"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "alibaba o2o dataset retail analysis",
      "online offline customer behavior data",
      "brick and mortar ecommerce dataset",
      "omnichannel retail analytics dataset"
    ]
  },
  {
    "name": "Alibaba Mobile 2021",
    "description": "Mobile user behavior data from Alibaba (2021)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/109858",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "mobile",
      "user behavior",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "behavioral-analytics"
    ],
    "topic_tags": [
      "mobile-analytics",
      "user-behavior",
      "e-commerce",
      "alibaba",
      "dataset"
    ],
    "summary": "Mobile user behavior dataset from Alibaba's 2021 platform activity, capturing user interactions, sessions, and engagement patterns. This dataset is valuable for data scientists working on mobile commerce optimization and user experience research. It provides real-world e-commerce behavioral data for building recommendation systems and conducting user journey analysis.",
    "use_cases": [
      "Building mobile app recommendation engines for e-commerce platforms",
      "Analyzing user session patterns to optimize mobile checkout flows"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Alibaba mobile user behavior dataset 2021",
      "e-commerce mobile analytics data",
      "user behavior data for recommendation systems",
      "mobile commerce behavioral dataset"
    ]
  },
  {
    "name": "Alibaba Clickstream 2018",
    "description": "Clickstream data from Alibaba platforms (2018)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/56",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clickstream",
      "Alibaba",
      "user behavior"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "clickstream-data",
      "e-commerce-analytics",
      "user-behavior",
      "alibaba-dataset"
    ],
    "summary": "Large-scale clickstream dataset from Alibaba's e-commerce platforms capturing user browsing and interaction patterns from 2018. This dataset provides real-world examples of user behavior data commonly found in tech companies. It's ideal for learning web analytics techniques and understanding how users navigate e-commerce sites.",
    "use_cases": [
      "Analyzing user journey patterns to optimize website conversion funnels",
      "Building recommendation systems based on historical browsing behavior"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "clickstream data for ecommerce analysis",
      "Alibaba user behavior dataset",
      "real world web analytics data",
      "ecommerce clickstream dataset download"
    ]
  },
  {
    "name": "Alibaba Cloud Theme",
    "description": "Themed dataset related to Alibaba Cloud services",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/9716",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cloud",
      "Alibaba",
      "themed"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "data-visualization"
    ],
    "topic_tags": [
      "cloud-computing",
      "e-commerce-data",
      "alibaba",
      "dataset",
      "business-analytics"
    ],
    "summary": "A themed dataset containing information about Alibaba Cloud services and their usage patterns. This dataset is suitable for learning cloud service analytics and exploring e-commerce infrastructure data. It provides real-world examples for practicing data analysis on cloud computing metrics.",
    "use_cases": [
      "Analyzing cloud service adoption patterns for market research",
      "Building dashboards to visualize cloud infrastructure usage trends"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Alibaba Cloud dataset for analysis",
      "cloud computing data for practice",
      "e-commerce infrastructure dataset",
      "themed dataset Alibaba services"
    ]
  },
  {
    "name": "Alibaba Ads Dataset",
    "description": "Advertising dataset from Alibaba for ad targeting and prediction",
    "category": "Advertising",
    "url": "https://tianchi.aliyun.com/dataset/148347",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "targeting",
      "Alibaba"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "click-through-rate-modeling",
      "feature-engineering"
    ],
    "topic_tags": [
      "advertising-data",
      "click-prediction",
      "user-behavior",
      "dataset",
      "alibaba"
    ],
    "summary": "Large-scale advertising dataset from Alibaba containing user interactions, ad features, and click/conversion data for training recommendation and targeting models. The dataset is commonly used for benchmarking click-through rate prediction algorithms and studying user behavior patterns in e-commerce advertising. It provides real-world scale and complexity typical of modern ad platforms.",
    "use_cases": [
      "Training CTR prediction models for ad targeting optimization",
      "Benchmarking recommendation algorithms against industry-scale data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "alibaba advertising dataset for click prediction",
      "large scale ad targeting training data",
      "CTR prediction benchmark datasets",
      "alibaba user behavior advertising data"
    ]
  },
  {
    "name": "Alibaba User Behavior 2018",
    "description": "649M user interactions (clicks, carts, buys) on 25M items",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "user behavior",
      "large-scale",
      "interactions"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-preprocessing"
    ],
    "topic_tags": [
      "user-behavior",
      "e-commerce",
      "clickstream",
      "large-scale-data",
      "recommendation-systems"
    ],
    "summary": "Large-scale dataset containing 649 million user interactions across clicks, cart additions, and purchases on 25 million items from Alibaba's e-commerce platform. This comprehensive behavioral data captures real user journeys and purchasing patterns at massive scale. Ideal for learning recommendation systems, user segmentation, and conversion funnel analysis on realistic industry data.",
    "use_cases": [
      "Building recommendation algorithms to predict user purchase behavior based on browsing and cart patterns",
      "Analyzing conversion funnels to identify drop-off points between clicks, cart additions, and final purchases"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "large scale user behavior dataset for recommendation systems",
      "e-commerce clickstream data with purchases",
      "alibaba user interaction dataset",
      "real world data for learning recommender systems"
    ]
  },
  {
    "name": "Alibaba Personalized Re-Ranking",
    "description": "Mobile shopping user click data on recommended items",
    "category": "E-Commerce",
    "url": "http://yongfeng.me/dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "re-ranking",
      "personalization",
      "recommendations"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "recommender-systems",
      "click-through-rate-modeling"
    ],
    "topic_tags": [
      "re-ranking",
      "personalization",
      "e-commerce",
      "click-data",
      "alibaba"
    ],
    "summary": "Real-world dataset from Alibaba's mobile shopping platform containing user click behavior on recommended items. Used for developing and evaluating personalized re-ranking algorithms that optimize recommendation order based on individual user preferences. Particularly valuable for studying how to improve recommendation systems beyond initial item selection.",
    "use_cases": [
      "Training personalized re-ranking models to optimize recommendation order for individual users",
      "Benchmarking recommendation algorithms against real e-commerce click data"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "alibaba recommendation dataset click data",
      "personalized re-ranking dataset e-commerce",
      "mobile shopping user behavior data",
      "recommendation system evaluation dataset"
    ]
  },
  {
    "name": "Online Shopping Intention",
    "description": "12,330 user sessions with numerical and categorical features for purchase prediction",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/henrysue/online-shoppers-intention",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "purchase prediction",
      "sessions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "logistic-regression"
    ],
    "topic_tags": [
      "purchase-prediction",
      "session-data",
      "classification",
      "e-commerce",
      "customer-behavior"
    ],
    "summary": "A dataset of 12,330 online shopping sessions with features like page views, bounce rates, and visitor types to predict purchase intention. Popular for learning classification techniques and understanding e-commerce customer behavior. Contains both numerical features (session duration, page values) and categorical features (visitor type, month, browser) making it ideal for feature engineering practice.",
    "use_cases": [
      "Building a model to identify high-intent visitors for targeted marketing campaigns",
      "Learning binary classification techniques with a realistic business dataset"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "dataset for predicting online purchase behavior",
      "e-commerce customer intention classification data",
      "beginner friendly purchase prediction dataset",
      "shopping session data with categorical features"
    ]
  },
  {
    "name": "MicroLens",
    "description": "1 billion interactions from 34 million users on 1 million micro-videos",
    "category": "Entertainment & Media",
    "url": "https://github.com/westlake-repl/MicroLens",
    "docs_url": null,
    "github_url": "https://github.com/westlake-repl/MicroLens",
    "tags": [
      "video",
      "micro-video",
      "large-scale",
      "recommendations"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "spark-dataframes"
    ],
    "topic_tags": [
      "micro-video",
      "user-interactions",
      "recommendation-systems",
      "large-scale-data",
      "entertainment"
    ],
    "summary": "MicroLens is a massive dataset containing 1 billion user interactions across 34 million users and 1 million micro-videos, designed for recommendation system research and development. This large-scale entertainment dataset enables researchers and data scientists to build and evaluate video recommendation algorithms at realistic scale. The dataset captures user engagement patterns on short-form video content, making it ideal for studying modern social media consumption behaviors.",
    "use_cases": [
      "Training and benchmarking recommendation algorithms for short-form video platforms like TikTok or Instagram Reels",
      "Analyzing user engagement patterns and content virality in micro-video ecosystems"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale video recommendation dataset",
      "micro video user interaction data",
      "billion scale recommendation system dataset",
      "short form video engagement dataset"
    ]
  },
  {
    "name": "KuaiSAR",
    "description": "5M search actions, 14.6M recommendation events from 25k users",
    "category": "Entertainment & Media",
    "url": "https://kuaisar.github.io/",
    "docs_url": "https://kuaisar.github.io/",
    "github_url": null,
    "tags": [
      "search",
      "recommendations",
      "video",
      "Kuaishou"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "search-behavior",
      "recommendation-systems",
      "user-interactions",
      "video-platform",
      "dataset"
    ],
    "summary": "KuaiSAR is a large-scale dataset containing 5 million search actions and 14.6 million recommendation events from 25,000 users on the Kuaishou video platform. This dataset provides real-world user behavior data for studying search and recommendation system interactions. It's valuable for researchers and practitioners working on understanding user engagement patterns in video streaming platforms.",
    "use_cases": [
      "Analyzing how users transition between search and recommendation behaviors on video platforms",
      "Building baseline models to predict user engagement with recommended vs searched content"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "video platform user behavior dataset",
      "search and recommendation interaction data",
      "Kuaishou user engagement dataset",
      "large scale video streaming dataset"
    ]
  },
  {
    "name": "Amazon Reviews (2023)",
    "description": "571M reviews (1996-2023), 33 categories, 48M items - comprehensive Amazon review dataset",
    "category": "E-Commerce",
    "url": "https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Amazon",
      "large-scale",
      "sentiment"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "JSON-parsing"
    ],
    "topic_tags": [
      "amazon-reviews",
      "sentiment-analysis",
      "e-commerce-data",
      "natural-language-processing",
      "consumer-behavior"
    ],
    "summary": "Massive collection of 571 million Amazon customer reviews spanning 27 years across 33 product categories. This comprehensive dataset enables large-scale analysis of consumer sentiment, product performance, and purchasing patterns. Essential resource for researchers studying e-commerce dynamics, recommendation systems, and natural language processing applications.",
    "use_cases": [
      "Building recommendation systems by analyzing review patterns and user preferences across product categories",
      "Training sentiment analysis models to classify customer satisfaction and predict product success"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Amazon review dataset for sentiment analysis",
      "large scale e-commerce customer feedback data",
      "product recommendation system training data",
      "Amazon reviews dataset 2023 download"
    ]
  },
  {
    "name": "M5Product",
    "description": "5 modalities (image, text, table, video, audio), 6M+ samples for multimodal learning",
    "category": "E-Commerce",
    "url": "https://xiaodongsuper.github.io/M5Product_dataset/index.html",
    "docs_url": "https://xiaodongsuper.github.io/M5Product_dataset/index.html",
    "github_url": null,
    "tags": [
      "multimodal",
      "product data",
      "images",
      "video"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "pytorch-dataloaders",
      "computer-vision-basics",
      "pandas-dataframes"
    ],
    "topic_tags": [
      "multimodal-learning",
      "e-commerce-data",
      "product-datasets",
      "computer-vision",
      "cross-modal"
    ],
    "summary": "M5Product is a large-scale multimodal dataset containing 6M+ product samples across 5 modalities: images, text descriptions, structured tables, videos, and audio. It's designed for researchers and practitioners working on multimodal machine learning in e-commerce contexts. The dataset enables training and evaluation of models that can understand and reason across different types of product information simultaneously.",
    "use_cases": [
      "Training multimodal product recommendation systems that combine visual features with textual descriptions",
      "Building cross-modal search engines where users can find products using text queries matched against images and videos"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "multimodal product dataset for e-commerce",
      "large scale dataset with images text and video",
      "M5Product dataset download",
      "multimodal learning datasets"
    ]
  },
  {
    "name": "Tmall Reviews",
    "description": "Product reviews from Tmall (Alibaba's B2C platform)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/140281",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Tmall",
      "China",
      "B2C"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "chinese-language-basics"
    ],
    "topic_tags": [
      "product-reviews",
      "chinese-ecommerce",
      "sentiment-analysis",
      "consumer-behavior",
      "text-data"
    ],
    "summary": "A dataset containing product reviews from Tmall, Alibaba's business-to-consumer e-commerce platform in China. This dataset provides insights into Chinese consumer behavior, product sentiment, and purchasing patterns. It's valuable for researchers studying e-commerce dynamics, cross-cultural consumer preferences, and Chinese market analysis.",
    "use_cases": [
      "Analyzing sentiment patterns of Chinese consumers across different product categories",
      "Training recommendation systems for Chinese e-commerce platforms"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Chinese e-commerce review data",
      "Tmall product reviews dataset",
      "Alibaba consumer sentiment data",
      "Chinese B2C platform reviews"
    ]
  },
  {
    "name": "Home Depot Product Search",
    "description": "Human-rated relevance scores (1-3) for search terms and products",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/thedevastator/the-home-depot-products-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search relevance",
      "retail",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-ML-evaluation",
      "data-cleaning"
    ],
    "topic_tags": [
      "search-relevance",
      "e-commerce",
      "ranking-metrics",
      "retail-data",
      "kaggle-dataset"
    ],
    "summary": "This dataset contains human-annotated relevance scores (1-3) for search query-product pairs from Home Depot's e-commerce platform. It's commonly used for learning search ranking and information retrieval concepts in retail contexts. The dataset provides a practical foundation for understanding how search relevance is measured and optimized in real e-commerce systems.",
    "use_cases": [
      "Training a learning-to-rank model for product search results",
      "Evaluating search algorithm performance using NDCG and other ranking metrics"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Home Depot search relevance dataset",
      "e-commerce product ranking training data",
      "retail search query relevance scores",
      "Kaggle dataset for learning to rank"
    ]
  },
  {
    "name": "Innerwear Data",
    "description": "Data scraped from Victoria's Secret and other innerwear retailers",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "retail",
      "scraped data"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "web-scraping-basics",
      "data-cleaning"
    ],
    "topic_tags": [
      "fashion-retail",
      "scraped-data",
      "product-catalog",
      "e-commerce",
      "apparel"
    ],
    "summary": "A dataset containing product information scraped from Victoria's Secret and other innerwear retailers. The data likely includes product names, prices, descriptions, sizes, and other catalog details useful for retail analytics. This type of scraped retail data is commonly used for competitive analysis and market research in the fashion industry.",
    "use_cases": [
      "Analyzing pricing strategies across innerwear brands and competitors",
      "Building recommendation systems for fashion e-commerce platforms"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "fashion retail scraped data",
      "Victoria's Secret product dataset",
      "innerwear pricing analysis data",
      "e-commerce fashion catalog data"
    ]
  },
  {
    "name": "Flipkart Products",
    "description": "Product information scraped from Flipkart e-commerce platform",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/PromptCloudHQ/flipkart-products",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "products",
      "India",
      "e-commerce"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "data-cleaning"
    ],
    "topic_tags": [
      "e-commerce-data",
      "product-catalog",
      "indian-market",
      "web-scraping",
      "retail-analytics"
    ],
    "summary": "Product information dataset scraped from Flipkart, one of India's largest e-commerce platforms. Contains product details like prices, ratings, categories, and descriptions. Useful for market research, pricing analysis, and understanding Indian e-commerce trends.",
    "use_cases": [
      "Analyzing pricing strategies and competitive positioning across product categories in Indian e-commerce",
      "Building recommendation systems or price prediction models using product features and customer ratings"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Flipkart product dataset for pricing analysis",
      "Indian e-commerce data for market research",
      "product catalog data with ratings and prices",
      "Flipkart scraped data for recommendation systems"
    ]
  },
  {
    "name": "Stanford Amazon/Beer",
    "description": "Amazon product data and BeerAdvocate reviews from Stanford SNAP",
    "category": "Entertainment & Media",
    "url": "https://snap.stanford.edu/data/#amazon",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Stanford",
      "beer",
      "Amazon"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-statistics",
      "data-cleaning"
    ],
    "topic_tags": [
      "product-reviews",
      "sentiment-analysis",
      "recommendation-systems",
      "e-commerce",
      "text-data"
    ],
    "summary": "Large-scale dataset containing Amazon product metadata and BeerAdvocate user reviews, curated by Stanford's SNAP research group. The dataset includes product information, user ratings, review text, and temporal data spanning multiple years. It's commonly used for learning recommendation systems, sentiment analysis, and exploring consumer behavior patterns in e-commerce settings.",
    "use_cases": [
      "Building a product recommendation system using collaborative filtering on beer ratings",
      "Analyzing sentiment trends in product reviews to understand consumer preferences over time"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Amazon product review dataset for recommendation systems",
      "beer review data for sentiment analysis",
      "Stanford SNAP datasets for e-commerce research",
      "product rating data for collaborative filtering tutorial"
    ]
  },
  {
    "name": "Metacritic Video Games",
    "description": "Video game reviews and metadata from Metacritic",
    "category": "Entertainment & Media",
    "url": "https://tianchi.aliyun.com/dataset/144719",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "video games",
      "reviews",
      "ratings"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "gaming-data",
      "review-analysis",
      "metacritic",
      "entertainment-analytics",
      "ratings-data"
    ],
    "summary": "A comprehensive dataset containing video game reviews, ratings, and metadata scraped from Metacritic. This dataset includes critic scores, user ratings, game metadata, and review text, making it ideal for learning data analysis fundamentals in an engaging entertainment context. Perfect for beginners to practice exploratory data analysis, visualization, and basic statistical analysis on real-world review data.",
    "use_cases": [
      "Analyzing factors that influence game ratings and commercial success",
      "Building recommendation systems based on user preferences and critic scores"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "video game ratings dataset",
      "metacritic game reviews data",
      "gaming industry analysis dataset",
      "video game recommendation system data"
    ]
  },
  {
    "name": "Goodreads",
    "description": "Book information and user reviews from Goodreads platform",
    "category": "Entertainment & Media",
    "url": "https://mengtingwan.github.io/data/goodreads.html#datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "books",
      "reviews",
      "recommendations"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "data-visualization"
    ],
    "topic_tags": [
      "book-data",
      "recommendation-systems",
      "user-ratings",
      "text-analysis",
      "social-networks"
    ],
    "summary": "A comprehensive dataset containing book metadata, user ratings, and reviews from the Goodreads social reading platform. This dataset is commonly used for building recommendation systems, analyzing reading patterns, and studying user behavior in social media contexts. It provides rich text data alongside numerical ratings, making it ideal for both collaborative filtering and content-based recommendation approaches.",
    "use_cases": [
      "Building a book recommendation engine using collaborative filtering on user ratings",
      "Analyzing sentiment patterns in book reviews to predict commercial success"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "book recommendation dataset with user ratings",
      "goodreads data for recommendation system project",
      "dataset with book reviews and ratings for NLP",
      "social reading platform data for collaborative filtering"
    ]
  },
  {
    "name": "Walmart (M5)",
    "description": "Hierarchical sales data for 3,049 products across 10 stores",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/m5-forecasting-accuracy",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "forecasting",
      "hierarchical",
      "Walmart",
      "M5 competition"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "time-series-forecasting",
      "python-pandas",
      "hierarchical-modeling"
    ],
    "topic_tags": [
      "time-series",
      "retail-forecasting",
      "hierarchical-data",
      "competition-dataset",
      "walmart"
    ],
    "summary": "The Walmart M5 dataset contains daily sales data for 3,049 products across 10 stores, organized in a hierarchical structure by state, store, category, and item. This dataset was featured in the M5 forecasting competition and is widely used for benchmarking hierarchical time series forecasting methods. It includes both sales quantities and pricing information, making it ideal for demand forecasting research and retail analytics applications.",
    "use_cases": [
      "Developing hierarchical forecasting models that predict sales at multiple aggregation levels (store, category, item)",
      "Benchmarking time series forecasting algorithms against competition baselines for retail demand prediction"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "hierarchical sales forecasting dataset",
      "Walmart M5 competition data",
      "retail demand forecasting benchmark dataset",
      "time series data with store hierarchy"
    ]
  },
  {
    "name": "Ecuador Grocery (Favorita)",
    "description": "Unit sales data with store/item metadata and oil prices from Ecuador",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "sales forecasting",
      "Ecuador",
      "Kaggle"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "time-series-forecasting",
      "retail-analytics",
      "kaggle-dataset",
      "sales-prediction",
      "grocery-data"
    ],
    "summary": "Complete grocery sales dataset from Ecuador's Favorita chain with daily unit sales across multiple stores and product categories, plus external factors like oil prices. Popular Kaggle competition dataset that's ideal for learning time series forecasting and retail analytics. Includes rich metadata on stores, items, promotions, and holidays making it perfect for feature engineering practice.",
    "use_cases": [
      "Learning time series forecasting techniques on real retail data with multiple stores and products",
      "Building demand forecasting models that incorporate external economic indicators and promotional effects"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "grocery store sales forecasting dataset",
      "Ecuador Favorita sales data for time series",
      "retail demand forecasting practice dataset",
      "Kaggle grocery sales data with promotions"
    ]
  },
  {
    "name": "Ukraine eCommerce (Fozzy)",
    "description": "E-commerce sales data from Fozzy Group retail chain in Ukraine",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Ukraine",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "ecommerce-data",
      "retail-analytics",
      "sales-forecasting",
      "customer-behavior",
      "ukraine-economy"
    ],
    "summary": "E-commerce sales data from Fozzy Group, one of Ukraine's largest retail chains, providing transaction-level records from their grocery and supermarket operations. This dataset offers insights into Ukrainian consumer behavior, seasonal patterns, and retail performance metrics. Ideal for learning retail analytics fundamentals and exploring Eastern European market dynamics.",
    "use_cases": [
      "Analyzing seasonal demand patterns for grocery products in Ukrainian markets",
      "Building customer segmentation models for Eastern European retail chains"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Ukraine retail sales data",
      "grocery store transaction dataset",
      "Eastern European ecommerce data",
      "Fozzy Group sales analytics dataset"
    ]
  },
  {
    "name": "Office Supplies (DMDA 2023)",
    "description": "Office supply sales for DMDA 2023 workshop challenge",
    "category": "Grocery & Supermarkets",
    "url": "https://sites.google.com/view/dmdaworkshop2023/data-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "office supplies",
      "forecasting",
      "workshop"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "time-series-forecasting",
      "retail-data",
      "workshop-dataset",
      "sales-prediction",
      "demand-planning"
    ],
    "summary": "A workshop dataset containing office supply sales data designed for the DMDA 2023 forecasting challenge. This beginner-friendly dataset provides clean sales transactions that are ideal for learning time series forecasting techniques and demand prediction methods. Perfect for practicing forecasting workflows and comparing different prediction models.",
    "use_cases": [
      "Learning time series forecasting methods on clean retail data",
      "Benchmarking forecasting algorithms in a workshop or classroom setting"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "office supplies sales forecasting dataset",
      "beginner time series data for practice",
      "DMDA workshop forecasting challenge data",
      "retail sales dataset for learning forecasting"
    ]
  },
  {
    "name": "Brazilian Drugs (ANVISA)",
    "description": "Sales data for controlled substances reported by ANVISA",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tiagoacardoso/venda-medicamentos-controlados-anvisa",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Brazil",
      "regulated"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "SQL-basics"
    ],
    "topic_tags": [
      "pharmaceuticals",
      "Brazil",
      "regulatory-data",
      "sales-data",
      "controlled-substances"
    ],
    "summary": "Sales data for controlled substances regulated by Brazil's National Health Surveillance Agency (ANVISA). This dataset provides transaction-level information on pharmaceutical sales, useful for studying drug market dynamics, regulatory compliance, and public health patterns. Researchers and analysts can examine prescription trends, market concentration, and regional distribution patterns.",
    "use_cases": [
      "Analyzing prescription drug market concentration and pricing patterns in Brazil",
      "Studying regional variations in controlled substance usage for public health research"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Brazil pharmaceutical sales data",
      "ANVISA controlled substances dataset",
      "prescription drug market data Brazil",
      "Brazilian regulatory pharmaceutical data"
    ]
  },
  {
    "name": "Indian Sales",
    "description": "Sales forecasting dataset for small basket items in India",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/girishvutukuri/sales-forecasting-for-small-basket",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "India",
      "forecasting",
      "retail"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "scikit-learn"
    ],
    "topic_tags": [
      "sales-forecasting",
      "retail-analytics",
      "indian-market",
      "time-series",
      "grocery-data"
    ],
    "summary": "A sales forecasting dataset containing transaction data for small basket grocery items in the Indian retail market. This dataset is ideal for learning time series forecasting techniques and understanding retail patterns in emerging markets. Perfect for practicing demand prediction models and seasonal trend analysis.",
    "use_cases": [
      "Building demand forecasting models for grocery retailers to optimize inventory management",
      "Analyzing seasonal purchasing patterns and consumer behavior in Indian retail markets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "indian grocery sales forecasting dataset",
      "retail sales data for demand prediction",
      "small basket items sales data india",
      "grocery store forecasting practice dataset"
    ]
  },
  {
    "name": "Walmart Sales",
    "description": "General sales data including CPI and unemployment rate",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/yasserh/walmart-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Walmart",
      "macro",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-regression",
      "time-series-basics"
    ],
    "topic_tags": [
      "retail-analytics",
      "macroeconomic-data",
      "time-series",
      "walmart",
      "sales-forecasting"
    ],
    "summary": "Historical sales data from Walmart stores combined with macroeconomic indicators like Consumer Price Index and unemployment rates. This dataset is commonly used for retail analytics and understanding how economic conditions impact consumer spending patterns. It provides a clean foundation for learning time series analysis and econometric modeling in a retail context.",
    "use_cases": [
      "Analyzing how unemployment rates correlate with grocery sales patterns",
      "Building sales forecasting models that incorporate macroeconomic variables"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "walmart sales data with economic indicators",
      "retail sales dataset with CPI unemployment",
      "grocery store sales macroeconomic analysis",
      "beginner friendly sales forecasting dataset"
    ]
  },
  {
    "name": "Montgomery Liquor",
    "description": "Warehouse and retail liquor sales from Montgomery County, Maryland",
    "category": "Grocery & Supermarkets",
    "url": "https://data.montgomerycountymd.gov/Community-Recreation/Warehouse-and-Retail-Sales/v76h-r7br",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "liquor",
      "retail",
      "government data"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "retail-analytics",
      "government-data",
      "sales-forecasting",
      "inventory-management",
      "alcohol-industry"
    ],
    "summary": "Government-collected sales data from liquor stores and warehouses in Montgomery County, Maryland. This clean, structured dataset is ideal for learning retail analytics fundamentals and understanding consumer purchasing patterns. Perfect for practicing time series analysis, seasonal trend identification, and basic forecasting techniques.",
    "use_cases": [
      "Analyzing seasonal alcohol sales patterns to optimize inventory management",
      "Building demand forecasting models for retail liquor store chains"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "liquor sales dataset for retail analysis",
      "government retail data Maryland alcohol",
      "seasonal sales patterns dataset beginner",
      "Montgomery County liquor sales data"
    ]
  },
  {
    "name": "Iowa Liquor",
    "description": "Monthly Class E liquor sales data with volume and pricing from Iowa",
    "category": "Grocery & Supermarkets",
    "url": "https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "liquor",
      "government data",
      "Iowa"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "retail-analytics",
      "government-data",
      "time-series",
      "pricing-data",
      "consumer-goods"
    ],
    "summary": "Monthly liquor sales dataset from Iowa containing transaction-level data with volume, pricing, and retailer information for Class E liquor licenses. This government dataset is commonly used for retail analytics, pricing studies, and demand forecasting exercises. The clean structure and comprehensive coverage make it ideal for learning data analysis techniques on real commercial data.",
    "use_cases": [
      "Analyzing seasonal demand patterns and price elasticity for alcoholic beverages",
      "Building predictive models for retail inventory management and sales forecasting"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Iowa liquor sales data for pricing analysis",
      "government retail dataset for demand forecasting",
      "clean dataset for learning time series analysis",
      "alcohol sales data with volume and pricing"
    ]
  },
  {
    "name": "Brazil Medical",
    "description": "Medicine sales data in Brazil",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tgomesjuliana/brazil-medicine-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Brazil",
      "healthcare"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "pharmaceuticals",
      "brazil-market",
      "sales-data",
      "healthcare-economics",
      "retail-analytics"
    ],
    "summary": "A dataset containing pharmaceutical sales transactions from Brazilian pharmacies and medical retailers. This data provides insights into medicine purchasing patterns, regional healthcare demand, and pharmaceutical market dynamics in Brazil. It's suitable for market analysis, demand forecasting, and understanding healthcare access patterns across Brazilian regions.",
    "use_cases": [
      "Analyzing regional differences in pharmaceutical demand to inform market entry strategies",
      "Building demand forecasting models for medicine inventory management in Brazilian retail chains"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Brazilian pharmaceutical sales data",
      "medicine sales dataset Brazil",
      "healthcare retail data for market analysis",
      "pharmaceutical demand forecasting dataset"
    ]
  },
  {
    "name": "Store Item Demand",
    "description": "50 items across 10 different stores over 5 years",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/demand-forecasting-kernels-only",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "demand forecasting",
      "Kaggle competition",
      "time series"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "demand-forecasting",
      "time-series",
      "retail-analytics",
      "kaggle-dataset"
    ],
    "summary": "A clean dataset containing daily sales data for 50 products across 10 stores over 5 years, originally from a Kaggle forecasting competition. Perfect for learning time series forecasting techniques and understanding retail demand patterns. The dataset's structure makes it ideal for comparing different forecasting methods and understanding seasonality in grocery sales.",
    "use_cases": [
      "Learning to build ARIMA or Prophet models for demand forecasting",
      "Comparing forecasting accuracy across different product categories and stores"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "beginner time series forecasting dataset",
      "retail demand forecasting practice data",
      "kaggle store sales forecasting dataset",
      "grocery store demand prediction data"
    ]
  },
  {
    "name": "Italian Grocers",
    "description": "Receipt-level sales data from Italian grocery stores",
    "category": "Grocery & Supermarkets",
    "url": "https://data.mendeley.com/datasets/s8dgbs3rng/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Italy",
      "receipts"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "retail-metrics",
      "time-series-analysis"
    ],
    "topic_tags": [
      "grocery-retail",
      "consumer-behavior",
      "sales-data",
      "receipts",
      "italy"
    ],
    "summary": "Receipt-level transaction data from Italian grocery stores containing detailed purchase information. This dataset is valuable for retail analysts and researchers studying consumer purchasing patterns in European grocery markets. The granular receipt data enables analysis of basket composition, shopping frequency, and seasonal trends.",
    "use_cases": [
      "Analyzing market basket composition and cross-selling opportunities for Italian grocery retailers",
      "Building demand forecasting models for specific product categories in European grocery chains"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Italian grocery store sales data",
      "receipt level transaction data Europe",
      "grocery shopping patterns dataset Italy",
      "supermarket consumer behavior data"
    ]
  },
  {
    "name": "Tesco Grocery 1.0",
    "description": "Grocery purchases from Tesco stores via loyalty cards",
    "category": "Grocery & Supermarkets",
    "url": "https://figshare.com/collections/Tesco_Grocery_1_0/4769354",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "loyalty cards",
      "UK",
      "Tesco"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "grocery-data",
      "loyalty-cards",
      "consumer-behavior",
      "retail-analytics",
      "UK-market"
    ],
    "summary": "This dataset contains grocery purchase transactions from Tesco stores collected through their loyalty card program. It provides rich consumer behavior data including product choices, spending patterns, and shopping frequency across UK locations. The dataset is ideal for learning retail analytics, customer segmentation, and market basket analysis techniques.",
    "use_cases": [
      "Analyzing customer purchase patterns to identify high-value segments for targeted marketing campaigns",
      "Building recommendation systems to suggest complementary products based on shopping basket analysis"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "grocery store purchase data UK",
      "Tesco loyalty card dataset consumer behavior",
      "retail transaction data for market basket analysis",
      "supermarket customer shopping patterns dataset"
    ]
  },
  {
    "name": "Rossmann Store Sales",
    "description": "1,115 Rossmann drug stores historical sales data",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/rossmann-store-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Germany",
      "Kaggle competition"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "linear-regression"
    ],
    "topic_tags": [
      "retail-analytics",
      "sales-forecasting",
      "time-series",
      "kaggle-dataset",
      "germany"
    ],
    "summary": "Historical daily sales data from 1,115 Rossmann drugstore locations in Germany, including store features, promotions, and external factors like holidays. This popular Kaggle competition dataset is widely used for learning sales forecasting and retail analytics. Contains rich contextual information making it ideal for exploring how promotions, seasonality, and store characteristics impact sales performance.",
    "use_cases": [
      "Learning time series forecasting techniques on retail sales data",
      "Building promotional impact analysis models for drugstore chains"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "retail sales forecasting dataset",
      "Rossmann store sales data",
      "German drugstore sales dataset",
      "Kaggle retail competition data"
    ]
  },
  {
    "name": "Polish Grocery",
    "description": "Yearly sales data (2018) from Polish grocery shop",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/agatii/total-sale-2018-yearly-data-of-grocery-shop",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Poland",
      "yearly data"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "grocery-retail",
      "sales-data",
      "poland",
      "time-series",
      "retail-analytics"
    ],
    "summary": "A complete year of sales transactions from a Polish grocery store in 2018, providing real-world retail data for analysis. This dataset is ideal for learning fundamental data analysis techniques on authentic business data. Perfect for practicing exploratory data analysis, sales forecasting, and understanding retail patterns.",
    "use_cases": [
      "Learning retail analytics fundamentals with real transaction data",
      "Building sales forecasting models for small grocery businesses"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "polish grocery store sales data",
      "retail transaction dataset for beginners",
      "grocery sales data 2018",
      "european retail analytics dataset"
    ]
  },
  {
    "name": "UK Gift Shop (Online Retail)",
    "description": "Online retail transactions (2010-2011) from UK gift retailer",
    "category": "Grocery & Supermarkets",
    "url": "http://archive.ics.uci.edu/dataset/352/online+retail",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "UK",
      "UCI",
      "transactions"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "basic-SQL"
    ],
    "topic_tags": [
      "retail-analytics",
      "customer-segmentation",
      "transaction-data",
      "e-commerce",
      "RFM-analysis"
    ],
    "summary": "Classic dataset of online retail transactions from a UK gift shop covering 2010-2011, containing customer purchases, product details, and transaction timestamps. Widely used for learning customer analytics, market basket analysis, and retail forecasting techniques. Perfect for practicing data cleaning and exploratory analysis on real-world e-commerce data.",
    "use_cases": [
      "Learning customer segmentation and RFM analysis techniques",
      "Building recommendation systems for retail products"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "UK retail dataset for customer analysis",
      "online transactions data for market basket analysis",
      "beginner friendly e-commerce dataset",
      "retail data for RFM segmentation practice"
    ]
  },
  {
    "name": "Turkish Drugs",
    "description": "Drug sales data from Turkey",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/emrahaydemr/drug-sales-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Turkey",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-analysis",
      "data-visualization"
    ],
    "topic_tags": [
      "pharmaceutical-sales",
      "turkey-market",
      "retail-data",
      "time-series",
      "healthcare"
    ],
    "summary": "This dataset contains drug sales data from the Turkish pharmaceutical market. It provides insights into medication purchasing patterns and market dynamics in Turkey's healthcare sector. Researchers and analysts can use this data to study pharmaceutical market trends, seasonal patterns, and consumer behavior in the Turkish healthcare system.",
    "use_cases": [
      "Analyzing seasonal patterns in pharmaceutical sales to optimize inventory management",
      "Studying market penetration of different drug categories across Turkish regions"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Turkish pharmaceutical sales data",
      "drug market data Turkey",
      "healthcare sales dataset",
      "Turkish medicine purchase patterns"
    ]
  },
  {
    "name": "NYC Shopping",
    "description": "Large sales dataset from New York City retail",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/pigment/big-sales-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NYC",
      "retail",
      "large-scale"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "retail-data",
      "sales-analysis",
      "consumer-behavior",
      "NYC-data",
      "tabular-data"
    ],
    "summary": "A comprehensive sales dataset from New York City retail establishments, focusing on grocery and supermarket transactions. This dataset provides rich transactional data ideal for learning retail analytics fundamentals and consumer behavior patterns. Perfect for beginners to practice data manipulation, visualization, and basic statistical analysis on real-world retail data.",
    "use_cases": [
      "Learning retail sales forecasting by analyzing seasonal patterns in NYC grocery purchases",
      "Building customer segmentation models to understand shopping behavior across different NYC neighborhoods"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NYC retail sales data for analysis",
      "grocery store transaction dataset",
      "New York shopping behavior data",
      "retail sales data for beginners"
    ]
  },
  {
    "name": "Mexican Grocery",
    "description": "Data from a Mexican grocery store",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/martinezjosegpe/grocery-store",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Mexico",
      "retail"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "grocery-data",
      "retail-analytics",
      "mexico",
      "consumer-behavior",
      "sales-data"
    ],
    "summary": "This dataset contains transactional and operational data from a Mexican grocery store, providing insights into consumer purchasing patterns, product performance, and retail operations. It's ideal for learning retail analytics fundamentals and exploring cross-cultural consumer behavior. The data can be used to practice basic data analysis techniques on real-world retail scenarios.",
    "use_cases": [
      "Analyzing seasonal purchasing patterns and product demand forecasting for a Mexican retail chain",
      "Comparing consumer behavior between Mexican and US grocery markets for market entry strategy"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Mexican grocery store sales data",
      "retail analytics dataset Mexico",
      "grocery shopping patterns dataset",
      "consumer behavior data Mexican market"
    ]
  },
  {
    "name": "Vietnam Supermarket",
    "description": "Sales and inventory snapshot data from Vietnamese supermarket",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tienanh2003/sales-and-inventory-snapshot-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "supermarket",
      "Vietnam",
      "inventory"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "retail-data",
      "inventory-management",
      "sales-analysis",
      "emerging-markets",
      "tabular-data"
    ],
    "summary": "Point-in-time sales and inventory data from a Vietnamese supermarket chain, providing insights into Southeast Asian retail patterns. Ideal for learning retail analytics fundamentals and exploring inventory turnover metrics. Contains product-level sales volumes, stock levels, and basic category information across multiple store locations.",
    "use_cases": [
      "Learning retail KPIs like inventory turnover and stockout analysis for portfolio projects",
      "Comparing product performance across different store locations to understand regional preferences"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Vietnamese retail sales data for practice",
      "supermarket inventory dataset for learning",
      "Southeast Asia grocery store data",
      "retail analytics beginner dataset"
    ]
  },
  {
    "name": "Indian Grocery (Flipkart Supermart)",
    "description": "Flipkart Supermart transaction and product details",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/aryansingh95/flipkart-grocery-transaction-and-product-details",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "India",
      "Flipkart"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-cleaning"
    ],
    "topic_tags": [
      "grocery-retail",
      "transaction-data",
      "india-ecommerce",
      "flipkart",
      "consumer-behavior"
    ],
    "summary": "Transaction and product data from Flipkart Supermart's grocery operations in India. This dataset provides real-world e-commerce grocery data for analyzing consumer purchasing patterns, product performance, and market dynamics in the Indian online grocery sector.",
    "use_cases": [
      "Analyzing seasonal demand patterns for grocery products in Indian e-commerce",
      "Building recommendation systems for online grocery shopping platforms"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "flipkart grocery transaction data",
      "indian ecommerce grocery dataset",
      "online supermarket consumer behavior data",
      "flipkart supermart purchase patterns"
    ]
  },
  {
    "name": "Israeli Grocery",
    "description": "Grocery purchase data from Israel",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/arielpazsawicki/kimonaim",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Israel",
      "purchases"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "data-visualization"
    ],
    "topic_tags": [
      "grocery-data",
      "consumer-behavior",
      "retail-analytics",
      "israel",
      "purchase-patterns"
    ],
    "summary": "This dataset contains grocery purchase transaction data from Israeli consumers, providing insights into shopping behaviors and consumption patterns. It's commonly used by retail analysts and economists studying consumer choice and market dynamics. The data can help understand seasonal trends, basket composition, and regional purchasing preferences in the Israeli grocery market.",
    "use_cases": [
      "Analyzing seasonal shopping patterns and holiday effects on grocery purchases",
      "Building market basket analysis models to understand product associations and cross-selling opportunities"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Israeli grocery shopping data",
      "consumer purchase behavior dataset Israel",
      "grocery basket analysis data",
      "retail transaction data Israel"
    ]
  },
  {
    "name": "Brazilian Store Chain",
    "description": "Sales data from Brazilian retail chain",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/marcio486/sales-data-for-a-chain-of-brazilian-stores",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Brazil",
      "chain stores"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "SQL-basics"
    ],
    "topic_tags": [
      "retail-analytics",
      "sales-forecasting",
      "consumer-behavior",
      "geographic-analysis",
      "time-series"
    ],
    "summary": "This dataset contains transactional sales data from a Brazilian retail chain, including product categories, store locations, and temporal patterns. It's ideal for learning retail analytics fundamentals and exploring consumer purchasing behavior across different regions. The data enables analysis of seasonality, regional preferences, and store performance metrics.",
    "use_cases": [
      "Analyzing seasonal demand patterns to optimize inventory management across different store locations",
      "Building customer segmentation models to understand regional purchasing behaviors and preferences"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Brazilian retail sales dataset",
      "grocery store chain data for analysis",
      "retail analytics practice dataset Brazil",
      "supermarket sales data with store locations"
    ]
  },
  {
    "name": "Dominicks Soft Drinks",
    "description": "Weekly scanner data on soft drink purchases from Dominick's Finer Foods",
    "category": "Grocery & Supermarkets",
    "url": "https://www.chicagobooth.edu/research/kilts/research-data/dominicks",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "scanner data",
      "soft drinks",
      "Chicago Booth"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-econometrics",
      "data-visualization"
    ],
    "topic_tags": [
      "scanner-data",
      "consumer-behavior",
      "pricing-analysis",
      "retail-data",
      "grocery"
    ],
    "summary": "Weekly scanner data capturing soft drink purchases from Dominick's Finer Foods, a Chicago-area grocery chain. This classic dataset is widely used in marketing and economics research to study consumer purchasing behavior, price elasticity, and promotional effects. The data includes product-level sales, prices, and promotional information across multiple store locations.",
    "use_cases": [
      "Analyzing price elasticity of demand for different soft drink brands",
      "Studying the effectiveness of promotional campaigns on consumer purchasing patterns"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "grocery store scanner data for demand analysis",
      "soft drink sales data with pricing information",
      "retail transaction data for economics research",
      "Dominicks dataset consumer behavior analysis"
    ]
  },
  {
    "name": "Hashed Multimodal Banking",
    "description": "Banking transactions and product purchases with hashed identifiers",
    "category": "Financial Services",
    "url": "https://github.com/dzhambo/mbd",
    "docs_url": null,
    "github_url": "https://github.com/dzhambo/mbd",
    "tags": [
      "banking",
      "transactions",
      "privacy-preserving"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "data-hashing"
    ],
    "topic_tags": [
      "banking-data",
      "privacy-preserving",
      "transaction-analysis",
      "multimodal-data"
    ],
    "summary": "A banking dataset containing transaction records and product purchase data with privacy-preserving hashed customer and merchant identifiers. The multimodal nature combines structured transaction data with product information, making it suitable for financial analytics while protecting sensitive customer information. Commonly used by data scientists in fintech and researchers studying consumer banking behavior.",
    "use_cases": [
      "Building fraud detection models without exposing customer identities",
      "Analyzing customer purchase patterns across different banking products"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "banking transaction dataset with privacy protection",
      "hashed customer data for fraud detection",
      "multimodal financial services dataset",
      "privacy-preserving banking analytics data"
    ]
  },
  {
    "name": "SEC EDGAR Filings",
    "description": "21M+ public company filings since 1994. 10-Ks, 8-Ks, proxy statements. Full text + structured XBRL data",
    "category": "Financial Services",
    "url": "https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent",
    "docs_url": "https://www.sec.gov/os/accessing-edgar-data",
    "github_url": "https://github.com/datasets/edgar",
    "tags": [
      "SEC",
      "corporate filings",
      "10-K",
      "disclosure",
      "large-scale"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "text-processing"
    ],
    "topic_tags": [
      "SEC-filings",
      "financial-data",
      "corporate-disclosure",
      "text-mining",
      "regulatory-data"
    ],
    "summary": "Comprehensive database of SEC corporate filings containing 21+ million documents from public companies since 1994. Includes annual reports (10-Ks), quarterly reports (10-Qs), current reports (8-Ks), and proxy statements in both full text and structured XBRL format. Essential resource for financial analysis, corporate research, and regulatory compliance studies.",
    "use_cases": [
      "Analyzing executive compensation trends across industries using proxy statement data",
      "Building models to predict stock price movements based on 10-K risk factor disclosures"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "SEC filing data for financial analysis",
      "corporate 10-K filings dataset",
      "public company disclosure documents",
      "XBRL financial data for research"
    ]
  },
  {
    "name": "Indonesian Fashion",
    "description": "Fashion items for image classification tasks from Indonesia",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/latifahhukma/fashion-campus",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "image classification",
      "Indonesia"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-opencv",
      "convolutional-neural-networks",
      "image-preprocessing"
    ],
    "topic_tags": [
      "image-classification",
      "fashion-dataset",
      "indonesia",
      "computer-vision",
      "apparel-recognition"
    ],
    "summary": "A curated dataset of Indonesian fashion items designed for image classification machine learning tasks. The dataset provides labeled images of traditional and contemporary clothing items from Indonesia, making it valuable for computer vision practitioners working on fashion recognition systems. It serves as both a learning resource for beginners and a practical dataset for building fashion recommendation or categorization applications.",
    "use_cases": [
      "Building an e-commerce clothing categorization system for Southeast Asian markets",
      "Training a fashion recommendation engine that understands regional clothing preferences"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Indonesian fashion image dataset for classification",
      "fashion apparel dataset from Indonesia",
      "image classification dataset for clothing items",
      "Southeast Asian fashion dataset for computer vision"
    ]
  },
  {
    "name": "Diginetica Fashion",
    "description": "Clickstream and purchase data for fashion e-commerce",
    "category": "Fashion & Apparel",
    "url": "https://competitions.codalab.org/competitions/11161",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "clickstream",
      "competition"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "session-analysis"
    ],
    "topic_tags": [
      "clickstream-data",
      "e-commerce-analytics",
      "fashion-retail",
      "user-behavior",
      "session-data"
    ],
    "summary": "Diginetica Fashion is a clickstream and purchase dataset from fashion e-commerce containing user interactions, product views, and transaction data. It's commonly used in data science competitions and educational projects for learning e-commerce analytics. The dataset provides real-world examples of user behavior patterns in online fashion retail.",
    "use_cases": [
      "Building recommendation systems for fashion e-commerce platforms",
      "Analyzing user journey patterns from browsing to purchase conversion"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "fashion e-commerce clickstream data",
      "user behavior dataset online retail",
      "diginetica competition dataset",
      "e-commerce session data for analysis"
    ]
  },
  {
    "name": "Dressipi Fashion (RecSys 2022)",
    "description": "Session interactions and item features from styling service",
    "category": "Fashion & Apparel",
    "url": "http://www.recsyschallenge.com/2022/dataset.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "RecSys",
      "styling",
      "sessions"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "session-based-recommendation"
    ],
    "topic_tags": [
      "fashion-recommendation",
      "session-data",
      "RecSys-dataset",
      "styling-interactions",
      "sequential-modeling"
    ],
    "summary": "A dataset from Dressipi's fashion styling service containing user session interactions and detailed item features, released for the RecSys 2022 conference. It captures real-world fashion recommendation scenarios with temporal dynamics and styling context. The dataset is valuable for researchers developing session-based and sequential recommendation algorithms in the fashion domain.",
    "use_cases": [
      "Developing session-based recommendation models for fashion e-commerce platforms",
      "Benchmarking sequential recommendation algorithms on real styling service data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "fashion recommendation dataset with sessions",
      "RecSys 2022 fashion styling data",
      "Dressipi dataset for sequential recommendations",
      "fashion item features dataset for machine learning"
    ]
  },
  {
    "name": "Fashion-MNIST",
    "description": "70,000 28x28 grayscale images of 10 fashion categories from Zalando",
    "category": "Fashion & Apparel",
    "url": "https://github.com/zalandoresearch/fashion-mnist",
    "docs_url": null,
    "github_url": "https://github.com/zalandoresearch/fashion-mnist",
    "tags": [
      "image classification",
      "benchmark",
      "deep learning"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-numpy",
      "convolutional-neural-networks",
      "image-preprocessing"
    ],
    "topic_tags": [
      "image-classification",
      "benchmark-dataset",
      "computer-vision",
      "fashion-retail",
      "deep-learning"
    ],
    "summary": "Fashion-MNIST is a dataset of 70,000 grayscale images showing clothing and accessories across 10 categories, designed as a more challenging replacement for the classic MNIST digit dataset. It's widely used by researchers and practitioners to benchmark image classification algorithms and test computer vision models. The dataset maintains the same format as MNIST but provides more realistic complexity for fashion item recognition tasks.",
    "use_cases": [
      "Testing and comparing different deep learning architectures for image classification before deploying on production fashion datasets",
      "Teaching computer vision concepts to students with a more engaging alternative to handwritten digits"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "fashion mnist dataset download",
      "alternative to mnist for image classification",
      "benchmark dataset for clothing recognition",
      "fashion item classification training data"
    ]
  },
  {
    "name": "BLP US Car Data",
    "description": "Classic dataset (1971-1990) for demand model estimation",
    "category": "Automotive",
    "url": "https://pyblp.readthedocs.io/en/stable/_notebooks/tutorial/blp.html",
    "docs_url": "https://pyblp.readthedocs.io/en/stable/_notebooks/tutorial/blp.html",
    "github_url": null,
    "tags": [
      "demand estimation",
      "BLP",
      "research",
      "classic"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "advanced",
    "prerequisites": [
      "structural-modeling",
      "GMM-estimation",
      "IV-regression"
    ],
    "topic_tags": [
      "demand-estimation",
      "BLP-model",
      "automotive-data",
      "structural-econometrics",
      "dataset"
    ],
    "summary": "The foundational dataset used in Berry, Levinsohn, and Pakes' seminal 1995 paper on demand estimation for differentiated products. Contains US automobile market data from 1971-1990 including prices, quantities, and product characteristics. Essential for learning and implementing BLP demand models in industrial organization research.",
    "use_cases": [
      "Learning to implement BLP demand estimation methods for PhD coursework or research",
      "Benchmarking new demand estimation algorithms against established results"
    ],
    "audience": [
      "Early-PhD",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "BLP automobile dataset download",
      "classic car demand estimation data",
      "Berry Levinsohn Pakes original dataset",
      "auto industry structural model data 1971-1990"
    ]
  },
  {
    "name": "European Car Market",
    "description": "Car information including prices and attributes (1970-1999)",
    "category": "Automotive",
    "url": "https://sites.google.com/site/frankverbo/data-and-software/data-set-on-the-european-car-market",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Europe",
      "prices",
      "IO"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-regression",
      "data-visualization"
    ],
    "topic_tags": [
      "automotive-data",
      "price-analysis",
      "industrial-organization",
      "european-markets",
      "panel-data"
    ],
    "summary": "A comprehensive dataset of European car sales containing vehicle characteristics, pricing, and market information from 1970-1999. This clean, structured dataset is ideal for learning econometric methods and exploring industrial organization concepts. Perfect for analyzing market dynamics, price elasticity, and consumer choice in the automotive sector.",
    "use_cases": [
      "Learning demand estimation and discrete choice modeling with real market data",
      "Analyzing how car features affect pricing and market share over three decades"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "European car prices dataset for econometrics",
      "automotive market data for demand analysis",
      "car sales data 1990s Europe",
      "vehicle pricing dataset for choice modeling"
    ]
  },
  {
    "name": "Russian Car Market",
    "description": "Car sales information in Russia",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/ekibee/car-sales-information",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Russia",
      "sales"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-econometrics"
    ],
    "topic_tags": [
      "automotive-data",
      "market-analysis",
      "russia",
      "sales-data",
      "tabular-dataset"
    ],
    "summary": "A dataset containing car sales information from the Russian automotive market. This dataset is useful for economists and data scientists studying consumer behavior, market dynamics, and pricing patterns in emerging markets. The data can be used to analyze demand patterns, brand preferences, and seasonal trends in car purchases.",
    "use_cases": [
      "Analyzing price elasticity and demand patterns for different car brands in the Russian market",
      "Building predictive models for car sales forecasting based on seasonal and economic factors"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Russian car sales dataset for market analysis",
      "automotive data Russia consumer behavior",
      "car market dataset emerging economies",
      "vehicle sales data econometric analysis"
    ]
  },
  {
    "name": "German Used Cars",
    "description": "Used car listings or sales in Germany",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/gogotchuri/myautogecardetails",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "used cars",
      "Germany",
      "listings"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-regression",
      "data-cleaning"
    ],
    "topic_tags": [
      "automotive-data",
      "pricing-models",
      "german-market",
      "used-cars",
      "consumer-behavior"
    ],
    "summary": "A dataset containing used car listings and sales data from the German automotive market. This dataset is commonly used by data scientists learning pricing models and market analysis techniques. It provides real-world examples of consumer behavior, vehicle depreciation patterns, and market dynamics in one of Europe's largest car markets.",
    "use_cases": [
      "Building price prediction models for used vehicles based on features like mileage, age, and brand",
      "Analyzing depreciation curves and market trends for different car manufacturers in the German market"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "German used car dataset for price prediction",
      "automotive data for learning regression models",
      "used car listings Germany dataset",
      "car depreciation analysis data"
    ]
  },
  {
    "name": "Indian Automobiles (Telangana)",
    "description": "Vehicle sales data for Telangana, India (2023)",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/zubairatha/revving-up-telangana-vehicle-sales-2023",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "vehicles",
      "India",
      "regional sales"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "automotive-data",
      "regional-sales",
      "india-market",
      "vehicle-analytics",
      "sales-dataset"
    ],
    "summary": "Vehicle sales dataset from Telangana state, India covering 2023 transactions and registrations. Useful for analysts studying regional automotive markets, consumer preferences, and sales patterns in emerging economies. Contains structured data suitable for exploratory analysis and visualization projects.",
    "use_cases": [
      "Market research analyst studying regional vehicle preferences and brand performance in Indian states",
      "Junior data scientist practicing exploratory data analysis on real-world sales data"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "vehicle sales data India by state",
      "Telangana car sales dataset 2023",
      "automotive market data regional analysis",
      "Indian vehicle registration data for practice"
    ]
  },
  {
    "name": "Fliggy Travel",
    "description": "Travel-related data from Alibaba's online travel platform",
    "category": "Travel & Hospitality",
    "url": "https://tianchi.aliyun.com/dataset/113649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "travel",
      "Alibaba",
      "bookings"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "travel-data",
      "e-commerce",
      "user-behavior",
      "booking-patterns",
      "alibaba"
    ],
    "summary": "Travel-related dataset from Fliggy, Alibaba's online travel platform containing booking and user interaction data. This dataset provides insights into travel booking patterns, user preferences, and seasonal trends in the Chinese travel market. It's valuable for understanding e-commerce travel platforms and consumer behavior analysis.",
    "use_cases": [
      "Analyzing seasonal travel booking patterns and peak demand periods",
      "Building recommendation systems for hotels and destinations based on user preferences"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "travel booking dataset China",
      "Alibaba Fliggy travel data",
      "e-commerce travel platform dataset",
      "user behavior travel booking data"
    ]
  },
  {
    "name": "Fliggy Transfers",
    "description": "Transfer-related data (flights, ground transport) from Fliggy",
    "category": "Travel & Hospitality",
    "url": "https://tianchi.aliyun.com/dataset/140721",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "travel",
      "transfers",
      "transportation"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "travel-data",
      "transportation-analytics",
      "booking-patterns",
      "mobility-data",
      "hospitality-dataset"
    ],
    "summary": "Fliggy Transfers is a dataset containing transfer-related booking and usage data from Alibaba's travel platform, covering flights and ground transportation services. This dataset is valuable for travel industry analysts and data scientists studying booking patterns, transfer preferences, and transportation network optimization. The data provides insights into customer behavior in the travel and hospitality sector.",
    "use_cases": [
      "Analyzing peak travel seasons and transfer demand patterns for transportation companies",
      "Building recommendation systems for optimal flight-to-ground transport connections"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "travel booking dataset with flight transfers",
      "Fliggy transportation data for demand forecasting",
      "hospitality industry dataset with booking patterns",
      "ground transport and flight connection data"
    ]
  },
  {
    "name": "Expedia Hotel",
    "description": "Hotel booking and search data from Expedia",
    "category": "Travel & Hospitality",
    "url": "https://www.kaggle.com/datasets/vijeetnigam26/expedia-hotel",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hotels",
      "bookings",
      "travel search"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "SQL-basics"
    ],
    "topic_tags": [
      "hotel-bookings",
      "search-behavior",
      "travel-data",
      "conversion-rates",
      "user-sessions"
    ],
    "summary": "Hotel booking and search data from Expedia containing user search sessions, hotel attributes, and booking outcomes. This dataset is commonly used for learning predictive modeling and understanding customer behavior in the travel industry. It provides a rich foundation for exploring conversion optimization and recommendation systems.",
    "use_cases": [
      "Building hotel recommendation systems based on user search patterns",
      "Analyzing conversion rates and identifying factors that drive bookings"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "hotel booking dataset for machine learning",
      "Expedia data for conversion analysis",
      "travel industry dataset with search behavior",
      "hotel recommendation system training data"
    ]
  },
  {
    "name": "Airline Delay",
    "description": "Airline flight delays and carrier information",
    "category": "Transportation & Mobility",
    "url": "https://www.kaggle.com/datasets/sriharshaeedala/airline-delay",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "airlines",
      "delays",
      "transportation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-sql",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "airline-operations",
      "delay-analysis",
      "transportation-data",
      "operational-metrics",
      "time-series"
    ],
    "summary": "A comprehensive dataset containing flight delay information and carrier details for analyzing airline operational performance. This dataset is commonly used by transportation analysts, operations researchers, and data scientists to study patterns in flight delays, carrier efficiency, and seasonal travel trends. It provides rich ground truth data for predictive modeling and operational optimization in the aviation industry.",
    "use_cases": [
      "Building predictive models to forecast flight delays based on carrier, route, and seasonal factors",
      "Conducting comparative analysis of airline carrier performance and operational efficiency metrics"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "flight delay dataset for predictive modeling",
      "airline performance comparison data",
      "transportation delay analysis dataset",
      "aviation operations research data"
    ]
  },
  {
    "name": "NetEase Music (INFORMS)",
    "description": "Data from NetEase Cloud Music for INFORMS competition",
    "category": "Entertainment & Media",
    "url": "https://connect.informs.org/rmp/awards/data-competition",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "streaming",
      "INFORMS",
      "China"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "exploratory-data-analysis",
      "basic-statistics"
    ],
    "topic_tags": [
      "music-streaming",
      "user-behavior",
      "competition-dataset",
      "chinese-market",
      "entertainment-analytics"
    ],
    "summary": "NetEase Cloud Music dataset from an INFORMS competition containing user listening behavior and music metadata from one of China's largest music streaming platforms. The dataset provides insights into music consumption patterns, user preferences, and streaming dynamics in the Chinese market. It's ideal for learning recommendation systems, user segmentation, and music analytics techniques.",
    "use_cases": [
      "Building music recommendation algorithms to predict user listening preferences",
      "Analyzing user engagement patterns to optimize playlist curation strategies"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NetEase music streaming dataset",
      "Chinese music platform data for analysis",
      "INFORMS competition music data",
      "music recommendation system dataset"
    ]
  },
  {
    "name": "Bandcamp Music Sales",
    "description": "Music sales data (digital/physical) from Bandcamp platform",
    "category": "Entertainment & Media",
    "url": "https://components.one/datasets/bandcamp-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "sales",
      "independent artists"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "music-industry",
      "sales-analytics",
      "independent-artists",
      "digital-commerce",
      "creative-economy"
    ],
    "summary": "This dataset contains music sales data from Bandcamp, covering both digital and physical purchases from independent artists on the platform. It provides insights into consumer behavior, pricing strategies, and sales patterns in the independent music ecosystem. The data is valuable for understanding how artists monetize their work outside traditional record label structures.",
    "use_cases": [
      "Analyzing pricing strategies for independent musicians to optimize revenue",
      "Understanding seasonal trends and fan purchasing behavior in digital music markets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "bandcamp sales data for music industry analysis",
      "independent artist revenue datasets",
      "digital music sales trends data",
      "creative economy sales analytics dataset"
    ]
  },
  {
    "name": "Spotify Music Streaming Sessions (MSSD)",
    "description": "150M+ listening sessions with skips, track features, and playlist context. The largest public music streaming behavior dataset",
    "category": "Entertainment & Media",
    "url": "https://paperswithcode.com/dataset/mssd",
    "docs_url": "https://arxiv.org/abs/1901.09851",
    "github_url": null,
    "tags": [
      "Spotify",
      "streaming",
      "sessions",
      "skips",
      "large-scale"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "basic-statistics"
    ],
    "topic_tags": [
      "music-streaming",
      "user-behavior",
      "large-scale-dataset",
      "spotify-data",
      "session-analysis"
    ],
    "summary": "The Spotify Music Streaming Sessions Dataset contains over 150 million listening sessions with detailed information about user skips, track audio features, and playlist context. This is the largest publicly available dataset for analyzing music streaming behavior and user preferences. Researchers and data scientists use it to study recommendation systems, user engagement patterns, and music consumption trends.",
    "use_cases": [
      "Building recommendation algorithms by analyzing skip patterns and track features",
      "Measuring user engagement and churn prediction based on listening session behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "large scale music streaming dataset",
      "spotify user behavior data with skips",
      "music recommendation system training data",
      "playlist context and listening sessions dataset"
    ]
  },
  {
    "name": "Online Auctions Collection",
    "description": "Collection of datasets from eBay and experimental auctions",
    "category": "Auctions & Marketplaces",
    "url": "https://www.modelingonlineauctions.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "eBay",
      "bidding"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "auction-data",
      "ebay-bidding",
      "marketplace-analysis",
      "experimental-auctions",
      "bidding-behavior"
    ],
    "summary": "Collection of real eBay auction data and controlled experimental auction datasets for studying bidding behavior and marketplace dynamics. These datasets are commonly used by researchers and practitioners to analyze auction mechanisms, price discovery, and strategic bidding patterns. The data includes bid histories, final prices, item characteristics, and participant behavior across different auction formats.",
    "use_cases": [
      "Analyzing bidding patterns and reserve price effects in online marketplaces",
      "Comparing auction formats and their impact on revenue and participant behavior"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "eBay auction data for bidding analysis",
      "experimental auction datasets",
      "online marketplace bidding behavior data",
      "auction mechanism comparison datasets"
    ]
  },
  {
    "name": "Crypto Art (SuperRare)",
    "description": "Bids and transactions from SuperRare NFT platform",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/franceschet/superrare",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NFT",
      "crypto",
      "art",
      "auctions"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "auction-theory",
      "web3-blockchain-concepts"
    ],
    "topic_tags": [
      "NFT-markets",
      "digital-auctions",
      "crypto-economics",
      "art-valuation",
      "blockchain-data"
    ],
    "summary": "This dataset contains bidding and transaction data from SuperRare, a prominent NFT marketplace focused on digital art. It provides researchers with real-world auction data to study pricing mechanisms, bidder behavior, and market dynamics in the emerging crypto art economy. The data enables analysis of digital collectibles markets and blockchain-based auction systems.",
    "use_cases": [
      "Analyzing bidding patterns and price discovery mechanisms in NFT auctions",
      "Studying the relationship between artist reputation, artwork characteristics, and final sale prices"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "NFT auction data for pricing analysis",
      "SuperRare bidding dataset",
      "crypto art marketplace transaction data",
      "blockchain auction behavior dataset"
    ]
  },
  {
    "name": "Ukraine Procurement (ProZorro)",
    "description": "Public procurement data from ProZorro system",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/oleksastepaniuk/prozorro-public-procurement-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "procurement",
      "government",
      "Ukraine"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "data-visualization"
    ],
    "topic_tags": [
      "public-procurement",
      "government-data",
      "auction-analysis",
      "transparency",
      "ukraine"
    ],
    "summary": "Public procurement data from Ukraine's ProZorro electronic procurement system, containing bidding information, contract awards, and supplier details. This dataset is valuable for economists and data scientists studying government spending patterns, market competition, and procurement transparency. The data includes auction mechanics, bid amounts, winner selection, and contract performance metrics.",
    "use_cases": [
      "Analyzing bid competition and collusion patterns in government contracts",
      "Studying the impact of transparency reforms on procurement outcomes and pricing"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Ukraine government procurement dataset",
      "ProZorro bidding data analysis",
      "public auction transparency research data",
      "government contract competition dataset"
    ]
  },
  {
    "name": "Romania Tenders",
    "description": "Public tender data (2007-2016) from Romania",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/gpreda/public-tenders-romania-20072016",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "tenders",
      "government",
      "Romania"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "procurement-economics",
      "data-cleaning"
    ],
    "topic_tags": [
      "public-procurement",
      "government-data",
      "auction-analysis",
      "Romania",
      "tender-data"
    ],
    "summary": "A comprehensive dataset of Romanian public procurement tenders from 2007-2016, containing bidding information, contract values, and supplier details. This dataset enables researchers and analysts to study government spending patterns, market competition, and procurement efficiency. It's particularly valuable for understanding public sector purchasing behavior and analyzing bidder participation in emerging European markets.",
    "use_cases": [
      "Analyzing corruption risks in public procurement by examining bid patterns and supplier concentration",
      "Studying the impact of EU procurement regulations on bidding competition and contract awards"
    ],
    "audience": [
      "Mid-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "Romanian government procurement data",
      "public tender dataset Europe",
      "analyzing government bidding patterns",
      "procurement corruption detection data"
    ]
  },
  {
    "name": "Art Auction (Artists for Lahaina)",
    "description": "Artists for Lahaina benefit art auction data (2023)",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/flkuhm/art-price-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "art",
      "charity",
      "auctions"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "art-markets",
      "auction-data",
      "charity-fundraising",
      "bidding-behavior",
      "dataset"
    ],
    "summary": "This dataset contains bidding and sales data from a 2023 charity art auction organized to benefit Lahaina fire victims. It provides real-world auction data suitable for analyzing bidding patterns, price determinants, and charitable giving behavior in art markets. The dataset is ideal for learning auction analysis techniques and understanding how charitable context affects market outcomes.",
    "use_cases": [
      "Analyzing factors that drive higher bids in charity auctions versus regular art sales",
      "Building models to predict final sale prices based on artist characteristics and auction dynamics"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "art auction dataset for learning data analysis",
      "charity auction bidding data",
      "Lahaina fundraising auction results",
      "art market data for beginners"
    ]
  },
  {
    "name": "Used Car Auction (PakWheels)",
    "description": "Listings from PakWheels Pakistani automobile marketplace",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/asimzahid/pakistans-largest-pakwheels-automobiles-listings",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Pakistan",
      "listings"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "automobile-pricing",
      "marketplace-data",
      "Pakistan-market",
      "used-cars",
      "auction-data"
    ],
    "summary": "A dataset of car listings from PakWheels, Pakistan's largest automobile marketplace, containing information about used car sales and pricing. This data is ideal for learning basic data analysis techniques and understanding marketplace dynamics. Researchers and analysts can use it to study pricing patterns, market trends, and consumer behavior in the Pakistani automotive sector.",
    "use_cases": [
      "Building a price prediction model for used cars in Pakistan",
      "Analyzing market trends and popular vehicle types in South Asian automotive markets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "used car pricing data Pakistan",
      "automobile marketplace dataset",
      "PakWheels car auction data",
      "car listing data for price prediction"
    ]
  },
  {
    "name": "Ipinyou RTB",
    "description": "Real-time bidding (RTB) dataset for CTR prediction",
    "category": "Advertising",
    "url": "https://github.com/wnzhang/make-ipinyou-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "RTB",
      "advertising",
      "CTR",
      "programmatic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "feature-engineering"
    ],
    "topic_tags": [
      "real-time-bidding",
      "click-through-rate",
      "programmatic-advertising",
      "conversion-prediction",
      "dataset"
    ],
    "summary": "The Ipinyou RTB dataset contains real-world data from programmatic advertising auctions, specifically designed for predicting click-through rates in real-time bidding scenarios. This dataset is widely used by researchers and practitioners to develop and benchmark CTR prediction models in computational advertising. It includes features like user demographics, ad characteristics, and contextual information from actual RTB campaigns.",
    "use_cases": [
      "Building machine learning models to predict which ads users are likely to click in programmatic auctions",
      "Benchmarking different CTR prediction algorithms against industry-standard data for ad tech research"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "RTB dataset for click prediction experiments",
      "real-time bidding data for CTR modeling",
      "programmatic advertising dataset with conversion labels",
      "Ipinyou dataset for ad tech machine learning"
    ]
  },
  {
    "name": "Adform Display",
    "description": "Display advertising dataset with impressions and clicks",
    "category": "Advertising",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/TADBY7",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "display ads",
      "impressions",
      "Harvard Dataverse"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "display-advertising",
      "click-through-rates",
      "impressions",
      "advertising-data",
      "conversion-analysis"
    ],
    "summary": "A display advertising dataset containing impression and click data from Adform's advertising platform. This dataset is ideal for learning digital advertising metrics and analyzing campaign performance. Researchers and practitioners use it to understand click-through rates, impression patterns, and basic advertising effectiveness.",
    "use_cases": [
      "calculating click-through rates and conversion metrics for advertising campaigns",
      "building predictive models to estimate ad performance based on impression data"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "display advertising dataset with clicks and impressions",
      "adform advertising data for analysis",
      "dataset for learning digital marketing metrics",
      "click-through rate data for practice"
    ]
  },
  {
    "name": "Tencent Social Ads",
    "description": "Social ad CTR prediction dataset from Tencent",
    "category": "Advertising",
    "url": "https://algo.qq.com/index.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social ads",
      "CTR",
      "Tencent",
      "China"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "machine-learning-classification",
      "feature-engineering"
    ],
    "topic_tags": [
      "CTR-prediction",
      "social-advertising",
      "dataset",
      "Tencent",
      "Chinese-market"
    ],
    "summary": "A click-through rate prediction dataset from Tencent's social advertising platform, containing user interactions and ad features from the Chinese market. This dataset is commonly used for benchmarking CTR prediction models and understanding social ad performance patterns. It provides real-world advertising data for developing and testing recommendation systems and predictive models.",
    "use_cases": [
      "Benchmarking CTR prediction algorithms against industry-standard dataset",
      "Training machine learning models for social media advertising optimization"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Tencent social ads CTR dataset",
      "Chinese social media advertising data",
      "CTR prediction benchmark dataset",
      "Tencent ad click through rate data"
    ]
  },
  {
    "name": "Outbrain Click Prediction",
    "description": "Click prediction based on browsing history from Outbrain",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/outbrain-click-prediction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "click prediction",
      "content",
      "Kaggle"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "feature-engineering"
    ],
    "topic_tags": [
      "click-prediction",
      "advertising",
      "kaggle-dataset",
      "browsing-behavior",
      "content-recommendation"
    ],
    "summary": "A Kaggle competition dataset from Outbrain containing user browsing history and click behavior for predicting content engagement. The dataset includes user demographics, page content features, and click/no-click labels for training recommendation models. Commonly used for learning click-through rate prediction techniques and content recommendation system development.",
    "use_cases": [
      "Training models to predict which recommended articles users will click based on their browsing patterns",
      "Benchmarking different feature engineering approaches for content recommendation systems"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "click prediction dataset with user behavior",
      "Outbrain browsing history data for recommendations",
      "Kaggle dataset for learning CTR prediction",
      "content recommendation training data with click labels"
    ]
  },
  {
    "name": "Soso (KDD Cup 2012)",
    "description": "KDD Cup 2012 Track 2 for sponsored search CTR prediction",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/kddcup2012-track2",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "sponsored search",
      "KDD",
      "CTR"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "logistic-regression",
      "python-pandas",
      "feature-engineering"
    ],
    "topic_tags": [
      "click-through-rate",
      "sponsored-search",
      "competition-dataset",
      "advertising-optimization",
      "binary-classification"
    ],
    "summary": "The KDD Cup 2012 Track 2 dataset contains sponsored search advertising data for predicting click-through rates on search ads. It's a classic benchmark dataset used by data scientists and researchers to develop and evaluate CTR prediction models. The dataset includes features like query terms, ad content, user behavior, and advertiser information.",
    "use_cases": [
      "Training machine learning models to predict which search ads users are likely to click",
      "Benchmarking new CTR prediction algorithms against established baselines from the competition"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "KDD Cup 2012 sponsored search dataset",
      "click through rate prediction competition data",
      "benchmark dataset for CTR modeling",
      "search advertising machine learning dataset"
    ]
  },
  {
    "name": "Real-Time Advertisers Auction",
    "description": "Real-time advertiser auction dataset for RTB research",
    "category": "Advertising",
    "url": "https://www.kaggle.com/datasets/saurav9786/real-time-advertisers-auction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "RTB",
      "auctions",
      "programmatic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "auction-theory",
      "python-pandas",
      "statistical-inference"
    ],
    "topic_tags": [
      "real-time-bidding",
      "auction-mechanisms",
      "programmatic-advertising",
      "dataset",
      "behavioral-data"
    ],
    "summary": "A dataset containing real-time bidding auction data from programmatic advertising platforms, including bid prices, advertiser behavior, and auction outcomes. Used by researchers and data scientists to study auction mechanisms, bidding strategies, and market dynamics in digital advertising. Provides ground truth data for developing and evaluating RTB algorithms and pricing models.",
    "use_cases": [
      "Testing bid optimization algorithms against historical auction data",
      "Analyzing market concentration and competitive dynamics in programmatic advertising"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "RTB auction dataset for bidding strategy research",
      "real-time advertising auction data",
      "programmatic advertising research dataset",
      "auction mechanism analysis data"
    ]
  },
  {
    "name": "ICPSR Auction Studies",
    "description": "Search results for auction studies from ICPSR",
    "category": "Advertising",
    "url": "https://www.openicpsr.org/openicpsr/search/studies",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "research",
      "social science"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "econometrics-basics",
      "auction-theory",
      "stata-or-r"
    ],
    "topic_tags": [
      "auction-mechanisms",
      "experimental-economics",
      "bidding-behavior",
      "market-design",
      "social-science-data"
    ],
    "summary": "ICPSR Auction Studies is a collection of datasets from experimental and field studies examining bidding behavior, auction mechanisms, and market outcomes. These datasets are commonly used by economists and social scientists to test auction theory predictions and understand strategic behavior in different auction formats. The collection includes both laboratory experiments and real-world auction data with detailed participant and outcome information.",
    "use_cases": [
      "Testing whether bidding behavior matches theoretical predictions in first-price sealed-bid auctions",
      "Analyzing the revenue effects of different auction formats using experimental data"
    ],
    "audience": [
      "Early-PhD",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "auction experiment datasets for research",
      "ICPSR bidding behavior data",
      "experimental auction studies database",
      "auction theory empirical validation datasets"
    ]
  },
  {
    "name": "Harvard Dataverse Auctions",
    "description": "Auction-related replication datasets from Harvard Dataverse",
    "category": "Advertising",
    "url": "https://dataverse.harvard.edu/dataverse/harvard",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "replication",
      "academic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-econometrics",
      "data-cleaning"
    ],
    "topic_tags": [
      "auctions",
      "replication-data",
      "advertising",
      "harvard-dataverse",
      "empirical-research"
    ],
    "summary": "A collection of auction-related datasets from Harvard Dataverse specifically curated for replication studies in advertising and auction research. These datasets enable researchers and practitioners to reproduce published academic findings and validate auction models. The data typically includes bid amounts, auction outcomes, participant behavior, and contextual variables from real-world auction environments.",
    "use_cases": [
      "Replicating seminal auction theory papers for thesis research",
      "Validating programmatic advertising bidding strategies using historical auction data"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "auction replication datasets",
      "Harvard Dataverse auction data",
      "advertising auction research data",
      "empirical auction analysis datasets"
    ]
  },
  {
    "name": "Cainiao Last-Mile (MSOM18)",
    "description": "Cainiao Last-Mile Delivery dataset from MSOM 2018",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/competition/entrance/231623/information",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "last-mile",
      "delivery",
      "Cainiao",
      "MSOM"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "network-analysis",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "last-mile-delivery",
      "logistics-optimization",
      "supply-chain",
      "operations-research",
      "dataset"
    ],
    "summary": "Real-world dataset from Cainiao's last-mile delivery operations, published in Manufacturing & Service Operations Management 2018. Contains delivery routes, timing, and operational metrics from one of China's largest logistics networks. Useful for studying delivery optimization, route planning, and supply chain analytics.",
    "use_cases": [
      "Analyzing delivery route efficiency and identifying bottlenecks in urban logistics networks",
      "Benchmarking last-mile delivery performance metrics against industry standards from a major e-commerce platform"
    ],
    "audience": [
      "Mid-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "Cainiao delivery dataset for route optimization research",
      "last mile delivery data from Chinese e-commerce",
      "MSOM 2018 logistics dataset download",
      "real world delivery network data for analysis"
    ]
  },
  {
    "name": "BTS Airline On-Time Performance",
    "description": "All US flights since 1987. Delays, cancellations, fares, capacity. Revenue management research goldmine",
    "category": "Transportation & Mobility",
    "url": "https://www.transtats.bts.gov/ontime/",
    "docs_url": "https://www.bts.gov/topics/airline-time-tables",
    "github_url": null,
    "tags": [
      "airline",
      "flights",
      "delays",
      "pricing",
      "large-scale"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "time-series-analysis"
    ],
    "topic_tags": [
      "airline-data",
      "delay-prediction",
      "pricing-analysis",
      "transportation",
      "large-dataset"
    ],
    "summary": "Comprehensive dataset containing all US commercial flights from 1987 onwards with detailed information on delays, cancellations, fares, and capacity. This is a go-to resource for transportation economists and data scientists studying airline operations, pricing strategies, and service quality. The dataset's size and temporal span make it ideal for learning large-scale data analysis and time series methods.",
    "use_cases": [
      "Building delay prediction models to optimize flight scheduling and passenger experience",
      "Analyzing airline pricing strategies and competitive dynamics across different routes and time periods"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "airline delay dataset for machine learning",
      "historical flight data for pricing analysis",
      "large transportation dataset for practice",
      "US airline performance data download"
    ]
  },
  {
    "name": "Amazon Last Mile",
    "description": "9,184 historical routes across 5 US metro areas",
    "category": "Logistics & Supply Chain",
    "url": "https://registry.opendata.aws/amazon-last-mile-challenges/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "routing",
      "last-mile",
      "Amazon",
      "AWS"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "geospatial-data-analysis",
      "basic-optimization"
    ],
    "topic_tags": [
      "routing-optimization",
      "last-mile-delivery",
      "geospatial-analysis",
      "operations-research",
      "dataset"
    ],
    "summary": "A comprehensive dataset containing 9,184 historical delivery routes from Amazon's last-mile operations across 5 major US metropolitan areas. This dataset provides real-world routing data that researchers and practitioners can use to benchmark routing algorithms, analyze delivery patterns, and develop optimization models. It's particularly valuable for understanding the complexities of urban delivery logistics and testing theoretical models against actual operational data.",
    "use_cases": [
      "Benchmarking vehicle routing algorithms against real Amazon delivery data",
      "Analyzing delivery efficiency patterns across different urban environments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Amazon delivery route optimization dataset",
      "last mile routing data for research",
      "real world vehicle routing problem data",
      "delivery logistics historical routes dataset"
    ]
  },
  {
    "name": "LaDe Last-Mile Delivery",
    "description": "10.6M+ packages, 619k trajectories with GPS data",
    "category": "Logistics & Supply Chain",
    "url": "https://arxiv.org/html/2306.10675v2",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "last-mile",
      "GPS",
      "trajectories",
      "large-scale"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "geospatial-analysis",
      "SQL-queries"
    ],
    "topic_tags": [
      "last-mile-delivery",
      "GPS-tracking",
      "logistics-optimization",
      "trajectory-analysis",
      "supply-chain"
    ],
    "summary": "Large-scale dataset containing over 10.6 million package deliveries with detailed GPS trajectory data from 619,000 delivery routes. Primarily used by logistics researchers and data scientists to analyze delivery patterns, optimize routing algorithms, and study last-mile delivery efficiency. The dataset provides real-world delivery behavior data for developing predictive models and operational improvements.",
    "use_cases": [
      "Building route optimization algorithms for delivery companies to reduce fuel costs and delivery times",
      "Analyzing delivery success rates and identifying factors that lead to failed deliveries or delays"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale GPS delivery dataset",
      "last mile logistics trajectory data",
      "package delivery route optimization dataset",
      "real world delivery GPS tracking data"
    ]
  },
  {
    "name": "DataCo Supply Chain",
    "description": "Synthetic supply chain dataset covering sales and returns",
    "category": "Logistics & Supply Chain",
    "url": "https://tianchi.aliyun.com/dataset/89959",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "supply chain",
      "synthetic",
      "returns"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-SQL"
    ],
    "topic_tags": [
      "supply-chain-analytics",
      "synthetic-data",
      "logistics",
      "dataset",
      "operations"
    ],
    "summary": "A synthetic dataset simulating supply chain operations including sales transactions, product returns, and logistics data. Designed for learning supply chain analytics without proprietary business data constraints. Ideal for students and practitioners wanting to explore inventory optimization, demand forecasting, and return rate analysis.",
    "use_cases": [
      "Learning supply chain KPIs and building dashboards for inventory turnover and fill rates",
      "Practicing demand forecasting models to predict seasonal sales patterns"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "supply chain dataset for practice",
      "synthetic logistics data",
      "returns analysis sample data",
      "supply chain analytics tutorial dataset"
    ]
  },
  {
    "name": "Drone Delivery",
    "description": "Drone delivery logistics and operations dataset",
    "category": "Logistics & Supply Chain",
    "url": "https://tianchi.aliyun.com/dataset/89726",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "drones",
      "delivery",
      "autonomous"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "geospatial-analysis",
      "optimization-algorithms"
    ],
    "topic_tags": [
      "drone-delivery",
      "last-mile-logistics",
      "route-optimization",
      "autonomous-vehicles",
      "supply-chain"
    ],
    "summary": "Comprehensive dataset covering drone delivery operations including flight paths, delivery times, weather conditions, and operational costs. Used by logistics companies and researchers to optimize delivery routes and analyze autonomous delivery performance. Contains real-world operational data for evaluating drone deployment strategies and efficiency metrics.",
    "use_cases": [
      "Optimizing drone delivery routes for e-commerce companies to minimize delivery time and operational costs",
      "Analyzing weather impact on drone delivery success rates for logistics planning and risk assessment"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "drone delivery route optimization dataset",
      "autonomous delivery logistics data",
      "last mile delivery performance analysis",
      "drone operations dataset weather impact"
    ]
  },
  {
    "name": "Natural Driving in Ohio",
    "description": "ADAS-equipped vehicles with driving behavior events",
    "category": "Transportation & Mobility",
    "url": "https://data.transportation.gov/Automobiles/Advanced-Driver-Assistance-System-ADAS-Equipped-Si/iie8-uenj/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "driving",
      "ADAS",
      "behavior",
      "government"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "driving-behavior",
      "ADAS",
      "transportation-data",
      "government-dataset"
    ],
    "summary": "A government dataset containing driving behavior events from vehicles equipped with Advanced Driver Assistance Systems (ADAS) in Ohio. The dataset captures real-world driving patterns, safety events, and system interventions from ADAS-enabled vehicles. This data is valuable for transportation researchers, automotive engineers, and data scientists studying driver behavior and autonomous vehicle safety.",
    "use_cases": [
      "Analyzing the effectiveness of ADAS features in preventing accidents or unsafe driving behaviors",
      "Building predictive models to identify high-risk driving scenarios or locations for traffic safety improvements"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "ADAS driving behavior dataset",
      "natural driving data Ohio government",
      "vehicle safety events dataset",
      "real world driving behavior data"
    ]
  },
  {
    "name": "NGSIM Vehicle Trajectories",
    "description": "Vehicle trajectory data for traffic flow modeling",
    "category": "Transportation & Mobility",
    "url": "https://data.transportation.gov/Automobiles/Next-Generation-Simulation-NGSIM-Vehicle-Trajector/8ect-6jqj/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "trajectories",
      "traffic",
      "simulation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "spatial-data-analysis",
      "time-series-processing"
    ],
    "topic_tags": [
      "vehicle-trajectories",
      "traffic-flow",
      "transportation-data",
      "microsimulation",
      "mobility-analysis"
    ],
    "summary": "NGSIM (Next Generation Simulation) contains high-resolution vehicle trajectory data collected from real highway segments, capturing individual vehicle positions, speeds, and movements over time. This dataset is widely used by transportation researchers and data scientists for developing and validating traffic flow models, autonomous vehicle algorithms, and mobility analytics. The data provides ground truth for understanding driving behavior patterns and traffic dynamics at the microscopic level.",
    "use_cases": [
      "Calibrating car-following models for autonomous vehicle simulation systems",
      "Analyzing lane-changing behavior patterns to improve traffic management algorithms"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "vehicle trajectory data for traffic modeling",
      "NGSIM dataset for autonomous vehicle research",
      "real highway driving behavior data",
      "microscopic traffic simulation validation data"
    ]
  },
  {
    "name": "Grab Driving GPS Traces",
    "description": "GPS trace data from Grab ride-hailing platform",
    "category": "Transportation & Mobility",
    "url": "https://engineering.grab.com/grab-posisi",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "GPS",
      "ride-hailing",
      "Southeast Asia"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "geospatial-analysis",
      "data-cleaning"
    ],
    "topic_tags": [
      "GPS-data",
      "ride-hailing",
      "transportation-analysis",
      "geospatial-datasets",
      "Southeast-Asia"
    ],
    "summary": "GPS trace data from Grab's ride-hailing platform covering Southeast Asian markets. This dataset provides real-world mobility patterns and routing behavior from one of the region's largest transportation platforms. Useful for studying urban mobility, route optimization, and transportation demand patterns in emerging markets.",
    "use_cases": [
      "Analyzing traffic patterns and congestion hotspots in Southeast Asian cities",
      "Building route recommendation systems for ride-hailing applications"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "GPS data from ride sharing apps",
      "Grab transportation dataset",
      "Southeast Asia mobility data",
      "ride hailing GPS traces dataset"
    ]
  },
  {
    "name": "NYC TLC Trip Records",
    "description": "3B+ taxi and rideshare trips since 2009. Fares, tips, surge pricing, driver pay. The gold standard for marketplace analytics",
    "category": "Transportation & Mobility",
    "url": "https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page",
    "docs_url": "https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf",
    "github_url": "https://github.com/toddwschneider/nyc-taxi-data",
    "tags": [
      "taxi",
      "Uber",
      "Lyft",
      "surge pricing",
      "NYC",
      "large-scale"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "statistical-hypothesis-testing"
    ],
    "topic_tags": [
      "transportation-data",
      "marketplace-dynamics",
      "surge-pricing",
      "large-datasets",
      "urban-analytics"
    ],
    "summary": "Comprehensive dataset of over 3 billion taxi and rideshare trips in NYC from 2009 onwards, including detailed fare structures, tip patterns, and surge pricing data. Widely used by researchers and practitioners studying two-sided marketplaces, urban mobility patterns, and dynamic pricing strategies. Considered the benchmark dataset for transportation economics and marketplace analysis.",
    "use_cases": [
      "Analyzing surge pricing effectiveness and consumer response patterns during peak demand periods",
      "Building predictive models for taxi demand forecasting across different NYC neighborhoods and time periods"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "NYC taxi trip data for surge pricing analysis",
      "large scale transportation dataset marketplace economics",
      "rideshare demand forecasting historical data",
      "taxi fare and tip analysis dataset NYC"
    ]
  },
  {
    "name": "Uber Movement",
    "description": "Zone-to-zone travel times and street speeds for 50+ cities worldwide. Congestion patterns from actual Uber rides",
    "category": "Transportation & Mobility",
    "url": "https://www.kaggle.com/datasets/ishandutta/uber-travel-movement-data-2-billion-trips",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Uber",
      "travel times",
      "congestion",
      "cities",
      "transportation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "geospatial-analysis"
    ],
    "topic_tags": [
      "urban-mobility",
      "travel-time-data",
      "congestion-analysis",
      "geospatial-data",
      "transportation-economics"
    ],
    "summary": "Uber Movement provides aggregated travel time and speed data from Uber trips across 50+ major cities worldwide. The dataset offers zone-to-zone movement patterns and congestion insights derived from real ride-sharing data. It's valuable for urban planners, transportation researchers, and data scientists studying mobility patterns and traffic optimization.",
    "use_cases": [
      "Analyzing how COVID-19 lockdowns affected urban mobility patterns across different city zones",
      "Optimizing delivery routes by identifying consistently congested areas during peak hours"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "uber travel time data for cities",
      "real world traffic congestion dataset",
      "zone to zone mobility data download",
      "transportation data for urban planning analysis"
    ]
  },
  {
    "name": "AirBnb (Inside Airbnb)",
    "description": "6M+ listings, 190M+ reviews with pricing and amenities",
    "category": "Real Estate",
    "url": "http://insideairbnb.com/explore",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Airbnb",
      "rentals",
      "pricing",
      "global"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "airbnb",
      "pricing-data",
      "hospitality",
      "geospatial",
      "dataset"
    ],
    "summary": "Inside Airbnb provides comprehensive data on 6+ million Airbnb listings across global cities, including detailed pricing, amenities, host information, and 190+ million guest reviews. This open dataset is widely used by researchers, analysts, and policymakers to study short-term rental markets, housing impacts, and tourism patterns. The data includes rich geographic information and temporal snapshots, making it ideal for market analysis and academic research.",
    "use_cases": [
      "Analyzing rental price determinants across different neighborhoods and cities",
      "Studying the impact of short-term rentals on local housing markets and availability"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Airbnb pricing dataset with reviews and amenities",
      "real estate rental data for market analysis",
      "Inside Airbnb dataset download",
      "hospitality pricing data with geographic information"
    ]
  },
  {
    "name": "Chicago Property Data",
    "description": "Property assessment values and sales data from Cook County",
    "category": "Real Estate",
    "url": "https://datacatalog.cookcountyil.gov/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "property",
      "Chicago",
      "assessments",
      "government"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-cleaning"
    ],
    "topic_tags": [
      "property-values",
      "real-estate",
      "government-data",
      "Chicago",
      "tabular-data"
    ],
    "summary": "Cook County property assessment and sales records providing detailed information on property values, characteristics, and transaction history in Chicago. This government dataset is commonly used by urban economists, real estate analysts, and policy researchers. The data enables analysis of housing markets, property tax equity, and neighborhood economic trends.",
    "use_cases": [
      "Analyzing property tax assessment accuracy and potential bias across different neighborhoods",
      "Building hedonic pricing models to understand how property characteristics affect market values"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Chicago property values dataset",
      "Cook County real estate data",
      "property assessment data for housing analysis",
      "Chicago neighborhood property prices data"
    ]
  },
  {
    "name": "NYC Property Sales",
    "description": "NYC property sales transactions across all boroughs",
    "category": "Real Estate",
    "url": "https://data.cityofnewyork.us/Housing-Development/NYC-Calendar-Sales-Archive-/uzf5-f8n2/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "NYC",
      "transactions",
      "government"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "basic-SQL"
    ],
    "topic_tags": [
      "real-estate",
      "NYC",
      "government-data",
      "property-values",
      "transactions"
    ],
    "summary": "Comprehensive dataset of property sales transactions across all five NYC boroughs, maintained by the Department of Finance. This dataset provides detailed information on sales prices, property characteristics, and transaction dates. It's ideal for learning data analysis fundamentals while exploring real estate market dynamics in one of the world's most complex property markets.",
    "use_cases": [
      "analyzing neighborhood price trends and gentrification patterns",
      "building predictive models for property valuations"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NYC property sales data for analysis",
      "real estate transactions dataset New York",
      "government property sales data",
      "NYC housing market data for beginners"
    ]
  },
  {
    "name": "Yelp Dataset",
    "description": "Business attributes, reviews, user data, and check-ins",
    "category": "Social & Web",
    "url": "https://www.yelp.com/dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "businesses",
      "local",
      "NLP"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "SQL-basics"
    ],
    "topic_tags": [
      "restaurant-data",
      "sentiment-analysis",
      "recommendation-systems",
      "location-analytics",
      "user-reviews"
    ],
    "summary": "Large-scale dataset containing millions of business reviews, ratings, and user interactions from Yelp's platform. Includes rich metadata like business categories, location data, user networks, and temporal check-in patterns. Widely used for learning NLP techniques, recommendation systems, and local business analytics.",
    "use_cases": [
      "Building restaurant recommendation engines based on user preferences and review sentiment",
      "Analyzing local business performance and customer satisfaction trends across different cities"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "restaurant review dataset for sentiment analysis",
      "yelp data for recommendation system project",
      "business rating data with location information",
      "user review dataset for NLP practice"
    ]
  },
  {
    "name": "Wikipedia Pageviews",
    "description": "296B views/year since 2007. Hourly pageview data for all Wikimedia projects. attention metrics at scale",
    "category": "Social & Web",
    "url": "https://dumps.wikimedia.org/other/pageviews/",
    "docs_url": "https://dumps.wikimedia.org/other/pageviews/readme.html",
    "github_url": null,
    "tags": [
      "Wikipedia",
      "pageviews",
      "attention",
      "time-series",
      "large-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "wikipedia",
      "pageviews",
      "attention-metrics",
      "time-series",
      "web-analytics"
    ],
    "summary": "Comprehensive dataset containing hourly pageview counts for all Wikipedia articles and Wikimedia projects since 2007, totaling 296 billion views annually. This large-scale attention data provides insights into information consumption patterns, trending topics, and collective behavior across different languages and cultures. Ideal for studying digital attention dynamics, content popularity, and real-world event impacts on information seeking.",
    "use_cases": [
      "Analyzing how news events drive Wikipedia traffic spikes to measure public interest",
      "Building predictive models for content popularity based on historical pageview patterns"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "wikipedia pageview data download",
      "measuring attention to wikipedia articles",
      "wikipedia traffic analysis dataset",
      "how to analyze wikipedia page popularity trends"
    ]
  },
  {
    "name": "Pushshift Reddit Archive",
    "description": "5.6B comments, 651M posts since 2005. Full Reddit history for social/economic research. 100+ papers published",
    "category": "Social & Web",
    "url": "https://arxiv.org/abs/2001.08435",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Reddit",
      "social media",
      "comments",
      "NLP",
      "large-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "API-requests",
      "text-preprocessing"
    ],
    "topic_tags": [
      "reddit-data",
      "social-media-analysis",
      "comment-mining",
      "user-behavior",
      "text-corpus"
    ],
    "summary": "Complete historical archive of Reddit containing 5.6 billion comments and 651 million posts from 2005 onwards. This dataset has been used in over 100 research papers for studying online social dynamics, content evolution, and user behavior patterns. Provides unprecedented scale for natural language processing and social network analysis in digital communities.",
    "use_cases": [
      "Analyzing how political discourse evolved on Reddit during election cycles",
      "Training language models on conversational text patterns from different subreddit communities"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Reddit dataset for social media research",
      "large scale comment data for NLP training",
      "historical social media posts dataset",
      "Reddit archive for academic research"
    ]
  },
  {
    "name": "Stack Overflow Data Dump",
    "description": "Full Q&A archive + annual developer survey (49K+ responses). Salaries, tech adoption, developer analytics",
    "category": "Social & Web",
    "url": "https://archive.org/details/stackexchange",
    "docs_url": "https://survey.stackoverflow.co/",
    "github_url": null,
    "tags": [
      "developers",
      "salaries",
      "tech",
      "survey",
      "Q&A"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "SQL-queries",
      "python-pandas",
      "data-visualization"
    ],
    "topic_tags": [
      "developer-surveys",
      "salary-data",
      "tech-adoption",
      "Q&A-analysis",
      "workforce-analytics"
    ],
    "summary": "Complete Stack Overflow data archive including all questions, answers, and comprehensive annual developer surveys with 49K+ responses. Contains rich data on developer salaries, technology adoption trends, and programming community insights. Widely used for understanding tech workforce dynamics and developer behavior patterns.",
    "use_cases": [
      "Analyzing salary trends across programming languages and geographic regions for compensation benchmarking",
      "Tracking technology adoption patterns over time to inform product strategy decisions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "developer salary data by programming language",
      "stack overflow survey dataset download",
      "tech adoption trends data",
      "developer survey responses analysis"
    ]
  },
  {
    "name": "Common Crawl",
    "description": "250TB/month web crawl. 9.5 PB archive since 2008. Product listings, pricing, economic text at web scale",
    "category": "Social & Web",
    "url": "https://commoncrawl.org/",
    "docs_url": "https://commoncrawl.org/the-data/get-started/",
    "github_url": null,
    "tags": [
      "web crawl",
      "text",
      "pricing",
      "petabyte-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-requests",
      "data-parsing",
      "distributed-computing"
    ],
    "topic_tags": [
      "web-crawling",
      "large-scale-data",
      "text-mining",
      "pricing-data",
      "petabyte-scale"
    ],
    "summary": "Common Crawl is a massive open dataset containing petabytes of web crawl data collected monthly since 2008. It provides researchers and data scientists with unprecedented access to web-scale text, product listings, and pricing information for economic analysis and research.",
    "use_cases": [
      "Training large language models on diverse web text for economic research",
      "Analyzing e-commerce pricing trends across millions of product listings over time"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale web crawl dataset",
      "petabyte web data for pricing analysis",
      "Common Crawl dataset economic research",
      "web scale text data for machine learning"
    ]
  },
  {
    "name": "Google Trends Datastore",
    "description": "Search interest data for nowcasting. Economic indicators, demand prediction, event detection",
    "category": "Social & Web",
    "url": "https://googletrends.github.io/data/",
    "docs_url": "https://developers.google.com/search/apis/trends",
    "github_url": null,
    "tags": [
      "search trends",
      "nowcasting",
      "research",
      "time-series"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "time-series-analysis",
      "API-requests"
    ],
    "topic_tags": [
      "google-trends",
      "nowcasting",
      "economic-indicators",
      "time-series",
      "search-data"
    ],
    "summary": "Google Trends provides search volume data that can predict economic activity in real-time. Researchers and analysts use this data to forecast unemployment, retail sales, housing demand, and other indicators weeks before official statistics are released. The dataset enables early detection of market shifts and consumer behavior changes.",
    "use_cases": [
      "Predicting quarterly GDP growth using search terms like 'unemployment benefits' and 'job search'",
      "Forecasting retail sales during holiday seasons by tracking product-related search volumes"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "google trends economic forecasting dataset",
      "search data for nowcasting economic indicators",
      "real-time prediction using google search volume",
      "google trends time series economic analysis"
    ]
  },
  {
    "name": "Yandex Datasets",
    "description": "Search ranking, translation quality, and ML task datasets",
    "category": "Data Portals",
    "url": "https://research.yandex.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search ranking",
      "translation",
      "ML",
      "Russia"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "basic-ML-evaluation"
    ],
    "topic_tags": [
      "search-ranking",
      "translation-quality",
      "russian-datasets",
      "ML-benchmarks",
      "yandex"
    ],
    "summary": "Collection of datasets from Yandex covering search ranking evaluation, translation quality assessment, and various machine learning tasks. These datasets are particularly valuable for researchers working on information retrieval and NLP problems, offering real-world data from one of Russia's largest tech companies. The datasets include both labeled examples and evaluation benchmarks commonly used in academic research.",
    "use_cases": [
      "Benchmarking search ranking algorithms against industry-standard datasets",
      "Training and evaluating machine translation models on Russian-English language pairs"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "Yandex search ranking dataset download",
      "Russian translation quality datasets",
      "where to find Yandex ML benchmarks",
      "search relevance evaluation datasets"
    ]
  },
  {
    "name": "Meta (Facebook) Research",
    "description": "1.1B+ public FB/IG posts with engagement metrics",
    "category": "Social & Web",
    "url": "https://fort.fb.com/researcher-datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social media",
      "Facebook",
      "Instagram",
      "engagement"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "social-network-analysis",
      "statistical-sampling"
    ],
    "topic_tags": [
      "social-media-data",
      "engagement-metrics",
      "large-scale-dataset",
      "behavioral-analysis",
      "platform-research"
    ],
    "summary": "A massive dataset containing over 1.1 billion public posts from Facebook and Instagram with associated engagement metrics like likes, shares, and comments. This dataset is valuable for researchers and data scientists studying social media behavior, viral content patterns, and platform dynamics at unprecedented scale.",
    "use_cases": [
      "Analyzing factors that drive viral content spread across different demographics and post types",
      "Building predictive models for engagement rates to optimize social media marketing strategies"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale social media engagement dataset",
      "Facebook Instagram posts with metrics data",
      "viral content analysis dataset",
      "social media behavior research data"
    ]
  },
  {
    "name": "Microsoft Research",
    "description": "Research tools and datasets across multiple domains",
    "category": "Data Portals",
    "url": "https://www.microsoft.com/en-us/research/tools/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Microsoft",
      "research",
      "various domains"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-analysis-basics"
    ],
    "topic_tags": [
      "microsoft-research",
      "datasets",
      "research-data",
      "multi-domain",
      "open-data"
    ],
    "summary": "Microsoft Research provides a comprehensive collection of research datasets and tools spanning computer vision, natural language processing, machine learning, and other domains. The platform offers both raw datasets and accompanying research tools developed by Microsoft's research teams. It serves as a valuable resource for researchers and practitioners looking for high-quality, well-documented datasets to support their projects.",
    "use_cases": [
      "Training computer vision models using Microsoft's image datasets",
      "Benchmarking NLP algorithms against Microsoft's language processing datasets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Microsoft research datasets",
      "where to find Microsoft ML datasets",
      "Microsoft open research data",
      "Microsoft AI datasets download"
    ]
  },
  {
    "name": "Amazon AWS Open Data",
    "description": "Registry of Open Data with analysis-ready datasets",
    "category": "Data Portals",
    "url": "https://registry.opendata.aws/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "AWS",
      "open data",
      "cloud",
      "various"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-boto3",
      "cloud-storage-concepts"
    ],
    "topic_tags": [
      "open-data",
      "cloud-computing",
      "data-discovery",
      "AWS",
      "public-datasets"
    ],
    "summary": "AWS Open Data is a registry of publicly available datasets hosted on Amazon's cloud infrastructure, covering domains from genomics to satellite imagery. The platform provides analysis-ready datasets that can be accessed directly through AWS services without download fees. It's designed to make large-scale public data more accessible for research and commercial applications.",
    "use_cases": [
      "Accessing satellite imagery data for environmental research without managing large file transfers",
      "Finding genomics datasets for machine learning model training that are already optimized for cloud computing"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "where to find free datasets on AWS",
      "public datasets for machine learning projects",
      "how to access open data on Amazon cloud",
      "analysis ready datasets AWS registry"
    ]
  },
  {
    "name": "Netflix Prize",
    "description": "100M+ anonymous movie ratings from 480k users",
    "category": "Entertainment & Media",
    "url": "https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "movies",
      "ratings",
      "recommendations",
      "classic"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "matrix-factorization"
    ],
    "topic_tags": [
      "collaborative-filtering",
      "movie-recommendations",
      "rating-prediction",
      "sparse-matrices"
    ],
    "summary": "The Netflix Prize dataset contains over 100 million anonymous movie ratings from 480,000 users on 17,000+ films, released for a famous $1M competition to improve recommendation accuracy by 10%. This classic dataset became the gold standard for testing collaborative filtering and matrix factorization techniques. It's ideal for learning recommendation systems fundamentals and benchmarking new algorithms.",
    "use_cases": [
      "Learning collaborative filtering by predicting user ratings for unseen movies",
      "Benchmarking new recommendation algorithms against established baselines"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "Netflix prize dataset for recommendation systems",
      "movie ratings dataset collaborative filtering",
      "classic recommendation system benchmark data",
      "large scale movie rating prediction dataset"
    ]
  },
  {
    "name": "JD.com Open Datasets",
    "description": "Open dataset portal for e-commerce and logistics from JD.com",
    "category": "Data Portals",
    "url": "https://datascience.jd.com/page/opendataset.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "JD.com",
      "e-commerce",
      "logistics",
      "China"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-cleaning"
    ],
    "topic_tags": [
      "e-commerce-data",
      "logistics-datasets",
      "chinese-market",
      "open-data",
      "retail-analytics"
    ],
    "summary": "JD.com's open dataset portal provides access to real-world e-commerce and logistics data from one of China's largest online retailers. The datasets cover areas like customer behavior, supply chain operations, and market dynamics in the Chinese e-commerce ecosystem. This resource is valuable for researchers and practitioners studying online retail patterns, logistics optimization, and cross-cultural consumer behavior.",
    "use_cases": [
      "Analyzing customer purchase patterns and recommendation systems using JD.com transaction data",
      "Studying logistics network efficiency and delivery optimization in Chinese urban markets"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "JD.com datasets for e-commerce research",
      "Chinese retail data for machine learning",
      "logistics optimization datasets China",
      "open e-commerce data JD"
    ]
  },
  {
    "name": "Rakuten Data Release",
    "description": "E-commerce, advertising, and multimedia datasets from Rakuten",
    "category": "Data Portals",
    "url": "https://rit.rakuten.com/data_release/#access",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Rakuten",
      "e-commerce",
      "multimedia"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "SQL-basics"
    ],
    "topic_tags": [
      "e-commerce-data",
      "advertising-datasets",
      "multimedia-data",
      "retail-analytics",
      "recommendation-systems"
    ],
    "summary": "Rakuten Data Release provides publicly available datasets from Japan's largest e-commerce platform, covering user behavior, product catalogs, advertising campaigns, and multimedia content. These datasets are commonly used by researchers and data scientists studying online marketplace dynamics, recommendation algorithms, and consumer behavior patterns. The collection includes both structured transaction data and unstructured multimedia content like product images and reviews.",
    "use_cases": [
      "Building recommendation systems for e-commerce platforms using historical purchase and browsing data",
      "Analyzing advertising campaign effectiveness and user engagement patterns in online marketplaces"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Rakuten e-commerce datasets for recommendation systems",
      "public retail datasets with user behavior data",
      "advertising effectiveness datasets from marketplace platforms",
      "Japanese e-commerce data for academic research"
    ]
  },
  {
    "name": "IBM Developer Data",
    "description": "AI, data science, healthcare, and weather datasets from IBM",
    "category": "Data Portals",
    "url": "https://developer.ibm.com/technologies/artificial-intelligence/data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "IBM",
      "AI",
      "healthcare",
      "weather"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-data-analysis",
      "API-requests"
    ],
    "topic_tags": [
      "datasets",
      "data-portal",
      "IBM",
      "healthcare-data",
      "weather-data"
    ],
    "summary": "IBM Developer Data is a collection of curated datasets spanning AI, data science, healthcare, and weather domains provided by IBM. The datasets are designed for developers and data scientists to practice analysis techniques and build applications. They offer clean, well-documented data across various industries and use cases.",
    "use_cases": [
      "Junior data scientist needs healthcare datasets to practice predictive modeling for patient outcomes",
      "Developer building a weather application requires historical weather data for training machine learning models"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Where can I find IBM datasets for data science projects",
      "Free healthcare datasets for machine learning practice",
      "IBM weather data for developers",
      "Curated datasets from IBM for AI projects"
    ]
  },
  {
    "name": "Baidu AI Datasets",
    "description": "AI, NLP, computer vision, and autonomous driving datasets",
    "category": "Data Portals",
    "url": "https://aistudio.baidu.com/datasetoverview",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Baidu",
      "NLP",
      "computer vision",
      "autonomous"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "tensorflow-keras",
      "opencv-basics"
    ],
    "topic_tags": [
      "datasets",
      "chinese-nlp",
      "computer-vision",
      "autonomous-driving",
      "baidu"
    ],
    "summary": "Baidu AI Datasets is a collection of machine learning datasets covering natural language processing, computer vision, and autonomous driving applications. The datasets are particularly valuable for Chinese language processing and include real-world data from Baidu's products and services. These resources are commonly used for training models, benchmarking algorithms, and academic research in AI applications.",
    "use_cases": [
      "Training Chinese language models for sentiment analysis or text classification",
      "Developing computer vision models for autonomous vehicle perception systems"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Chinese NLP datasets for training",
      "Baidu autonomous driving dataset download",
      "computer vision datasets from Chinese companies",
      "free AI datasets for deep learning projects"
    ]
  },
  {
    "name": "Inside Airbnb Raw Data",
    "description": "Raw data files from Inside Airbnb project",
    "category": "Data Portals",
    "url": "http://insideairbnb.com/get-the-data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Airbnb",
      "raw data",
      "rentals"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "CSV-handling"
    ],
    "topic_tags": [
      "airbnb-data",
      "rental-market",
      "raw-datasets",
      "hospitality-economics",
      "urban-planning"
    ],
    "summary": "Raw data files from the Inside Airbnb project containing detailed listings, reviews, and calendar information for Airbnb properties across major cities worldwide. This community-sourced dataset provides unprocessed rental market data that researchers and analysts use to study short-term rental impacts on housing markets. The data includes property details, pricing, availability, host information, and guest reviews in CSV format.",
    "use_cases": [
      "Analyzing rental price trends and market dynamics in different neighborhoods",
      "Research on Airbnb's impact on local housing affordability and availability"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "airbnb rental data download",
      "inside airbnb raw dataset",
      "airbnb listings data for analysis",
      "short term rental market data"
    ]
  },
  {
    "name": "Yongfeng Dataset Collection",
    "description": "E-commerce and recommendation system datasets",
    "category": "Data Portals",
    "url": "https://www.yongfeng.me/dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "recommendations",
      "e-commerce",
      "academic"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "recommender-systems",
      "data-preprocessing"
    ],
    "topic_tags": [
      "recommender-systems",
      "e-commerce",
      "datasets",
      "collaborative-filtering",
      "user-behavior"
    ],
    "summary": "A curated collection of datasets specifically designed for recommendation system research and e-commerce analysis. Contains user-item interaction data, product catalogs, and user behavior logs from various domains. Widely used by researchers and practitioners to benchmark recommendation algorithms and study consumer behavior patterns.",
    "use_cases": [
      "Benchmarking collaborative filtering algorithms against standard datasets",
      "Training recommendation models for academic research or thesis projects"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "recommendation system datasets for research",
      "e-commerce user behavior data download",
      "benchmark datasets collaborative filtering",
      "academic recommendation system data"
    ]
  },
  {
    "name": "Julian McAuley Datasets",
    "description": "Reviews, recommendations, and social network data",
    "category": "Data Portals",
    "url": "https://cseweb.ucsd.edu/~jmcauley/datasets.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "recommendations",
      "UCSD",
      "academic"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-data-cleaning",
      "json-parsing"
    ],
    "topic_tags": [
      "product-reviews",
      "recommendation-systems",
      "social-networks",
      "e-commerce",
      "dataset-collection"
    ],
    "summary": "A collection of publicly available datasets from UCSD containing product reviews, user ratings, and social network data from various platforms like Amazon, Yelp, and others. These datasets are widely used in academic research for recommendation systems, sentiment analysis, and social network studies. The data is preprocessed and ready for analysis, making it accessible for researchers and practitioners working on user behavior and product recommendation problems.",
    "use_cases": [
      "Building a recommendation system for an e-commerce platform using Amazon review data",
      "Analyzing sentiment patterns in restaurant reviews to understand customer preferences"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "Amazon review dataset for recommendation systems",
      "UCSD product review data McAuley",
      "social network datasets for academic research",
      "where to find preprocessed e-commerce review data"
    ]
  },
  {
    "name": "Makridakis Competitions",
    "description": "Time series data for forecasting competitions (M1-M5)",
    "category": "Data Portals",
    "url": "https://www.mcompetitions.unic.ac.cy/the-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "time series",
      "forecasting",
      "M competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "time-series-analysis",
      "python-pandas",
      "forecasting-basics"
    ],
    "topic_tags": [
      "time-series",
      "forecasting",
      "benchmark-datasets",
      "competitions",
      "historical-data"
    ],
    "summary": "The Makridakis Competitions (M1-M5) are a series of influential forecasting competitions that provide standardized time series datasets for benchmarking forecasting methods. These datasets span decades and include various types of time series data from business, economics, and other domains. They serve as the gold standard for evaluating and comparing forecasting algorithms in academic research and industry practice.",
    "use_cases": [
      "Benchmarking a new forecasting algorithm against established baselines using standardized competition data",
      "Teaching forecasting methods by having students practice on well-documented historical datasets with known performance benchmarks"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "forecasting competition datasets",
      "Makridakis time series data",
      "benchmark datasets for forecasting algorithms",
      "M4 M5 competition data download"
    ]
  },
  {
    "name": "RecSys Datasets Collection",
    "description": "Datasets from ACM Recommender Systems challenges",
    "category": "Data Portals",
    "url": "https://github.com/RUCAIBox/RecSysDatasets",
    "docs_url": null,
    "github_url": "https://github.com/RUCAIBox/RecSysDatasets",
    "tags": [
      "RecSys",
      "recommendations",
      "ACM"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "collaborative-filtering"
    ],
    "topic_tags": [
      "recommender-systems",
      "datasets",
      "collaborative-filtering",
      "ACM-challenges",
      "benchmark-data"
    ],
    "summary": "A curated collection of datasets from ACM RecSys challenges, providing standardized benchmarks for recommender systems research and development. These datasets include user-item interactions, ratings, and contextual information from various domains like movies, music, and e-commerce. Widely used by researchers and practitioners to evaluate recommendation algorithms and compare performance across different approaches.",
    "use_cases": [
      "Benchmarking a new collaborative filtering algorithm against established baselines",
      "Learning recommender systems by implementing basic algorithms on clean, well-documented datasets"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "ACM RecSys challenge datasets download",
      "benchmark datasets for recommender systems",
      "where to find recommendation algorithm test data",
      "RecSys competition datasets for research"
    ]
  },
  {
    "name": "NeurIPS Competition Data",
    "description": "Top-tier conference with competitions and benchmarks",
    "category": "Data Portals",
    "url": "https://nips.cc/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NeurIPS",
      "ML",
      "benchmarks"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "pytorch-basics"
    ],
    "topic_tags": [
      "competition-data",
      "ml-benchmarks",
      "neurips",
      "datasets",
      "model-evaluation"
    ],
    "summary": "NeurIPS Competition Data provides curated datasets and benchmarks from the premier machine learning conference's annual competitions. These datasets cover diverse ML challenges from computer vision to reinforcement learning, with established evaluation metrics and baselines. Perfect for learning state-of-the-art methods, comparing model performance, and understanding how top researchers approach complex problems.",
    "use_cases": [
      "Benchmarking a new computer vision model against competition winners to validate performance claims",
      "Learning reinforcement learning by reproducing winning solutions from past NeurIPS competitions"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NeurIPS competition datasets download",
      "machine learning benchmark datasets",
      "where to find ML competition data",
      "NeurIPS challenge data for model testing"
    ]
  },
  {
    "name": "IJCAI Competitions",
    "description": "International AI conference with competitions",
    "category": "Data Portals",
    "url": "https://www.ijcai.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "IJCAI",
      "AI",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-scikit-learn",
      "kaggle-competitions",
      "model-evaluation"
    ],
    "topic_tags": [
      "AI-competitions",
      "benchmark-datasets",
      "competition-platforms",
      "machine-learning",
      "academic-contests"
    ],
    "summary": "IJCAI (International Joint Conference on Artificial Intelligence) hosts annual AI competitions featuring diverse machine learning challenges and benchmark datasets. These competitions provide standardized evaluation frameworks for comparing AI methods across domains like computer vision, NLP, and reinforcement learning. Participants can access high-quality datasets, baseline models, and leaderboards to test their algorithms against state-of-the-art approaches.",
    "use_cases": [
      "Benchmarking a new machine learning algorithm against established baselines on standardized competition datasets",
      "Finding curated datasets with clear evaluation metrics for academic research or method validation"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "IJCAI competition datasets machine learning",
      "AI competition benchmarks academic research",
      "where to find IJCAI challenge data",
      "international AI competition leaderboards"
    ]
  },
  {
    "name": "MSOM Data Challenges",
    "description": "Manufacturing & Service Operations Management challenges",
    "category": "Data Portals",
    "url": "https://pubsonline.informs.org/journal/msom",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "MSOM",
      "operations",
      "INFORMS"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "operations-research-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "operations-management",
      "supply-chain",
      "manufacturing",
      "service-operations",
      "competition-datasets"
    ],
    "summary": "MSOM Data Challenges are annual competitions hosted by INFORMS featuring real-world operations management datasets from manufacturing and service industries. These challenges provide practitioners and researchers with access to high-quality, industry-relevant data for developing and testing operations research methods. The datasets typically focus on supply chain optimization, demand forecasting, inventory management, and service delivery problems.",
    "use_cases": [
      "Developing demand forecasting models for retail inventory management using real transaction data",
      "Optimizing manufacturing scheduling algorithms with actual production line constraints and performance metrics"
    ],
    "audience": [
      "Mid-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "operations management datasets for forecasting",
      "MSOM challenge data supply chain optimization",
      "manufacturing operations research competition data",
      "service operations management real datasets"
    ]
  },
  {
    "name": "Data Mining Cup",
    "description": "Industry-sponsored data mining competitions",
    "category": "Data Portals",
    "url": "https://www.data-mining-cup.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "data mining",
      "industry",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "data-mining",
      "competitions",
      "industry-datasets",
      "predictive-modeling",
      "benchmarking"
    ],
    "summary": "Data Mining Cup provides industry-sponsored data mining competitions with real-world datasets and business problems. These competitions offer hands-on experience with practical data science challenges while allowing participants to benchmark their skills against others. The datasets typically come from actual companies looking to solve specific business problems through data analysis.",
    "use_cases": [
      "Junior data scientist wanting to practice on real industry problems before applying techniques at work",
      "PhD student seeking to test academic methods on practical business datasets with ground truth"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "industry data mining competitions",
      "real world datasets for practice",
      "business problem datasets",
      "data science competition platforms"
    ]
  },
  {
    "name": "KDD Cup",
    "description": "ACM SIGKDD annual data mining competition",
    "category": "Data Portals",
    "url": "https://kdd.org/kdd-cup",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "KDD",
      "data mining",
      "ACM"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "exploratory-data-analysis"
    ],
    "topic_tags": [
      "data-mining",
      "machine-learning-competitions",
      "benchmark-datasets",
      "classification",
      "clustering"
    ],
    "summary": "KDD Cup is the premier annual data mining competition organized by ACM SIGKDD, featuring real-world datasets and challenging machine learning problems. It provides standardized benchmark datasets that have become foundational for evaluating new algorithms and methods in data science. The competition attracts thousands of participants globally and serves as a testing ground for cutting-edge data mining techniques.",
    "use_cases": [
      "Benchmarking a new classification algorithm against established baselines using historical KDD Cup datasets",
      "Learning practical data mining skills by participating in the current year's competition with real industry problems"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "KDD Cup datasets for machine learning practice",
      "data mining competition benchmark datasets",
      "ACM SIGKDD annual competition problems",
      "real world datasets for algorithm testing"
    ]
  },
  {
    "name": "Marketing Science Databases",
    "description": "INFORMS conference with data-focused opportunities",
    "category": "Data Portals",
    "url": "https://pubsonline.informs.org/page/mksc/online-databases",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "marketing",
      "INFORMS",
      "databases"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "SQL-basics",
      "research-design-fundamentals"
    ],
    "topic_tags": [
      "marketing-data",
      "academic-databases",
      "consumer-behavior",
      "INFORMS",
      "research-datasets"
    ],
    "summary": "Marketing Science Databases is a collection of research datasets made available through INFORMS conferences and publications. These databases contain real-world marketing data including consumer behavior, advertising effectiveness, and market research studies. The datasets are primarily used by academics and industry researchers for empirical marketing research and methodology development.",
    "use_cases": [
      "Academic researcher studying consumer response to digital advertising campaigns using real transaction and exposure data",
      "Marketing analyst validating pricing models against historical customer purchase behavior from retail chains"
    ],
    "audience": [
      "Early-PhD",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "marketing research datasets for academic studies",
      "INFORMS marketing science data collection",
      "consumer behavior databases for research",
      "where to find marketing experiment data"
    ]
  },
  {
    "name": "DrivenData",
    "description": "Data science competitions for social impact",
    "category": "Data Portals",
    "url": "https://www.drivendata.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social impact",
      "competitions",
      "non-profit"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "jupyter-notebooks"
    ],
    "topic_tags": [
      "data-competitions",
      "social-impact",
      "public-datasets",
      "kaggle-style",
      "non-profit"
    ],
    "summary": "DrivenData hosts data science competitions focused on solving social and environmental challenges for non-profit organizations. Unlike traditional competitions, these emphasize real-world impact in areas like health, education, and sustainability. Participants can access curated datasets, compete for prizes, and contribute to meaningful causes while building portfolio projects.",
    "use_cases": [
      "Building a portfolio with social impact projects while learning competition-style data science",
      "Accessing real-world datasets from non-profits for educational or research purposes"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "data science competitions for good",
      "kaggle alternatives social impact",
      "non-profit datasets machine learning",
      "beginner friendly data science competitions"
    ]
  },
  {
    "name": "CodaLab",
    "description": "Platform for competitions, benchmarks, and reproducible research",
    "category": "Data Portals",
    "url": "https://codalab.lisn.upsaclay.fr/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "benchmarks",
      "reproducibility",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-basics",
      "git-version-control"
    ],
    "topic_tags": [
      "research-competitions",
      "model-benchmarking",
      "reproducible-research",
      "dataset-hosting"
    ],
    "summary": "CodaLab is a collaborative platform that hosts machine learning competitions, research benchmarks, and enables reproducible computational research. It allows researchers to share datasets, code, and evaluation metrics while providing standardized environments for fair model comparisons. The platform is widely used for organizing challenges and maintaining leaderboards across various ML domains.",
    "use_cases": [
      "Participating in a computer vision challenge with standardized evaluation metrics",
      "Hosting a research benchmark to compare different NLP models on the same dataset"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "Where can I find ML competitions to practice on?",
      "How to benchmark my model against others reproducibly?",
      "Platform for hosting research competitions",
      "CodaLab alternatives for model evaluation"
    ]
  },
  {
    "name": "OpenML",
    "description": "Platform for sharing datasets, tasks, and ML code",
    "category": "Data Portals",
    "url": "https://www.openml.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "ML",
      "open science",
      "benchmarks"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-scikit-learn",
      "machine-learning-basics",
      "data-preprocessing"
    ],
    "topic_tags": [
      "open-data",
      "ml-benchmarks",
      "reproducible-research",
      "dataset-sharing",
      "model-evaluation"
    ],
    "summary": "OpenML is a collaborative platform for sharing machine learning datasets, experiments, and code with standardized formats and APIs. It provides access to thousands of curated datasets with metadata, enabling reproducible research and fair model comparisons. The platform is widely used by researchers and practitioners for benchmarking algorithms and sharing experimental results.",
    "use_cases": [
      "Comparing multiple ML algorithms on standardized benchmark datasets for research publication",
      "Finding pre-processed datasets with established baselines for prototyping new models"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "where to find benchmark datasets for machine learning",
      "platform for sharing ML experiments and code",
      "standardized datasets for algorithm comparison",
      "open source machine learning data repository"
    ]
  },
  {
    "name": "RecSys Challenge 2025 (Synerise)",
    "description": "1M users, 6 months of real e-commerce behavior logs with 5 event types for universal behavioral modeling",
    "category": "Data Portals",
    "url": "https://recsys.synerise.com/data-set",
    "docs_url": "https://recsys.synerise.com/",
    "github_url": "https://github.com/Synerise/recsys2025",
    "tags": [
      "RecSys",
      "e-commerce",
      "large-scale",
      "real-world",
      "2025",
      "user behavior"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "jupyter-notebooks"
    ],
    "topic_tags": [
      "recommender-systems",
      "e-commerce-data",
      "behavioral-analytics",
      "large-scale-datasets"
    ],
    "summary": "A comprehensive dataset from the 2025 RecSys Challenge containing 1 million users' e-commerce behavioral logs over 6 months. Features 5 distinct event types capturing real shopping interactions for developing and benchmarking recommendation algorithms. Ideal for learning recommendation systems and testing behavioral modeling approaches on realistic, large-scale data.",
    "use_cases": [
      "Building recommendation models for e-commerce platforms using real user interaction patterns",
      "Benchmarking collaborative filtering algorithms against industry-standard datasets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "RecSys challenge 2025 dataset download",
      "large scale e-commerce user behavior data",
      "recommendation system benchmark datasets",
      "real world shopping behavior logs for ML"
    ]
  },
  {
    "name": "RecSys Challenge 2024 (EB-NeRD)",
    "description": "2.3M users, 380M+ news impressions from Ekstra Bladet for news recommendation research",
    "category": "Data Portals",
    "url": "https://www.recsyschallenge.com/2024/",
    "docs_url": null,
    "github_url": "https://github.com/recsyspolimi/recsys-challenge-2024-ekstrabladet",
    "tags": [
      "RecSys",
      "news",
      "large-scale",
      "real-world",
      "2024",
      "impressions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "recommender-systems",
      "implicit-feedback"
    ],
    "topic_tags": [
      "news-recommendation",
      "large-scale-datasets",
      "user-behavior",
      "implicit-feedback",
      "recsys-challenge"
    ],
    "summary": "A massive dataset from Ekstra Bladet containing 2.3 million users and 380+ million news article impressions, designed for the 2024 RecSys Challenge. This real-world dataset enables researchers to develop and benchmark news recommendation algorithms on authentic user behavior patterns. It's particularly valuable for studying implicit feedback scenarios where user engagement signals drive recommendations.",
    "use_cases": [
      "Benchmarking news recommendation algorithms against other RecSys Challenge participants",
      "Training deep learning models for personalized news delivery in production systems"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "RecSys Challenge 2024 dataset news recommendation",
      "large scale news impression data machine learning",
      "Ekstra Bladet user behavior dataset",
      "real world news recommendation training data"
    ]
  },
  {
    "name": "Amazon ShopBench (KDD Cup 2024)",
    "description": "57 tasks, 20K questions derived from real Amazon shopping data for LLM shopping assistants",
    "category": "Data Portals",
    "url": "https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms",
    "docs_url": null,
    "github_url": "https://github.com/fzp0424/ec-guide-kddup-2024",
    "tags": [
      "KDD",
      "Amazon",
      "e-commerce",
      "LLM",
      "2024",
      "multi-task"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-transformers",
      "pytorch-datasets",
      "multi-task-learning"
    ],
    "topic_tags": [
      "shopping-assistant",
      "e-commerce-nlp",
      "llm-evaluation",
      "multi-task-benchmark",
      "conversational-ai"
    ],
    "summary": "Amazon ShopBench is a comprehensive benchmark dataset from KDD Cup 2024 containing 57 diverse tasks and 20,000 questions derived from real Amazon shopping scenarios. It's designed to evaluate and train LLM-based shopping assistants across multiple e-commerce use cases including product search, recommendation, and customer service. The dataset provides a standardized way to assess conversational AI performance in retail contexts.",
    "use_cases": [
      "Training and evaluating chatbots for e-commerce customer support and product recommendations",
      "Benchmarking multi-task LLM performance on real-world shopping assistant scenarios"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "KDD Cup 2024 Amazon shopping assistant dataset",
      "multi-task benchmark for e-commerce LLMs",
      "Amazon ShopBench evaluation dataset",
      "shopping chatbot training data with real queries"
    ]
  },
  {
    "name": "DrivenData Water Supply Forecasting (2024)",
    "description": "Western US water supply data from Bureau of Reclamation, $500K prize pool for seasonal forecasting",
    "category": "Data Portals",
    "url": "https://www.drivendata.org/competitions/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "climate",
      "forecasting",
      "2024",
      "government data",
      "real-world",
      "time series"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "time-series-analysis",
      "python-pandas",
      "cross-validation"
    ],
    "topic_tags": [
      "water-forecasting",
      "seasonal-prediction",
      "government-datasets",
      "climate-modeling",
      "competition-data"
    ],
    "summary": "A comprehensive dataset from the US Bureau of Reclamation containing Western US water supply measurements for seasonal forecasting challenges. This competition dataset offers real-world hydrology data with a $500K prize pool, making it ideal for practicing time series forecasting on climate-critical infrastructure. The data includes historical water supply measurements across multiple Western US locations with associated meteorological and geographic features.",
    "use_cases": [
      "Building seasonal water supply prediction models for municipal planning",
      "Benchmarking time series forecasting algorithms on real climate data"
    ],
    "audience": [
      "Mid-DS",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "water supply forecasting competition dataset",
      "bureau of reclamation seasonal prediction data",
      "western US hydrology time series data",
      "climate forecasting practice datasets"
    ]
  },
  {
    "name": "OpenStreetMap Planet",
    "description": "84GB PBF (2TB+ uncompressed) complete world map database with full edit history, weekly updates",
    "category": "Social & Web",
    "url": "https://planet.openstreetmap.org/",
    "docs_url": "https://wiki.openstreetmap.org/wiki/Planet.osm",
    "github_url": null,
    "tags": [
      "database dump",
      "geospatial",
      "large-scale",
      "real-world",
      "PostgreSQL",
      "messy data"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "PostgreSQL",
      "python-geopandas",
      "PostGIS"
    ],
    "topic_tags": [
      "geospatial-data",
      "open-data",
      "database-management",
      "spatial-analysis",
      "data-processing"
    ],
    "summary": "OpenStreetMap Planet is the complete global database of crowdsourced geographic data, containing roads, buildings, points of interest, and their full edit histories. This massive dataset requires specialized tools and infrastructure to process but provides unparalleled global coverage for spatial analysis. It's the go-to resource for researchers and practitioners working with real-world geographic data at scale.",
    "use_cases": [
      "Building location-based recommendation systems using POI data and road networks",
      "Analyzing urban development patterns by comparing map edits over time across different cities"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "complete OpenStreetMap database download",
      "large scale geospatial dataset for analysis",
      "global map data with edit history",
      "PostGIS compatible geographic database"
    ]
  },
  {
    "name": "Wikipedia Full Database Dump",
    "description": "Complete Wikipedia content and metadata in SQL/XML format, includes all revisions and edit history",
    "category": "Social & Web",
    "url": "https://dumps.wikimedia.org/",
    "docs_url": "https://en.wikipedia.org/wiki/Wikipedia:Database_download",
    "github_url": null,
    "tags": [
      "database dump",
      "SQL",
      "large-scale",
      "text",
      "real-world",
      "encyclopedic"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "SQL-queries",
      "python-pandas",
      "text-preprocessing"
    ],
    "topic_tags": [
      "wikipedia-data",
      "text-mining",
      "database-dump",
      "revision-history",
      "large-scale-text"
    ],
    "summary": "Complete Wikipedia database containing all articles, edit histories, and metadata in structured SQL/XML format. This massive dataset enables researchers to study collaborative knowledge creation, information diffusion, and large-scale text analysis. The full revision history makes it valuable for studying how information evolves over time and analyzing editor behavior patterns.",
    "use_cases": [
      "Analyzing how controversial topics evolve by tracking edit patterns and revision histories across politically sensitive articles",
      "Building large-scale natural language processing models using Wikipedia's structured, multilingual text corpus with metadata"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "wikipedia database dump download",
      "wikipedia edit history analysis dataset",
      "large scale text corpus wikipedia SQL",
      "wikipedia revision tracking data mining"
    ]
  },
  {
    "name": "UK Land Registry Price Paid",
    "description": "4.3GB of UK property sales transactions going back decades, messy real-world government data",
    "category": "Real Estate",
    "url": "https://www.gov.uk/government/collections/price-paid-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "UK",
      "government data",
      "large-scale",
      "transactions",
      "messy data"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "SQL-basics"
    ],
    "topic_tags": [
      "real-estate",
      "government-data",
      "UK-housing",
      "transaction-data",
      "data-cleaning"
    ],
    "summary": "The UK Land Registry Price Paid dataset contains 4.3GB of property sales transactions spanning decades of UK housing market activity. This messy, real-world government dataset provides comprehensive records of residential and commercial property purchases across England and Wales. It's an excellent resource for learning data cleaning techniques while exploring housing market trends and building real estate analytics models.",
    "use_cases": [
      "Building a housing price prediction model for UK properties",
      "Analyzing regional housing market trends and gentrification patterns over time"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "UK housing data for machine learning",
      "real estate transaction dataset",
      "UK property prices historical data",
      "messy government dataset for practice"
    ]
  },
  {
    "name": "Redfin Housing Market Data",
    "description": "Downloadable housing market data: home prices, sales, inventory, listings by metro/city/zip. Updated weekly from MLS",
    "category": "Real Estate",
    "url": "https://www.redfin.com/news/data-center/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "housing prices",
      "large-scale",
      "real-world",
      "time series"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-statistics"
    ],
    "topic_tags": [
      "housing-market",
      "time-series-data",
      "real-estate-analytics",
      "MLS-data",
      "market-trends"
    ],
    "summary": "Comprehensive housing market dataset from Redfin containing weekly updates on home prices, sales volumes, inventory levels, and listings across US metros, cities, and zip codes. The data is sourced from Multiple Listing Services (MLS) and provides ready-to-use insights for real estate market analysis. Ideal for practitioners learning time series analysis or conducting housing market research.",
    "use_cases": [
      "Analyzing housing price trends and seasonality patterns across different metropolitan areas",
      "Building predictive models for real estate investment decisions using inventory and sales data"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "housing market data for time series analysis",
      "real estate prices dataset by city",
      "Redfin MLS data download",
      "weekly housing inventory and sales data"
    ]
  },
  {
    "name": "Zillow Research Data",
    "description": "Home values (ZHVI), rents (ZORI), inventory, and market heat indices across US metros and zip codes",
    "category": "Real Estate",
    "url": "https://www.zillow.com/research/data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "housing prices",
      "rents",
      "large-scale",
      "time series"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "housing-data",
      "time-series",
      "real-estate-economics",
      "market-analysis",
      "zillow"
    ],
    "summary": "Comprehensive dataset from Zillow containing standardized home values, rental prices, inventory levels, and market activity metrics across US metropolitan areas and zip codes. The data includes their flagship Home Value Index (ZHVI) and rental index (ZORI) with historical time series going back over a decade. Essential resource for housing market research, real estate economics, and regional economic analysis.",
    "use_cases": [
      "Analyzing housing affordability trends across different metropolitan areas for urban economics research",
      "Building predictive models for real estate investment decisions using historical price and inventory data"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "housing price data by zip code",
      "zillow home value index dataset",
      "real estate market trends data",
      "rental price time series data US metros"
    ]
  },
  {
    "name": "IEEE-CIS Fraud Detection",
    "description": "590K card-not-present transactions with 393 features from Vesta Corp. Real messy fraud data (3.5% fraud rate)",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/competitions/ieee-fraud-detection",
    "docs_url": null,
    "github_url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "tags": [
      "fraud detection",
      "transactions",
      "large-scale",
      "messy data",
      "fintech",
      "competition"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "imbalanced-classification",
      "feature-engineering"
    ],
    "topic_tags": [
      "fraud-detection",
      "financial-services",
      "imbalanced-data",
      "feature-engineering",
      "kaggle-dataset"
    ],
    "summary": "A large-scale fraud detection dataset with 590K real-world card-not-present transactions from Vesta Corp, featuring 393 anonymized features and a 3.5% fraud rate. This messy, realistic dataset was used in a Kaggle competition and represents the challenges of production fraud detection systems. Perfect for practicing feature engineering, handling imbalanced data, and building robust classification models on noisy financial data.",
    "use_cases": [
      "Building fraud detection models for payment processors or fintech companies",
      "Benchmarking machine learning algorithms on imbalanced classification problems"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "fraud detection dataset with real transaction data",
      "imbalanced classification dataset for credit card fraud",
      "large scale financial fraud data for machine learning",
      "messy fraud detection dataset with feature engineering challenges"
    ]
  },
  {
    "name": "MSOM Pharma Manufacturing (2024)",
    "description": "Continuous pharmaceutical manufacturing data from MSD. Real production processes for operations management research",
    "category": "Logistics & Supply Chain",
    "url": "https://pubsonline.informs.org/page/msom/data-driven-challenge",
    "docs_url": "https://pubsonline.informs.org/doi/10.1287/msom.2024.0860",
    "github_url": null,
    "tags": [
      "manufacturing",
      "operations",
      "INFORMS",
      "2024",
      "real-world",
      "competition"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "operations-research",
      "statistical-process-control"
    ],
    "topic_tags": [
      "pharmaceutical-manufacturing",
      "operations-research",
      "supply-chain-optimization",
      "process-data",
      "INFORMS"
    ],
    "summary": "Real-world continuous pharmaceutical manufacturing dataset from MSD containing production process data for operations management research. This dataset provides authentic industry data for analyzing manufacturing efficiency, quality control, and supply chain optimization in pharmaceutical production. Researchers and practitioners can use it to develop and validate operations research models for pharmaceutical manufacturing.",
    "use_cases": [
      "Developing predictive models for pharmaceutical production yield and quality optimization",
      "Benchmarking supply chain disruption mitigation strategies using real manufacturing process data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "pharmaceutical manufacturing dataset for operations research",
      "real pharma production data MSD",
      "continuous manufacturing process optimization data",
      "INFORMS pharmaceutical supply chain dataset"
    ]
  },
  {
    "name": "NBER Public Use Data Archive",
    "description": "Eclectic mix of economic, demographic, and enterprise data from NBER-affiliated research projects",
    "category": "Data Portals",
    "url": "https://www.nber.org/research/data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "research",
      "research",
      "NBER",
      "demographics",
      "enterprise"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-cleaning",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "economic-data",
      "demographics",
      "research-datasets",
      "NBER",
      "public-data"
    ],
    "summary": "The NBER Public Use Data Archive provides free access to datasets from National Bureau of Economic Research projects, covering topics from labor economics to firm-level analysis. These datasets have been used in published academic research and offer cleaned, documented data for replication and new studies. It's particularly valuable for researchers and students who need established datasets with clear provenance.",
    "use_cases": [
      "Replicating results from published NBER working papers using the original datasets",
      "Finding demographic or economic panel data for thesis research or course projects"
    ],
    "audience": [
      "Early-PhD",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NBER datasets for economics research",
      "free economic data for academic projects",
      "where to find demographic data from NBER studies",
      "public datasets used in economics papers"
    ]
  },
  {
    "name": "PaySim Synthetic Transactions",
    "description": "6M+ mobile money transactions simulating real fraud patterns. Agent-based model calibrated on real African mobile money logs",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/ealaxi/paysim1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fraud detection",
      "mobile payments",
      "transactions",
      "large-scale",
      "synthetic"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "imbalanced-learn"
    ],
    "topic_tags": [
      "fraud-detection",
      "mobile-payments",
      "synthetic-data",
      "financial-transactions",
      "large-scale-dataset"
    ],
    "summary": "PaySim is a synthetic dataset containing over 6 million mobile money transactions designed to simulate real-world fraud patterns from African mobile payment systems. The dataset was generated using an agent-based model calibrated on actual transaction logs, making it ideal for fraud detection research and model development. It provides a realistic, large-scale playground for testing machine learning approaches without privacy concerns.",
    "use_cases": [
      "Building and benchmarking fraud detection models for mobile payment systems",
      "Learning data science techniques on a realistic large-scale financial dataset"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "mobile money fraud detection dataset",
      "synthetic financial transactions for machine learning",
      "large scale payment fraud data",
      "African mobile payments simulation data"
    ]
  },
  {
    "name": "Chicago TNC Trips",
    "description": "100M+ rideshare trips with fares (unlike NYC which lacks fare data). Trip-level pricing for Uber/Lyft economic analysis",
    "category": "Transportation & Mobility",
    "url": "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "rideshare",
      "fares",
      "Uber",
      "Lyft",
      "Chicago",
      "pricing"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "regression-analysis",
      "SQL-aggregations"
    ],
    "topic_tags": [
      "rideshare-pricing",
      "fare-data",
      "transportation-economics",
      "demand-modeling",
      "chicago-data"
    ],
    "summary": "Comprehensive dataset of 100M+ Chicago rideshare trips including detailed fare information for Uber and Lyft rides. Unlike other major city datasets (such as NYC), this includes complete pricing data enabling economic analysis of rideshare markets. Ideal for studying pricing strategies, demand patterns, and competitive dynamics in the gig economy transportation sector.",
    "use_cases": [
      "Analyzing surge pricing algorithms and demand elasticity across different Chicago neighborhoods and time periods",
      "Building predictive models for rideshare pricing to understand competitive dynamics between Uber and Lyft"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "rideshare fare data with pricing information",
      "Chicago Uber Lyft trip dataset with fares",
      "transportation economics rideshare pricing analysis data",
      "rideshare demand modeling dataset Chicago"
    ]
  },
  {
    "name": "Criteo Counterfactual Learning",
    "description": "25M logged interactions with counterfactual propensity scores. Gold standard for offline policy evaluation and causal inference in ads",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/criteo-uplift-prediction-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "causal inference",
      "counterfactual",
      "advertising",
      "uplift modeling",
      "offline evaluation"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "advanced",
    "prerequisites": [
      "propensity-score-matching",
      "inverse-probability-weighting",
      "python-scikit-learn"
    ],
    "topic_tags": [
      "counterfactual-learning",
      "offline-policy-evaluation",
      "logged-bandit-feedback",
      "ad-targeting",
      "causal-inference"
    ],
    "summary": "A large-scale dataset of 25 million real-world advertising interactions with pre-computed propensity scores for counterfactual analysis. This is the gold standard benchmark for researchers developing offline policy evaluation methods and testing causal inference algorithms in advertising contexts. The dataset enables rigorous comparison of different approaches for learning from logged bandit feedback without online experimentation.",
    "use_cases": [
      "Benchmarking new offline policy evaluation algorithms against established baselines",
      "Training counterfactual models to predict ad campaign performance before deployment"
    ],
    "audience": [
      "Senior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "criteo counterfactual learning dataset",
      "offline policy evaluation advertising data",
      "propensity scored ad interaction dataset",
      "benchmark dataset for counterfactual inference"
    ]
  },
  {
    "name": "OTTO Session-based Recommendations",
    "description": "12M+ e-commerce sessions with click \u2192 cart \u2192 order sequences. Real multi-stage conversion funnel data from German retailer",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/otto/recsys-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "sessions",
      "conversion funnel",
      "Kaggle",
      "recommendations",
      "e-commerce"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "recommendation-systems",
      "session-data-analysis"
    ],
    "topic_tags": [
      "session-based-recommendations",
      "conversion-funnel",
      "e-commerce-data",
      "multi-stage-modeling",
      "kaggle-dataset"
    ],
    "summary": "Large-scale dataset of 12M+ real e-commerce user sessions from a German retailer, capturing the complete customer journey from clicks to cart additions to purchases. Contains sequential behavioral data ideal for building session-based recommendation systems and analyzing conversion funnels. Popular Kaggle competition dataset that provides realistic multi-stage conversion patterns for experimentation.",
    "use_cases": [
      "Building session-based recommendation models that predict next item interactions based on user click sequences",
      "Analyzing conversion funnel drop-offs to optimize e-commerce checkout flows and reduce cart abandonment"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "session based recommendation dataset",
      "e-commerce conversion funnel data",
      "OTTO kaggle dataset download",
      "multi-stage recommendation system data"
    ]
  },
  {
    "name": "LendingClub Loans",
    "description": "2.7M loans (2007-2019) with 151 features. Interest rates, credit scores, defaults. The canonical P2P lending dataset for credit risk modeling",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/wordsforthewise/lending-club",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P lending",
      "credit risk",
      "loans",
      "defaults",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "feature-engineering"
    ],
    "topic_tags": [
      "credit-risk",
      "p2p-lending",
      "default-prediction",
      "fintech",
      "tabular-data"
    ],
    "summary": "A comprehensive dataset of 2.7 million peer-to-peer loans from LendingClub spanning 2007-2019, featuring 151 variables including borrower demographics, credit scores, loan terms, and default outcomes. This is the go-to dataset for learning credit risk modeling and default prediction in fintech applications. Perfect for practicing classification techniques and understanding how lending platforms assess borrower risk.",
    "use_cases": [
      "Building default prediction models for loan approval systems",
      "Analyzing factors that drive interest rate pricing in peer-to-peer lending"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "lending club dataset credit risk modeling",
      "peer to peer loan default prediction data",
      "fintech credit scoring dataset with outcomes",
      "loan approval machine learning training data"
    ]
  },
  {
    "name": "Amazon Fraud Detection Benchmark",
    "description": "9 consolidated fraud datasets with unified format. Includes IEEE-CIS, credit card, e-commerce fraud. Benchmark for fraud ML research",
    "category": "Financial Services",
    "url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "docs_url": null,
    "github_url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "tags": [
      "fraud detection",
      "benchmark",
      "Amazon",
      "ML",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "binary-classification"
    ],
    "topic_tags": [
      "fraud-detection",
      "benchmark-datasets",
      "financial-ml",
      "classification",
      "fintech"
    ],
    "summary": "A collection of 9 standardized fraud detection datasets from Amazon Research, consolidating major public datasets like IEEE-CIS and credit card fraud data into a unified format. This benchmark enables researchers and practitioners to compare fraud detection algorithms across consistent data formats and evaluation metrics. Perfect for learning fraud ML techniques or testing new detection methods.",
    "use_cases": [
      "Testing a new fraud detection algorithm against established benchmarks",
      "Learning fraud detection by practicing on real-world formatted datasets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "fraud detection benchmark datasets",
      "Amazon fraud detection data",
      "standardized fraud ML datasets",
      "credit card fraud benchmark data"
    ]
  },
  {
    "name": "ORBITAAL Bitcoin Transactions",
    "description": "13 years of Bitcoin transaction graphs (2009-2022). Complete blockchain with labeled entities. network analysis at scale",
    "category": "Financial Services",
    "url": "https://zenodo.org/records/7958648",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Bitcoin",
      "blockchain",
      "transactions",
      "network analysis",
      "cryptocurrency"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-networkx",
      "graph-theory",
      "pandas-dataframes"
    ],
    "topic_tags": [
      "bitcoin-blockchain",
      "transaction-networks",
      "cryptocurrency-analysis",
      "temporal-graphs",
      "labeled-entities"
    ],
    "summary": "Complete 13-year Bitcoin blockchain dataset with transaction graphs and labeled entities from 2009-2022. Essential resource for cryptocurrency researchers and data scientists studying blockchain networks. Enables large-scale analysis of payment flows, entity behavior, and network evolution over Bitcoin's entire history.",
    "use_cases": [
      "Analyzing money laundering patterns and suspicious transaction flows for compliance research",
      "Studying Bitcoin network evolution and adoption patterns for cryptocurrency market analysis"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "bitcoin transaction network dataset with labels",
      "blockchain graph analysis historical data",
      "cryptocurrency transaction flows 2009-2022",
      "labeled bitcoin entities network analysis"
    ]
  },
  {
    "name": "LOBSTER Order Book",
    "description": "NASDAQ limit order book data at millisecond precision. Level 1-10 depth, message-by-message reconstruction. Market microstructure research",
    "category": "Financial Services",
    "url": "https://lobsterdata.com/",
    "docs_url": "https://lobsterdata.com/info/DataStructure.php",
    "github_url": null,
    "tags": [
      "order book",
      "NASDAQ",
      "high-frequency",
      "market microstructure",
      "trading"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "advanced",
    "prerequisites": [
      "python-pandas",
      "time-series-analysis",
      "financial-markets-knowledge"
    ],
    "topic_tags": [
      "limit-order-book",
      "high-frequency-trading",
      "market-microstructure",
      "financial-data",
      "millisecond-data"
    ],
    "summary": "NASDAQ's millisecond-precision limit order book data providing complete market depth and message-by-message reconstruction. Essential for market microstructure research, high-frequency trading analysis, and understanding price formation dynamics. Enables detailed study of order flow, liquidity patterns, and market maker behavior.",
    "use_cases": [
      "Analyzing market impact of large trades and optimal execution strategies",
      "Studying bid-ask spread dynamics and liquidity provision patterns during market stress"
    ],
    "audience": [
      "Senior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "NASDAQ order book data for market microstructure research",
      "high frequency trading dataset with millisecond precision",
      "limit order book data for liquidity analysis",
      "market depth data for price formation studies"
    ]
  },
  {
    "name": "FI-2010 Limit Order Book",
    "description": "4.3M samples of NASDAQ Nordic limit order book data. 10 depth levels, 5 stocks, normalized features. Benchmark for price prediction",
    "category": "Financial Services",
    "url": "https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "order book",
      "limit orders",
      "NASDAQ",
      "price prediction",
      "benchmark"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "time-series-analysis",
      "neural-networks"
    ],
    "topic_tags": [
      "limit-order-book",
      "high-frequency-trading",
      "price-prediction",
      "financial-microstructure",
      "benchmark-dataset"
    ],
    "summary": "High-frequency NASDAQ Nordic limit order book data with 4.3 million samples across 5 stocks and 10 depth levels. Widely used benchmark dataset for developing and evaluating algorithmic trading models and price movement prediction algorithms. Features are normalized and structured for machine learning applications in financial markets.",
    "use_cases": [
      "Training deep learning models to predict short-term price movements in equity markets",
      "Benchmarking high-frequency trading algorithms against standardized market microstructure data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "limit order book dataset machine learning",
      "NASDAQ high frequency trading data",
      "price prediction benchmark financial data",
      "order book depth levels training data"
    ]
  },
  {
    "name": "OPTN Organ Transplant",
    "description": "Complete US organ donation records since 1987. Waiting lists, donor-recipient matches, outcomes. Market design and matching research",
    "category": "Healthcare",
    "url": "https://optn.transplant.hrsa.gov/data/",
    "docs_url": "https://optn.transplant.hrsa.gov/data/about-data/",
    "github_url": null,
    "tags": [
      "organ transplant",
      "matching",
      "market design",
      "healthcare",
      "waitlists"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "survival-analysis",
      "matching-algorithms"
    ],
    "topic_tags": [
      "organ-transplant",
      "matching-markets",
      "healthcare-data",
      "survival-analysis",
      "market-design"
    ],
    "summary": "Comprehensive dataset of US organ donation and transplant records from 1987 to present, maintained by the Organ Procurement and Transplantation Network. Contains detailed information on waiting lists, donor-recipient matching, transplant outcomes, and patient survival rates. Widely used by economists and researchers studying matching markets, healthcare allocation mechanisms, and medical outcomes.",
    "use_cases": [
      "Analyzing the effectiveness of kidney allocation algorithms and their impact on patient outcomes",
      "Studying geographic disparities in organ availability and wait times across different regions"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "organ transplant matching algorithm data",
      "kidney allocation market design dataset",
      "OPTN transplant outcomes survival analysis",
      "healthcare matching markets research data"
    ]
  },
  {
    "name": "FCC Spectrum Auctions",
    "description": "87+ auctions (1994-present) with round-by-round bidding data. Complete bid histories, reserve prices, winners. Auction theory empirics",
    "category": "Auctions & Marketplaces",
    "url": "https://www.fcc.gov/auctions-summary",
    "docs_url": "https://www.fcc.gov/auction/",
    "github_url": null,
    "tags": [
      "spectrum auctions",
      "FCC",
      "bidding",
      "auction theory",
      "telecommunications"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "auction-theory",
      "regression-analysis"
    ],
    "topic_tags": [
      "spectrum-auctions",
      "bidding-data",
      "auction-theory",
      "telecommunications",
      "empirical-analysis"
    ],
    "summary": "Complete bidding dataset from 87+ FCC spectrum auctions spanning 1994 to present, containing round-by-round bid histories, reserve prices, and winner information. This rich empirical dataset enables researchers to test auction theory predictions and analyze bidding strategies in high-stakes telecommunications markets. The data supports both descriptive analysis of auction outcomes and structural modeling of bidder behavior.",
    "use_cases": [
      "Testing whether bidding follows theoretical predictions like revenue equivalence or strategic demand reduction",
      "Estimating bidder valuations and market power effects in telecommunications spectrum markets"
    ],
    "audience": [
      "Early-PhD",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "FCC spectrum auction bidding data",
      "auction theory empirical dataset",
      "telecommunications spectrum auction results",
      "round by round bidding data FCC"
    ]
  },
  {
    "name": "USASpending Federal Awards",
    "description": "All federal contracts, grants, loans since 2001. 400+ variables, $50T+ in awards. Government procurement analytics",
    "category": "Data Portals",
    "url": "https://www.usaspending.gov/download_center/award_data_archive",
    "docs_url": "https://www.usaspending.gov/data-dictionary",
    "github_url": null,
    "tags": [
      "government",
      "procurement",
      "contracts",
      "grants",
      "federal spending"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "data-visualization"
    ],
    "topic_tags": [
      "government-data",
      "procurement-analysis",
      "public-spending",
      "contract-data",
      "federal-awards"
    ],
    "summary": "Comprehensive database of all federal government spending including contracts, grants, and loans since 2001, totaling over $50 trillion in awards. Contains detailed information on recipients, award amounts, agencies, and procurement methods across 400+ variables. Essential resource for analyzing government spending patterns, vendor relationships, and public sector economics.",
    "use_cases": [
      "Analyzing which companies receive the most federal contracts in specific industries",
      "Studying geographic distribution of federal grant funding across states and congressional districts"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "federal government spending data by company",
      "USASpending database for procurement analysis",
      "government contracts and grants dataset",
      "federal award data for economic research"
    ]
  },
  {
    "name": "Census Business Dynamics Statistics",
    "description": "8M+ establishments with firm age data. Job creation/destruction, startups, exits. Longitudinal firm dynamics since 1977",
    "category": "Data Portals",
    "url": "https://www.census.gov/programs-surveys/bds.html",
    "docs_url": "https://www.census.gov/programs-surveys/bds/documentation.html",
    "github_url": null,
    "tags": [
      "Census",
      "firm dynamics",
      "startups",
      "employment",
      "longitudinal"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "stata-basics",
      "panel-data-analysis"
    ],
    "topic_tags": [
      "firm-dynamics",
      "business-demographics",
      "longitudinal-data",
      "establishment-data",
      "job-flows"
    ],
    "summary": "The Census Business Dynamics Statistics provides comprehensive longitudinal data on over 8 million U.S. establishments, tracking firm births, deaths, job creation and destruction from 1977 onwards. This dataset is essential for researchers studying entrepreneurship, labor market dynamics, and business cycle effects on firm behavior. It enables analysis of startup rates, firm survival, employment growth patterns, and regional economic development.",
    "use_cases": [
      "Analyzing how startup formation varies across industries and regions during economic recessions",
      "Measuring job reallocation rates and studying which firm characteristics predict high growth"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "firm age data job creation destruction",
      "longitudinal establishment data census",
      "startup exit rates by industry dataset",
      "business dynamics statistics firm survival"
    ]
  },
  {
    "name": "PatentsView",
    "description": "13M+ US patents (1976-present) with citations, inventors, assignees. Full patent text and claims. innovation research at scale",
    "category": "Data Portals",
    "url": "https://patentsview.org/download/data-download-tables",
    "docs_url": "https://patentsview.org/download/data-download-dictionary",
    "github_url": null,
    "tags": [
      "patents",
      "innovation",
      "USPTO",
      "citations",
      "intellectual property"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-basics",
      "data-visualization"
    ],
    "topic_tags": [
      "patent-data",
      "innovation-metrics",
      "citation-networks",
      "intellectual-property",
      "research-datasets"
    ],
    "summary": "PatentsView provides comprehensive access to over 13 million US patents from 1976 to present, including full text, citations, inventor details, and assignee information. This USPTO-maintained database enables large-scale innovation research and patent analytics. The dataset is particularly valuable for studying technology trends, company innovation strategies, and knowledge spillovers through citation networks.",
    "use_cases": [
      "Analyzing technology diffusion patterns by tracking patent citations across companies and time periods",
      "Building innovation metrics for tech companies by measuring patent volume, quality, and cross-industry impact"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "patent dataset for innovation research",
      "US patent data with citations and inventors",
      "large scale patent analytics database",
      "USPTO patent data for tech company analysis"
    ]
  },
  {
    "name": "EU TED Procurement",
    "description": "800K+ procurement notices annually. All EU public contracts above thresholds. Structured XML since 2006. Cross-country procurement research",
    "category": "Auctions & Marketplaces",
    "url": "https://ted.europa.eu/TED/browse/browseByMap.do",
    "docs_url": "https://simap.ted.europa.eu/web/simap/standard-forms-for-public-procurement",
    "github_url": null,
    "tags": [
      "EU",
      "procurement",
      "tenders",
      "government",
      "cross-country"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "regression-analysis"
    ],
    "topic_tags": [
      "procurement-data",
      "government-contracts",
      "cross-country-analysis",
      "auction-theory",
      "XML-data"
    ],
    "summary": "Comprehensive dataset of 800K+ annual EU public procurement notices covering all contracts above regulatory thresholds since 2006. Contains structured bidding information, contract values, and supplier details across all EU member states. Essential resource for studying government procurement patterns, market competition, and cross-country institutional differences.",
    "use_cases": [
      "Analyzing bid competition and pricing patterns across different EU countries and sectors",
      "Studying the effectiveness of procurement regulations and threshold policies on market outcomes"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "EU government procurement dataset",
      "public tender data for auction research",
      "cross-country procurement contract analysis",
      "European bidding data for competition studies"
    ]
  },
  {
    "name": "CMS Hospital Price Transparency",
    "description": "Hospital pricing data mandated since 2021. Negotiated rates, chargemaster prices across 6,000+ hospitals. Healthcare pricing research",
    "category": "Healthcare",
    "url": "https://www.cms.gov/hospital-price-transparency",
    "docs_url": "https://www.cms.gov/hospital-price-transparency/resources",
    "github_url": null,
    "tags": [
      "healthcare",
      "hospital pricing",
      "transparency",
      "CMS",
      "insurance"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "healthcare-economics",
      "data-cleaning"
    ],
    "topic_tags": [
      "hospital-pricing",
      "healthcare-transparency",
      "CMS-data",
      "price-variation",
      "negotiated-rates"
    ],
    "summary": "Comprehensive dataset of hospital pricing information mandated by CMS transparency rules starting in 2021. Contains negotiated insurance rates and chargemaster prices from over 6,000 hospitals across the US. Essential resource for healthcare economists studying price variation, market competition, and the effects of transparency regulations.",
    "use_cases": [
      "Analyzing price variation across hospitals and geographic regions to study healthcare market competition",
      "Evaluating the impact of price transparency mandates on negotiated rates between hospitals and insurers"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "hospital pricing transparency data CMS",
      "negotiated rates dataset healthcare economics",
      "chargemaster prices analysis hospital competition",
      "CMS price transparency mandate data research"
    ]
  },
  {
    "name": "Mendeley Food Delivery Reviews",
    "description": "1.69M reviews from DoorDash, Grubhub, Uber Eats. Ratings, text reviews, restaurant metadata. Gig economy platform research",
    "category": "Food & Delivery",
    "url": "https://data.mendeley.com/datasets/m5jk7wzyg7/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "food delivery",
      "reviews",
      "DoorDash",
      "Grubhub",
      "Uber Eats",
      "gig economy"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "basic-statistics"
    ],
    "topic_tags": [
      "food-delivery",
      "customer-reviews",
      "gig-economy",
      "platform-data",
      "sentiment-analysis"
    ],
    "summary": "A comprehensive dataset containing 1.69 million customer reviews across major food delivery platforms (DoorDash, Grubhub, Uber Eats) with ratings, text feedback, and restaurant metadata. This dataset is valuable for researchers and analysts studying gig economy platforms, consumer behavior, and food delivery market dynamics. The rich combination of structured ratings and unstructured text makes it suitable for both exploratory analysis and machine learning applications.",
    "use_cases": [
      "Analyzing customer satisfaction patterns across different food delivery platforms to understand competitive positioning",
      "Building sentiment analysis models to predict restaurant success based on review text and ratings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "food delivery platform reviews dataset",
      "DoorDash Grubhub Uber Eats customer data",
      "gig economy restaurant reviews analysis",
      "large scale food delivery sentiment data"
    ]
  },
  {
    "name": "DiDi GAIA Open Data",
    "description": "Billions of GPS points and ride trajectories from China's largest ride-hailing platform. Driver behavior and urban mobility patterns",
    "category": "Transportation & Mobility",
    "url": "https://gaia.didichuxing.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "rideshare",
      "GPS",
      "trajectories",
      "China",
      "DiDi",
      "mobility"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "geospatial-analysis",
      "SQL-queries"
    ],
    "topic_tags": [
      "GPS-data",
      "ride-hailing",
      "urban-mobility",
      "geospatial-datasets",
      "transportation-economics"
    ],
    "summary": "Massive GPS trajectory dataset from DiDi's ride-hailing platform containing billions of data points from Chinese cities. Researchers and analysts use this data to study urban mobility patterns, driver behavior, and transportation network effects. The dataset provides unprecedented scale for understanding ride-sharing economics and city-level transportation dynamics.",
    "use_cases": [
      "Analyzing surge pricing effects on driver supply and passenger demand across different urban areas",
      "Studying traffic congestion patterns and optimal routing algorithms using real-world trajectory data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale GPS trajectory data for mobility research",
      "DiDi ride sharing dataset China transportation",
      "urban mobility patterns GPS data analysis",
      "ride hailing driver behavior trajectory dataset"
    ]
  },
  {
    "name": "Prosper Loans",
    "description": "113K P2P loans with borrower characteristics, credit grades, and loan outcomes. Alternative to LendingClub for P2P lending research",
    "category": "Financial Services",
    "url": "https://www.prosper.com/plp/about/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P lending",
      "loans",
      "credit",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "basic-SQL"
    ],
    "topic_tags": [
      "peer-to-peer-lending",
      "credit-scoring",
      "financial-risk",
      "loan-default",
      "fintech-data"
    ],
    "summary": "A comprehensive dataset of 113,000 peer-to-peer loans from Prosper Marketplace containing borrower demographics, credit information, loan terms, and repayment outcomes. This dataset serves as an excellent alternative to LendingClub data for researchers studying P2P lending markets, credit risk assessment, and alternative finance mechanisms. It's particularly valuable for learning credit modeling techniques and understanding factors that drive loan performance in marketplace lending.",
    "use_cases": [
      "Building credit risk models to predict loan default probability using borrower characteristics and credit grades",
      "Analyzing the relationship between interest rates, borrower profiles, and loan outcomes in P2P lending markets"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "P2P lending dataset for credit risk modeling",
      "Prosper loans data alternative to LendingClub",
      "peer to peer lending default prediction dataset",
      "fintech loan performance analysis data"
    ]
  },
  {
    "name": "Google BigQuery Crypto",
    "description": "8 complete blockchain histories (Bitcoin, Ethereum, etc.) with daily updates. Transaction-level data for crypto analytics research",
    "category": "Financial Services",
    "url": "https://cloud.google.com/bigquery/public-data",
    "docs_url": "https://cloud.google.com/blog/products/data-analytics/introducing-six-new-cryptocurrencies-in-bigquery-public-datasets",
    "github_url": null,
    "tags": [
      "blockchain",
      "cryptocurrency",
      "Bitcoin",
      "Ethereum",
      "BigQuery"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "SQL-queries",
      "BigQuery-API",
      "blockchain-fundamentals"
    ],
    "topic_tags": [
      "cryptocurrency-data",
      "blockchain-analytics",
      "transaction-analysis",
      "BigQuery-datasets",
      "financial-data"
    ],
    "summary": "Comprehensive dataset containing complete transaction histories for 8 major blockchains including Bitcoin and Ethereum, updated daily in Google BigQuery. Provides transaction-level granularity for researchers and analysts studying cryptocurrency markets, user behavior, and blockchain economics. Essential resource for crypto analytics requiring large-scale, structured blockchain data.",
    "use_cases": [
      "Analyzing Bitcoin transaction patterns to identify market manipulation or whale behavior",
      "Building Ethereum DeFi protocol usage dashboards with real-time transaction monitoring"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "blockchain transaction data BigQuery",
      "Bitcoin Ethereum dataset for analysis",
      "cryptocurrency transaction history database",
      "crypto analytics data source"
    ]
  },
  {
    "name": "Netflix Viewing Behavior",
    "description": "1.7M episodes/movies watched by 1,060 users over 1 year. Watch patterns, session length, preferences, predictability metrics",
    "category": "Entertainment & Media",
    "url": "https://ieeexplore.ieee.org/document/9500874",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Netflix",
      "streaming",
      "viewing behavior",
      "sessions",
      "video"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-queries",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "streaming-data",
      "user-behavior",
      "media-consumption",
      "session-analysis",
      "entertainment"
    ],
    "summary": "A comprehensive dataset of Netflix viewing patterns from over 1,000 users across one year, containing 1.7M viewing records with session details and user preferences. This dataset is ideal for analyzing streaming behavior, content recommendation systems, and media consumption patterns. Perfect for data scientists learning user behavior analytics or studying entertainment industry metrics.",
    "use_cases": [
      "Building recommendation systems based on viewing patterns and session data",
      "Analyzing user engagement metrics to optimize content strategy and retention"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Netflix viewing behavior dataset",
      "streaming user data for recommendation systems",
      "video consumption patterns data",
      "Netflix session analysis dataset"
    ]
  },
  {
    "name": "Netflix Engagement Reports",
    "description": "Hours viewed for every Netflix title (original and licensed) watched >50K hours. First public streaming metrics since 2021",
    "category": "Entertainment & Media",
    "url": "https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Netflix",
      "streaming",
      "engagement",
      "viewership",
      "hours watched"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "streaming-data",
      "entertainment-analytics",
      "engagement-metrics",
      "viewership-analysis",
      "media-consumption"
    ],
    "summary": "Netflix's first public release of comprehensive viewing metrics showing hours watched for all titles with >50K hours engagement since 2021. This dataset provides unprecedented transparency into streaming consumption patterns across Netflix's global catalog of original and licensed content. Essential for understanding modern media consumption behaviors and content performance benchmarks.",
    "use_cases": [
      "Analyzing content performance patterns to inform streaming strategy decisions",
      "Benchmarking engagement metrics for entertainment industry market research"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Netflix viewership data public streaming metrics",
      "streaming platform engagement hours watched dataset",
      "Netflix original vs licensed content performance data",
      "entertainment media consumption analytics dataset"
    ]
  },
  {
    "name": "YouTube User Watch History",
    "description": "1.8M videos watched by 243 users over 1.5 years. Recommendation engine performance, caching research, viewing patterns",
    "category": "Entertainment & Media",
    "url": "https://netsg.cs.sfu.ca/youtubedata/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "YouTube",
      "watch history",
      "recommendations",
      "video",
      "user behavior"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "exploratory-data-analysis",
      "basic-statistics"
    ],
    "topic_tags": [
      "youtube-data",
      "user-behavior",
      "recommendation-systems",
      "video-analytics",
      "longitudinal-data"
    ],
    "summary": "A longitudinal dataset containing 1.8 million video watch records from 243 YouTube users tracked over 1.5 years. This rich behavioral dataset enables analysis of viewing patterns, recommendation algorithm effectiveness, and user engagement trends. Ideal for researchers studying digital media consumption, recommendation systems, or user behavior analytics.",
    "use_cases": [
      "Analyzing recommendation algorithm performance by comparing suggested vs. actually watched videos",
      "Building predictive models for user engagement and video popularity trends"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "YouTube user behavior dataset",
      "video recommendation algorithm evaluation data",
      "longitudinal viewing patterns dataset",
      "user watch history data for analysis"
    ]
  },
  {
    "name": "YouTube Engagement Dataset",
    "description": "5M videos with watch percentage, engagement maps, Freebase topic labels. Video-level engagement metrics for content research",
    "category": "Entertainment & Media",
    "url": "https://github.com/avalanchesiqi/youtube-engagement",
    "docs_url": null,
    "github_url": "https://github.com/avalanchesiqi/youtube-engagement",
    "tags": [
      "YouTube",
      "engagement",
      "video",
      "watch time",
      "topics"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "youtube-analytics",
      "video-engagement",
      "content-metrics",
      "media-research",
      "behavioral-data"
    ],
    "summary": "A comprehensive dataset of 5 million YouTube videos with detailed engagement metrics including watch percentage, engagement maps, and Freebase topic classifications. This dataset enables researchers and analysts to study video content performance, audience behavior patterns, and topic-based engagement trends across the YouTube platform.",
    "use_cases": [
      "Analyzing which video topics and formats drive highest audience retention for content strategy optimization",
      "Building predictive models to forecast video engagement based on content characteristics and topic categories"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "YouTube video engagement dataset",
      "video watch time analysis data",
      "content performance metrics dataset",
      "YouTube audience behavior data"
    ]
  },
  {
    "name": "YouTube-8M",
    "description": "8M videos with video-level features for large-scale video understanding. Google Research benchmark for video classification",
    "category": "Entertainment & Media",
    "url": "https://research.google.com/youtube8m/",
    "docs_url": "https://research.google.com/youtube8m/download.html",
    "github_url": null,
    "tags": [
      "YouTube",
      "video",
      "classification",
      "benchmark",
      "Google Research"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "tensorflow-keras",
      "python-pandas",
      "neural-networks"
    ],
    "topic_tags": [
      "video-classification",
      "large-scale-dataset",
      "benchmark",
      "deep-learning",
      "computer-vision"
    ],
    "summary": "YouTube-8M is a massive dataset containing 8 million YouTube videos with pre-extracted features designed for video classification tasks. It serves as a standard benchmark in the computer vision community for developing and evaluating large-scale video understanding models. The dataset is particularly valuable for researchers working on video content analysis without requiring raw video processing.",
    "use_cases": [
      "Benchmarking video classification models against industry standard",
      "Training content recommendation systems for video platforms"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale video classification dataset",
      "YouTube video understanding benchmark",
      "Google Research video dataset",
      "video classification training data"
    ]
  },
  {
    "name": "Twitch Gamers Social Network",
    "description": "168K nodes with mutual follower relationships. 6 ML tasks including churn, affiliate status, view count prediction",
    "category": "Entertainment & Media",
    "url": "https://snap.stanford.edu/data/twitch-social-networks.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Twitch",
      "social network",
      "gaming",
      "followers",
      "SNAP"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "scikit-learn",
      "network-analysis"
    ],
    "topic_tags": [
      "social-networks",
      "twitch-data",
      "user-behavior",
      "churn-prediction",
      "graph-datasets"
    ],
    "summary": "A large-scale social network dataset from Twitch containing 168,000 gaming streamers and their mutual follower relationships. The dataset includes user features and supports 6 different machine learning tasks including churn prediction, affiliate status classification, and view count forecasting. Ideal for practitioners learning social network analysis or testing recommendation and prediction algorithms on real gaming platform data.",
    "use_cases": [
      "Building churn prediction models for gaming or social media platforms",
      "Testing graph neural networks and social network analysis algorithms on real follower data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "twitch social network dataset for machine learning",
      "gaming platform user data with follower relationships",
      "social media churn prediction dataset",
      "large scale network data for recommendation systems"
    ]
  },
  {
    "name": "Twitch Streaming Dataset",
    "description": "16 days of viewer counts, stream metadata, game categories from Oct 2017. Live streaming platform dynamics",
    "category": "Entertainment & Media",
    "url": "https://github.com/mingt2019/Twitch-Dataset",
    "docs_url": null,
    "github_url": "https://github.com/mingt2019/twitch-streamers-social-network",
    "tags": [
      "Twitch",
      "live streaming",
      "viewership",
      "gaming"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-time-series"
    ],
    "topic_tags": [
      "streaming-data",
      "viewership-analytics",
      "gaming-industry",
      "time-series",
      "social-media"
    ],
    "summary": "A dataset containing 16 days of Twitch streaming data from October 2017, including viewer counts, stream metadata, and game categories. Perfect for analyzing live streaming platform dynamics and understanding viewer behavior patterns. Accessible format ideal for learning exploratory data analysis and time series methods in the entertainment industry context.",
    "use_cases": [
      "Analyzing peak viewing times and content preferences to optimize streaming schedules",
      "Building predictive models for stream popularity based on game categories and metadata"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "twitch viewership data for analysis",
      "streaming platform dataset with viewer counts",
      "gaming industry data for time series analysis",
      "live streaming behavior dataset"
    ]
  },
  {
    "name": "LastFM-1B",
    "description": "1 billion listening events with long-term user histories. Music recommendation and listening behavior research",
    "category": "Entertainment & Media",
    "url": "http://www.cp.jku.at/datasets/LFM-1b/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "listening",
      "recommendations",
      "large-scale",
      "LastFM"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "implicit-feedback-models"
    ],
    "topic_tags": [
      "music-recommendation",
      "implicit-feedback",
      "large-scale-datasets",
      "user-behavior",
      "entertainment-data"
    ],
    "summary": "LastFM-1B contains one billion music listening events with extended user listening histories from the Last.fm platform. This large-scale dataset is widely used by researchers and practitioners developing music recommendation systems and studying long-term user listening patterns. The dataset enables analysis of implicit feedback behaviors and temporal listening dynamics at unprecedented scale.",
    "use_cases": [
      "Building and benchmarking collaborative filtering algorithms for music streaming platforms",
      "Analyzing long-term user preference drift and seasonal listening patterns in music consumption"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale music recommendation dataset",
      "LastFM billion listening events dataset",
      "implicit feedback music data for recommendation systems",
      "long term user listening behavior dataset"
    ]
  },
  {
    "name": "Spotify Million Playlist",
    "description": "1M playlists with 2M unique tracks from 300K artists. RecSys 2018 Challenge for playlist continuation research",
    "category": "Entertainment & Media",
    "url": "https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Spotify",
      "playlists",
      "music",
      "recommendations",
      "RecSys"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "collaborative-filtering",
      "matrix-factorization"
    ],
    "topic_tags": [
      "music-recommendation",
      "playlist-dataset",
      "collaborative-filtering",
      "sequential-data",
      "user-behavior"
    ],
    "summary": "Large-scale dataset containing one million Spotify playlists with detailed track and artist metadata, originally created for the RecSys 2018 Challenge. Perfect for learning recommendation system fundamentals and experimenting with playlist continuation algorithms. Provides real-world music consumption patterns at scale with rich sequential listening behavior data.",
    "use_cases": [
      "Building a playlist recommendation system to suggest next songs based on existing tracks",
      "Analyzing music listening patterns and user preferences across different genres and artists"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "spotify playlist dataset for recommendation systems",
      "music recommendation dataset million playlists",
      "playlist continuation challenge data",
      "large scale music listening behavior dataset"
    ]
  },
  {
    "name": "YFCC100M",
    "description": "100M Flickr photos/videos with metadata under Creative Commons. Yahoo/Flickr dataset for multimedia research",
    "category": "Entertainment & Media",
    "url": "https://multimediacommons.wordpress.com/yfcc100m-core-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Flickr",
      "photos",
      "video",
      "multimedia",
      "Creative Commons"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "image-processing-libraries",
      "data-cleaning"
    ],
    "topic_tags": [
      "multimedia-data",
      "creative-commons",
      "computer-vision",
      "social-media-analysis"
    ],
    "summary": "YFCC100M is a massive dataset containing 100 million photos and videos from Flickr with associated metadata, all released under Creative Commons licenses. It serves as a benchmark dataset for multimedia research, computer vision, and social media analysis. The dataset includes rich metadata like timestamps, geolocation, tags, and user information making it valuable for studying visual content at scale.",
    "use_cases": [
      "Training computer vision models for image classification or object detection using real-world social media photos",
      "Analyzing geographic and temporal patterns in user-generated content for social media research"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "large scale image dataset for computer vision",
      "Flickr photos dataset creative commons",
      "multimedia dataset with metadata social media",
      "100 million images benchmark dataset"
    ]
  },
  {
    "name": "Meta Content Library",
    "description": "Full Facebook/Instagram public archive via ICPSR application. Posts, Pages, groups, events for academic research",
    "category": "Social & Web",
    "url": "https://transparency.meta.com/researchtools/meta-content-library",
    "docs_url": "https://developers.facebook.com/docs/content-library-and-api",
    "github_url": null,
    "tags": [
      "Facebook",
      "Instagram",
      "Meta",
      "social media",
      "posts"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "API-authentication",
      "data-privacy-regulations"
    ],
    "topic_tags": [
      "social-media-data",
      "facebook-research",
      "content-analysis",
      "platform-data",
      "ICPSR"
    ],
    "summary": "The Meta Content Library provides researchers with access to Facebook and Instagram's public content archive through ICPSR's secure application process. This comprehensive dataset includes posts, pages, groups, and events specifically curated for academic research purposes. Researchers can analyze social media behavior, content trends, and platform dynamics at scale while maintaining compliance with privacy regulations.",
    "use_cases": [
      "Studying misinformation spread patterns across Facebook posts and groups during election periods",
      "Analyzing Instagram content trends and engagement patterns to understand social commerce behavior"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Facebook Instagram research dataset ICPSR",
      "Meta public content archive for academics",
      "social media posts dataset Facebook research",
      "how to access Facebook data for research"
    ]
  },
  {
    "name": "Facebook URL Shares",
    "description": "38M URLs with 10T exposure numbers, fact-checking flags, interaction types (2017-2019). Social Science One initiative",
    "category": "Social & Web",
    "url": "https://socialscience.one/our-facebook-partnership",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "URL sharing",
      "misinformation",
      "fact-checking",
      "social media"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "hypothesis-testing"
    ],
    "topic_tags": [
      "misinformation-detection",
      "social-media-analysis",
      "fact-checking",
      "url-sharing",
      "exposure-metrics"
    ],
    "summary": "Massive dataset of 38 million URLs shared on Facebook from 2017-2019, including 10 trillion exposure measurements, fact-checking labels, and user interaction patterns. Created through Facebook's Social Science One initiative to enable academic research on misinformation spread. Provides unprecedented scale for studying how false information propagates across social networks and measuring the effectiveness of fact-checking interventions.",
    "use_cases": [
      "Measuring the viral spread patterns of misinformation versus factual content across different user demographics",
      "Evaluating the impact of Facebook's fact-checking labels on user engagement and sharing behavior"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Facebook misinformation dataset with fact checking labels",
      "large scale URL sharing data social media",
      "measuring viral spread of false information",
      "Social Science One Facebook exposure data"
    ]
  },
  {
    "name": "SNAP Facebook Ego Networks",
    "description": "4K users with social circles and anonymized node features. Stanford Network Analysis Project dataset",
    "category": "Social & Web",
    "url": "https://snap.stanford.edu/data/ego-Facebook.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "social network",
      "ego networks",
      "SNAP",
      "Stanford"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "networkx",
      "graph-visualization"
    ],
    "topic_tags": [
      "social-networks",
      "ego-networks",
      "graph-data",
      "facebook-data",
      "network-analysis"
    ],
    "summary": "A collection of Facebook social network data containing 4,000 users organized into ego networks (a user and their immediate connections). Each network includes anonymized node features, making it ideal for learning social network analysis techniques. This is one of the most accessible datasets from Stanford's SNAP collection for understanding social graph structures.",
    "use_cases": [
      "Learning social network analysis by exploring how friend circles form and overlap in Facebook networks",
      "Developing community detection algorithms to identify social groups within ego networks"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "Facebook social network dataset for learning",
      "ego networks data with node features",
      "SNAP Facebook dataset download",
      "social circle detection dataset"
    ]
  },
  {
    "name": "US 2020 Election Study",
    "description": "Facebook/Instagram impact on political attitudes. Published in Science/Nature 2023. SOMAR Michigan access",
    "category": "Social & Web",
    "url": "https://www.icpsr.umich.edu/web/ICPSR/series/2045",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "Instagram",
      "elections",
      "politics",
      "social media"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "randomized-controlled-trials",
      "python-pandas",
      "causal-inference"
    ],
    "topic_tags": [
      "social-media-research",
      "election-analysis",
      "political-behavior",
      "facebook-data",
      "experimental-design"
    ],
    "summary": "Large-scale randomized controlled trial studying how Facebook and Instagram usage affected political attitudes and behaviors during the 2020 US election. Published in top-tier journals with data accessible through SOMAR at University of Michigan. Provides gold-standard experimental evidence on social media's causal impact on democratic processes.",
    "use_cases": [
      "Researchers studying social media's causal impact on political polarization and voter behavior",
      "Policy analysts evaluating platform regulation effects on democratic participation"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Facebook Instagram election study 2020",
      "social media causal effects political attitudes",
      "randomized trial social media democracy",
      "2020 election Facebook experiment data"
    ]
  },
  {
    "name": "MobileRec",
    "description": "19.3M user reviews from 700K users across 10K apps in 48 categories. Google Play app recommendation research",
    "category": "App Stores",
    "url": "https://github.com/mhmaqbool/mobilerec",
    "docs_url": null,
    "github_url": "https://github.com/JianmoBian/MobileRec",
    "tags": [
      "mobile apps",
      "reviews",
      "Google Play",
      "recommendations",
      "app store"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "mobile-apps",
      "user-reviews",
      "recommendation-systems",
      "app-store-data",
      "google-play"
    ],
    "summary": "MobileRec is a large-scale dataset containing 19.3 million user reviews from 700,000 users across 10,000 mobile applications spanning 48 categories on Google Play. This comprehensive dataset is designed for app recommendation research and provides rich user-app interaction data. It's ideal for researchers and practitioners working on mobile app analytics, recommendation algorithms, and understanding user behavior in app ecosystems.",
    "use_cases": [
      "Building recommendation systems to suggest relevant apps to users based on review patterns and app categories",
      "Analyzing user sentiment and preferences across different app categories to inform product development strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Google Play app review dataset for recommendation systems",
      "large mobile app user review data",
      "app store recommendation research dataset",
      "user behavior data for mobile applications"
    ]
  },
  {
    "name": "Google Play Store Dataset",
    "description": "2.3M apps with ratings, reviews, categories, sizes, installs. Android app marketplace data",
    "category": "App Stores",
    "url": "https://www.kaggle.com/datasets/gauthamp10/google-playstore-apps",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Google Play",
      "Android",
      "apps",
      "ratings",
      "Kaggle"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "basic-statistics"
    ],
    "topic_tags": [
      "mobile-apps",
      "user-behavior",
      "market-analysis",
      "app-store-data",
      "android"
    ],
    "summary": "A comprehensive dataset of 2.3 million Android applications from Google Play Store including user ratings, review counts, categories, file sizes, and install numbers. This dataset is ideal for market research, user behavior analysis, and understanding mobile app ecosystem trends. Perfect for exploratory data analysis and learning data science fundamentals with real-world marketplace data.",
    "use_cases": [
      "Analyzing which app categories have highest user engagement and ratings",
      "Predicting app success based on size, category, and pricing strategies"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Google Play Store app data for analysis",
      "Android app ratings and reviews dataset",
      "mobile app market research data",
      "dataset for predicting app success"
    ]
  },
  {
    "name": "Apple App Store Dataset",
    "description": "7,200 iOS apps with pricing, ratings, genres, in-app purchases. Apple app marketplace analysis",
    "category": "App Stores",
    "url": "https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Apple",
      "iOS",
      "apps",
      "pricing",
      "App Store"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "mobile-apps",
      "pricing-analysis",
      "marketplace-data",
      "consumer-behavior",
      "app-economics"
    ],
    "summary": "A dataset containing 7,200 iOS applications with comprehensive metadata including pricing, user ratings, genres, and in-app purchase information from the Apple App Store. This dataset enables analysis of mobile app marketplace dynamics, pricing strategies, and consumer preferences. It's ideal for learning data analysis fundamentals while exploring the economics of digital platforms.",
    "use_cases": [
      "Analyzing optimal pricing strategies for mobile app developers by comparing successful apps across different genres",
      "Studying the relationship between app ratings, pricing models, and in-app purchase strategies to understand consumer behavior"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Apple App Store pricing data",
      "iOS app ratings dataset",
      "mobile app marketplace analysis data",
      "App Store economics dataset"
    ]
  },
  {
    "name": "JobHop (Flanders)",
    "description": "2.3M occupations and 391K resumes with real career trajectories mapped to ESCO codes. Labor mobility research",
    "category": "Labor Markets",
    "url": "https://huggingface.co/datasets/VDAB/jobhop",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "careers",
      "resumes",
      "occupations",
      "labor mobility",
      "ESCO"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "network-analysis",
      "survival-analysis"
    ],
    "topic_tags": [
      "career-trajectories",
      "labor-mobility",
      "occupational-transitions",
      "ESCO-taxonomy",
      "longitudinal-data"
    ],
    "summary": "A comprehensive dataset containing 2.3 million job positions and 391,000 real resumes from Flanders, Belgium, with career paths mapped to standardized ESCO occupation codes. This longitudinal dataset enables researchers to analyze labor market mobility patterns, career progression dynamics, and occupational transitions at scale. The standardized coding makes it particularly valuable for cross-European labor market comparisons and policy research.",
    "use_cases": [
      "Modeling career transition probabilities between different occupation categories to predict workforce flows",
      "Analyzing the impact of economic shocks on career mobility patterns across different industries and skill levels"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "career transition dataset with occupation codes",
      "labor mobility data for workforce analytics",
      "resume dataset with job progression trajectories",
      "ESCO occupation mobility research data"
    ]
  },
  {
    "name": "BLS JOLTS",
    "description": "Monthly job openings, hires, separations by industry since 2000. Bureau of Labor Statistics time series",
    "category": "Labor Markets",
    "url": "https://www.bls.gov/jlt/data.htm",
    "docs_url": "https://www.bls.gov/jlt/jltover.htm",
    "github_url": null,
    "tags": [
      "jobs",
      "labor",
      "openings",
      "hires",
      "BLS"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "time-series-data",
      "basic-visualization"
    ],
    "topic_tags": [
      "labor-economics",
      "time-series",
      "government-data",
      "employment",
      "industry-analysis"
    ],
    "summary": "The Bureau of Labor Statistics Job Openings and Labor Turnover Survey (JOLTS) provides monthly data on job openings, hires, and separations across industries since 2000. This dataset is widely used by economists, policymakers, and data scientists to analyze labor market trends and employment dynamics. It offers reliable, granular insights into hiring patterns and job market health across different sectors of the economy.",
    "use_cases": [
      "Analyzing post-recession hiring recovery patterns by industry",
      "Building predictive models for job market tightness using opening-to-hire ratios"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "BLS jobs data monthly hiring trends",
      "government employment statistics by industry",
      "job openings separations time series data",
      "JOLTS dataset labor market analysis"
    ]
  },
  {
    "name": "Glassdoor Reviews",
    "description": "Company ratings, salary reports, interview experiences. Employer review platform data for labor analytics",
    "category": "Labor Markets",
    "url": "https://www.glassdoor.com/research/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "salaries",
      "company reviews",
      "interviews",
      "employer ratings"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-regression",
      "data-cleaning"
    ],
    "topic_tags": [
      "employer-reviews",
      "salary-data",
      "labor-markets",
      "survey-data",
      "compensation-analysis"
    ],
    "summary": "Glassdoor Reviews is a dataset containing employee-generated company ratings, salary reports, and interview experiences from the popular employer review platform. This data provides insights into workplace culture, compensation trends, and hiring practices across companies and industries. It's commonly used by researchers studying labor markets, compensation equity, and organizational behavior.",
    "use_cases": [
      "Analyzing gender pay gaps by comparing salary reports across demographics and companies",
      "Building predictive models for company satisfaction scores based on review text and ratings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "employee review data for salary analysis",
      "glassdoor dataset for compensation research",
      "company ratings data for labor economics",
      "employer review platform data download"
    ]
  },
  {
    "name": "Revelio Labs COSMOS",
    "description": "4.1B job postings from 6.6M companies. Deduplicated, parsed, enriched workforce data (commercial/academic partnerships)",
    "category": "Labor Markets",
    "url": "https://www.reveliolabs.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "job postings",
      "workforce",
      "companies",
      "labor",
      "commercial"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "data-cleaning"
    ],
    "topic_tags": [
      "job-postings",
      "workforce-analytics",
      "labor-economics",
      "company-data",
      "dataset"
    ],
    "summary": "Revelio Labs COSMOS is a massive dataset containing 4.1 billion job postings from 6.6 million companies, offering deduplicated and enriched workforce data. This comprehensive resource enables researchers and analysts to study labor market trends, hiring patterns, and workforce dynamics at scale. The dataset is available through commercial partnerships and academic collaborations.",
    "use_cases": [
      "Analyzing skill demand trends across industries to inform workforce development policy",
      "Building predictive models for labor market tightness and wage growth using company hiring patterns"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale job posting dataset for labor economics research",
      "workforce data with company information for hiring analysis",
      "deduplicated job postings dataset commercial access",
      "labor market data billions of job postings companies"
    ]
  },
  {
    "name": "HateXplain",
    "description": "20K social media posts with human rationales across 10 hate speech target categories. Explainable AI for content moderation",
    "category": "Content Moderation",
    "url": "https://github.com/hate-alert/HateXplain",
    "docs_url": null,
    "github_url": "https://github.com/hate-alert/HateXplain",
    "tags": [
      "hate speech",
      "explainability",
      "NLP",
      "content moderation",
      "annotations"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "transformers-library",
      "annotation-schemes"
    ],
    "topic_tags": [
      "hate-speech",
      "explainable-ai",
      "content-moderation",
      "human-annotations",
      "social-media"
    ],
    "summary": "HateXplain is a dataset of 20,000 social media posts labeled for hate speech detection with human-provided rationales explaining the decisions. It covers 10 different hate speech target categories and enables training explainable AI models for content moderation. The dataset is particularly valuable for researchers developing interpretable NLP systems that need to justify their hate speech classifications.",
    "use_cases": [
      "Training explainable hate speech detection models that can highlight specific words or phrases that indicate hateful content",
      "Benchmarking content moderation systems that need to provide human-interpretable explanations for automated decisions"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "hate speech dataset with explanations",
      "explainable AI content moderation data",
      "social media hate detection training data",
      "annotated hate speech dataset human rationales"
    ]
  },
  {
    "name": "HateDay",
    "description": "Global representative sample of real-world hate speech across languages. 2024 benchmark for content moderation",
    "category": "Content Moderation",
    "url": "https://arxiv.org/abs/2404.06465",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hate speech",
      "multilingual",
      "benchmark",
      "content moderation"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "multilingual-NLP",
      "classification-metrics"
    ],
    "topic_tags": [
      "hate-speech",
      "multilingual-datasets",
      "content-moderation",
      "benchmark-evaluation",
      "safety-AI"
    ],
    "summary": "HateDay is a comprehensive global dataset containing real-world hate speech examples across multiple languages, serving as a standardized benchmark for evaluating content moderation systems. It provides researchers and practitioners with representative samples to test and compare hate speech detection models. The dataset is particularly valuable for developing robust multilingual content moderation tools that work across diverse linguistic and cultural contexts.",
    "use_cases": [
      "Benchmarking a new hate speech detection model against existing state-of-the-art systems",
      "Training multilingual content moderation systems for global social media platforms"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "multilingual hate speech dataset 2024",
      "benchmark for content moderation systems",
      "global hate speech detection training data",
      "HateDay dataset for AI safety research"
    ]
  },
  {
    "name": "ETHOS Hate Speech",
    "description": "998 online comments labeled for hate speech detection in English. Binary and multi-label annotations",
    "category": "Content Moderation",
    "url": "https://zenodo.org/records/4459923",
    "docs_url": null,
    "github_url": "https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset",
    "tags": [
      "hate speech",
      "NLP",
      "annotations",
      "English"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "classification-metrics"
    ],
    "topic_tags": [
      "hate-speech-detection",
      "text-classification",
      "content-moderation",
      "labeled-dataset",
      "NLP"
    ],
    "summary": "ETHOS is a labeled dataset of 998 English online comments annotated for hate speech detection research. It provides both binary (hate/not hate) and multi-label classifications, making it useful for training and evaluating content moderation models. The dataset is particularly valuable for researchers and practitioners working on automated hate speech detection systems.",
    "use_cases": [
      "Training machine learning models to automatically flag hateful comments on social media platforms",
      "Benchmarking different NLP approaches for content moderation systems"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "hate speech detection dataset",
      "labeled comments for content moderation",
      "English hate speech training data",
      "multi-label hate speech annotations"
    ]
  },
  {
    "name": "Hate Speech Data Catalogue",
    "description": "50+ hate speech datasets across languages compiled at hatespeechdata.com. Meta-resource for content moderation research",
    "category": "Content Moderation",
    "url": "https://hatespeechdata.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hate speech",
      "catalogue",
      "multilingual",
      "meta-dataset"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "dataset-handling"
    ],
    "topic_tags": [
      "hate-speech",
      "content-moderation",
      "multilingual-datasets",
      "meta-resource",
      "catalogue"
    ],
    "summary": "A comprehensive catalogue of 50+ hate speech datasets spanning multiple languages, hosted at hatespeechdata.com. This meta-resource serves as a central hub for researchers and practitioners working on content moderation systems. It provides structured access to diverse hate speech datasets for training and evaluating detection models.",
    "use_cases": [
      "Building multilingual hate speech detection models for social media platforms",
      "Benchmarking content moderation algorithms across different languages and cultural contexts"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "multilingual hate speech datasets",
      "content moderation training data",
      "hate speech detection benchmark datasets",
      "where to find labeled hate speech data"
    ]
  },
  {
    "name": "CoAID COVID Misinformation",
    "description": "4,251 news articles and 296K claims about COVID-19 healthcare misinformation. Fact-checked with ground truth labels",
    "category": "Content Moderation",
    "url": "https://github.com/cuilimeng/CoAID",
    "docs_url": null,
    "github_url": "https://github.com/cuilimeng/CoAID",
    "tags": [
      "COVID-19",
      "misinformation",
      "fact-checking",
      "healthcare",
      "fake news"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "natural-language-processing",
      "classification-algorithms"
    ],
    "topic_tags": [
      "misinformation-detection",
      "covid-19",
      "fact-checking",
      "content-moderation",
      "dataset"
    ],
    "summary": "A comprehensive dataset containing 4,251 COVID-19 related news articles and 296K health claims with verified fact-checking labels. This resource enables researchers and data scientists to build and evaluate misinformation detection systems specifically for healthcare content during pandemic situations.",
    "use_cases": [
      "Training machine learning models to automatically detect COVID-19 health misinformation on social media platforms",
      "Benchmarking fact-checking algorithms against ground truth labels for pandemic-related content"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "COVID misinformation dataset for training models",
      "fact-checked healthcare claims data",
      "pandemic fake news detection training data",
      "ground truth labels for COVID misinformation research"
    ]
  },
  {
    "name": "LIAR Fact-Checking",
    "description": "12.8K fact-checked political statements with speaker metadata and 6-way truthfulness labels. Politifact benchmark",
    "category": "Content Moderation",
    "url": "https://www.cs.ucsb.edu/~william/data/liar_dataset.zip",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fact-checking",
      "politics",
      "misinformation",
      "NLP",
      "Politifact"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-preprocessing",
      "classification-metrics"
    ],
    "topic_tags": [
      "fact-checking",
      "political-text",
      "misinformation-detection",
      "benchmark-dataset",
      "multi-class-classification"
    ],
    "summary": "A widely-used benchmark dataset containing 12,800 political statements from Politifact with 6-level truthfulness ratings (pants-on-fire to true) plus speaker metadata. Popular starting point for researchers building automated fact-checking systems and studying misinformation patterns in political discourse.",
    "use_cases": [
      "Training ML models to automatically classify statement truthfulness for content moderation platforms",
      "Analyzing patterns in political misinformation by party, speaker, or topic for research papers"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "politifact dataset for fact checking",
      "benchmark data for misinformation detection",
      "political statements truthfulness labels",
      "LIAR dataset download"
    ]
  },
  {
    "name": "FakeNewsNet",
    "description": "23K news articles labeled fake/real with social context. Includes PolitiFact and GossipCop sources",
    "category": "Content Moderation",
    "url": "https://github.com/KaiDMML/FakeNewsNet",
    "docs_url": null,
    "github_url": "https://github.com/KaiDMML/FakeNewsNet",
    "tags": [
      "fake news",
      "misinformation",
      "social media",
      "fact-checking"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-classification",
      "text-preprocessing"
    ],
    "topic_tags": [
      "fake-news",
      "misinformation",
      "social-media",
      "content-moderation",
      "labeled-dataset"
    ],
    "summary": "FakeNewsNet is a comprehensive dataset containing 23,000 news articles labeled as fake or real, sourced from PolitiFact and GossipCop with accompanying social media context. It provides researchers and practitioners with ground truth data for developing and testing misinformation detection algorithms. The dataset includes both textual content and social engagement metrics, making it valuable for studying how false information spreads online.",
    "use_cases": [
      "Training machine learning models to automatically detect fake news articles on social media platforms",
      "Analyzing patterns in how misinformation spreads compared to legitimate news stories"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "fake news detection dataset",
      "labeled misinformation data for machine learning",
      "social media fake news research data",
      "PolitiFact GossipCop dataset"
    ]
  },
  {
    "name": "Patreon Creator Data",
    "description": "279K+ active creators with membership tiers and patron counts. Creator economy platform metrics from Graphtreon",
    "category": "Creator Economy",
    "url": "https://graphtreon.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Patreon",
      "creators",
      "memberships",
      "subscriptions",
      "creator economy"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "patreon-data",
      "creator-economy",
      "subscription-metrics",
      "platform-data",
      "membership-tiers"
    ],
    "summary": "A comprehensive dataset of 279K+ active Patreon creators including their membership tier structures and patron counts from Graphtreon. This dataset provides insights into the creator economy landscape, allowing analysis of subscription patterns, creator success metrics, and platform dynamics. Useful for understanding monetization strategies and market trends in the digital creator space.",
    "use_cases": [
      "Analyzing creator revenue distribution and success factors across different content categories",
      "Building predictive models for creator growth based on membership tier pricing strategies"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "patreon creator dataset with patron counts",
      "creator economy subscription data",
      "membership tier analysis data",
      "patreon platform metrics dataset"
    ]
  },
  {
    "name": "Social Blade",
    "description": "Public subscriber/follower counts and growth metrics across YouTube, Twitch, Instagram, Twitter, TikTok",
    "category": "Creator Economy",
    "url": "https://socialblade.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "YouTube",
      "Twitch",
      "Instagram",
      "followers",
      "growth metrics"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "data-visualization",
      "API-requests"
    ],
    "topic_tags": [
      "social-media-analytics",
      "creator-economy",
      "growth-tracking",
      "platform-metrics",
      "influencer-data"
    ],
    "summary": "Social Blade provides publicly available subscriber and follower counts across major social platforms including YouTube, Twitch, Instagram, Twitter, and TikTok. The dataset includes historical growth metrics and engagement statistics that are commonly used by creators, marketers, and researchers. This data is particularly valuable for analyzing creator economy trends and platform-specific growth patterns.",
    "use_cases": [
      "Analyzing YouTube creator growth patterns to identify successful content strategies",
      "Comparing influencer reach across platforms for brand partnership decisions"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "YouTube subscriber data for creator economy research",
      "social media follower growth datasets",
      "influencer analytics data across platforms",
      "TikTok Instagram Twitter growth metrics dataset"
    ]
  },
  {
    "name": "Creator Economy Reports",
    "description": "Survey-based earnings breakdowns by platform (YouTube, TikTok, Instagram, Twitch). Influencer Marketing Factory research",
    "category": "Creator Economy",
    "url": "https://theinfluencermarketingfactory.com/creator-economy/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "creator economy",
      "earnings",
      "influencers",
      "surveys"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "creator-economy",
      "platform-earnings",
      "survey-data",
      "influencer-marketing"
    ],
    "summary": "Survey-based dataset from Influencer Marketing Factory showing earnings breakdowns across major creator platforms including YouTube, TikTok, Instagram, and Twitch. The data provides insights into creator monetization patterns and income distribution across different social media platforms. Useful for understanding the economics of content creation and platform-specific earning potential.",
    "use_cases": [
      "Benchmarking creator earnings against platform averages for partnership negotiations",
      "Market research on creator economy trends for platform strategy or investment decisions"
    ],
    "audience": [
      "Curious-browser",
      "Junior-DS"
    ],
    "synthetic_questions": [
      "creator earnings by platform data",
      "how much do YouTubers vs TikTokers make",
      "influencer income survey results",
      "creator economy earnings breakdown dataset"
    ]
  },
  {
    "name": "Medicare Provider Utilization",
    "description": "All Medicare providers with service utilization and payment data. CMS public use files for healthcare analytics",
    "category": "Healthcare",
    "url": "https://data.cms.gov/provider-summary-by-type-of-service",
    "docs_url": "https://data.cms.gov/",
    "github_url": null,
    "tags": [
      "Medicare",
      "healthcare",
      "providers",
      "payments",
      "CMS"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "healthcare-basics",
      "data-cleaning"
    ],
    "topic_tags": [
      "medicare-data",
      "healthcare-analytics",
      "provider-payments",
      "cms-data",
      "public-datasets"
    ],
    "summary": "Comprehensive dataset containing utilization and payment information for all Medicare providers from the Centers for Medicare & Medicaid Services. This public use file enables analysis of healthcare spending patterns, provider behavior, and geographic variations in Medicare services. Essential resource for healthcare economists studying payment systems and service delivery.",
    "use_cases": [
      "Analyzing geographic variation in Medicare spending per beneficiary across different regions",
      "Identifying high-volume providers and their payment patterns for fraud detection research"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Medicare provider payment data for healthcare analysis",
      "CMS public use files for studying healthcare spending",
      "Dataset showing Medicare utilization by provider",
      "Healthcare economics data on provider payments"
    ]
  },
  {
    "name": "Google Dataset Search",
    "description": "Universal search engine for datasets across the web. Meta-tool for discovering research data",
    "category": "Data Portals",
    "url": "https://datasetsearch.research.google.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search engine",
      "datasets",
      "discovery",
      "Google"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "basic-web-search",
      "dataset-formats"
    ],
    "topic_tags": [
      "data-discovery",
      "research-datasets",
      "search-engine",
      "open-data"
    ],
    "summary": "Google Dataset Search is a specialized search engine that indexes datasets from across the web, making it easy to discover publicly available research data. It aggregates datasets from repositories, government sites, news organizations, and academic publishers in one searchable interface. Researchers and data scientists use it to find relevant datasets without having to search individual data portals separately.",
    "use_cases": [
      "Finding public datasets for a machine learning project on climate change",
      "Discovering government economic data for policy research analysis"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "how to find datasets online",
      "Google dataset search tool",
      "where to discover research datasets",
      "search engine for public data"
    ]
  },
  {
    "name": "Hugging Face Datasets",
    "description": "ML/NLP datasets hub with 100K+ datasets. Easy loading via Python library. Community-driven repository",
    "category": "Data Portals",
    "url": "https://huggingface.co/datasets",
    "docs_url": "https://huggingface.co/docs/datasets",
    "github_url": null,
    "tags": [
      "ML",
      "NLP",
      "datasets",
      "Hugging Face",
      "community"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-basics",
      "pandas-dataframes"
    ],
    "topic_tags": [
      "datasets",
      "machine-learning",
      "NLP",
      "data-loading",
      "community-repository"
    ],
    "summary": "Hugging Face Datasets is a comprehensive hub containing over 100,000 machine learning and NLP datasets with a simple Python library for easy loading. It's a community-driven platform that standardizes dataset access and preprocessing for ML practitioners. The library handles caching, streaming, and format conversion automatically.",
    "use_cases": [
      "Loading pre-processed text datasets for training transformer models",
      "Finding benchmark datasets for comparing model performance across standard evaluation tasks"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Where can I find datasets for NLP projects",
      "How to load machine learning datasets in Python",
      "Best repository for ML datasets with easy API",
      "Hugging Face datasets library tutorial"
    ]
  },
  {
    "name": "Criteo Terabyte",
    "description": "342GB, 45M samples with 13 integer features and 26 hashed categorical features for CTR prediction",
    "category": "Advertising",
    "url": "https://huggingface.co/datasets/criteo/CriteoClickLogs",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR",
      "advertising",
      "large-scale",
      "benchmark"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "machine-learning-classification",
      "feature-engineering"
    ],
    "topic_tags": [
      "click-through-rate",
      "advertising",
      "large-scale-data",
      "benchmark-dataset",
      "categorical-features"
    ],
    "summary": "The Criteo Terabyte dataset is a massive 342GB collection of 45 million click-through rate prediction samples from online advertising. It contains 13 integer features and 26 hashed categorical features, making it the standard benchmark for evaluating CTR prediction models at scale. This dataset is widely used by researchers and practitioners to test algorithms on realistic advertising data with production-scale volume.",
    "use_cases": [
      "Benchmarking new CTR prediction algorithms against state-of-the-art baselines",
      "Testing scalability of machine learning systems with terabyte-scale advertising data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "large scale CTR prediction dataset",
      "Criteo advertising benchmark data",
      "terabyte click through rate dataset",
      "categorical features advertising machine learning"
    ]
  },
  {
    "name": "Open e-commerce 1.0",
    "description": "1.85M Amazon purchases from 5,027 US consumers (2018-2022) linked to demographics (age, gender, income, education)",
    "category": "E-Commerce",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGLYDY",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "demographics",
      "purchases",
      "linked data"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "SQL-joins",
      "descriptive-statistics"
    ],
    "topic_tags": [
      "consumer-behavior",
      "amazon-data",
      "demographic-analysis",
      "purchase-patterns",
      "longitudinal-data"
    ],
    "summary": "A comprehensive dataset containing 1.85 million Amazon purchase records from over 5,000 US consumers spanning 2018-2022, with linked demographic information including age, gender, income, and education levels. This dataset enables researchers and analysts to study consumer behavior patterns and demographic influences on e-commerce purchasing decisions. The multi-year timeframe allows for longitudinal analysis of shopping trends and consumer segments.",
    "use_cases": [
      "Analyzing how demographic factors (age, income, education) influence Amazon purchase categories and spending patterns",
      "Building customer segmentation models to identify distinct consumer groups based on purchasing behavior and demographics"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Amazon purchase data with demographics",
      "consumer behavior dataset e-commerce",
      "demographic analysis shopping patterns dataset",
      "longitudinal purchase data US consumers"
    ]
  },
  {
    "name": "OTTO Session Data",
    "description": "12M German e-commerce sessions with click \u2192 cart \u2192 order sequences. RecSys 2022 competition",
    "category": "E-Commerce",
    "url": "https://github.com/otto-de/recsys-dataset",
    "docs_url": null,
    "github_url": "https://github.com/otto-de/recsys-dataset",
    "tags": [
      "sessions",
      "recommendations",
      "Germany",
      "RecSys"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "basic-SQL",
      "recommendation-systems-concepts"
    ],
    "topic_tags": [
      "session-data",
      "e-commerce-analytics",
      "recommendation-systems",
      "sequential-data",
      "conversion-funnel"
    ],
    "summary": "A large dataset of 12 million German e-commerce user sessions tracking the customer journey from clicks to cart additions to purchases. Created for the RecSys 2022 competition, it provides real-world sequential interaction data ideal for building and evaluating recommendation systems. The dataset captures the complete conversion funnel with temporal ordering of user actions.",
    "use_cases": [
      "Building next-item recommendation models for e-commerce platforms",
      "Analyzing conversion rates and drop-off patterns in online shopping funnels"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "e-commerce recommendation dataset",
      "session data for RecSys competition",
      "German online shopping behavior data",
      "click to purchase conversion dataset"
    ]
  },
  {
    "name": "ASOS Digital Experiments",
    "description": "99 real A/B experiments with 24,153 time-granular snapshots for adaptive stopping research",
    "category": "E-Commerce",
    "url": "https://osf.io/64jsb/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "experiments",
      "adaptive",
      "fashion"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "statistical-hypothesis-testing",
      "A/B-test-design"
    ],
    "topic_tags": [
      "A/B-testing",
      "adaptive-stopping",
      "e-commerce",
      "experimental-design",
      "real-world-data"
    ],
    "summary": "A collection of 99 real A/B experiments from ASOS with over 24,000 time-granular snapshots, designed for studying adaptive stopping methods in digital experimentation. This dataset provides researchers and practitioners with authentic e-commerce experimental data to develop and validate sequential testing approaches. The time-series nature allows for analysis of when experiments should be stopped based on accumulating evidence.",
    "use_cases": [
      "Developing and benchmarking adaptive stopping rules for A/B tests to reduce experiment duration while maintaining statistical validity",
      "Training machine learning models to predict optimal experiment stopping times based on real e-commerce conversion patterns"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "real A/B testing datasets with time series data",
      "adaptive stopping rules experiment data",
      "ASOS digital experiments dataset",
      "e-commerce A/B test snapshots for research"
    ]
  },
  {
    "name": "Prosper Loan Data",
    "description": "113K P2P loans with borrower characteristics and outcomes",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/henryokam/prosper-loan-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P",
      "lending",
      "loans"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "logistic-regression",
      "data-visualization"
    ],
    "topic_tags": [
      "peer-to-peer",
      "credit-risk",
      "financial-services",
      "loan-default",
      "dataset"
    ],
    "summary": "A comprehensive dataset of 113,000 peer-to-peer loans from Prosper marketplace containing borrower demographics, credit scores, loan terms, and repayment outcomes. Commonly used by data scientists and researchers studying credit risk modeling and alternative lending markets. Perfect for building predictive models of loan default and analyzing factors that influence lending decisions.",
    "use_cases": [
      "Building machine learning models to predict loan default probability based on borrower characteristics",
      "Analyzing bias in peer-to-peer lending decisions across different demographic groups"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "peer to peer lending dataset",
      "loan default prediction data",
      "prosper marketplace loan data",
      "credit risk modeling dataset"
    ]
  },
  {
    "name": "ORBITAAL Bitcoin Graph",
    "description": "13 years (2009-2021) of entity-level Bitcoin transaction networks with BTC/USD values",
    "category": "Financial Services",
    "url": "https://www.nature.com/articles/s41597-023-02416-6",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Bitcoin",
      "crypto",
      "graph",
      "transactions"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "graph-analysis",
      "SQL-joins"
    ],
    "topic_tags": [
      "bitcoin-transactions",
      "cryptocurrency-networks",
      "graph-data",
      "financial-networks",
      "blockchain-analysis"
    ],
    "summary": "A comprehensive dataset containing 13 years of Bitcoin transaction networks organized at the entity level, with corresponding BTC/USD exchange rates. This dataset enables researchers and data scientists to analyze cryptocurrency flow patterns, entity behavior, and network evolution over Bitcoin's entire history. The graph structure allows for network analysis of Bitcoin's transaction ecosystem.",
    "use_cases": [
      "Analyzing money laundering patterns and suspicious transaction flows in cryptocurrency networks",
      "Studying the evolution of Bitcoin's network structure and identifying key entities or hubs over time"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "bitcoin transaction network dataset",
      "cryptocurrency graph analysis data",
      "bitcoin entity level transaction history",
      "blockchain network analysis dataset"
    ]
  },
  {
    "name": "Stack Overflow Developer Survey",
    "description": "49K+ annual responses with salaries, tech adoption, and developer analytics",
    "category": "Labor Markets",
    "url": "https://survey.stackoverflow.co/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "developers",
      "salaries",
      "survey",
      "tech"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "descriptive-statistics",
      "data-visualization"
    ],
    "topic_tags": [
      "developer-survey",
      "salary-data",
      "tech-adoption",
      "workforce-analytics",
      "survey-data"
    ],
    "summary": "Annual comprehensive survey dataset from Stack Overflow containing responses from 49,000+ developers worldwide. Includes detailed information on salaries, technology preferences, job satisfaction, and demographic data. Widely used for understanding tech labor market trends and developer ecosystem dynamics.",
    "use_cases": [
      "Benchmarking salary expectations for different programming languages and experience levels",
      "Analyzing technology adoption patterns to inform product roadmaps or hiring decisions"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "developer salary data by programming language",
      "stack overflow survey dataset download",
      "tech industry workforce trends data",
      "how much do python developers make compared to javascript"
    ]
  },
  {
    "name": "LIAR",
    "description": "12.8K fact-checked political statements with speaker metadata",
    "category": "Content Moderation",
    "url": "https://sites.cs.ucsb.edu/~william/software.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fact-checking",
      "politics",
      "misinformation"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "python-pandas",
      "text-classification",
      "natural-language-processing"
    ],
    "topic_tags": [
      "fact-checking",
      "political-statements",
      "misinformation-detection",
      "labeled-dataset",
      "content-moderation"
    ],
    "summary": "LIAR is a dataset containing 12,800 manually fact-checked political statements from PolitiFact, labeled with truthfulness ratings and enriched with speaker metadata. It's commonly used for building automated fact-checking systems and studying misinformation patterns in political discourse. The dataset provides a standardized benchmark for researchers working on misinformation detection and content moderation applications.",
    "use_cases": [
      "Training machine learning models to automatically classify political statements as true, false, or misleading",
      "Analyzing patterns in political misinformation by speaker demographics, party affiliation, or statement topics"
    ],
    "audience": [
      "Junior-DS",
      "Early-PhD"
    ],
    "synthetic_questions": [
      "fact checking dataset political statements",
      "misinformation detection training data",
      "LIAR dataset for fake news classification",
      "political fact checking benchmark dataset"
    ]
  },
  {
    "name": "LaDe (Cainiao)",
    "description": "10.6M+ packages with 619K trajectories and GPS data from Alibaba logistics",
    "category": "Logistics & Supply Chain",
    "url": "https://huggingface.co/datasets/Cainiao-AI/LaDe",
    "docs_url": null,
    "github_url": "https://github.com/chuxiaoyu/LaDE",
    "tags": [
      "packages",
      "trajectories",
      "Alibaba",
      "delivery"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "python-pandas",
      "geospatial-analysis",
      "time-series-analysis"
    ],
    "topic_tags": [
      "logistics-data",
      "trajectory-analysis",
      "supply-chain",
      "geospatial",
      "delivery-optimization"
    ],
    "summary": "LaDe is a massive logistics dataset from Alibaba's Cainiao network containing over 10.6 million package records with 619K delivery trajectories and GPS tracking data. It provides real-world insights into last-mile delivery operations, route optimization, and supply chain efficiency at unprecedented scale. The dataset is valuable for researchers and practitioners working on logistics optimization, delivery prediction models, and urban mobility analysis.",
    "use_cases": [
      "Building delivery time prediction models using trajectory and GPS data",
      "Analyzing route optimization patterns for last-mile delivery efficiency"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Alibaba logistics dataset with GPS trajectories",
      "large scale delivery data for route optimization",
      "real-world package tracking dataset",
      "Cainiao supply chain data for research"
    ]
  }
]
