[
  {
    "name": "JD.com 2020 (MSOM-20)",
    "description": "2.5M customers (457k purchasers) and 31,868 SKUs from JD.com",
    "category": "E-Commerce",
    "url": "https://huggingface.co/datasets/a6687543/MSOM_Data_Driven_Challenge_2020",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "customers",
      "SKUs",
      "INFORMS",
      "operations"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "operations"
    ],
    "summary": "This dataset contains information on 2.5 million customers, including 457,000 purchasers, and 31,868 SKUs from JD.com. It can be used to analyze consumer behavior, purchasing patterns, and inventory management.",
    "use_cases": [
      "Analyze purchasing patterns of customers",
      "Evaluate SKU performance",
      "Study consumer behavior trends",
      "Optimize inventory management"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "JD.com customer dataset",
      "2020 JD.com SKUs data",
      "E-commerce purchasing behavior dataset",
      "JD.com customer analysis",
      "Dataset on JD.com purchasers",
      "Operations data from JD.com",
      "E-commerce dataset for analysis",
      "Customer data from JD.com"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2020",
    "size_category": "medium",
    "model_score": 0.6277
  },
  {
    "name": "Retail Rocket",
    "description": "2.76M events (views, carts, purchases) from 1.4M visitors",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "user events",
      "conversions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Retail Rocket dataset contains 2.76 million user events, including views, carts, and purchases, from 1.4 million visitors. It can be used for analyzing consumer behavior and conversion rates in e-commerce.",
    "use_cases": [
      "Analyzing conversion rates from views to purchases",
      "Understanding user behavior through event tracking",
      "Predicting future purchasing trends based on past data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Retail Rocket dataset?",
      "How can I analyze user events in e-commerce?",
      "What insights can be gained from 2.76M events?",
      "Where can I find datasets on user conversions?",
      "What are the characteristics of 1.4M visitors in e-commerce?",
      "How to use Retail Rocket data for consumer behavior analysis?",
      "What tools can I use to analyze e-commerce datasets?",
      "Are there similar datasets to Retail Rocket on Kaggle?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.6165
  },
  {
    "name": "BestBuy",
    "description": "Mobile website clicks (~42k) for Xbox games from BestBuy",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/competitions/acm-sf-chapter-hackathon-big",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clicks",
      "mobile",
      "gaming",
      "hackathon"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "gaming"
    ],
    "summary": "This dataset contains mobile website click data for Xbox games from BestBuy, totaling approximately 42,000 clicks. It can be used to analyze consumer behavior in the gaming sector and optimize marketing strategies for e-commerce.",
    "use_cases": [
      "Analyzing consumer engagement with Xbox games on mobile devices",
      "Evaluating the effectiveness of mobile marketing campaigns for gaming",
      "Identifying popular Xbox games based on mobile click data",
      "Understanding user behavior patterns in e-commerce for gaming products"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the mobile website clicks for Xbox games from BestBuy?",
      "How many clicks did Xbox games receive on mobile platforms?",
      "What is the click-through rate for Xbox games on BestBuy's mobile site?",
      "Which Xbox games had the highest mobile clicks on BestBuy?",
      "What trends can be observed in mobile clicks for gaming products?",
      "How does mobile traffic for Xbox games compare to other categories on BestBuy?"
    ],
    "domain_tags": [
      "retail",
      "gaming"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.5028
  },
  {
    "name": "LMSYS-Chat-1M",
    "description": "1M real-world conversations with 25 state-of-the-art LLMs spanning 154 languages",
    "category": "AI & LLM",
    "url": "https://huggingface.co/datasets/lmsys/lmsys-chat-1m",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "LLM",
      "conversations",
      "multilingual",
      "chatbot"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "LMSYS-Chat-1M is a dataset containing 1 million real-world conversations generated by 25 state-of-the-art large language models (LLMs) across 154 languages. It can be used for training, evaluating, and analyzing chatbot performance and multilingual conversation capabilities.",
    "use_cases": [
      "Training chatbots in multiple languages",
      "Evaluating LLM performance in conversation",
      "Analyzing conversational patterns across languages"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is LMSYS-Chat-1M dataset?",
      "Where can I find multilingual conversation datasets?",
      "How many languages are covered in LMSYS-Chat-1M?",
      "What are the applications of LMSYS-Chat-1M?",
      "What types of LLMs are included in LMSYS-Chat-1M?",
      "Can I use LMSYS-Chat-1M for chatbot training?"
    ],
    "domain_tags": [
      "AI",
      "Chatbot"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.4536
  },
  {
    "name": "Open E-Commerce 1.0 (MIT)",
    "description": "1.8M Amazon purchases with demographics (age, gender, location). Real household e-commerce behavior at scale",
    "category": "E-Commerce",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGAVK9",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "demographics",
      "purchases",
      "households",
      "MIT"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 1.8 million Amazon purchases along with demographic information such as age, gender, and location. It allows for analysis of real household e-commerce behavior at scale, providing insights into consumer purchasing patterns.",
    "use_cases": [
      "Analyzing consumer behavior based on demographics",
      "Studying the impact of location on purchasing patterns",
      "Evaluating trends in household e-commerce spending"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the demographics of Amazon purchasers?",
      "How can I analyze household e-commerce behavior?",
      "What insights can be gained from Amazon purchase data?",
      "What is the scale of e-commerce behavior in households?",
      "How does age and gender affect purchasing decisions on Amazon?",
      "Where can I find datasets on Amazon purchases?",
      "What are common demographic trends in e-commerce?",
      "How to visualize Amazon purchase data?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.404
  },
  {
    "name": "DiQAD",
    "description": "100K real-world user dialogues with comprehensive 6-dimension quality assessment",
    "category": "AI & LLM",
    "url": "https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation",
    "docs_url": null,
    "github_url": "https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation",
    "tags": [
      "dialogue",
      "quality assessment",
      "NLP"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "DiQAD is a dataset containing 100K real-world user dialogues that are assessed across six dimensions of quality. It can be used to train and evaluate natural language processing models focused on dialogue systems.",
    "use_cases": [
      "Training dialogue systems",
      "Evaluating NLP models",
      "Conducting quality assessments of dialogues"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the DiQAD dataset?",
      "How can I access the DiQAD dataset?",
      "What are the dimensions of quality in the DiQAD dataset?",
      "What type of dialogues are included in the DiQAD dataset?",
      "How many dialogues are in the DiQAD dataset?",
      "What is the purpose of the DiQAD dataset?",
      "Can I use the DiQAD dataset for NLP research?",
      "What quality assessment metrics are used in the DiQAD dataset?"
    ],
    "domain_tags": [
      "AI",
      "NLP"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.359
  },
  {
    "name": "Instacart",
    "description": "3.4M orders, 206k+ users, 49k+ products with reorder behavior",
    "category": "Food & Delivery",
    "url": "https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "orders",
      "reorder prediction"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Instacart dataset contains 3.4 million orders from over 206,000 users, featuring more than 49,000 products with reorder behavior. This data can be used to analyze consumer purchasing patterns and develop reorder prediction models.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Developing reorder prediction models",
      "Evaluating product popularity",
      "Understanding user engagement with grocery orders"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Instacart dataset?",
      "How can I analyze reorder behavior in grocery orders?",
      "What insights can be gained from Instacart order data?",
      "How many users are in the Instacart dataset?",
      "What products are included in the Instacart dataset?",
      "How to predict reorder behavior using Instacart data?",
      "What are common use cases for grocery order datasets?",
      "How to visualize consumer behavior in grocery shopping?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.3294
  },
  {
    "name": "Athey's Course Datasets",
    "description": "Datasets related to causal inference and experimental design from Susan Athey",
    "category": "Education",
    "url": "https://github.com/itamarcaspi/experimentdatar",
    "docs_url": null,
    "github_url": "https://github.com/itamarcaspi/experimentdatar",
    "tags": [
      "causal inference",
      "experiments",
      "research"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner|intermediate|advanced",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Athey's Course Datasets provide data related to causal inference and experimental design, primarily used for educational purposes. These datasets can be utilized for research and analysis in the field of economics and data science.",
    "use_cases": [
      "Analyzing causal relationships in experiments",
      "Teaching causal inference methods",
      "Conducting research in experimental design"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "datasets on causal inference",
      "Susan Athey experimental design datasets",
      "Athey course datasets",
      "causal inference datasets for education",
      "research datasets by Susan Athey",
      "experimental design data for analysis"
    ],
    "domain_tags": [
      "education"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.3294
  },
  {
    "name": "Amazon Sessions (KDD Cup 23)",
    "description": "Sessions from 6 locales with 40k-500k products per locale",
    "category": "E-Commerce",
    "url": "https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "sessions",
      "multilingual",
      "KDD"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains session data from Amazon across six locales, featuring between 40,000 to 500,000 products per locale. It can be used to analyze consumer behavior, product interactions, and multilingual shopping patterns.",
    "use_cases": [
      "Analyzing consumer behavior across different locales",
      "Comparing product performance in multilingual settings",
      "Studying session length and engagement metrics",
      "Evaluating the impact of locale on purchasing decisions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are Amazon sessions?",
      "How do sessions vary across locales?",
      "What products are included in the Amazon sessions dataset?",
      "How can I analyze consumer behavior using Amazon session data?",
      "What insights can be gained from multilingual session data?",
      "What is the KDD Cup 23 dataset about?",
      "How many products are available in each locale?",
      "What are the key features of Amazon sessions?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.2307
  },
  {
    "name": "BLP US Car Data",
    "description": "Classic dataset (1971-1990) for demand model estimation",
    "category": "Automotive",
    "url": "https://pyblp.readthedocs.io/en/stable/_notebooks/tutorial/blp.html",
    "docs_url": "https://pyblp.readthedocs.io/en/stable/_notebooks/tutorial/blp.html",
    "github_url": null,
    "tags": [
      "demand estimation",
      "BLP",
      "research",
      "classic"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "demand estimation",
      "consumer behavior",
      "automotive"
    ],
    "summary": "The BLP US Car Data is a classic dataset from 1971 to 1990 used for estimating demand models in the automotive sector. It provides insights into consumer preferences and pricing strategies.",
    "use_cases": [
      "Estimating demand for different car models",
      "Analyzing consumer preferences in automotive purchases",
      "Evaluating the impact of pricing on car sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the BLP US Car Data?",
      "How to use BLP US Car Data for demand estimation?",
      "Where can I find classic automotive datasets?",
      "What are the applications of BLP models?",
      "BLP US Car Data research papers",
      "Demand estimation datasets for automotive research",
      "Classic datasets for economic modeling",
      "How to analyze consumer behavior using BLP data?"
    ],
    "domain_tags": [
      "automotive"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1971-1990",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "Uber Movement",
    "description": "Zone-to-zone travel times and street speeds for 50+ cities worldwide. Congestion patterns from actual Uber rides",
    "category": "Transportation & Mobility",
    "url": "https://www.kaggle.com/datasets/ishandutta/uber-travel-movement-data-2-billion-trips",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Uber",
      "travel times",
      "congestion",
      "cities",
      "transportation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "mobility",
      "urban planning"
    ],
    "summary": "Uber Movement provides zone-to-zone travel times and street speeds for over 50 cities worldwide, derived from actual Uber rides. This dataset can be used to analyze congestion patterns and improve urban mobility planning.",
    "use_cases": [
      "Analyzing traffic congestion patterns in urban areas",
      "Comparing travel times across different cities",
      "Assessing the impact of ride-sharing on city traffic",
      "Informing urban mobility strategies and policies"
    ],
    "audience": [
      "Curious-browser",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the travel times in different cities using Uber Movement?",
      "How does congestion vary across urban areas?",
      "What street speeds are reported in the Uber Movement dataset?",
      "How can I access Uber Movement data for my city?",
      "What insights can be drawn from Uber's congestion patterns?",
      "Are there any trends in travel times over the past year?",
      "How does Uber Movement data help in urban planning?",
      "What cities are included in the Uber Movement dataset?"
    ],
    "domain_tags": [
      "transportation",
      "urban planning"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "IEEE-CIS Fraud Detection",
    "description": "590K card-not-present transactions with 393 features from Vesta Corp. Real messy fraud data (3.5% fraud rate)",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/competitions/ieee-fraud-detection",
    "docs_url": null,
    "github_url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "tags": [
      "fraud detection",
      "transactions",
      "large-scale",
      "messy data",
      "fintech",
      "competition"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "fraud detection",
      "financial services",
      "data analysis"
    ],
    "summary": "The IEEE-CIS Fraud Detection dataset contains 590K card-not-present transactions with 393 features, sourced from Vesta Corp. This dataset is useful for developing and testing fraud detection algorithms in financial services.",
    "use_cases": [
      "Building fraud detection models",
      "Analyzing transaction patterns",
      "Evaluating the effectiveness of fraud detection algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the IEEE-CIS Fraud Detection dataset?",
      "How can I access the IEEE-CIS Fraud Detection dataset?",
      "What features are included in the IEEE-CIS Fraud Detection dataset?",
      "What is the fraud rate in the IEEE-CIS Fraud Detection dataset?",
      "How to analyze fraud detection using the IEEE-CIS dataset?",
      "What are the challenges in working with messy fraud data?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "Chicago TNC Trips",
    "description": "100M+ rideshare trips with fares (unlike NYC which lacks fare data). Trip-level pricing for Uber/Lyft economic analysis",
    "category": "Transportation & Mobility",
    "url": "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "rideshare",
      "fares",
      "Uber",
      "Lyft",
      "Chicago",
      "pricing"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "mobility",
      "pricing"
    ],
    "summary": "The Chicago TNC Trips dataset contains over 100 million rideshare trips with fare data, allowing for detailed economic analysis of Uber and Lyft pricing in Chicago. Researchers can use this dataset to explore trends in rideshare pricing and consumer behavior.",
    "use_cases": [
      "Analyzing fare trends over time",
      "Comparing pricing strategies of Uber and Lyft",
      "Investigating the impact of events on rideshare demand",
      "Studying consumer behavior in rideshare usage"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the fare trends in Chicago rideshare trips?",
      "How do Uber and Lyft pricing compare in Chicago?",
      "What factors influence rideshare fares in Chicago?",
      "How many rideshare trips were taken in Chicago?",
      "What is the average fare for Uber and Lyft in Chicago?",
      "How can I analyze rideshare pricing data?",
      "What insights can be gained from Chicago TNC trips data?",
      "Where can I find rideshare trip data for Chicago?"
    ],
    "domain_tags": [
      "transportation",
      "mobility"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Chicago",
    "size_category": "massive",
    "model_score": 0.156
  },
  {
    "name": "OPTN Organ Transplant",
    "description": "Complete US organ donation records since 1987. Waiting lists, donor-recipient matches, outcomes. Market design and matching research",
    "category": "Healthcare",
    "url": "https://optn.transplant.hrsa.gov/data/",
    "docs_url": "https://optn.transplant.hrsa.gov/data/about-data/",
    "github_url": null,
    "tags": [
      "organ transplant",
      "matching",
      "market design",
      "healthcare",
      "waitlists"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The OPTN Organ Transplant dataset contains comprehensive records of organ donations in the US since 1987, including waiting lists, donor-recipient matches, and outcomes. This data can be utilized for research in market design and matching algorithms in the healthcare sector.",
    "use_cases": [
      "Analyzing trends in organ donation over the years.",
      "Studying the effectiveness of matching algorithms in organ transplants.",
      "Evaluating outcomes based on donor-recipient demographics.",
      "Investigating the impact of policy changes on waiting lists."
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the US organ donation records since 1987?",
      "How do donor-recipient matches work in organ transplants?",
      "What are the outcomes of organ transplants in the US?",
      "What is the waiting list data for organ transplants?",
      "How can market design improve organ transplant matching?",
      "What research exists on organ transplant waitlists?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1987-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "CMS Hospital Price Transparency",
    "description": "Hospital pricing data mandated since 2021. Negotiated rates, chargemaster prices across 6,000+ hospitals. Healthcare pricing research",
    "category": "Healthcare",
    "url": "https://www.cms.gov/hospital-price-transparency",
    "docs_url": "https://www.cms.gov/hospital-price-transparency/resources",
    "github_url": null,
    "tags": [
      "healthcare",
      "hospital pricing",
      "transparency",
      "CMS",
      "insurance"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "healthcare",
      "pricing",
      "transparency"
    ],
    "summary": "The CMS Hospital Price Transparency dataset contains hospital pricing data mandated since 2021, including negotiated rates and chargemaster prices across over 6,000 hospitals. This data can be used for healthcare pricing research and analysis.",
    "use_cases": [
      "Analyzing pricing trends across different hospitals",
      "Comparing negotiated rates for specific procedures",
      "Researching the impact of price transparency on healthcare costs",
      "Evaluating the effectiveness of insurance plans based on hospital pricing"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the CMS Hospital Price Transparency dataset?",
      "Where can I find hospital pricing data?",
      "How do hospitals determine their chargemaster prices?",
      "What are the negotiated rates for healthcare services?",
      "What insights can be gained from hospital pricing transparency?",
      "How has hospital pricing changed since 2021?",
      "What is the significance of hospital price transparency?",
      "Which hospitals are included in the CMS pricing data?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2021",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "Medicare Provider Utilization",
    "description": "All Medicare providers with service utilization and payment data. CMS public use files for healthcare analytics",
    "category": "Healthcare",
    "url": "https://data.cms.gov/provider-summary-by-type-of-service",
    "docs_url": "https://data.cms.gov/",
    "github_url": null,
    "tags": [
      "Medicare",
      "healthcare",
      "providers",
      "payments",
      "CMS"
    ],
    "best_for": "Understanding healthcare analytics, patient outcomes, and clinical predictions",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Medicare Provider Utilization dataset contains information on all Medicare providers, including their service utilization and payment data. This dataset can be used for healthcare analytics to understand provider performance and payment patterns.",
    "use_cases": [
      "Analyzing payment trends among Medicare providers",
      "Evaluating service utilization rates across different regions",
      "Comparing provider performance based on payment data",
      "Identifying outliers in Medicare provider payments"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Medicare Provider Utilization dataset?",
      "How can I access Medicare provider payment data?",
      "What information is included in the CMS public use files?",
      "Where can I find healthcare analytics datasets?",
      "What are the service utilization metrics for Medicare providers?",
      "How do Medicare payments vary by provider?",
      "What is the purpose of the Medicare Provider Utilization dataset?",
      "Who are the Medicare providers included in the dataset?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.156
  },
  {
    "name": "Coveo Shopping (SIGIR-21)",
    "description": "30M+ browsing events with query and image vectors for e-commerce search",
    "category": "E-Commerce",
    "url": "https://github.com/coveooss/SIGIR-ecom-data-challenge",
    "docs_url": null,
    "github_url": "https://github.com/coveooss/SIGIR-ecom-data-challenge",
    "tags": [
      "browsing",
      "search",
      "embeddings",
      "SIGIR"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Coveo Shopping dataset contains over 30 million browsing events along with query and image vectors specifically designed for e-commerce search. This dataset can be utilized for analyzing consumer behavior and improving search algorithms in online retail.",
    "use_cases": [
      "Analyzing consumer behavior trends in e-commerce.",
      "Improving search algorithms based on browsing events.",
      "Evaluating the effectiveness of image vectors in search results."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the browsing events in the Coveo Shopping dataset?",
      "How can I analyze query vectors from the Coveo Shopping dataset?",
      "What insights can be gained from the image vectors in the Coveo Shopping dataset?",
      "What is the significance of the Coveo Shopping dataset for e-commerce search?",
      "How does the Coveo Shopping dataset help in understanding consumer behavior?",
      "What are the applications of the Coveo Shopping dataset in search optimization?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "model_score": 0.0963
  },
  {
    "name": "Google Merchandise",
    "description": "3 months obfuscated GA4 e-commerce data (Nov 2020-Jan 2021)",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/bigquery/google-analytics-sample",
    "docs_url": "https://support.google.com/analytics/answer/7586738",
    "github_url": null,
    "tags": [
      "Google Analytics",
      "GA4",
      "web analytics"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "web analytics"
    ],
    "summary": "This dataset contains three months of obfuscated Google Analytics 4 e-commerce data, covering the period from November 2020 to January 2021. It can be used to analyze online consumer behavior, sales trends, and website performance metrics.",
    "use_cases": [
      "Analyzing consumer purchasing patterns during the holiday season.",
      "Evaluating the effectiveness of marketing campaigns on sales.",
      "Identifying popular products and categories.",
      "Assessing website traffic and conversion rates."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Google Merchandise dataset?",
      "How can I analyze GA4 e-commerce data?",
      "What insights can be gained from obfuscated Google Analytics data?",
      "Where can I find Google Analytics 4 datasets?",
      "What are common use cases for e-commerce analytics?",
      "How to interpret web analytics data?",
      "What tools can be used to analyze GA4 data?",
      "What trends can be identified in e-commerce data from 2020?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2020-2021",
    "size_category": "medium",
    "model_score": 0.0963
  },
  {
    "name": "Shopee",
    "description": "Dataset from Shopee's 2020 Code League competition",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/c/shopee-code-league-2021",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Shopee",
      "competition",
      "Southeast Asia"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "competition"
    ],
    "summary": "This dataset contains data from Shopee's 2020 Code League competition, focusing on e-commerce activities in Southeast Asia. It can be used to analyze consumer behavior, pricing strategies, and competition dynamics in the online retail space.",
    "use_cases": [
      "Analyzing consumer behavior in e-commerce",
      "Evaluating pricing strategies for online products",
      "Studying competition in Southeast Asian markets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Shopee 2020 Code League dataset",
      "E-commerce datasets for analysis",
      "Southeast Asia competition datasets",
      "Shopee data for consumer behavior",
      "Online retail datasets",
      "Datasets for pricing analysis in e-commerce"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2020",
    "geographic_scope": "Southeast Asia",
    "size_category": "medium",
    "model_score": 0.0963
  },
  {
    "name": "Brazilian eCommerce",
    "description": "100,000 orders (2016-2018) structured in 9 relational tables from Olist",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "orders",
      "Brazil",
      "relational data",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 100,000 orders from Brazilian eCommerce platform Olist, structured in 9 relational tables. It can be used to analyze consumer behavior, pricing strategies, and order trends in the Brazilian market.",
    "use_cases": [
      "Analyzing trends in consumer purchasing behavior",
      "Evaluating pricing strategies in the e-commerce sector",
      "Studying the impact of delivery times on customer satisfaction"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Brazilian eCommerce dataset",
      "Olist orders data",
      "Kaggle Brazilian eCommerce dataset",
      "relational data on Brazilian orders",
      "2016-2018 eCommerce data Brazil",
      "analysis of Olist orders",
      "Brazil eCommerce consumer behavior data"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2016-2018",
    "geographic_scope": "Brazil",
    "size_category": "medium",
    "model_score": 0.0902
  },
  {
    "name": "Open CDP",
    "description": "Omnichannel interaction tracking with AI-driven identity resolution",
    "category": "E-Commerce",
    "url": "https://rees46.com/en/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "omnichannel",
      "customer data",
      "identity resolution"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Open CDP dataset provides insights into omnichannel interactions by utilizing AI-driven identity resolution. It enables businesses to track customer behavior across multiple channels, enhancing their understanding of consumer preferences and improving marketing strategies.",
    "use_cases": [
      "Analyzing customer behavior across different channels",
      "Improving marketing strategies based on identity resolution",
      "Tracking the effectiveness of omnichannel campaigns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Open CDP dataset?",
      "How does omnichannel interaction tracking work?",
      "What are the benefits of AI-driven identity resolution?",
      "How can I analyze customer data from Open CDP?",
      "What tools can be used for omnichannel data analysis?",
      "What insights can be gained from customer data in e-commerce?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0902
  },
  {
    "name": "Alibaba Ads (IJCAI-18)",
    "description": "6 billion display ad/click logs over 8 days from 100M users",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/147588",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "clicks",
      "large-scale",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "advertising"
    ],
    "summary": "The Alibaba Ads dataset contains 6 billion display ad and click logs collected over 8 days from 100 million users. This dataset can be used to analyze user behavior in response to advertisements and to optimize advertising strategies.",
    "use_cases": [
      "Analyzing user engagement with ads",
      "Optimizing ad placements based on click data",
      "Studying the effectiveness of different advertising strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the click rates for Alibaba ads?",
      "How do user demographics affect ad performance?",
      "What patterns can be observed in ad clicks over time?",
      "How can this dataset be used to improve advertising strategies?",
      "What is the distribution of clicks across different ad types?",
      "How do different user segments interact with ads?",
      "What insights can be drawn from large-scale ad data?"
    ],
    "domain_tags": [
      "e-commerce"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0902
  },
  {
    "name": "Flipkart",
    "description": "Sales dataset from Indian e-commerce platform Flipkart",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/iyumrahul/flipkartsalesdataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "India",
      "sales",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "sales"
    ],
    "summary": "The Flipkart dataset contains sales data from the Indian e-commerce platform Flipkart. It can be used to analyze consumer behavior, sales trends, and pricing strategies in the e-commerce sector.",
    "use_cases": [
      "Analyze sales trends over time",
      "Evaluate pricing strategies",
      "Understand consumer behavior in e-commerce"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Flipkart sales dataset",
      "Flipkart e-commerce data",
      "sales analysis dataset India",
      "Kaggle Flipkart dataset",
      "Flipkart sales trends",
      "e-commerce sales data India"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "India",
    "size_category": "medium",
    "model_score": 0.0573
  },
  {
    "name": "Pakistan e-commerce",
    "description": "500k+ transactions (Mar 2016 - Aug 2018) from Pakistan's largest e-commerce",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Pakistan",
      "transactions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "transactions"
    ],
    "summary": "This dataset contains over 500,000 transactions from Pakistan's largest e-commerce platform, covering the period from March 2016 to August 2018. It can be used to analyze consumer behavior, pricing strategies, and market trends in the e-commerce sector.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Evaluating pricing strategies over time",
      "Studying the impact of promotions on sales",
      "Forecasting future e-commerce trends"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Pakistan e-commerce dataset",
      "500k transactions from Pakistan",
      "e-commerce data analysis in Pakistan",
      "Kaggle e-commerce datasets",
      "transactions dataset for consumer behavior",
      "Pakistan online shopping data",
      "e-commerce trends in Pakistan",
      "large e-commerce datasets"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2016-03 to 2018-08",
    "geographic_scope": "Pakistan",
    "size_category": "massive",
    "model_score": 0.0573
  },
  {
    "name": "Arena Human Preference (55K)",
    "description": "55K+ real-world conversations with human preference labels from Chatbot Arena",
    "category": "AI & LLM",
    "url": "https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "human preference",
      "LLM evaluation",
      "chatbot arena"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Arena Human Preference dataset consists of over 55,000 real-world conversations labeled with human preferences from the Chatbot Arena. It can be used for evaluating chatbot performance and understanding user preferences in AI interactions.",
    "use_cases": [
      "Evaluating chatbot performance",
      "Analyzing user preferences in AI interactions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Arena Human Preference dataset?",
      "How can I access the Arena Human Preference dataset?",
      "What are the applications of the Arena Human Preference dataset?",
      "What type of data is included in the Arena Human Preference dataset?",
      "How many conversations are in the Arena Human Preference dataset?",
      "What labels are used in the Arena Human Preference dataset?",
      "What is Chatbot Arena?",
      "How is human preference evaluated in chatbots?"
    ],
    "domain_tags": [
      "AI",
      "chatbots"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0395
  },
  {
    "name": "USS (User Satisfaction Simulation)",
    "description": "6,800 dialogues with 5-level satisfaction scale labels across multiple domains",
    "category": "AI & LLM",
    "url": "https://github.com/sunnweiwei/user-satisfaction-simulation",
    "docs_url": null,
    "github_url": "https://github.com/sunnweiwei/user-satisfaction-simulation",
    "tags": [
      "user satisfaction",
      "dialogue",
      "simulation"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The USS (User Satisfaction Simulation) dataset contains 6,800 dialogues labeled with a 5-level satisfaction scale across various domains. This dataset can be used to analyze user satisfaction trends and improve dialogue systems.",
    "use_cases": [
      "Analyzing user satisfaction trends",
      "Improving dialogue systems",
      "Training machine learning models for sentiment analysis"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the USS dataset?",
      "How can I analyze user satisfaction using the USS dataset?",
      "What are the domains covered in the USS dataset?",
      "What type of dialogues are included in the USS dataset?",
      "How many dialogues are in the USS dataset?",
      "What satisfaction scale is used in the USS dataset?",
      "Can I use the USS dataset for machine learning?",
      "What insights can I gain from the USS dataset?"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0123
  },
  {
    "name": "ConvAI Dataset",
    "description": "4,750 human-to-bot dialogues with thumbs up/down feedback plus quality scores",
    "category": "AI & LLM",
    "url": "http://convai.io/2017/data/dataset_description.pdf",
    "docs_url": "http://convai.io/2017/data/dataset_description.pdf",
    "github_url": null,
    "tags": [
      "chatbot",
      "human feedback",
      "dialogue quality"
    ],
    "best_for": "Learning LLM evaluation, chatbot quality assessment, and dialogue systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The ConvAI Dataset contains 4,750 human-to-bot dialogues that include feedback and quality scores. It can be used to analyze chatbot performance and improve dialogue systems through human feedback.",
    "use_cases": [
      "Analyzing chatbot performance",
      "Improving dialogue systems",
      "Evaluating human feedback on AI interactions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the ConvAI Dataset?",
      "Where can I find the ConvAI Dataset?",
      "How to analyze chatbot dialogues?",
      "What are the quality scores in the ConvAI Dataset?",
      "What feedback is provided in the ConvAI Dataset?",
      "How many dialogues are in the ConvAI Dataset?"
    ],
    "domain_tags": [
      "AI"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0123
  },
  {
    "name": "Amazon ShopBench (KDD Cup 2024)",
    "description": "57 tasks, 20K questions derived from real Amazon shopping data for LLM shopping assistants",
    "category": "Data Portals",
    "url": "https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms",
    "docs_url": null,
    "github_url": "https://github.com/fzp0424/ec-guide-kddup-2024",
    "tags": [
      "KDD",
      "Amazon",
      "e-commerce",
      "LLM",
      "2024",
      "multi-task"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Amazon ShopBench dataset consists of 57 tasks and 20,000 questions derived from real Amazon shopping data, specifically designed for training large language model shopping assistants. It can be used to evaluate and enhance the performance of LLMs in e-commerce contexts.",
    "use_cases": [
      "Training LLMs for shopping assistance",
      "Evaluating LLM performance on e-commerce tasks",
      "Developing multi-task learning models",
      "Analyzing consumer behavior in online shopping"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Amazon ShopBench dataset?",
      "How can I use Amazon shopping data for LLM training?",
      "What tasks are included in the KDD Cup 2024 dataset?",
      "Where can I find the Amazon ShopBench dataset?",
      "What types of questions are in the Amazon ShopBench?",
      "How does the Amazon ShopBench support multi-task learning?",
      "What is the purpose of the KDD Cup 2024?",
      "What are the applications of LLM in e-commerce?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0084
  },
  {
    "name": "Open e-commerce 1.0",
    "description": "1.85M Amazon purchases from 5,027 US consumers (2018-2022) linked to demographics (age, gender, income, education)",
    "category": "E-Commerce",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGLYDY",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Amazon",
      "demographics",
      "purchases",
      "linked data"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "demographics"
    ],
    "summary": "This dataset contains 1.85 million Amazon purchases made by 5,027 US consumers from 2018 to 2022, linked to various demographic factors such as age, gender, income, and education. It can be used to analyze consumer behavior, purchasing trends, and the impact of demographics on buying decisions.",
    "use_cases": [
      "Analyzing the impact of demographics on purchasing behavior",
      "Identifying trends in consumer spending over time",
      "Segmenting consumers based on demographic attributes for targeted marketing",
      "Evaluating the effectiveness of marketing strategies across different demographic groups"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the demographics of Amazon purchasers in the US?",
      "How do age and income affect purchasing behavior on Amazon?",
      "What trends can be observed in Amazon purchases from 2018 to 2022?",
      "How many purchases were made by consumers of different education levels?",
      "What is the average purchase amount for different demographic groups?",
      "How does gender influence Amazon purchasing patterns?",
      "What insights can be gained from linking purchase data to demographics?",
      "What are the key demographic factors affecting e-commerce sales?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2018-2022",
    "geographic_scope": "US",
    "size_category": "massive",
    "model_score": 0.0034
  },
  {
    "name": "Alibaba Mobile 2021",
    "description": "Mobile user behavior data from Alibaba (2021)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/109858",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "mobile",
      "user behavior",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains mobile user behavior data from Alibaba for the year 2021. It can be used to analyze trends in mobile shopping and consumer interactions on the Alibaba platform.",
    "use_cases": [
      "Analyzing mobile shopping trends",
      "Understanding consumer behavior on Alibaba",
      "Evaluating user engagement metrics",
      "Comparing mobile vs desktop user behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Alibaba Mobile 2021 dataset?",
      "Where can I find mobile user behavior data from Alibaba?",
      "How to analyze Alibaba user behavior data?",
      "What insights can be gained from Alibaba Mobile 2021?",
      "Is there a dataset for Alibaba mobile users?",
      "What are the trends in mobile shopping on Alibaba in 2021?",
      "How does Alibaba's mobile user behavior compare to other platforms?",
      "What tools can I use to analyze Alibaba Mobile 2021 data?"
    ],
    "domain_tags": [
      "e-commerce"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2021",
    "size_category": "medium",
    "model_score": 0.0021
  },
  {
    "name": "Alibaba User Behavior 2018",
    "description": "649M user interactions (clicks, carts, buys) on 25M items",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "user behavior",
      "large-scale",
      "interactions"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 649 million user interactions, including clicks, carts, and purchases, across 25 million items on Alibaba. It can be used to analyze user behavior patterns and improve marketing strategies.",
    "use_cases": [
      "Analyzing user engagement trends over time.",
      "Identifying factors influencing purchase decisions.",
      "Segmenting users based on interaction patterns.",
      "Optimizing product recommendations based on user behavior."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the user interactions in the Alibaba User Behavior 2018 dataset?",
      "How many items are included in the Alibaba User Behavior 2018 dataset?",
      "What types of user behavior does the Alibaba User Behavior 2018 dataset track?",
      "Where can I find the Alibaba User Behavior 2018 dataset?",
      "What is the size of the Alibaba User Behavior 2018 dataset?",
      "What insights can be gained from the Alibaba User Behavior 2018 dataset?",
      "How can I analyze user behavior using the Alibaba User Behavior 2018 dataset?",
      "What is the significance of the Alibaba User Behavior 2018 dataset in e-commerce research?"
    ],
    "domain_tags": [
      "e-commerce"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2018",
    "size_category": "massive",
    "model_score": 0.0016
  },
  {
    "name": "Twitch Gamers Social Network",
    "description": "168K nodes with mutual follower relationships. 6 ML tasks including churn, affiliate status, view count prediction",
    "category": "Entertainment & Media",
    "url": "https://snap.stanford.edu/data/twitch-social-networks.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Twitch",
      "social network",
      "gaming",
      "followers",
      "SNAP"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "pandas-dataframes",
      "regression-analysis"
    ],
    "topic_tags": [
      "gaming",
      "social-network-analysis"
    ],
    "summary": "This dataset contains a social network of Twitch gamers with 168K nodes representing mutual follower relationships. It can be used for various machine learning tasks, including churn prediction and view count forecasting.",
    "use_cases": [
      "Predicting churn among Twitch gamers",
      "Analyzing follower relationships in social networks",
      "Forecasting view counts for Twitch streams",
      "Determining affiliate status based on social connections"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Twitch Gamers Social Network dataset?",
      "How can I analyze mutual follower relationships on Twitch?",
      "What machine learning tasks can be performed with Twitch social network data?",
      "Where can I find datasets related to gaming and social networks?",
      "What are the characteristics of Twitch gamers' social networks?",
      "How to predict churn in social networks using Twitch data?",
      "What is the size of the Twitch Gamers Social Network dataset?",
      "What tags are associated with the Twitch Gamers Social Network dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "graph",
    "size_category": "medium",
    "model_score": 0.0015
  },
  {
    "name": "JD.com Open Datasets",
    "description": "Open dataset portal for e-commerce and logistics from JD.com",
    "category": "Data Portals",
    "url": "https://datascience.jd.com/page/opendataset.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "JD.com",
      "e-commerce",
      "logistics",
      "China"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "logistics"
    ],
    "summary": "The JD.com Open Datasets provide access to a variety of data related to e-commerce and logistics operations from JD.com. Researchers and analysts can utilize this data to explore consumer behavior, pricing strategies, and operational efficiencies in the e-commerce sector.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Evaluating logistics efficiency",
      "Studying market trends in e-commerce"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the JD.com Open Datasets?",
      "How can I access JD.com e-commerce data?",
      "What types of logistics data are available from JD.com?",
      "What insights can be gained from JD.com datasets?",
      "Where can I find open datasets for e-commerce?",
      "What are the applications of JD.com logistics data?",
      "How does JD.com data support research in e-commerce?",
      "What are the key features of JD.com Open Datasets?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0013
  },
  {
    "name": "CMS Medicare & Medicaid Data",
    "description": "Public use files from Centers for Medicare & Medicaid Services including claims data, provider statistics, and program enrollment",
    "category": "Insurance & Actuarial",
    "url": "https://data.cms.gov/",
    "docs_url": "https://www.cms.gov/Research-Statistics-Data-and-Systems/Research-Statistics-Data-and-Systems",
    "github_url": null,
    "tags": [
      "medicare",
      "medicaid",
      "claims-data",
      "healthcare",
      "government-programs"
    ],
    "best_for": "Healthcare policy research, reimbursement modeling, and population health analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The CMS Medicare & Medicaid Data consists of public use files from the Centers for Medicare & Medicaid Services, which include claims data, provider statistics, and program enrollment information. This dataset can be used for analyzing healthcare trends, evaluating program effectiveness, and understanding the dynamics of Medicare and Medicaid services.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the CMS Medicare & Medicaid Data?",
      "Where can I find Medicare claims data?",
      "How to access Medicaid program enrollment statistics?",
      "What are the public use files from CMS?",
      "What types of provider statistics are available in the CMS dataset?",
      "How can I analyze healthcare data from CMS?",
      "What insights can be gained from Medicare and Medicaid claims data?",
      "Where to download CMS public use files?"
    ],
    "use_cases": [
      "Analyzing trends in Medicare claims over time",
      "Evaluating the impact of Medicaid enrollment on healthcare access",
      "Comparing provider statistics across different regions",
      "Studying the relationship between program enrollment and healthcare outcomes"
    ],
    "domain_tags": [
      "healthcare",
      "insurance"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0012
  },
  {
    "name": "ASOS Digital Experiments",
    "description": "99 real A/B experiments with 24,153 time-granular snapshots for adaptive stopping research",
    "category": "E-Commerce",
    "url": "https://osf.io/64jsb/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "experiments",
      "adaptive",
      "fashion"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "experimentation",
      "data-analysis"
    ],
    "summary": "The ASOS Digital Experiments dataset contains 99 real A/B experiments with 24,153 time-granular snapshots, making it a valuable resource for researchers interested in adaptive stopping methods. Users can analyze the impact of various factors on consumer behavior in the fashion industry.",
    "use_cases": [
      "Analyzing the effectiveness of different marketing strategies.",
      "Studying consumer behavior changes based on website design variations.",
      "Evaluating the impact of pricing changes on sales.",
      "Researching adaptive stopping techniques in experimental design."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the ASOS Digital Experiments?",
      "How can I access A/B testing datasets?",
      "What insights can be gained from ASOS's A/B experiments?",
      "What is adaptive stopping in A/B testing?",
      "Where can I find datasets for e-commerce experiments?",
      "What are the key findings from ASOS's A/B testing?",
      "How to analyze A/B test results in fashion?",
      "What tools can be used for A/B testing analysis?"
    ],
    "domain_tags": [
      "retail",
      "fashion"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0011
  },
  {
    "name": "LaDe (Cainiao)",
    "description": "10.6M+ packages with 619K trajectories and GPS data from Alibaba logistics",
    "category": "Logistics & Supply Chain",
    "url": "https://huggingface.co/datasets/Cainiao-AI/LaDe",
    "docs_url": null,
    "github_url": "https://huggingface.co/datasets/Cainiao-AI/LaDe",
    "tags": [
      "packages",
      "trajectories",
      "Alibaba",
      "delivery"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "logistics",
      "supply-chain",
      "data-analysis"
    ],
    "summary": "LaDe (Cainiao) is a dataset containing over 10.6 million packages with 619,000 trajectories and GPS data from Alibaba logistics. This dataset can be used to analyze delivery patterns, optimize logistics operations, and improve supply chain efficiency.",
    "use_cases": [
      "Analyzing delivery efficiency of Alibaba logistics",
      "Optimizing route planning for package delivery",
      "Studying consumer behavior in logistics",
      "Evaluating the impact of logistics on supply chain performance"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the LaDe (Cainiao) dataset?",
      "How can I access GPS data from Alibaba logistics?",
      "What are the trajectories in the LaDe dataset?",
      "What insights can be gained from analyzing package delivery data?",
      "How many packages are included in the LaDe dataset?",
      "What logistics challenges can be addressed with this dataset?",
      "What types of analyses can be performed on Alibaba logistics data?",
      "Where can I find datasets related to logistics and supply chain?"
    ],
    "domain_tags": [
      "logistics",
      "supply-chain"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "model_score": 0.0011
  },
  {
    "name": "Alibaba Brick and Mortar (IJCAI-16)",
    "description": "Online and offline check-ins/purchases from 1,000+ stores",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/53",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "O2O",
      "offline",
      "retail",
      "IJCAI"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Alibaba Brick and Mortar dataset includes online and offline check-ins and purchases from over 1,000 stores. It can be used to analyze consumer behavior in retail settings and the impact of online interactions on offline purchases.",
    "use_cases": [
      "Analyzing the impact of online marketing on offline sales",
      "Studying consumer behavior patterns in retail",
      "Evaluating the effectiveness of O2O strategies",
      "Comparing purchase behaviors across different store types"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the online and offline check-ins in the Alibaba dataset?",
      "How can I analyze retail purchases from the Alibaba Brick and Mortar dataset?",
      "What insights can be gained from the IJCAI-16 Alibaba dataset?",
      "What are the consumer behaviors reflected in the Alibaba retail data?",
      "How does O2O influence retail sales in the Alibaba dataset?",
      "What types of stores are included in the Alibaba Brick and Mortar dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0011
  },
  {
    "name": "Gamified Learning",
    "description": "Experiments on gamification in learning environments",
    "category": "Education",
    "url": "https://data.mendeley.com/datasets/7kgpn39m8w/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "gamification",
      "education",
      "experiments"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains experiments on gamification in learning environments, exploring how gamification techniques can enhance educational experiences. Researchers and educators can analyze the effects of gamification on learning outcomes and engagement.",
    "use_cases": [
      "Analyzing the impact of gamification on student performance",
      "Evaluating different gamification strategies in educational settings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is gamified learning?",
      "How does gamification affect education?",
      "What experiments have been conducted on gamification?",
      "What are the benefits of gamification in learning?",
      "Can gamification improve student engagement?",
      "What data is available on gamification in education?"
    ],
    "domain_tags": [
      "education"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0011
  },
  {
    "name": "ASOS Experiments",
    "description": "99 real e-commerce experiments with daily checkpoints from ASOS",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/marinazmieva/asos-digital-experiments-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "e-commerce",
      "fashion",
      "Kaggle"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "A/B testing",
      "fashion"
    ],
    "summary": "The ASOS Experiments dataset contains 99 real e-commerce experiments with daily checkpoints from ASOS. This data can be used to analyze consumer behavior and the effectiveness of various marketing strategies in the fashion industry.",
    "use_cases": [
      "Analyzing the impact of A/B testing on sales",
      "Evaluating consumer behavior trends in fashion",
      "Testing different marketing strategies",
      "Understanding daily performance metrics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "ASOS e-commerce experiments dataset",
      "real e-commerce A/B testing data",
      "daily checkpoints ASOS experiments",
      "fashion industry experiments dataset",
      "Kaggle ASOS experiments",
      "e-commerce consumer behavior analysis",
      "A/B testing in fashion"
    ],
    "domain_tags": [
      "fashion",
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0011
  },
  {
    "name": "ICPSR Auction Studies",
    "description": "Search results for auction studies from ICPSR",
    "category": "Advertising",
    "url": "https://www.openicpsr.org/openicpsr/search/studies",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "research",
      "social science"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "social science",
      "research",
      "auctions"
    ],
    "summary": "The ICPSR Auction Studies dataset contains search results for various auction studies available through the ICPSR repository. Researchers can use this dataset to analyze auction mechanisms, bidding behavior, and outcomes in different contexts.",
    "use_cases": [
      "Analyzing bidding strategies in auctions",
      "Comparing auction outcomes across different studies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the available auction studies in ICPSR?",
      "How can I access auction research data from ICPSR?",
      "What insights can be gained from ICPSR auction studies?",
      "Are there specific auction types studied in ICPSR?",
      "What methodologies are used in ICPSR auction research?",
      "Can I find data on bidding strategies in auction studies from ICPSR?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.001
  },
  {
    "name": "KuaiSAR",
    "description": "5M search actions, 14.6M recommendation events from 25k users",
    "category": "Entertainment & Media",
    "url": "https://kuaisar.github.io/",
    "docs_url": "https://kuaisar.github.io/",
    "github_url": null,
    "tags": [
      "search",
      "recommendations",
      "video",
      "Kuaishou"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior"
    ],
    "summary": "The KuaiSAR dataset contains 5 million search actions and 14.6 million recommendation events from 25,000 users, providing insights into user interactions with video content. It can be used to analyze search patterns and recommendation effectiveness in the entertainment and media sector.",
    "use_cases": [
      "Analyzing user search behavior in video platforms",
      "Evaluating the effectiveness of recommendation algorithms",
      "Studying user engagement with video content",
      "Identifying trends in user preferences over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the search actions in the KuaiSAR dataset?",
      "How many recommendation events are recorded in KuaiSAR?",
      "What user interactions are included in the KuaiSAR dataset?",
      "What insights can be gained from the KuaiSAR dataset?",
      "How does user behavior vary in the KuaiSAR dataset?",
      "What types of recommendations are made in the KuaiSAR dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0009
  },
  {
    "name": "Chicago Rideshare Data",
    "description": "Trip-level data for all Transportation Network Provider (Uber/Lyft) trips in Chicago since 2018. Includes ~57 million trips annually with origins, destinations, and fares.",
    "category": "Transportation Economics & Technology",
    "url": "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "rideshare",
      "Chicago",
      "trip-data",
      "urban-mobility",
      "Uber",
      "Lyft"
    ],
    "best_for": "Ridesharing market analysis, platform competition, and urban transportation research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "urban-mobility"
    ],
    "summary": "The Chicago Rideshare Data provides trip-level information for all Uber and Lyft rides in Chicago since 2018. This dataset can be used to analyze transportation patterns, fare structures, and urban mobility trends.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Chicago Rideshare Data?",
      "How to access trip-level data for Uber and Lyft in Chicago?",
      "What insights can be gained from Chicago rideshare data?",
      "Where can I find transportation network provider data for Chicago?",
      "What are the trends in rideshare usage in Chicago since 2018?",
      "How many rides were completed by Uber and Lyft in Chicago annually?"
    ],
    "use_cases": [
      "Analyzing fare trends over time",
      "Studying the impact of rideshare services on urban traffic",
      "Evaluating the distribution of rides across different neighborhoods"
    ],
    "domain_tags": [
      "transportation"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2018-present",
    "geographic_scope": "Chicago",
    "size_category": "massive",
    "model_score": 0.0009
  },
  {
    "name": "Criteo Counterfactual Learning",
    "description": "25M logged interactions with counterfactual propensity scores. Gold standard for offline policy evaluation and causal inference in ads",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/criteo-uplift-prediction-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "causal inference",
      "counterfactual",
      "advertising",
      "uplift modeling",
      "offline evaluation"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "causal inference",
      "uplift modeling"
    ],
    "summary": "The Criteo Counterfactual Learning dataset consists of 25 million logged interactions along with counterfactual propensity scores. It serves as a gold standard for offline policy evaluation and causal inference in advertising.",
    "use_cases": [
      "Evaluating advertising strategies",
      "Testing causal inference models",
      "Conducting uplift modeling analysis"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Criteo Counterfactual Learning dataset",
      "counterfactual propensity scores in advertising",
      "offline policy evaluation datasets",
      "causal inference datasets",
      "uplift modeling data",
      "advertising interaction datasets",
      "datasets for causal analysis in ads"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0008
  },
  {
    "name": "WRDS (Wharton Research Data Services)",
    "description": "350+ terabytes from CRSP, Compustat, TAQ - de facto standard for academic finance",
    "category": "Dataset Aggregators",
    "url": "https://wrds-www.wharton.upenn.edu",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "finance",
      "CRSP",
      "Compustat",
      "academic",
      "premium"
    ],
    "best_for": "Publication in top finance journals - requires institutional subscription",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "finance"
    ],
    "summary": "WRDS (Wharton Research Data Services) provides access to over 350 terabytes of data from CRSP, Compustat, and TAQ, making it the de facto standard for academic finance research. Researchers can utilize this extensive dataset for financial analysis, modeling, and empirical research.",
    "use_cases": [
      "Conducting empirical research in finance using CRSP data.",
      "Analyzing corporate financial performance with Compustat.",
      "Performing high-frequency trading analysis with TAQ data."
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is WRDS?",
      "How to access CRSP data from WRDS?",
      "What datasets are included in WRDS?",
      "How can I use Compustat data for financial analysis?",
      "What is the size of the WRDS dataset?",
      "What types of analysis can be performed with TAQ data?",
      "Is WRDS suitable for academic research?",
      "What are the benefits of using WRDS for finance studies?"
    ],
    "domain_tags": [
      "finance"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "model_score": 0.0008
  },
  {
    "name": "Online Shopping Intention",
    "description": "12,330 user sessions with numerical and categorical features for purchase prediction",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/henrysue/online-shoppers-intention",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "purchase prediction",
      "sessions",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 12,330 user sessions with both numerical and categorical features aimed at predicting purchase intentions. It can be used for analyzing consumer behavior and building predictive models for online shopping.",
    "use_cases": [
      "Predicting purchase intentions based on user sessions",
      "Analyzing the impact of categorical features on shopping behavior",
      "Building a regression model for e-commerce predictions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Online Shopping Intention dataset?",
      "How can I use the Online Shopping Intention dataset for purchase prediction?",
      "Where can I find user session data for e-commerce?",
      "What features are included in the Online Shopping Intention dataset?",
      "How to analyze online shopping behavior using datasets?",
      "What is the size of the Online Shopping Intention dataset?",
      "Is there a dataset for predicting online purchases?",
      "What are the tags associated with the Online Shopping Intention dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0008
  },
  {
    "name": "AXA Driver Telematics (Kaggle)",
    "description": "Driving behavior dataset with 50K driver trips characterized by second-by-second GPS coordinates for usage-based insurance",
    "category": "Insurance & Actuarial",
    "url": "https://www.kaggle.com/c/axa-driver-telematics-analysis",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "telematics",
      "UBI",
      "driving-behavior",
      "auto-insurance",
      "GPS-data"
    ],
    "best_for": "Usage-based insurance pricing, driver risk scoring, and behavior analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "driving-behavior",
      "insurance",
      "data-analysis"
    ],
    "summary": "The AXA Driver Telematics dataset contains detailed information on driving behavior, including second-by-second GPS coordinates from 50,000 driver trips. This dataset can be used to analyze driving patterns, assess risk for usage-based insurance, and improve auto insurance models.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the AXA Driver Telematics dataset?",
      "How can I analyze driving behavior using the AXA dataset?",
      "What insights can be gained from GPS data in telematics?",
      "Where can I find the AXA Driver Telematics dataset?",
      "What are the applications of telematics in auto insurance?",
      "How does driving behavior affect usage-based insurance models?",
      "What tools can I use to analyze telematics data?",
      "What is the significance of second-by-second GPS data in driving analysis?"
    ],
    "use_cases": [
      "Analyzing risk factors for usage-based insurance.",
      "Identifying patterns in driving behavior for insurance pricing.",
      "Developing predictive models for driver safety.",
      "Assessing the impact of driving habits on insurance claims."
    ],
    "domain_tags": [
      "insurance",
      "automotive"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0008
  },
  {
    "name": "Fliggy Transfers",
    "description": "Transfer-related data (flights, ground transport) from Fliggy",
    "category": "Travel & Hospitality",
    "url": "https://tianchi.aliyun.com/dataset/140721",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "travel",
      "transfers",
      "transportation"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "travel",
      "transfers",
      "transportation"
    ],
    "summary": "Fliggy Transfers provides data related to various modes of transport, including flights and ground transport. This dataset can be utilized for analyzing travel patterns, optimizing transportation logistics, and understanding consumer preferences in the travel sector.",
    "use_cases": [
      "Analyzing travel trends",
      "Optimizing ground transport logistics",
      "Studying consumer behavior in travel"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Fliggy Transfers data?",
      "How to analyze Fliggy transport data?",
      "What types of transfers does Fliggy offer?",
      "Where can I find Fliggy flight data?",
      "What insights can be gained from Fliggy Transfers?",
      "How to visualize transportation data from Fliggy?"
    ],
    "domain_tags": [
      "travel",
      "hospitality"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0008
  },
  {
    "name": "PaySim Synthetic Transactions",
    "description": "6M+ mobile money transactions simulating real fraud patterns. Agent-based model calibrated on real African mobile money logs",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/ealaxi/paysim1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fraud detection",
      "mobile payments",
      "transactions",
      "large-scale",
      "synthetic"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "fraud detection",
      "mobile payments",
      "transactions"
    ],
    "summary": "The PaySim Synthetic Transactions dataset contains over 6 million mobile money transactions that simulate real fraud patterns. It can be used to analyze and detect fraudulent activities in mobile payment systems.",
    "use_cases": [
      "Fraud detection analysis",
      "Simulation of mobile payment scenarios",
      "Testing machine learning models for fraud detection"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "PaySim dataset for fraud detection",
      "synthetic transactions dataset",
      "mobile money transaction simulation",
      "fraud patterns in mobile payments",
      "agent-based model for transactions",
      "large-scale mobile money dataset",
      "African mobile money logs"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Africa",
    "size_category": "massive",
    "model_score": 0.0007
  },
  {
    "name": "Used Car Auction (PakWheels)",
    "description": "Listings from PakWheels Pakistani automobile marketplace",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/asimzahid/pakistans-largest-pakwheels-automobiles-listings",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Pakistan",
      "listings"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "This dataset contains listings from the PakWheels marketplace, focusing on used cars in Pakistan. It can be used to analyze market trends, pricing strategies, and consumer preferences in the automotive sector.",
    "use_cases": [
      "Analyzing price trends of used cars in the Pakistani market",
      "Comparing consumer preferences for different car models",
      "Evaluating the impact of economic factors on used car prices"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest used car listings on PakWheels?",
      "How do prices of used cars vary in Pakistan?",
      "What are the most popular car models listed on PakWheels?",
      "How many listings are available for used cars in Pakistan?",
      "What is the average price of used cars on PakWheels?",
      "What trends can be observed in used car listings over time?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Pakistan",
    "size_category": "medium",
    "model_score": 0.0007
  },
  {
    "name": "RecSys Challenge 2025 (Synerise)",
    "description": "1M users, 6 months of real e-commerce behavior logs with 5 event types for universal behavioral modeling",
    "category": "Data Portals",
    "url": "https://recsys.synerise.com/data-set",
    "docs_url": "https://recsys.synerise.com/",
    "github_url": "https://github.com/Synerise/recsys2025",
    "tags": [
      "RecSys",
      "e-commerce",
      "large-scale",
      "real-world",
      "2025",
      "user behavior"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "user behavior"
    ],
    "summary": "The RecSys Challenge 2025 dataset contains real e-commerce behavior logs from 1 million users over a period of 6 months, featuring 5 event types. This dataset can be used for universal behavioral modeling and to analyze user interactions in an online retail environment.",
    "use_cases": [
      "Analyzing user purchase patterns over time",
      "Modeling user behavior for recommendation systems",
      "Evaluating the effectiveness of marketing strategies",
      "Understanding the impact of user interactions on sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the RecSys Challenge 2025 dataset?",
      "Where can I find e-commerce user behavior datasets?",
      "How to access the Synerise dataset for RecSys Challenge 2025?",
      "What are the event types in the RecSys Challenge 2025 dataset?",
      "Is there a dataset for modeling user behavior in e-commerce?",
      "What are the characteristics of the RecSys Challenge 2025 dataset?",
      "How many users are included in the RecSys Challenge 2025 dataset?",
      "What time period does the RecSys Challenge 2025 dataset cover?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0007
  },
  {
    "name": "ORBITAAL Bitcoin Transactions",
    "description": "13 years of Bitcoin transaction graphs (2009-2022). Complete blockchain with labeled entities. network analysis at scale",
    "category": "Financial Services",
    "url": "https://zenodo.org/records/7958648",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Bitcoin",
      "blockchain",
      "transactions",
      "network analysis",
      "cryptocurrency"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "financial services",
      "cryptocurrency",
      "network analysis"
    ],
    "summary": "The ORBITAAL Bitcoin Transactions dataset provides 13 years of Bitcoin transaction graphs from 2009 to 2022, including a complete blockchain with labeled entities. This dataset allows for extensive network analysis of Bitcoin transactions at scale.",
    "use_cases": [
      "Analyzing transaction patterns in Bitcoin over time",
      "Identifying key entities in the Bitcoin blockchain",
      "Conducting network analysis to understand transaction flows",
      "Studying the impact of Bitcoin transactions on financial markets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the Bitcoin transaction graphs from 2009 to 2022?",
      "How can I analyze Bitcoin transactions using the ORBITAAL dataset?",
      "What labeled entities are included in the complete blockchain?",
      "What insights can be gained from network analysis of Bitcoin transactions?",
      "Where can I find a dataset for Bitcoin transaction analysis?",
      "What is the structure of the ORBITAAL Bitcoin Transactions dataset?",
      "How to perform network analysis on cryptocurrency transactions?",
      "What time period does the ORBITAAL Bitcoin dataset cover?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "graph",
    "temporal_coverage": "2009-2022",
    "size_category": "medium",
    "model_score": 0.0007
  },
  {
    "name": "IJCAI Competitions",
    "description": "International AI conference with competitions",
    "category": "Data Portals",
    "url": "https://www.ijcai.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "IJCAI",
      "AI",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "AI",
      "competitions"
    ],
    "summary": "The IJCAI Competitions dataset includes data from international AI competitions held at the IJCAI conference. Researchers and practitioners can use this data to analyze AI competition outcomes and methodologies.",
    "use_cases": [
      "Analyzing competition results",
      "Comparing AI methodologies",
      "Evaluating participant performance"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the IJCAI competitions?",
      "How can I access the IJCAI Competitions dataset?",
      "What types of AI competitions are included in IJCAI?",
      "What data is available from IJCAI competitions?",
      "Who participates in IJCAI competitions?",
      "What are the outcomes of IJCAI competitions?",
      "How to analyze data from IJCAI competitions?",
      "What is the significance of IJCAI competitions in AI research?"
    ],
    "domain_tags": [
      "technology"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0007
  },
  {
    "name": "Yoyi",
    "description": "Computational advertising dataset from Chinese ad platform",
    "category": "Advertising",
    "url": "https://apex.sjtu.edu.cn/datasets/7",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "China",
      "computational ads"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Yoyi dataset is a computational advertising dataset sourced from a Chinese ad platform. It can be used for analyzing advertising strategies and consumer behavior in the context of digital marketing.",
    "use_cases": [
      "Analyzing advertising effectiveness",
      "Studying consumer behavior in China"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Yoyi computational advertising dataset?",
      "Where can I find the Yoyi dataset?",
      "How to use the Yoyi dataset for advertising analysis?",
      "What insights can be gained from the Yoyi dataset?",
      "Is the Yoyi dataset available for public use?",
      "What are the features of the Yoyi dataset?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0007
  },
  {
    "name": "OTTO Session Data",
    "description": "12M German e-commerce sessions with click \u2192 cart \u2192 order sequences. RecSys 2022 competition",
    "category": "E-Commerce",
    "url": "https://github.com/otto-de/recsys-dataset",
    "docs_url": null,
    "github_url": "https://github.com/otto-de/recsys-dataset",
    "tags": [
      "sessions",
      "recommendations",
      "Germany",
      "RecSys"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "recommendations"
    ],
    "summary": "The OTTO Session Data consists of 12 million e-commerce sessions from Germany, capturing the click, cart, and order sequences. This dataset can be utilized for building recommendation systems and analyzing consumer behavior in online shopping.",
    "use_cases": [
      "Building recommendation systems",
      "Analyzing consumer behavior",
      "Optimizing e-commerce strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "OTTO Session Data for e-commerce analysis",
      "German e-commerce session dataset",
      "dataset for recommendation systems",
      "click cart order sequence data",
      "OTTO dataset RecSys competition",
      "e-commerce session data analysis",
      "recommendation system datasets",
      "German online shopping data"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Germany",
    "size_category": "medium",
    "model_score": 0.0006
  },
  {
    "name": "KDD Cup",
    "description": "ACM SIGKDD annual data mining competition",
    "category": "Data Portals",
    "url": "https://kdd.org/kdd-cup",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "KDD",
      "data mining",
      "ACM"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The KDD Cup is an annual data mining competition organized by ACM SIGKDD, providing datasets for participants to analyze and develop innovative solutions. It serves as a platform for showcasing advancements in data mining techniques and methodologies.",
    "use_cases": [],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the KDD Cup?",
      "How to participate in the KDD Cup?",
      "What datasets are available for the KDD Cup?",
      "What are the challenges in the KDD Cup?",
      "How to analyze KDD Cup data?",
      "What techniques are used in KDD Cup competitions?"
    ],
    "domain_tags": [
      "data mining"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0006
  },
  {
    "name": "CAISO OASIS",
    "description": "California ISO market data including prices, generation, demand, and transmission",
    "category": "Energy",
    "url": "http://oasis.caiso.com/",
    "docs_url": "http://www.caiso.com/market/Pages/MarketProcesses.aspx",
    "github_url": null,
    "tags": [
      "California",
      "prices",
      "wholesale",
      "real-time",
      "day-ahead"
    ],
    "best_for": "Studying wholesale electricity market dynamics and renewable integration",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "energy",
      "market-analysis",
      "pricing"
    ],
    "summary": "The CAISO OASIS dataset provides comprehensive market data from the California ISO, including prices, generation, demand, and transmission information. This data can be used for analyzing market trends, forecasting energy prices, and evaluating supply and demand dynamics in the energy sector.",
    "use_cases": [
      "Analyzing price trends in the California energy market",
      "Forecasting future energy demand based on historical data",
      "Evaluating the impact of generation sources on market prices",
      "Studying the relationship between demand and transmission capacity"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the CAISO OASIS dataset?",
      "How can I access California ISO market data?",
      "What types of data are included in CAISO OASIS?",
      "Where can I find real-time energy prices in California?",
      "What is the significance of day-ahead market data?",
      "How does generation and demand data affect energy pricing?",
      "What are the key components of California ISO market data?",
      "How can I analyze transmission data from CAISO OASIS?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2009-present",
    "geographic_scope": "California",
    "size_category": "medium",
    "model_score": 0.0006
  },
  {
    "name": "Criteo Attribution Dataset",
    "description": "30 days of advertising traffic with conversion attribution data for multi-touch attribution research",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/",
    "docs_url": "https://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/",
    "github_url": null,
    "tags": [
      "attribution",
      "conversions",
      "touchpoints",
      "Criteo"
    ],
    "best_for": "Multi-touch attribution modeling and conversion path analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Criteo Attribution Dataset contains 30 days of advertising traffic data along with conversion attribution data. This dataset can be used for multi-touch attribution research to analyze the effectiveness of different advertising touchpoints in driving conversions.",
    "use_cases": [
      "Analyzing the effectiveness of different advertising channels",
      "Understanding consumer behavior through touchpoint analysis"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Criteo Attribution Dataset?",
      "How can I analyze multi-touch attribution with Criteo data?",
      "What insights can be gained from advertising traffic data?",
      "What are the conversion rates in the Criteo Attribution Dataset?",
      "How does Criteo track advertising touchpoints?",
      "What research can be conducted using the Criteo Attribution Dataset?",
      "What types of conversions are included in the Criteo dataset?",
      "How can I access the Criteo Attribution Dataset?"
    ],
    "domain_tags": [
      "ad tech"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "30 days",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0006
  },
  {
    "name": "RecSys Challenge 2024 (EB-NeRD)",
    "description": "2.3M users, 380M+ news impressions from Ekstra Bladet for news recommendation research",
    "category": "Data Portals",
    "url": "https://www.recsyschallenge.com/2024/",
    "docs_url": null,
    "github_url": "https://github.com/recsyspolimi/recsys-challenge-2024-ekstrabladet",
    "tags": [
      "RecSys",
      "news",
      "large-scale",
      "real-world",
      "2024",
      "impressions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "news recommendation",
      "machine learning",
      "data analysis"
    ],
    "summary": "The RecSys Challenge 2024 (EB-NeRD) dataset consists of 2.3 million users and over 380 million news impressions from Ekstra Bladet. It is designed for research in news recommendation systems, allowing researchers to analyze user behavior and improve recommendation algorithms.",
    "use_cases": [
      "Analyzing user engagement with news articles",
      "Developing and testing recommendation algorithms",
      "Studying the impact of news impressions on user behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the RecSys Challenge 2024 dataset?",
      "How can I access the EB-NeRD dataset for news recommendation research?",
      "What are the user demographics in the RecSys Challenge 2024 dataset?",
      "What types of news impressions are included in the EB-NeRD dataset?",
      "How many users are in the RecSys Challenge 2024 dataset?",
      "What is the scale of the news impressions in the EB-NeRD dataset?",
      "What research can be conducted using the RecSys Challenge 2024 dataset?",
      "Where can I find datasets for news recommendation systems?"
    ],
    "domain_tags": [
      "media",
      "technology"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0006
  },
  {
    "name": "MicroLens",
    "description": "1 billion interactions from 34 million users on 1 million micro-videos",
    "category": "Entertainment & Media",
    "url": "https://github.com/westlake-repl/MicroLens",
    "docs_url": null,
    "github_url": "https://github.com/westlake-repl/MicroLens",
    "tags": [
      "video",
      "micro-video",
      "large-scale",
      "recommendations"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "MicroLens contains 1 billion interactions from 34 million users on 1 million micro-videos. This dataset can be used to analyze user engagement and develop recommendation systems for video content.",
    "use_cases": [
      "Analyzing user engagement patterns in micro-videos",
      "Developing personalized video recommendations",
      "Studying trends in micro-video consumption",
      "Evaluating the effectiveness of marketing strategies in video content"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the MicroLens dataset?",
      "How can I access the MicroLens dataset?",
      "What types of analyses can be performed on the MicroLens dataset?",
      "What are the user demographics in the MicroLens dataset?",
      "How many interactions are recorded in the MicroLens dataset?",
      "What is the focus of the MicroLens dataset?",
      "What insights can be gained from the MicroLens dataset?",
      "What are the applications of the MicroLens dataset in recommendations?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "Fliggy Travel",
    "description": "Travel-related data from Alibaba's online travel platform",
    "category": "Travel & Hospitality",
    "url": "https://tianchi.aliyun.com/dataset/113649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "travel",
      "Alibaba",
      "bookings"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "travel"
    ],
    "summary": "Fliggy Travel provides travel-related data from Alibaba's online travel platform, enabling analysis of consumer behavior and booking trends. This dataset can be used to explore travel patterns and preferences among users.",
    "use_cases": [
      "Analyzing booking trends over time",
      "Exploring consumer preferences in travel",
      "Comparing travel data across different demographics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What data does Fliggy Travel provide?",
      "How can I analyze travel bookings from Alibaba?",
      "What insights can be gained from Fliggy Travel data?",
      "Where can I find travel-related datasets?",
      "What are the trends in online travel bookings?",
      "How does consumer behavior vary in travel?",
      "What is Fliggy Travel's impact on the travel industry?",
      "What travel data is available from Alibaba?"
    ],
    "domain_tags": [
      "travel",
      "e-commerce"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "Walmart Sales",
    "description": "General sales data including CPI and unemployment rate",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/yasserh/walmart-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Walmart",
      "macro",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "This dataset contains general sales data from Walmart, including economic indicators such as the Consumer Price Index (CPI) and unemployment rate. It can be used to analyze sales trends in relation to macroeconomic factors.",
    "use_cases": [
      "Analyzing the impact of CPI on sales",
      "Studying the relationship between unemployment rates and grocery sales",
      "Forecasting future sales trends based on economic indicators"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Walmart sales data analysis",
      "CPI impact on Walmart sales",
      "unemployment rate and grocery sales",
      "Walmart sales trends",
      "macro factors affecting Walmart sales",
      "Walmart sales dataset download"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "AEA Data and Code Repository",
    "description": "Replication packages for all AEA publications since 2019 with DOI-assigned packages",
    "category": "Dataset Aggregators",
    "url": "https://www.openicpsr.org/openicpsr/search/aea/studies",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "replication",
      "AEA",
      "economics",
      "reproducibility"
    ],
    "best_for": "Verifying published empirical work with data, code, and documentation",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The AEA Data and Code Repository contains replication packages for all AEA publications since 2019, allowing users to access and verify the data and code used in these publications. Researchers can utilize this repository to ensure reproducibility in their own work and to explore economic research findings.",
    "use_cases": [
      "Verifying research findings from AEA publications",
      "Conducting reproducibility analyses in economics",
      "Accessing data for educational purposes",
      "Utilizing code for economic modeling"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the replication packages available in the AEA Data and Code Repository?",
      "How can I access AEA publications since 2019?",
      "What is the purpose of the AEA Data and Code Repository?",
      "Are there any DOI-assigned packages in the AEA Data and Code Repository?",
      "What types of data are included in the AEA Data and Code Repository?",
      "How does the AEA Data and Code Repository support reproducibility in economics research?"
    ],
    "domain_tags": [
      "economics"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "National Transit Database (NTD)",
    "description": "Definitive source for US transit statistics since 2002. Ridership, operating expenses, capital expenses, safety incidents for all federally-funded transit agencies.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.transit.dot.gov/ntd",
    "docs_url": "https://www.transit.dot.gov/ntd/ntd-data",
    "github_url": null,
    "tags": [
      "transit",
      "ridership",
      "financials",
      "safety",
      "US"
    ],
    "best_for": "Transit system performance analysis, cost benchmarking, and ridership trends",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "economics",
      "data-analysis"
    ],
    "summary": "The National Transit Database (NTD) is the definitive source for US transit statistics, providing data on ridership, operating expenses, capital expenses, and safety incidents for federally-funded transit agencies. This dataset allows for comprehensive analysis of transit trends and financial performance across the United States.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the National Transit Database?",
      "How to access US transit statistics?",
      "What data does the NTD provide?",
      "Where can I find information on transit ridership in the US?",
      "What are the operating expenses of US transit agencies?",
      "How to analyze safety incidents in public transportation?",
      "What trends can be observed in US transit data since 2002?"
    ],
    "use_cases": [
      "Analyzing trends in transit ridership over the years",
      "Comparing operating expenses across different transit agencies",
      "Evaluating the impact of safety incidents on public perception of transit",
      "Assessing capital expenses for planning future transit projects"
    ],
    "domain_tags": [
      "transportation",
      "public policy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2002-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "iPinYou RTB Dataset",
    "description": "Real-time bidding dataset from Chinese DSP with ~35GB of bid requests, impressions, clicks, and conversions with bidding prices",
    "category": "Advertising",
    "url": "https://contest.ipinyou.com/",
    "docs_url": "https://github.com/wnzhang/make-ipinyou-data",
    "github_url": "https://github.com/wnzhang/make-ipinyou-data",
    "tags": [
      "RTB",
      "bidding",
      "conversions",
      "iPinYou"
    ],
    "best_for": "Bid optimization and RTB algorithm research with actual market prices",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "ad-tech",
      "bidding",
      "data-analysis"
    ],
    "summary": "The iPinYou RTB Dataset is a comprehensive collection of real-time bidding data from a Chinese demand-side platform. It includes bid requests, impressions, clicks, and conversions, allowing for in-depth analysis of bidding strategies and performance metrics.",
    "use_cases": [
      "Analyzing bidding strategies",
      "Evaluating conversion rates",
      "Understanding user engagement through clicks",
      "Optimizing ad spend based on bidding data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the iPinYou RTB Dataset?",
      "How can I analyze bidding data from iPinYou?",
      "What insights can be gained from the iPinYou RTB Dataset?",
      "Where can I find the iPinYou RTB Dataset?",
      "What are the key features of the iPinYou RTB Dataset?",
      "How does real-time bidding work in the iPinYou dataset?",
      "What are the applications of the iPinYou RTB Dataset?",
      "What is the size of the iPinYou RTB Dataset?"
    ],
    "domain_tags": [
      "advertising",
      "technology"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "9 days (2013)",
    "geographic_scope": "China",
    "size_category": "large",
    "model_score": 0.0005
  },
  {
    "name": "Microsoft Research",
    "description": "Research tools and datasets across multiple domains",
    "category": "Data Portals",
    "url": "https://www.microsoft.com/en-us/research/tools/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Microsoft",
      "research",
      "various domains"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Microsoft Research provides a variety of research tools and datasets across multiple domains, enabling users to explore and analyze data in various fields. This platform is ideal for researchers and data scientists looking for diverse datasets to support their work.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets does Microsoft Research offer?",
      "How can I access Microsoft Research tools?",
      "What domains are covered by Microsoft Research?",
      "Are there any datasets for data science on Microsoft Research?",
      "What research tools are available at Microsoft Research?",
      "Can I find datasets related to various domains on Microsoft Research?"
    ],
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "BTS Airline On-Time Performance",
    "description": "All US flights since 1987. Delays, cancellations, fares, capacity. Revenue management research goldmine",
    "category": "Transportation & Mobility",
    "url": "https://www.transtats.bts.gov/ontime/",
    "docs_url": "https://www.bts.gov/topics/airline-time-tables",
    "github_url": null,
    "tags": [
      "airline",
      "flights",
      "delays",
      "pricing",
      "large-scale"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "data-analysis"
    ],
    "summary": "The BTS Airline On-Time Performance dataset contains information on all US flights since 1987, including delays, cancellations, fares, and capacity. This dataset serves as a valuable resource for revenue management research and analysis in the transportation sector.",
    "use_cases": [
      "Analyzing trends in flight delays over time",
      "Studying the impact of cancellations on airline revenue",
      "Comparing fares across different airlines and routes",
      "Investigating capacity utilization in the airline industry"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the BTS Airline On-Time Performance dataset?",
      "How can I analyze flight delays using the BTS dataset?",
      "What insights can be gained from the BTS Airline dataset?",
      "Where can I find US flight performance data?",
      "What are the trends in airline delays since 1987?",
      "How do cancellations affect airline pricing?",
      "What factors contribute to flight delays in the US?",
      "Is there a dataset for US airline performance?"
    ],
    "domain_tags": [
      "transportation"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1987-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "ORBITAAL Bitcoin Graph",
    "description": "13 years (2009-2021) of entity-level Bitcoin transaction networks with BTC/USD values",
    "category": "Financial Services",
    "url": "https://www.nature.com/articles/s41597-023-02416-6",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Bitcoin",
      "crypto",
      "graph",
      "transactions"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "financial-services",
      "cryptocurrency",
      "data-analysis"
    ],
    "summary": "The ORBITAAL Bitcoin Graph dataset contains 13 years of entity-level Bitcoin transaction networks with corresponding BTC/USD values. This dataset can be used for analyzing transaction patterns, understanding market dynamics, and exploring the relationships between entities in the Bitcoin ecosystem.",
    "use_cases": [
      "Analyzing transaction patterns in Bitcoin over time",
      "Studying the relationships between different entities in the Bitcoin network",
      "Exploring market dynamics using BTC/USD values",
      "Conducting research on cryptocurrency trends and behaviors"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the ORBITAAL Bitcoin Graph dataset?",
      "How can I analyze Bitcoin transaction networks?",
      "What are the BTC/USD values in the ORBITAAL dataset?",
      "What time period does the ORBITAAL Bitcoin Graph cover?",
      "Where can I find entity-level Bitcoin transaction data?",
      "What insights can be gained from Bitcoin transaction networks?",
      "How does the ORBITAAL dataset contribute to cryptocurrency research?",
      "What tools can I use to visualize Bitcoin transaction data?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "graph",
    "temporal_coverage": "2009-2021",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "ICPSR",
    "description": "World's largest social science archive - 250,000+ files across 16,000 studies since 1962",
    "category": "Dataset Aggregators",
    "url": "https://www.icpsr.umich.edu",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social science",
      "surveys",
      "GSS",
      "ANES",
      "academic"
    ],
    "best_for": "GSS, ANES, World Values Survey - essential for empirical economics research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The ICPSR is the world's largest social science archive, containing over 250,000 files across 16,000 studies since 1962. Researchers can utilize this extensive dataset for various analyses in social science fields, including surveys and academic research.",
    "use_cases": [
      "Analyzing social trends over time",
      "Conducting survey research",
      "Comparing data from different studies",
      "Exploring demographic information"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the ICPSR dataset?",
      "How can I access the world's largest social science archive?",
      "What types of studies are available in ICPSR?",
      "What data files does ICPSR contain?",
      "How can I use ICPSR for social science research?",
      "What are the main topics covered in ICPSR datasets?",
      "Is ICPSR suitable for academic research?",
      "What social science surveys are included in ICPSR?"
    ],
    "domain_tags": [
      "academic",
      "social science"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0005
  },
  {
    "name": "Store Item Demand",
    "description": "50 items across 10 different stores over 5 years",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/demand-forecasting-kernels-only",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "demand forecasting",
      "Kaggle competition",
      "time series"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [
      "pandas-dataframes",
      "time series analysis"
    ],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "demand forecasting"
    ],
    "summary": "This dataset contains demand data for 50 items across 10 different stores over a period of 5 years. It can be used for demand forecasting and analyzing consumer purchasing patterns.",
    "use_cases": [
      "Forecasting future demand for grocery items",
      "Analyzing sales trends across different stores",
      "Evaluating the impact of promotions on item demand"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Store item demand dataset",
      "Kaggle competition demand forecasting",
      "Time series analysis grocery data",
      "50 items demand data",
      "Retail demand forecasting dataset",
      "Store sales prediction dataset",
      "Grocery item sales over 5 years"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "5 years",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Harvard Dataverse Auctions",
    "description": "Auction-related replication datasets from Harvard Dataverse",
    "category": "Advertising",
    "url": "https://dataverse.harvard.edu/dataverse/harvard",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "replication",
      "academic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Harvard Dataverse Auctions dataset includes auction-related replication datasets that can be used for academic research. Researchers can analyze auction dynamics and consumer behavior through these datasets.",
    "use_cases": [
      "Analyzing bidding strategies in auctions",
      "Studying consumer behavior in auction settings",
      "Evaluating the effectiveness of auction formats"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Harvard Dataverse Auctions datasets?",
      "How can I access auction-related datasets from Harvard Dataverse?",
      "What replication datasets are available for auction research?",
      "What academic research has been done using Harvard Dataverse Auctions?",
      "How do auctions affect consumer behavior?",
      "What is the significance of replication datasets in auction studies?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Real-Time Advertisers Auction",
    "description": "Real-time advertiser auction dataset for RTB research",
    "category": "Advertising",
    "url": "https://www.kaggle.com/datasets/saurav9786/real-time-advertisers-auction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "RTB",
      "auctions",
      "programmatic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Real-Time Advertisers Auction dataset provides insights into the dynamics of real-time bidding in advertising. Researchers can analyze bidding strategies, auction outcomes, and advertiser behavior in programmatic advertising.",
    "use_cases": [
      "Analyzing bidding strategies in real-time auctions",
      "Evaluating the effectiveness of programmatic advertising",
      "Studying advertiser behavior in competitive environments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Real-Time Advertisers Auction dataset?",
      "How can I analyze RTB data?",
      "What insights can be gained from auction datasets?",
      "Where can I find real-time bidding auction data?",
      "What are the trends in programmatic advertising?",
      "How do advertisers perform in real-time auctions?",
      "What factors influence auction outcomes?",
      "What is the significance of RTB in advertising research?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "M5Product",
    "description": "5 modalities (image, text, table, video, audio), 6M+ samples for multimodal learning",
    "category": "E-Commerce",
    "url": "https://xiaodongsuper.github.io/M5Product_dataset/index.html",
    "docs_url": "https://xiaodongsuper.github.io/M5Product_dataset/index.html",
    "github_url": null,
    "tags": [
      "multimodal",
      "product data",
      "images",
      "video"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "multimodal learning"
    ],
    "summary": "The M5Product dataset contains over 6 million samples across five modalities: image, text, table, video, and audio. It is designed for multimodal learning applications, allowing researchers and developers to explore and analyze product data in various formats.",
    "use_cases": [
      "Multimodal product classification",
      "Image and text analysis for e-commerce",
      "Video content analysis for product marketing"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the M5Product dataset?",
      "How can I access the M5Product dataset?",
      "What modalities are included in the M5Product dataset?",
      "What are the applications of the M5Product dataset?",
      "How many samples are in the M5Product dataset?",
      "What types of data does the M5Product dataset provide?",
      "Is the M5Product dataset suitable for multimodal learning?",
      "What are the tags associated with the M5Product dataset?"
    ],
    "domain_tags": [
      "e-commerce"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "model_score": 0.0004
  },
  {
    "name": "OTTO Session-based Recommendations",
    "description": "12M+ e-commerce sessions with click \u2192 cart \u2192 order sequences. Real multi-stage conversion funnel data from German retailer",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/otto/recsys-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "sessions",
      "conversion funnel",
      "Kaggle",
      "recommendations",
      "e-commerce"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "The OTTO Session-based Recommendations dataset contains over 12 million e-commerce sessions detailing click, cart, and order sequences. This data can be used to analyze consumer behavior and improve recommendation systems.",
    "use_cases": [
      "Analyzing consumer behavior patterns",
      "Improving recommendation algorithms",
      "Studying conversion funnel efficiency",
      "Evaluating the impact of marketing strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the OTTO Session-based Recommendations dataset?",
      "How can I analyze e-commerce session data?",
      "What insights can be gained from click to cart sequences?",
      "Where can I find datasets for recommendations?",
      "What are the use cases for conversion funnel data?",
      "How to use session data for e-commerce analysis?",
      "What is the significance of multi-stage conversion funnels?",
      "How to access the OTTO dataset on Kaggle?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Germany",
    "size_category": "massive",
    "model_score": 0.0004
  },
  {
    "name": "NGSIM Vehicle Trajectories",
    "description": "Vehicle trajectory data for traffic flow modeling",
    "category": "Transportation & Mobility",
    "url": "https://data.transportation.gov/Automobiles/Next-Generation-Simulation-NGSIM-Vehicle-Trajector/8ect-6jqj/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "trajectories",
      "traffic",
      "simulation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NGSIM Vehicle Trajectories dataset contains detailed vehicle trajectory data that can be used for traffic flow modeling. Researchers and practitioners can analyze this data to improve traffic management and simulation models.",
    "use_cases": [
      "Traffic flow analysis",
      "Simulation of vehicle interactions",
      "Modeling traffic congestion"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NGSIM Vehicle Trajectories dataset",
      "vehicle trajectory data for traffic modeling",
      "traffic flow simulation dataset",
      "NGSIM traffic data",
      "vehicle trajectories for analysis",
      "traffic simulation data download"
    ],
    "domain_tags": [
      "transportation",
      "mobility"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Common Crawl",
    "description": "250TB/month web crawl. 9.5 PB archive since 2008. Product listings, pricing, economic text at web scale",
    "category": "Social & Web",
    "url": "https://commoncrawl.org/",
    "docs_url": "https://commoncrawl.org/the-data/get-started/",
    "github_url": null,
    "tags": [
      "web crawl",
      "text",
      "pricing",
      "petabyte-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "Common Crawl is a massive web archive that provides a wealth of data from web pages, including product listings and pricing information. Researchers and analysts can leverage this dataset to study economic trends, consumer behavior, and pricing strategies at a large scale.",
    "use_cases": [
      "Analyzing pricing trends across different e-commerce platforms",
      "Studying consumer behavior through web text analysis",
      "Extracting product listings for market research"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Common Crawl dataset?",
      "How can I access the Common Crawl data?",
      "What types of information are included in the Common Crawl?",
      "How does Common Crawl support economic research?",
      "What are the main features of the Common Crawl dataset?",
      "How can I analyze pricing data from Common Crawl?",
      "What is the size of the Common Crawl archive?",
      "What are the use cases for Common Crawl data?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "size_category": "massive",
    "model_score": 0.0004
  },
  {
    "name": "HCUP (Healthcare Cost and Utilization Project)",
    "description": "Largest collection of longitudinal hospital care data in the US with 100+ million records per year covering inpatient and emergency visits",
    "category": "Insurance & Actuarial",
    "url": "https://hcup-us.ahrq.gov/",
    "docs_url": "https://hcup-us.ahrq.gov/databases.jsp",
    "github_url": null,
    "tags": [
      "hospital-data",
      "inpatient",
      "emergency",
      "healthcare-utilization",
      "cost-data"
    ],
    "best_for": "Hospital cost analysis, readmission prediction, and healthcare ML applications",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The HCUP dataset is the largest collection of longitudinal hospital care data in the US, containing over 100 million records per year that cover inpatient and emergency visits. This dataset can be used to analyze healthcare utilization trends, costs, and patterns in hospital care.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the HCUP dataset?",
      "How can I access the HCUP hospital care data?",
      "What types of records are included in HCUP?",
      "What insights can be gained from HCUP data?",
      "How does HCUP data help in healthcare research?",
      "What are the applications of HCUP data in cost analysis?"
    ],
    "use_cases": [
      "Analyzing trends in hospital admissions and emergency visits",
      "Evaluating the cost of inpatient care across different demographics",
      "Studying the impact of healthcare policies on hospital utilization",
      "Comparing healthcare utilization patterns between states"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "US",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Medical Expenditure Panel Survey (MEPS)",
    "description": "Definitive U.S. data on healthcare expenditures, utilization, and insurance coverage. Surveys ~15,000 households annually with detailed spending by payer and service type. Free public use files.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://meps.ahrq.gov/mepsweb/",
    "source": "Agency for Healthcare Research and Quality (AHRQ)",
    "type": "Survey",
    "access": "Free public use files",
    "format": "SAS/Stata/CSV",
    "tags": [
      "Healthcare",
      "Expenditures",
      "Survey",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "healthcare",
      "economics",
      "data-analysis"
    ],
    "summary": "The Medical Expenditure Panel Survey (MEPS) provides comprehensive data on healthcare expenditures, utilization, and insurance coverage in the U.S. It allows researchers and policymakers to analyze spending patterns by payer and service type, facilitating informed decisions in healthcare economics.",
    "use_cases": [
      "Analyzing trends in healthcare spending over time",
      "Evaluating the impact of insurance coverage on healthcare utilization",
      "Comparing expenditures across different service types",
      "Studying the relationship between demographics and healthcare costs"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Medical Expenditure Panel Survey?",
      "How can I access the MEPS data?",
      "What types of healthcare expenditures are covered in MEPS?",
      "What is the sample size of the MEPS survey?",
      "How often is the MEPS data collected?",
      "What insights can be gained from analyzing MEPS data?",
      "What are the key findings from the latest MEPS report?",
      "How does MEPS data inform healthcare policy?"
    ],
    "update_frequency": "Annual",
    "geographic_coverage": "United States (national)",
    "domain_tags": [
      "healthcare",
      "economics"
    ],
    "data_modality": "tabular",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "European Car Market",
    "description": "Car information including prices and attributes (1970-1999)",
    "category": "Automotive",
    "url": "https://sites.google.com/site/frankverbo/data-and-software/data-set-on-the-european-car-market",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Europe",
      "prices",
      "IO"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "automotive",
      "pricing"
    ],
    "summary": "The European Car Market dataset contains information about cars, including their prices and various attributes from 1970 to 1999. This dataset can be used to analyze trends in car pricing and attributes over time in Europe.",
    "use_cases": [
      "Analyzing price trends of European cars over time",
      "Comparing car attributes across different models",
      "Studying the impact of economic factors on car prices"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "European car prices from 1970 to 1999",
      "attributes of cars in Europe",
      "car market trends in Europe",
      "historical car pricing data",
      "automotive data analysis Europe",
      "car attributes dataset 1970-1999"
    ],
    "domain_tags": [
      "automotive"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1970-1999",
    "geographic_scope": "Europe",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "SOA Mortality Tables",
    "description": "Society of Actuaries mortality tables and experience studies used as industry standards for life insurance pricing",
    "category": "Insurance & Actuarial",
    "url": "https://mort.soa.org/",
    "docs_url": "https://www.soa.org/resources/experience-studies/",
    "github_url": null,
    "tags": [
      "mortality-tables",
      "life-insurance",
      "actuarial",
      "experience-studies",
      "annuities"
    ],
    "best_for": "Life insurance product development, reserving, and mortality assumption setting",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "insurance",
      "actuarial science",
      "mortality analysis"
    ],
    "summary": "The SOA Mortality Tables provide standardized mortality rates and experience studies used in life insurance pricing. They can be utilized for actuarial analysis, pricing strategies, and understanding life expectancy trends.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Society of Actuaries mortality tables?",
      "How are mortality tables used in life insurance pricing?",
      "What is the significance of experience studies in actuarial science?",
      "Where can I find SOA mortality tables?",
      "What data is included in the SOA mortality tables?",
      "How do actuaries use mortality tables?",
      "What are the industry standards for life insurance pricing?",
      "What is the role of mortality tables in annuities?"
    ],
    "use_cases": [
      "Analyzing life insurance pricing models using mortality data",
      "Evaluating the impact of demographic changes on mortality rates",
      "Developing actuarial forecasts for life expectancy",
      "Conducting experience studies to refine pricing strategies"
    ],
    "domain_tags": [
      "insurance",
      "actuarial"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Avazu Click-Through Rate Dataset",
    "description": "Mobile advertising dataset with 40+ million ad click records from Avazu mobile advertising platform",
    "category": "Advertising",
    "url": "https://www.kaggle.com/c/avazu-ctr-prediction/data",
    "docs_url": "https://www.kaggle.com/c/avazu-ctr-prediction",
    "github_url": null,
    "tags": [
      "mobile ads",
      "CTR",
      "Kaggle",
      "Avazu"
    ],
    "best_for": "Mobile-specific CTR prediction and feature engineering",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "ad-tech",
      "mobile-ads"
    ],
    "summary": "The Avazu Click-Through Rate Dataset is a mobile advertising dataset containing over 40 million ad click records from the Avazu mobile advertising platform. This dataset can be used to analyze click-through rates and improve advertising strategies.",
    "use_cases": [
      "Analyzing click-through rates for mobile ads",
      "Improving ad targeting strategies",
      "Evaluating the effectiveness of mobile advertising campaigns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Avazu Click-Through Rate Dataset?",
      "How to analyze mobile ad click data?",
      "Where can I find the Avazu dataset on Kaggle?",
      "What are the features of the Avazu Click-Through Rate Dataset?",
      "How to use the Avazu dataset for CTR analysis?",
      "What insights can be gained from mobile advertising data?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "10 days",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "ASSISTments Dataset",
    "description": "Data from online tutoring platform for educational data mining",
    "category": "Education",
    "url": "https://sites.google.com/site/las2016data/home",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "education",
      "tutoring",
      "learning analytics"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The ASSISTments Dataset contains data from an online tutoring platform designed for educational data mining. It can be used to analyze student learning behaviors and improve educational outcomes.",
    "use_cases": [
      "Analyze student performance trends",
      "Evaluate the effectiveness of tutoring methods",
      "Develop predictive models for student success"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "ASSISTments Dataset",
      "educational data mining datasets",
      "online tutoring data",
      "learning analytics datasets",
      "tutoring platform data",
      "student learning behavior datasets"
    ],
    "domain_tags": [
      "education"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Crypto Art (SuperRare)",
    "description": "Bids and transactions from SuperRare NFT platform",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/franceschet/superrare",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NFT",
      "crypto",
      "art",
      "auctions"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "This dataset contains bids and transactions from the SuperRare NFT platform, which focuses on the buying and selling of digital art as NFTs. It can be used to analyze market trends, pricing strategies, and consumer behavior in the crypto art space.",
    "use_cases": [
      "Analyzing price trends of NFTs over time",
      "Studying consumer behavior in the crypto art market",
      "Evaluating the impact of auctions on NFT prices",
      "Comparing transaction volumes across different NFT categories"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest bids on SuperRare?",
      "How do transaction volumes on SuperRare compare over time?",
      "What types of art are most frequently sold on SuperRare?",
      "What is the average price of NFTs sold on SuperRare?",
      "How has the market for crypto art evolved on SuperRare?",
      "What are the trends in bidding behavior on SuperRare?"
    ],
    "domain_tags": [
      "art",
      "technology",
      "finance"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "MSOM Pharma Manufacturing (2024)",
    "description": "Continuous pharmaceutical manufacturing data from MSD. Real production processes for operations management research",
    "category": "Logistics & Supply Chain",
    "url": "https://pubsonline.informs.org/page/msom/data-driven-challenge",
    "docs_url": "https://pubsonline.informs.org/doi/10.1287/msom.2024.0860",
    "github_url": null,
    "tags": [
      "manufacturing",
      "operations",
      "INFORMS",
      "2024",
      "real-world",
      "competition"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains continuous pharmaceutical manufacturing data from MSD, providing real production processes that can be utilized for operations management research. Researchers can analyze the data to improve manufacturing efficiency and understand operational challenges in the pharmaceutical industry.",
    "use_cases": [
      "Analyzing production efficiency in pharmaceutical manufacturing",
      "Researching operational challenges in continuous manufacturing processes",
      "Benchmarking manufacturing practices against industry standards"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the MSOM Pharma Manufacturing dataset?",
      "How can I access the continuous pharmaceutical manufacturing data from MSD?",
      "What insights can be gained from the MSOM Pharma Manufacturing dataset?",
      "What are the real production processes documented in the MSOM Pharma Manufacturing dataset?",
      "How does the MSOM Pharma Manufacturing dataset contribute to operations management research?",
      "What are the key tags associated with the MSOM Pharma Manufacturing dataset?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2024",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Criteo AI Lab Datasets",
    "description": "World's largest public ML dataset - 1TB Click Logs with 4 billion advertising events",
    "category": "Dataset Aggregators",
    "url": "https://ailab.criteo.com/ressources/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "CTR",
      "recommendations",
      "benchmark"
    ],
    "best_for": "Click-through rate prediction and recommendation systems benchmarks",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "machine-learning",
      "data-analysis"
    ],
    "summary": "The Criteo AI Lab Datasets is the world's largest public machine learning dataset, consisting of 1TB of click logs with 4 billion advertising events. It can be used for various analyses such as click-through rate (CTR) predictions and recommendation system benchmarks.",
    "use_cases": [
      "CTR prediction analysis",
      "recommendation system benchmarking"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Criteo AI Lab Datasets",
      "public ML dataset for advertising",
      "1TB click logs dataset",
      "advertising events dataset",
      "Criteo click-through rate dataset",
      "benchmark dataset for recommendations"
    ],
    "domain_tags": [
      "advertising",
      "e-commerce"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "benchmark_usage": [
      "CTR predictions",
      "recommendation system evaluations"
    ],
    "model_score": 0.0004
  },
  {
    "name": "Iowa Liquor",
    "description": "Monthly Class E liquor sales data with volume and pricing from Iowa",
    "category": "Grocery & Supermarkets",
    "url": "https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "liquor",
      "government data",
      "Iowa"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "liquor sales",
      "government data",
      "Iowa"
    ],
    "summary": "This dataset contains monthly Class E liquor sales data from Iowa, detailing both volume and pricing. It can be used to analyze trends in liquor sales, pricing strategies, and consumer behavior in the state.",
    "use_cases": [
      "Analyzing seasonal trends in liquor sales.",
      "Evaluating the impact of pricing changes on sales volume.",
      "Comparing liquor sales across different months.",
      "Studying consumer behavior related to liquor purchases."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the monthly liquor sales in Iowa?",
      "How does pricing vary for liquor in Iowa?",
      "What trends can be observed in Iowa's liquor sales data?",
      "Where can I find government data on liquor sales in Iowa?",
      "What is the volume of Class E liquor sold in Iowa?",
      "How do Iowa liquor sales compare month over month?",
      "What factors influence liquor pricing in Iowa?",
      "Is there a correlation between volume and pricing in Iowa liquor sales?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Iowa",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "DiDi GAIA Open Data",
    "description": "Billions of GPS points and ride trajectories from China's largest ride-hailing platform. Driver behavior and urban mobility patterns",
    "category": "Transportation & Mobility",
    "url": "https://gaia.didichuxing.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "rideshare",
      "GPS",
      "trajectories",
      "China",
      "DiDi",
      "mobility"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "urban-mobility",
      "data-analysis"
    ],
    "summary": "The DiDi GAIA Open Data consists of billions of GPS points and ride trajectories from China's largest ride-hailing platform. This dataset can be used to analyze driver behavior and urban mobility patterns in Chinese cities.",
    "use_cases": [
      "Analyzing urban mobility trends",
      "Studying driver behavior patterns",
      "Evaluating the impact of ride-hailing on traffic",
      "Understanding GPS data for transportation studies"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is DiDi GAIA Open Data?",
      "How to analyze ride trajectories from DiDi?",
      "What insights can be gained from DiDi's GPS data?",
      "Where can I find DiDi ride-hailing data?",
      "What are the urban mobility patterns in China?",
      "How does DiDi's driver behavior compare to other platforms?"
    ],
    "domain_tags": [
      "transportation",
      "mobility"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "nflverse",
    "description": "Comprehensive NFL play-by-play data from 1999-present with EPA, win probability, and player participation data",
    "category": "Sports & Athletics",
    "url": "https://github.com/nflverse/nflverse-data",
    "docs_url": "https://nflreadr.nflverse.com/",
    "github_url": "https://github.com/nflverse/nflverse-data",
    "tags": [
      "football",
      "NFL",
      "play-by-play",
      "EPA",
      "win-probability"
    ],
    "best_for": "NFL analytics, expected points analysis, and game strategy optimization",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The nflverse dataset provides comprehensive NFL play-by-play data from 1999 to the present, including metrics like EPA and win probability, as well as player participation data. This dataset can be used for analyzing game strategies, player performance, and overall team effectiveness in the NFL.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the nflverse dataset?",
      "How can I access NFL play-by-play data?",
      "What metrics are included in the nflverse dataset?",
      "Where can I find EPA and win probability data for NFL games?",
      "What years does the nflverse dataset cover?",
      "How can I analyze player participation in NFL games?",
      "Is there a dataset for NFL play-by-play analysis?",
      "What data is available for NFL game strategies?"
    ],
    "use_cases": [
      "Analyzing the impact of player participation on game outcomes",
      "Evaluating team performance using EPA and win probability metrics",
      "Conducting historical analysis of NFL games from 1999 to present",
      "Comparing play-by-play data across different seasons"
    ],
    "domain_tags": [
      "sports",
      "analytics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1999-present",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Adform Display",
    "description": "Display advertising dataset with impressions and clicks",
    "category": "Advertising",
    "url": "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/TADBY7",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "display ads",
      "impressions",
      "Harvard Dataverse"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "digital marketing"
    ],
    "summary": "The Adform Display dataset contains data on display advertising, specifically focusing on impressions and clicks. This dataset can be used to analyze the effectiveness of display ads and understand consumer engagement.",
    "use_cases": [
      "Analyzing the effectiveness of display ads",
      "Understanding consumer engagement with ads",
      "Comparing click-through rates across different campaigns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Adform Display dataset?",
      "How can I analyze display ad impressions?",
      "What insights can be gained from clicks on display ads?",
      "Where can I find the Adform Display dataset?",
      "What are the key metrics in display advertising?",
      "How do impressions relate to clicks in advertising?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Yahoo A1 Search Advertising Dataset",
    "description": "Search advertising competition dataset with sponsored search auction features and click outcomes",
    "category": "Advertising",
    "url": "https://webscope.sandbox.yahoo.com/catalog.php?datatype=a",
    "docs_url": "https://webscope.sandbox.yahoo.com/",
    "github_url": null,
    "tags": [
      "search advertising",
      "sponsored search",
      "Yahoo",
      "auctions"
    ],
    "best_for": "Sponsored search click prediction and auction dynamics research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "search advertising",
      "sponsored search",
      "auctions"
    ],
    "summary": "The Yahoo A1 Search Advertising Dataset contains features related to sponsored search auctions and click outcomes. It can be used to analyze search advertising performance and understand auction dynamics.",
    "use_cases": [
      "Analyzing click-through rates in search advertising",
      "Studying auction dynamics in sponsored search",
      "Evaluating the effectiveness of ad placements",
      "Comparing performance metrics across different search ads"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Yahoo A1 Search Advertising Dataset?",
      "How can I access the Yahoo A1 Search Advertising Dataset?",
      "What features are included in the Yahoo A1 Search Advertising Dataset?",
      "What are the click outcomes in the Yahoo A1 Search Advertising Dataset?",
      "How does the Yahoo A1 Search Advertising Dataset relate to sponsored search?",
      "What insights can be gained from the Yahoo A1 Search Advertising Dataset?",
      "What is the significance of auctions in the Yahoo A1 Search Advertising Dataset?",
      "Where can I find datasets on search advertising?"
    ],
    "domain_tags": [
      "ad tech"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "varies",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0004
  },
  {
    "name": "Amazon Fraud Detection Benchmark",
    "description": "9 consolidated fraud datasets with unified format. Includes IEEE-CIS, credit card, e-commerce fraud. Benchmark for fraud ML research",
    "category": "Financial Services",
    "url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "docs_url": null,
    "github_url": "https://github.com/amazon-science/fraud-dataset-benchmark",
    "tags": [
      "fraud detection",
      "benchmark",
      "Amazon",
      "ML",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "fraud detection",
      "machine learning",
      "financial services"
    ],
    "summary": "The Amazon Fraud Detection Benchmark is a collection of 9 consolidated fraud datasets formatted uniformly. It serves as a benchmark for machine learning research in fraud detection across various domains such as credit card and e-commerce fraud.",
    "use_cases": [
      "Evaluating fraud detection algorithms",
      "Comparing performance of machine learning models",
      "Researching fraud patterns in e-commerce",
      "Developing new fraud detection techniques"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Amazon Fraud Detection Benchmark?",
      "How can I access the Amazon Fraud Detection datasets?",
      "What types of fraud are included in the Amazon Fraud Detection Benchmark?",
      "What is the format of the Amazon Fraud Detection datasets?",
      "How can I use the Amazon Fraud Detection Benchmark for ML research?",
      "What are the key features of the Amazon Fraud Detection datasets?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "benchmark_usage": [
      "Benchmark for fraud ML research"
    ],
    "model_score": 0.0003
  },
  {
    "name": "Google BigQuery Crypto",
    "description": "8 complete blockchain histories (Bitcoin, Ethereum, etc.) with daily updates. Transaction-level data for crypto analytics research",
    "category": "Financial Services",
    "url": "https://cloud.google.com/bigquery/public-data",
    "docs_url": "https://cloud.google.com/blog/products/data-analytics/introducing-six-new-cryptocurrencies-in-bigquery-public-datasets",
    "github_url": null,
    "tags": [
      "blockchain",
      "cryptocurrency",
      "Bitcoin",
      "Ethereum",
      "BigQuery"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains complete blockchain histories for cryptocurrencies such as Bitcoin and Ethereum, updated daily. It provides transaction-level data that can be utilized for various crypto analytics research purposes.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Google BigQuery Crypto dataset?",
      "How can I access blockchain histories for Bitcoin and Ethereum?",
      "What transaction-level data is available for crypto analytics?",
      "Where can I find daily updates on cryptocurrency data?",
      "What are the use cases for Google BigQuery Crypto?",
      "How to analyze blockchain data using Google BigQuery?"
    ],
    "domain_tags": [
      "financial services",
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Nasdaq Data Link",
    "description": "250+ datasets from 400+ publishers with API access - formerly Quandl",
    "category": "Dataset Aggregators",
    "url": "https://data.nasdaq.com",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "finance",
      "Quandl",
      "alternative data",
      "API"
    ],
    "best_for": "Financial econometrics and alternative data research with Python/R/Excel",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "finance",
      "alternative data"
    ],
    "summary": "Nasdaq Data Link provides access to over 250 datasets from more than 400 publishers through an API. Users can leverage this data for financial analysis, research, and decision-making in various sectors.",
    "use_cases": [
      "Conducting financial trend analysis",
      "Comparing datasets from different publishers",
      "Building financial models using alternative data",
      "Researching market behaviors using historical data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Nasdaq Data Link?",
      "How to access datasets from Nasdaq Data Link?",
      "What types of data are available on Nasdaq Data Link?",
      "Where can I find financial datasets?",
      "What is the API for Nasdaq Data Link?",
      "How to use Quandl datasets?",
      "What are alternative data sources for finance?",
      "What publishers provide data on Nasdaq Data Link?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Art Auction (Artists for Lahaina)",
    "description": "Artists for Lahaina benefit art auction data (2023)",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/flkuhm/art-price-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "art",
      "charity",
      "auctions"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "auctions",
      "charity",
      "art"
    ],
    "summary": "This dataset contains information about an art auction organized to benefit Lahaina in 2023. It can be used to analyze auction trends, artist participation, and the impact of charity events on art sales.",
    "use_cases": [
      "Analyzing auction pricing trends",
      "Evaluating artist participation in charity events",
      "Studying consumer behavior in art auctions"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Art auction data for charity",
      "Artists for Lahaina auction details",
      "2023 art auctions statistics",
      "Charity auctions in 2023",
      "Art market trends 2023",
      "Benefit art auctions analysis"
    ],
    "domain_tags": [
      "charity",
      "art"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2023",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "JD-pretrain-data",
    "description": "Encoded search queries and item data for intent detection",
    "category": "E-Commerce",
    "url": "https://github.com/jdcomsearch/jd-pretrain-data",
    "docs_url": null,
    "github_url": "https://github.com/jdcomsearch/jd-pretrain-data",
    "tags": [
      "search",
      "intent detection",
      "embeddings"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The JD-pretrain-data dataset contains encoded search queries and item data specifically designed for intent detection. It can be utilized to improve search algorithms and enhance user experience in e-commerce platforms.",
    "use_cases": [
      "Improving search algorithms",
      "Enhancing user experience in e-commerce",
      "Training machine learning models for intent detection"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is JD-pretrain-data?",
      "Where can I find JD-pretrain-data?",
      "How to access JD-pretrain-data?",
      "What are the applications of JD-pretrain-data?",
      "Who developed JD-pretrain-data?",
      "What data is included in JD-pretrain-data?",
      "How can JD-pretrain-data be used for intent detection?",
      "What are the features of JD-pretrain-data?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Grab Driving GPS Traces",
    "description": "GPS trace data from Grab ride-hailing platform",
    "category": "Transportation & Mobility",
    "url": "https://engineering.grab.com/grab-posisi",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "GPS",
      "ride-hailing",
      "Southeast Asia"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Grab Driving GPS Traces dataset contains GPS trace data from the Grab ride-hailing platform, primarily used for analyzing transportation patterns and mobility trends in Southeast Asia. Researchers and analysts can utilize this data to study ride-hailing behaviors, optimize routes, and improve service efficiency.",
    "use_cases": [
      "Analyzing ride patterns in urban areas",
      "Optimizing routes for ride-hailing services",
      "Studying the impact of ride-hailing on traffic congestion"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Grab Driving GPS Traces dataset?",
      "How can I access GPS trace data from Grab?",
      "What insights can be gained from Grab ride-hailing GPS data?",
      "Where can I find transportation data for Southeast Asia?",
      "What are the applications of GPS trace data in ride-hailing?",
      "How does Grab's GPS data help in urban mobility studies?"
    ],
    "domain_tags": [
      "transportation",
      "mobility"
    ],
    "data_modality": "time-series",
    "geographic_scope": "Southeast Asia",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "FERC Form 714",
    "description": "Hourly electricity load data from major U.S. utilities and regional transmission organizations",
    "category": "Energy",
    "url": "https://www.ferc.gov/industries-data/electric/general-information/electric-industry-forms/form-714-annual-electric",
    "docs_url": "https://www.ferc.gov/industries-data/electric/general-information/electric-industry-forms/form-714-annual-electric",
    "github_url": null,
    "tags": [
      "load",
      "demand",
      "hourly",
      "utilities"
    ],
    "best_for": "Hourly demand analysis, load forecasting, and peak demand studies",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The FERC Form 714 dataset contains hourly electricity load data from major U.S. utilities and regional transmission organizations. This data can be used for analyzing electricity demand patterns and understanding load variations over time.",
    "use_cases": [
      "Analyzing trends in electricity demand over different times of the day.",
      "Comparing load data across different utilities to identify patterns.",
      "Forecasting future electricity demand based on historical load data."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the FERC Form 714 dataset?",
      "Where can I find hourly electricity load data?",
      "How does electricity demand vary across U.S. utilities?",
      "What are the major U.S. utilities included in FERC Form 714?",
      "How can I analyze hourly load data from regional transmission organizations?",
      "What insights can be gained from FERC Form 714 data?",
      "What tools can I use to work with FERC Form 714 dataset?",
      "What is the significance of hourly electricity load data?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "2006-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "IPUMS",
    "description": "Harmonized microdata from US Census (1850-present), ACS, CPS, and 103+ countries' censuses",
    "category": "Dataset Aggregators",
    "url": "https://www.ipums.org",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "census",
      "microdata",
      "harmonized",
      "demographics"
    ],
    "best_for": "Harmonized census microdata across time and countries - free for academic research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "IPUMS provides harmonized microdata from the US Census and other countries, allowing researchers to analyze demographic trends over time. Users can leverage this data for various statistical analyses and to understand population dynamics.",
    "use_cases": [
      "Analyzing demographic changes in the US over time",
      "Comparing census data across different countries",
      "Conducting research on population trends",
      "Studying the impact of socio-economic factors on demographics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is IPUMS?",
      "How to access IPUMS microdata?",
      "What types of census data are available in IPUMS?",
      "How can I use IPUMS for demographic analysis?",
      "What is the historical coverage of IPUMS?",
      "Where can I find harmonized microdata for US Census?",
      "What countries' censuses are included in IPUMS?",
      "What are the main features of IPUMS data?"
    ],
    "domain_tags": [
      "demographics"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Upworthy News Headlines",
    "description": "32,487 headline/image experiments on 538M assignments",
    "category": "Advertising",
    "url": "https://upworthy.natematias.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "A/B testing",
      "headlines",
      "media",
      "experimentation"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Upworthy News Headlines dataset contains 32,487 experiments focused on headlines and images, analyzed across 538 million assignments. This dataset can be used to study the effectiveness of different headlines in media and advertising contexts.",
    "use_cases": [
      "Analyzing the effectiveness of different headlines",
      "Studying consumer engagement with media content",
      "Exploring the impact of images on headline performance"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Upworthy News Headlines?",
      "How can I analyze A/B testing results from Upworthy?",
      "What insights can be gained from Upworthy's headline experiments?",
      "What types of media experimentation does Upworthy conduct?",
      "How many assignments are included in the Upworthy dataset?",
      "What is the significance of headlines in advertising according to Upworthy?",
      "Can I find A/B testing data from Upworthy?",
      "What are the key findings from Upworthy's headline/image experiments?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Tmall Reviews",
    "description": "Product reviews from Tmall (Alibaba's B2C platform)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/140281",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Tmall",
      "China",
      "B2C"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Tmall Reviews dataset contains product reviews from Tmall, Alibaba's B2C platform. It can be used to analyze consumer sentiment, product performance, and market trends in the e-commerce sector.",
    "use_cases": [
      "Sentiment analysis of product reviews",
      "Market trend analysis based on consumer feedback",
      "Comparative analysis of product ratings",
      "Understanding consumer preferences in e-commerce"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Tmall product reviews dataset",
      "E-commerce reviews analysis",
      "Consumer behavior in Tmall reviews",
      "Sentiment analysis on Tmall reviews",
      "Tmall reviews data for research",
      "Alibaba B2C platform reviews dataset"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Airline Delay",
    "description": "Airline flight delays and carrier information",
    "category": "Transportation & Mobility",
    "url": "https://www.kaggle.com/datasets/sriharshaeedala/airline-delay",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "airlines",
      "delays",
      "transportation"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "mobility"
    ],
    "summary": "The Airline Delay dataset contains information on airline flight delays and carrier performance. It can be used to analyze patterns in flight delays, compare carrier reliability, and improve operational efficiency.",
    "use_cases": [
      "Analyzing flight delay patterns",
      "Comparing performance of different airlines",
      "Investigating the impact of weather on flight schedules"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the common causes of airline delays?",
      "How do different airlines compare in terms of delays?",
      "What is the average delay time for flights?",
      "How do weather conditions affect airline delays?",
      "What trends can be observed in airline delays over time?",
      "How can airline delays impact passenger satisfaction?"
    ],
    "domain_tags": [
      "transportation"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "OpenStreetMap Planet",
    "description": "84GB PBF (2TB+ uncompressed) complete world map database with full edit history, weekly updates",
    "category": "Social & Web",
    "url": "https://planet.openstreetmap.org/",
    "docs_url": "https://wiki.openstreetmap.org/wiki/Planet.osm",
    "github_url": null,
    "tags": [
      "database dump",
      "geospatial",
      "large-scale",
      "real-world",
      "PostgreSQL",
      "messy data"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The OpenStreetMap Planet dataset is a comprehensive global map database that includes full edit history and is updated weekly. It can be used for various geospatial analyses and applications in urban planning, transportation, and geographic research.",
    "use_cases": [
      "Urban planning and development analysis",
      "Transportation network optimization",
      "Geospatial data visualization",
      "Environmental impact assessments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the OpenStreetMap Planet dataset?",
      "How can I access the OpenStreetMap Planet database?",
      "What are the updates frequency for OpenStreetMap Planet?",
      "What types of data are included in the OpenStreetMap Planet dataset?",
      "How large is the OpenStreetMap Planet dataset?",
      "What can I do with the OpenStreetMap Planet data?",
      "Is the OpenStreetMap Planet dataset suitable for PostgreSQL?",
      "What are the characteristics of the OpenStreetMap Planet dataset?"
    ],
    "domain_tags": [
      "geospatial"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "model_score": 0.0003
  },
  {
    "name": "CoAID COVID Misinformation",
    "description": "4,251 news articles and 296K claims about COVID-19 healthcare misinformation. Fact-checked with ground truth labels",
    "category": "Content Moderation",
    "url": "https://github.com/cuilimeng/CoAID",
    "docs_url": null,
    "github_url": "https://github.com/cuilimeng/CoAID",
    "tags": [
      "COVID-19",
      "misinformation",
      "fact-checking",
      "healthcare",
      "fake news"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "COVID-19",
      "misinformation",
      "fact-checking",
      "healthcare",
      "fake news"
    ],
    "summary": "The CoAID COVID Misinformation dataset contains 4,251 news articles and 296,000 claims related to COVID-19 healthcare misinformation. It can be used for research and analysis in content moderation and fact-checking.",
    "use_cases": [
      "Analyzing the spread of COVID-19 misinformation in media.",
      "Evaluating the effectiveness of fact-checking initiatives.",
      "Studying the impact of misinformation on public health behavior."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the CoAID COVID Misinformation dataset?",
      "How many articles are in the CoAID COVID Misinformation dataset?",
      "What types of claims does the CoAID COVID Misinformation dataset include?",
      "What is the focus of the CoAID COVID Misinformation dataset?",
      "How can I access the CoAID COVID Misinformation dataset?",
      "What are the ground truth labels in the CoAID COVID Misinformation dataset?",
      "What research can be conducted using the CoAID COVID Misinformation dataset?",
      "What are the key topics covered in the CoAID COVID Misinformation dataset?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Stanford GSB Experiment Collection",
    "description": "Datasets for experimentation analysis from Stanford Graduate School of Business",
    "category": "Education",
    "url": "https://github.com/gsbDBI/ExperimentData",
    "docs_url": null,
    "github_url": "https://github.com/gsbDBI/ExperimentData",
    "tags": [
      "Stanford",
      "causal inference",
      "experiments"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Stanford GSB Experiment Collection contains datasets for experimentation analysis sourced from the Stanford Graduate School of Business. Researchers and students can utilize this data to conduct causal inference studies and analyze various experimental outcomes.",
    "use_cases": [
      "Analyzing causal relationships in business experiments",
      "Conducting statistical analysis on experimental data"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Stanford GSB Experiment Collection datasets",
      "datasets for experimentation analysis Stanford",
      "Stanford Graduate School of Business experiments",
      "causal inference datasets Stanford",
      "business experiments data",
      "Stanford GSB research datasets"
    ],
    "domain_tags": [
      "education"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Alibaba Fashion Combo",
    "description": "Fashion item combinations from Alibaba for outfit recommendation",
    "category": "Fashion & Apparel",
    "url": "https://tianchi.aliyun.com/dataset/131519",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "outfit",
      "recommendation"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Alibaba Fashion Combo dataset contains combinations of fashion items sourced from Alibaba, aimed at providing recommendations for outfits. This dataset can be used to analyze consumer preferences and enhance recommendation systems in the fashion industry.",
    "use_cases": [
      "Analyzing popular fashion combinations",
      "Developing a recommendation system for outfits",
      "Studying consumer preferences in fashion",
      "Evaluating the effectiveness of outfit recommendations"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the best outfit combinations from Alibaba?",
      "How can I use Alibaba Fashion Combo for outfit recommendations?",
      "What fashion trends can be identified from Alibaba data?",
      "How does Alibaba's fashion data influence consumer behavior?",
      "What items are commonly paired together in Alibaba's fashion offerings?",
      "Can I analyze outfit recommendations using Alibaba Fashion Combo?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Flipkart Products",
    "description": "Product information scraped from Flipkart e-commerce platform",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/PromptCloudHQ/flipkart-products",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "products",
      "India",
      "e-commerce"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce"
    ],
    "summary": "This dataset contains product information scraped from the Flipkart e-commerce platform, providing insights into various products available in India. It can be used for analysis related to consumer behavior, pricing strategies, and market trends.",
    "use_cases": [
      "Analyzing pricing strategies of products",
      "Studying consumer behavior based on product reviews",
      "Comparing product features across categories"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What products are available on Flipkart?",
      "How do prices vary for similar products on Flipkart?",
      "What are the most popular product categories on Flipkart?",
      "What trends can be observed in Flipkart product listings?",
      "How does product availability change over time on Flipkart?",
      "What are the common features of products listed on Flipkart?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "India",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Indian Grocery (Flipkart Supermart)",
    "description": "Flipkart Supermart transaction and product details",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/aryansingh95/flipkart-grocery-transaction-and-product-details",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "India",
      "Flipkart"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Indian Grocery dataset contains transaction and product details from Flipkart Supermart. It can be used to analyze consumer purchasing patterns and pricing strategies in the grocery sector.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Evaluating pricing strategies",
      "Identifying popular grocery items"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the transaction details in the Indian Grocery dataset?",
      "How can I analyze product details from Flipkart Supermart?",
      "What insights can be gained from grocery transactions in India?",
      "What consumer behavior trends can be identified in the Indian Grocery dataset?",
      "How does pricing vary in the Flipkart Supermart transactions?",
      "What products are most frequently purchased in the Indian Grocery dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "India",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "SEC EDGAR Filings",
    "description": "21M+ public company filings since 1994. 10-Ks, 8-Ks, proxy statements. Full text + structured XBRL data",
    "category": "Financial Services",
    "url": "https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent",
    "docs_url": "https://www.sec.gov/os/accessing-edgar-data",
    "github_url": "https://github.com/datasets/edgar",
    "tags": [
      "SEC",
      "corporate filings",
      "10-K",
      "disclosure",
      "large-scale"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The SEC EDGAR Filings dataset contains over 21 million public company filings since 1994, including 10-Ks, 8-Ks, and proxy statements. Users can analyze corporate disclosures and financial data for research and decision-making.",
    "use_cases": [
      "Analyzing trends in corporate financial disclosures.",
      "Comparing financial performance across different companies.",
      "Researching compliance and regulatory practices in public companies."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are SEC EDGAR filings?",
      "How to access public company filings?",
      "What types of documents are included in SEC EDGAR?",
      "Where can I find 10-K and 8-K filings?",
      "What is the significance of SEC filings for investors?",
      "How to analyze corporate filings data?",
      "What is XBRL data in SEC filings?",
      "How to use SEC EDGAR data for financial analysis?"
    ],
    "domain_tags": [
      "financial services"
    ],
    "data_modality": "mixed",
    "temporal_coverage": "1994-2023",
    "size_category": "massive",
    "model_score": 0.0003
  },
  {
    "name": "NYC TLC Trip Records",
    "description": "3B+ taxi and rideshare trips since 2009. Fares, tips, surge pricing, driver pay. The gold standard for marketplace analytics",
    "category": "Transportation & Mobility",
    "url": "https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page",
    "docs_url": "https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf",
    "github_url": "https://github.com/toddwschneider/nyc-taxi-data",
    "tags": [
      "taxi",
      "Uber",
      "Lyft",
      "surge pricing",
      "NYC",
      "large-scale"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NYC TLC Trip Records dataset contains over 3 billion taxi and rideshare trips since 2009, providing insights into fares, tips, surge pricing, and driver pay. This dataset is ideal for analyzing marketplace dynamics and consumer behavior in urban transportation.",
    "use_cases": [
      "Analyzing fare trends over time",
      "Studying the impact of surge pricing on ridership",
      "Evaluating driver earnings based on trip data",
      "Comparing taxi and rideshare service usage in NYC"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the NYC TLC Trip Records?",
      "How can I analyze taxi fares in NYC?",
      "What insights can be gained from rideshare trip data?",
      "Where can I find large-scale taxi trip datasets?",
      "What is the impact of surge pricing on driver pay?",
      "How to access NYC taxi trip records for analysis?",
      "What data is available on Uber and Lyft trips in NYC?",
      "How have taxi and rideshare trends changed since 2009?"
    ],
    "domain_tags": [
      "transportation",
      "mobility"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2009-present",
    "geographic_scope": "NYC",
    "size_category": "massive",
    "model_score": 0.0003
  },
  {
    "name": "IBM Developer Data",
    "description": "AI, data science, healthcare, and weather datasets from IBM",
    "category": "Data Portals",
    "url": "https://developer.ibm.com/technologies/artificial-intelligence/data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "IBM",
      "AI",
      "healthcare",
      "weather"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The IBM Developer Data includes a variety of datasets related to AI, data science, healthcare, and weather. Users can leverage these datasets for analysis, model training, and research in various domains.",
    "use_cases": [],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets does IBM provide for AI?",
      "Where can I find healthcare datasets from IBM?",
      "Are there any weather datasets available from IBM?",
      "How can I access IBM's data science datasets?",
      "What types of data are included in IBM Developer Data?",
      "Can I use IBM datasets for machine learning projects?",
      "What is the focus of the datasets provided by IBM?",
      "How to utilize IBM Developer Data for research?"
    ],
    "domain_tags": [
      "healthcare",
      "weather"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Meta Content Library",
    "description": "Full Facebook/Instagram public archive via ICPSR application. Posts, Pages, groups, events for academic research",
    "category": "Social & Web",
    "url": "https://transparency.meta.com/researchtools/meta-content-library",
    "docs_url": "https://developers.facebook.com/docs/content-library-and-api",
    "github_url": null,
    "tags": [
      "Facebook",
      "Instagram",
      "Meta",
      "social media",
      "posts"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Meta Content Library is a comprehensive archive of public posts, pages, groups, and events from Facebook and Instagram, available through the ICPSR application. This dataset can be used for academic research to analyze social media interactions and trends.",
    "use_cases": [
      "Analyzing social media engagement trends over time",
      "Studying the impact of social media on public opinion",
      "Investigating the dynamics of online communities",
      "Examining event promotion effectiveness on social media"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Meta Content Library?",
      "How can I access the Facebook public archive?",
      "What types of data are included in the Meta Content Library?",
      "Can I use Instagram data for academic research?",
      "What research can be conducted using the Meta Content Library?",
      "Where can I find social media datasets for research?"
    ],
    "domain_tags": [
      "social media"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Facebook URL Shares",
    "description": "38M URLs with 10T exposure numbers, fact-checking flags, interaction types (2017-2019). Social Science One initiative",
    "category": "Social & Web",
    "url": "https://socialscience.one/our-facebook-partnership",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "URL sharing",
      "misinformation",
      "fact-checking",
      "social media"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains 38 million URLs along with exposure numbers and interaction types related to Facebook shares from 2017 to 2019. It can be used to analyze misinformation trends and the effectiveness of fact-checking efforts on social media.",
    "use_cases": [
      "Analyzing the impact of fact-checking on misinformation spread.",
      "Studying user interaction patterns with shared URLs on Facebook.",
      "Evaluating the effectiveness of social media campaigns.",
      "Investigating trends in URL sharing over time."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the most shared URLs on Facebook?",
      "How does fact-checking influence URL sharing on Facebook?",
      "What types of interactions are associated with Facebook URL shares?",
      "How many URLs were flagged for misinformation on Facebook?",
      "What is the exposure number for a specific URL shared on Facebook?",
      "What trends can be observed in Facebook URL sharing from 2017 to 2019?",
      "How do different interaction types vary in relation to URL shares on Facebook?",
      "What is the impact of social media on misinformation dissemination?"
    ],
    "domain_tags": [
      "social media",
      "information technology"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2017-2019",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Apple App Store Dataset",
    "description": "7,200 iOS apps with pricing, ratings, genres, in-app purchases. Apple app marketplace analysis",
    "category": "App Stores",
    "url": "https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Apple",
      "iOS",
      "apps",
      "pricing",
      "App Store"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Apple App Store Dataset contains information on 7,200 iOS apps, including their pricing, ratings, genres, and in-app purchases. This dataset can be used to analyze trends in the Apple app marketplace and understand consumer preferences.",
    "use_cases": [
      "Analyzing pricing strategies of iOS apps",
      "Studying consumer behavior in app purchases",
      "Identifying trends in app ratings by genre",
      "Evaluating the impact of in-app purchases on overall app success"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the pricing distribution of iOS apps in the Apple App Store?",
      "How do ratings correlate with in-app purchases in iOS apps?",
      "What genres are most popular among iOS apps?",
      "How has the pricing of iOS apps changed over time?",
      "What are the top-rated iOS apps in the Apple App Store?",
      "How do in-app purchases affect app ratings?",
      "What trends can be observed in the Apple App Store app genres?",
      "How do user ratings vary across different pricing tiers of iOS apps?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Hugging Face Datasets",
    "description": "ML/NLP datasets hub with 100K+ datasets. Easy loading via Python library. Community-driven repository",
    "category": "Data Portals",
    "url": "https://huggingface.co/datasets",
    "docs_url": "https://huggingface.co/docs/datasets",
    "github_url": null,
    "tags": [
      "ML",
      "NLP",
      "datasets",
      "Hugging Face",
      "community"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "ML",
      "NLP"
    ],
    "summary": "Hugging Face Datasets is a hub for machine learning and natural language processing datasets, featuring over 100,000 datasets. Users can easily load these datasets via a Python library, making it accessible for various ML/NLP tasks.",
    "use_cases": [
      "Training NLP models",
      "Benchmarking ML algorithms",
      "Exploring community-contributed datasets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the available datasets on Hugging Face?",
      "How can I load datasets from Hugging Face using Python?",
      "What types of ML datasets does Hugging Face offer?",
      "Where can I find community-driven datasets for NLP?",
      "What is the Hugging Face Datasets hub?",
      "How many datasets are available on Hugging Face?"
    ],
    "domain_tags": [
      "technology"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "NYC TLC Trip Records",
    "description": "Complete trip-level data for all NYC taxi and for-hire vehicle trips including Uber and Lyft. Billions of records since 2009 with pickups, dropoffs, fares, and tips.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page",
    "docs_url": "https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records.pdf",
    "github_url": null,
    "tags": [
      "taxi",
      "rideshare",
      "NYC",
      "trip-data",
      "surge-pricing"
    ],
    "best_for": "Ridesharing analysis, surge pricing research, and urban mobility patterns",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "economics",
      "data-analysis"
    ],
    "summary": "The NYC TLC Trip Records dataset contains comprehensive trip-level data for all taxi and for-hire vehicle trips in New York City, including rides from services like Uber and Lyft. This dataset allows for detailed analysis of trip patterns, fare structures, and consumer behavior in the transportation sector.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the NYC TLC Trip Records?",
      "How can I access NYC taxi trip data?",
      "What data is available for Uber and Lyft trips in NYC?",
      "What insights can be gained from NYC taxi trip data?",
      "Where can I find trip-level data for NYC taxis?",
      "What are the trends in NYC taxi fares over time?",
      "How does surge pricing affect taxi trips in NYC?",
      "What is included in the NYC TLC Trip Records dataset?"
    ],
    "use_cases": [
      "Analyzing fare trends and pricing strategies in NYC taxis",
      "Studying the impact of ride-sharing services on traditional taxi usage",
      "Evaluating the effects of surge pricing on trip demand",
      "Investigating geographic patterns of taxi pickups and drop-offs"
    ],
    "domain_tags": [
      "transportation",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2009-2023",
    "geographic_scope": "New York City",
    "size_category": "massive",
    "model_score": 0.0003
  },
  {
    "name": "Federal Procurement Data System (FPDS)",
    "description": "Comprehensive U.S. government contract database with 50+ million unclassified actions and 200+ data elements per transaction",
    "category": "Defense Economics",
    "url": "https://www.fpds.gov/",
    "docs_url": "https://www.fpds.gov/wiki/index.php/V1.4_Atom_Feed_FAQ",
    "github_url": null,
    "tags": [
      "procurement",
      "contracts",
      "government",
      "acquisition"
    ],
    "best_for": "Analyzing U.S. defense contracting patterns and vendor relationships",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Federal Procurement Data System (FPDS) is a comprehensive database of U.S. government contracts, containing over 50 million unclassified actions and more than 200 data elements per transaction. This dataset can be utilized for analyzing government procurement trends, contract allocations, and acquisition strategies.",
    "use_cases": [
      "Analyzing trends in federal government procurement over time.",
      "Evaluating the distribution of contracts across different sectors.",
      "Assessing the impact of government acquisitions on the economy."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Federal Procurement Data System?",
      "How to access U.S. government contract data?",
      "What data elements are available in FPDS?",
      "What are the trends in government procurement?",
      "How many unclassified actions are in the FPDS?",
      "What is the significance of government acquisition data?",
      "Where can I find information on government contracts?",
      "What types of contracts are recorded in FPDS?"
    ],
    "domain_tags": [
      "defense",
      "government"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2004-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Hugging Face Datasets",
    "description": "659,000+ datasets across text, image, audio, and tabular with one-line data loaders",
    "category": "Dataset Aggregators",
    "url": "https://huggingface.co/datasets",
    "docs_url": "https://huggingface.co/docs/datasets",
    "github_url": "https://github.com/huggingface/datasets",
    "tags": [
      "NLP",
      "AI",
      "ML",
      "transformers",
      "streaming"
    ],
    "best_for": "Modern AI/NLP research with seamless ML framework integration",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "NLP",
      "AI",
      "ML"
    ],
    "summary": "Hugging Face Datasets is a collection of over 659,000 datasets that cover various modalities including text, image, audio, and tabular data. It provides one-line data loaders to facilitate easy access and utilization of these datasets for machine learning and AI applications.",
    "use_cases": [],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are Hugging Face Datasets?",
      "How can I access datasets from Hugging Face?",
      "What types of data are available on Hugging Face Datasets?",
      "Are there datasets for NLP on Hugging Face?",
      "How many datasets does Hugging Face offer?",
      "What is the purpose of Hugging Face Datasets?",
      "Can I find image datasets on Hugging Face?",
      "What are the data loaders provided by Hugging Face?"
    ],
    "domain_tags": [
      "AI",
      "NLP"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Computational Neuroscience",
    "description": "Experimental data from neural recordings and behavior",
    "category": "Education",
    "url": "https://crcns.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "neuroscience",
      "neural data",
      "behavior"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains experimental data from neural recordings and behavior, which can be used to analyze neural activity in relation to behavioral patterns. Researchers can utilize this data to explore the relationship between neural processes and behavioral outcomes.",
    "use_cases": [
      "Analyzing neural activity patterns",
      "Studying the relationship between behavior and neural recordings"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Computational Neuroscience dataset?",
      "Where can I find neural recordings data?",
      "How can I analyze behavior using neural data?",
      "What experiments are included in the Computational Neuroscience dataset?",
      "What insights can be gained from neural recordings?",
      "Is there data available on behavior in neuroscience?"
    ],
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "Alibaba Clickstream 2018",
    "description": "Clickstream data from Alibaba platforms (2018)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/56",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clickstream",
      "Alibaba",
      "user behavior"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Alibaba Clickstream 2018 dataset contains clickstream data from Alibaba platforms, allowing for analysis of user behavior and interactions. Researchers can utilize this data to understand consumer patterns and improve e-commerce strategies.",
    "use_cases": [
      "Analyzing user navigation patterns on Alibaba platforms",
      "Identifying trends in consumer purchasing behavior",
      "Optimizing product placement based on clickstream data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Alibaba Clickstream 2018 dataset?",
      "How can I analyze user behavior using Alibaba clickstream data?",
      "What insights can be gained from Alibaba's clickstream data?",
      "Where can I find clickstream data for e-commerce?",
      "What are the applications of clickstream data in retail?",
      "How does Alibaba's clickstream data reflect consumer trends?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2018",
    "size_category": "medium",
    "model_score": 0.0003
  },
  {
    "name": "LaDe Last-Mile Delivery",
    "description": "10.6M+ packages, 619k trajectories with GPS data",
    "category": "Logistics & Supply Chain",
    "url": "https://arxiv.org/html/2306.10675v2",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "last-mile",
      "GPS",
      "trajectories",
      "large-scale"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The LaDe Last-Mile Delivery dataset contains over 10.6 million packages and 619,000 trajectories with GPS data. It can be used to analyze last-mile delivery efficiency, optimize routes, and study consumer behavior in logistics.",
    "use_cases": [
      "Optimize delivery routes",
      "Analyze consumer behavior in last-mile delivery",
      "Study the impact of GPS data on logistics efficiency"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "last-mile delivery dataset",
      "GPS trajectories for logistics",
      "large-scale package delivery data",
      "analyze last-mile delivery efficiency",
      "last-mile logistics data",
      "package delivery GPS data",
      "trajectories in logistics",
      "logistics and supply chain datasets"
    ],
    "domain_tags": [
      "logistics",
      "supply chain"
    ],
    "data_modality": "tabular",
    "size_category": "large",
    "model_score": 0.0002
  },
  {
    "name": "AirBnb (Inside Airbnb)",
    "description": "6M+ listings, 190M+ reviews with pricing and amenities",
    "category": "Real Estate",
    "url": "http://insideairbnb.com/explore",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Airbnb",
      "rentals",
      "pricing",
      "global"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "This dataset contains over 6 million Airbnb listings and more than 190 million reviews, providing insights into pricing and amenities across various locations. It can be used for analyzing rental trends, consumer preferences, and market dynamics in the real estate sector.",
    "use_cases": [
      "Analyzing pricing strategies for Airbnb rentals",
      "Studying consumer behavior in the short-term rental market",
      "Evaluating the impact of amenities on rental success",
      "Comparing Airbnb listings across different geographic areas"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest Airbnb listings?",
      "How do pricing trends vary across different cities?",
      "What amenities are most commonly offered in Airbnb rentals?",
      "How many reviews does the average Airbnb listing receive?",
      "What is the distribution of Airbnb listings by price?",
      "How do user ratings correlate with pricing?",
      "What are the most popular neighborhoods for Airbnb rentals?",
      "How has the number of Airbnb listings changed over time?"
    ],
    "domain_tags": [
      "real estate"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Netflix Viewing Behavior",
    "description": "1.7M episodes/movies watched by 1,060 users over 1 year. Watch patterns, session length, preferences, predictability metrics",
    "category": "Entertainment & Media",
    "url": "https://ieeexplore.ieee.org/document/9500874",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Netflix",
      "streaming",
      "viewing behavior",
      "sessions",
      "video"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior",
      "video"
    ],
    "summary": "This dataset contains viewing behavior data from Netflix, including 1.7 million episodes and movies watched by 1,060 users over a year. It can be used to analyze watch patterns, session lengths, user preferences, and predictability metrics.",
    "use_cases": [
      "Analyzing user engagement on streaming platforms",
      "Studying the impact of session length on viewing preferences",
      "Predicting user behavior based on past viewing data",
      "Identifying trends in content consumption over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the viewing patterns of Netflix users?",
      "How long do users typically watch Netflix in a session?",
      "What are the preferences of Netflix viewers?",
      "How predictable is Netflix viewing behavior?",
      "What metrics can be derived from Netflix viewing data?",
      "How many episodes and movies are watched by users on Netflix?",
      "What is the average session length for Netflix users?",
      "What trends can be observed in Netflix viewing behavior over a year?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1 year",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Netflix Engagement Reports",
    "description": "Hours viewed for every Netflix title (original and licensed) watched >50K hours. First public streaming metrics since 2021",
    "category": "Entertainment & Media",
    "url": "https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Netflix",
      "streaming",
      "engagement",
      "viewership",
      "hours watched"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "entertainment",
      "media",
      "viewership"
    ],
    "summary": "The Netflix Engagement Reports provide data on the hours viewed for every Netflix title that has been watched for over 50,000 hours. This dataset can be used to analyze viewer engagement and trends in streaming content.",
    "use_cases": [
      "Analyze viewer engagement trends over time.",
      "Compare viewership between original and licensed titles.",
      "Identify popular genres based on hours viewed.",
      "Examine the impact of marketing campaigns on streaming hours."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Netflix Engagement Reports?",
      "How many hours were viewed for popular Netflix titles?",
      "What streaming metrics has Netflix released since 2021?",
      "What is the engagement level of Netflix original content?",
      "How does viewership vary across different Netflix titles?",
      "What data is available on Netflix's licensed content viewership?",
      "How can I analyze Netflix streaming metrics?",
      "What are the trends in Netflix viewership data?"
    ],
    "domain_tags": [
      "entertainment"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Inside Airbnb Raw Data",
    "description": "Raw data files from Inside Airbnb project",
    "category": "Data Portals",
    "url": "http://insideairbnb.com/get-the-data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Airbnb",
      "raw data",
      "rentals"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Inside Airbnb Raw Data consists of raw data files from the Inside Airbnb project, which provides insights into Airbnb rentals. This dataset can be used for various analyses related to rental pricing, occupancy rates, and consumer behavior in the short-term rental market.",
    "use_cases": [
      "Analyzing rental pricing trends",
      "Studying consumer behavior in short-term rentals",
      "Evaluating occupancy rates of Airbnb listings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Inside Airbnb raw data",
      "Airbnb rental data analysis",
      "Airbnb dataset for research",
      "Inside Airbnb project data",
      "Airbnb data files",
      "Airbnb raw data download"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Wikipedia Full Database Dump",
    "description": "Complete Wikipedia content and metadata in SQL/XML format, includes all revisions and edit history",
    "category": "Social & Web",
    "url": "https://dumps.wikimedia.org/",
    "docs_url": "https://en.wikipedia.org/wiki/Wikipedia:Database_download",
    "github_url": null,
    "tags": [
      "database dump",
      "SQL",
      "large-scale",
      "text",
      "real-world",
      "encyclopedic"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Wikipedia Full Database Dump contains the complete content and metadata of Wikipedia in SQL/XML format, including all revisions and edit history. This dataset can be used for various analyses, such as studying content evolution, understanding user contributions, and exploring the breadth of knowledge available on Wikipedia.",
    "use_cases": [
      "Analyzing the evolution of Wikipedia articles over time",
      "Studying the patterns of user contributions and edits",
      "Exploring the breadth of topics covered in Wikipedia",
      "Conducting research on the reliability and accuracy of Wikipedia content"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Where can I find the Wikipedia Full Database Dump?",
      "What is included in the Wikipedia Full Database Dump?",
      "How to access the complete Wikipedia content in SQL format?",
      "What metadata is available in the Wikipedia Full Database Dump?",
      "Is there a way to download the Wikipedia database dump?",
      "What formats are available for the Wikipedia Full Database Dump?",
      "How can I analyze Wikipedia edit history using the database dump?",
      "What are the use cases for the Wikipedia Full Database Dump?"
    ],
    "domain_tags": [
      "social",
      "web"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Instacart Market Basket Analysis",
    "description": "3 million grocery orders from 200,000 Instacart users with product details and order sequences. Released for a Kaggle competition to predict which products users will reorder.",
    "category": "MarTech & Customer Analytics",
    "url": "https://www.kaggle.com/c/instacart-market-basket-analysis/data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "market-basket",
      "sequential",
      "grocery",
      "reorder-prediction"
    ],
    "best_for": "Learning market basket analysis, sequential recommendations, and next-basket prediction",
    "difficulty": "intermediate",
    "prerequisites": [
      "pandas-dataframes"
    ],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 3 million grocery orders from 200,000 Instacart users, detailing product information and order sequences. It can be used to analyze purchasing patterns and predict which products users are likely to reorder.",
    "use_cases": [
      "Analyzing customer purchasing patterns",
      "Predicting product reorders",
      "Optimizing inventory based on order sequences"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Instacart Market Basket Analysis dataset",
      "grocery order prediction dataset",
      "market basket analysis for reorders",
      "Kaggle competition grocery dataset",
      "Instacart user order sequences",
      "predicting grocery reorders dataset",
      "Instacart product details analysis"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Ele.me Search",
    "description": "Search log dataset from Ele.me (Chinese food delivery)",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/dataset/120281",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "food delivery",
      "search logs",
      "China"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Ele.me Search dataset consists of search logs from Ele.me, a Chinese food delivery service. It can be used to analyze consumer behavior and trends in food delivery preferences in China.",
    "use_cases": [
      "Analyzing consumer preferences in food delivery",
      "Identifying trends in food search behavior",
      "Evaluating the impact of promotions on search queries"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the most common search queries on Ele.me?",
      "How do search trends vary by region in China?",
      "What food items are most frequently searched on Ele.me?",
      "How does search behavior change during holidays?",
      "What are the peak search times for food delivery?",
      "How do user search patterns differ between urban and rural areas?",
      "What keywords are associated with high delivery rates?",
      "How do seasonal changes affect food delivery searches?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Brazilian Store Chain",
    "description": "Sales data from Brazilian retail chain",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/marcio486/sales-data-for-a-chain-of-brazilian-stores",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Brazil",
      "chain stores"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains sales data from a Brazilian retail chain, providing insights into consumer purchasing patterns and sales performance. It can be used to analyze trends in grocery and supermarket sales in Brazil.",
    "use_cases": [
      "Analyzing sales trends over time",
      "Comparing performance between different store locations",
      "Understanding consumer purchasing behavior",
      "Evaluating the impact of promotions on sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Brazilian retail sales data",
      "grocery chain sales analysis Brazil",
      "supermarket sales trends Brazil",
      "retail chain data for analysis",
      "Brazilian store chain dataset",
      "sales data grocery supermarkets Brazil"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Brazil",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Online Auctions Collection",
    "description": "Collection of datasets from eBay and experimental auctions",
    "category": "Auctions & Marketplaces",
    "url": "https://www.modelingonlineauctions.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "auctions",
      "eBay",
      "bidding"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Online Auctions Collection includes datasets from eBay and experimental auctions, providing insights into bidding behavior and auction dynamics. Researchers and analysts can use this data to study market trends and consumer behavior in online auctions.",
    "use_cases": [
      "Analyzing bidding strategies in online auctions",
      "Studying the effects of auction design on consumer behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available on eBay auctions?",
      "How can I analyze bidding patterns in online auctions?",
      "What is the impact of auction formats on bidding behavior?",
      "Where can I find datasets for experimental auctions?",
      "What data is included in the Online Auctions Collection?",
      "How to access eBay auction datasets for research?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Stack Overflow Data Dump",
    "description": "Full Q&A archive + annual developer survey (49K+ responses). Salaries, tech adoption, developer analytics",
    "category": "Social & Web",
    "url": "https://archive.org/details/stackexchange",
    "docs_url": "https://survey.stackoverflow.co/",
    "github_url": null,
    "tags": [
      "developers",
      "salaries",
      "tech",
      "survey",
      "Q&A"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Stack Overflow Data Dump is a comprehensive archive of questions and answers along with an annual developer survey featuring over 49,000 responses. This dataset can be used to analyze developer salaries, technology adoption trends, and various developer analytics.",
    "use_cases": [
      "Analyzing salary trends among developers",
      "Studying technology adoption rates",
      "Understanding developer demographics",
      "Exploring Q&A patterns in programming topics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Stack Overflow Data Dump?",
      "Where can I find developer salary data?",
      "How to analyze tech adoption trends from Stack Overflow?",
      "What insights can be drawn from the annual developer survey?",
      "What are the key findings from the Stack Overflow Q&A archive?",
      "How to access the Stack Overflow Data Dump?",
      "What types of analytics can be performed on developer data?",
      "What are common developer technologies according to Stack Overflow?"
    ],
    "domain_tags": [
      "technology",
      "software development"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "LOBSTER Order Book",
    "description": "NASDAQ limit order book data at millisecond precision. Level 1-10 depth, message-by-message reconstruction. Market microstructure research",
    "category": "Financial Services",
    "url": "https://lobsterdata.com/",
    "docs_url": "https://lobsterdata.com/info/DataStructure.php",
    "github_url": null,
    "tags": [
      "order book",
      "NASDAQ",
      "high-frequency",
      "market microstructure",
      "trading"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The LOBSTER Order Book dataset provides NASDAQ limit order book data with millisecond precision, allowing for detailed market microstructure research. Researchers can analyze trading behaviors and order book dynamics at a granular level.",
    "use_cases": [
      "Analyzing trading patterns in high-frequency trading",
      "Studying the impact of order book depth on price movements",
      "Researching market microstructure and liquidity",
      "Developing trading algorithms based on order book data"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the LOBSTER Order Book dataset?",
      "How to access NASDAQ limit order book data?",
      "What are the applications of market microstructure research?",
      "How to analyze high-frequency trading data?",
      "What is the significance of order book depth?",
      "Where can I find NASDAQ trading data?",
      "What tools can be used for analyzing order book data?",
      "What insights can be gained from message-by-message reconstruction of order books?"
    ],
    "domain_tags": [
      "financial services",
      "fintech"
    ],
    "data_modality": "time-series",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Mendeley Food Delivery Reviews",
    "description": "1.69M reviews from DoorDash, Grubhub, Uber Eats. Ratings, text reviews, restaurant metadata. Gig economy platform research",
    "category": "Food & Delivery",
    "url": "https://data.mendeley.com/datasets/m5jk7wzyg7/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "food delivery",
      "reviews",
      "DoorDash",
      "Grubhub",
      "Uber Eats",
      "gig economy"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "gig economy"
    ],
    "summary": "This dataset contains 1.69 million reviews from popular food delivery services such as DoorDash, Grubhub, and Uber Eats. It provides insights into consumer preferences and experiences in the gig economy, making it useful for analyzing trends in food delivery services.",
    "use_cases": [
      "Analyzing customer satisfaction trends across different food delivery platforms.",
      "Comparing review sentiments between various restaurants on the same platform.",
      "Investigating the impact of delivery times on customer ratings.",
      "Exploring the relationship between restaurant type and review scores."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the most common ratings for food delivery services?",
      "How do customer reviews vary between DoorDash, Grubhub, and Uber Eats?",
      "What factors influence customer satisfaction in food delivery?",
      "Can we analyze trends in food delivery reviews over time?",
      "What restaurant metadata is available in the food delivery reviews dataset?",
      "How does the gig economy affect consumer behavior in food delivery?",
      "What are the key themes in text reviews for food delivery services?",
      "How do ratings correlate with restaurant metadata?"
    ],
    "domain_tags": [
      "retail",
      "food service",
      "gig economy"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "FEMA NFIP Claims & Policies",
    "description": "National Flood Insurance Program data with 2M+ claims since 1978 and policy-level information for flood risk modeling",
    "category": "Insurance & Actuarial",
    "url": "https://www.fema.gov/openfema-data-page/fima-nfip-redacted-claims-v2",
    "docs_url": "https://www.fema.gov/about/openfema/data-sets",
    "github_url": null,
    "tags": [
      "flood-insurance",
      "catastrophe",
      "claims-data",
      "natural-disasters",
      "property-insurance"
    ],
    "best_for": "Catastrophe modeling, flood risk analysis, and climate-related insurance research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The FEMA NFIP Claims & Policies dataset contains over 2 million claims data since 1978, along with policy-level information essential for flood risk modeling. This dataset can be used to analyze flood insurance claims, assess risk factors, and inform policy decisions.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the FEMA NFIP Claims & Policies dataset?",
      "How many claims are in the FEMA NFIP dataset?",
      "What information does the FEMA NFIP dataset provide?",
      "Where can I find flood insurance claims data?",
      "How can I use FEMA NFIP data for flood risk modeling?",
      "What years does the FEMA NFIP dataset cover?",
      "What types of claims are included in the FEMA NFIP dataset?",
      "How to access FEMA NFIP policy-level information?"
    ],
    "use_cases": [
      "Analyzing trends in flood insurance claims over time",
      "Assessing the impact of natural disasters on property insurance",
      "Modeling flood risk based on historical claims data",
      "Evaluating the effectiveness of flood insurance policies"
    ],
    "domain_tags": [
      "insurance",
      "natural-disasters"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1978-present",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "DB1B Airline Origin and Destination Survey",
    "description": "10% random sample of all US airline tickets with origin, destination, fare, and itinerary details. Quarterly since 1993. The gold standard for airline pricing research.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.transtats.bts.gov/DatabaseInfo.asp?QO_VQ=EFI",
    "docs_url": "https://www.transtats.bts.gov/Fields.asp?gnoession_VQ=FHK",
    "github_url": null,
    "tags": [
      "airlines",
      "fares",
      "routes",
      "BTS",
      "pricing"
    ],
    "best_for": "Airline pricing research, competition analysis, and route economics",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "transportation",
      "economics",
      "pricing"
    ],
    "summary": "The DB1B Airline Origin and Destination Survey provides a 10% random sample of all US airline tickets, including details on origin, destination, fare, and itinerary. This dataset is invaluable for conducting research on airline pricing and understanding market dynamics in the airline industry.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the DB1B Airline Origin and Destination Survey?",
      "How can I access the DB1B Airline dataset?",
      "What data is included in the DB1B Airline survey?",
      "What are common analyses performed using the DB1B Airline data?",
      "Where can I find information on US airline ticket pricing?",
      "What insights can be gained from the DB1B Airline dataset?",
      "How does the DB1B dataset support transportation economics research?",
      "What is the significance of the DB1B Airline survey in pricing research?"
    ],
    "use_cases": [
      "Analyzing fare trends over time",
      "Studying the impact of routes on pricing strategies",
      "Comparing airline pricing across different markets"
    ],
    "domain_tags": [
      "transportation",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1993-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "benchmark_usage": [
      "airline pricing research"
    ],
    "model_score": 0.0002
  },
  {
    "name": "Alpha Vantage",
    "description": "NASDAQ-licensed stock data for 200,000+ tickers with free tier (25 requests/day)",
    "category": "Dataset Aggregators",
    "url": "https://www.alphavantage.co",
    "docs_url": "https://www.alphavantage.co/documentation/",
    "github_url": null,
    "tags": [
      "stocks",
      "free",
      "API",
      "technical indicators"
    ],
    "best_for": "Individual researchers needing free stock data with 50+ technical indicators",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Alpha Vantage provides NASDAQ-licensed stock data for over 200,000 tickers, allowing users to access stock information and technical indicators. With a free tier offering 25 requests per day, it is suitable for those looking to analyze stock market trends.",
    "use_cases": [
      "Analyzing stock market trends using historical data",
      "Building a stock price prediction model",
      "Creating visualizations of stock performance",
      "Comparing technical indicators across different stocks"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Alpha Vantage stock data?",
      "How to access NASDAQ stock data using Alpha Vantage?",
      "What are the features of Alpha Vantage API?",
      "How many tickers does Alpha Vantage cover?",
      "Is Alpha Vantage free to use?",
      "What are technical indicators available in Alpha Vantage?",
      "How to make requests to Alpha Vantage API?",
      "What is the daily request limit for Alpha Vantage?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "time-series",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Goodreads",
    "description": "Book information and user reviews from Goodreads platform",
    "category": "Entertainment & Media",
    "url": "https://mengtingwan.github.io/data/goodreads.html#datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "books",
      "reviews",
      "recommendations"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior"
    ],
    "summary": "The Goodreads dataset contains book information and user reviews from the Goodreads platform. It can be used to analyze user preferences, trends in book ratings, and recommendations based on reviews.",
    "use_cases": [
      "Analyzing user sentiment in book reviews",
      "Identifying popular book genres based on ratings",
      "Creating a recommendation system for books"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Goodreads dataset?",
      "How to analyze book reviews from Goodreads?",
      "What information is available in the Goodreads dataset?",
      "How can I use Goodreads data for recommendations?",
      "What are the trends in book ratings on Goodreads?",
      "How to visualize user reviews from Goodreads?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Diginetica Fashion",
    "description": "Clickstream and purchase data for fashion e-commerce",
    "category": "Fashion & Apparel",
    "url": "https://competitions.codalab.org/competitions/11161",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "clickstream",
      "competition"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "Diginetica Fashion provides clickstream and purchase data for fashion e-commerce, allowing analysis of consumer behavior and competition in the online retail space. This dataset can be used to understand shopping patterns and optimize marketing strategies.",
    "use_cases": [
      "Analyzing consumer purchase patterns",
      "Evaluating the impact of clickstream data on sales",
      "Comparing competition strategies in fashion e-commerce"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Diginetica Fashion dataset?",
      "How to analyze clickstream data for fashion e-commerce?",
      "What insights can be derived from fashion purchase data?",
      "How does competition affect online fashion sales?",
      "What are the trends in consumer behavior in fashion e-commerce?",
      "How to use Diginetica Fashion for market analysis?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Soso (KDD Cup 2012)",
    "description": "KDD Cup 2012 Track 2 for sponsored search CTR prediction",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/kddcup2012-track2",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "sponsored search",
      "KDD",
      "CTR"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "data science"
    ],
    "summary": "The Soso dataset from KDD Cup 2012 is designed for predicting click-through rates (CTR) in sponsored search. It provides insights into user interactions with advertisements, which can be used to improve targeting and ad performance.",
    "use_cases": [
      "Predicting click-through rates for ads",
      "Analyzing user behavior in sponsored search",
      "Improving ad targeting strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Soso dataset?",
      "Where can I find the KDD Cup 2012 dataset?",
      "How to access the Soso dataset for CTR prediction?",
      "What are the features of the KDD Cup 2012 Track 2 dataset?",
      "What is the purpose of the Soso dataset?",
      "How can I use the Soso dataset for advertising analysis?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Cainiao Last-Mile (MSOM18)",
    "description": "Cainiao Last-Mile Delivery dataset from MSOM 2018",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/competition/entrance/231623/information",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "last-mile",
      "delivery",
      "Cainiao",
      "MSOM"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "logistics"
    ],
    "summary": "The Cainiao Last-Mile Delivery dataset from MSOM 2018 provides insights into last-mile delivery operations. It can be used to analyze delivery efficiency and consumer behavior in logistics.",
    "use_cases": [
      "Analyzing delivery times",
      "Evaluating consumer satisfaction",
      "Optimizing delivery routes"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Cainiao Last-Mile Delivery dataset",
      "MSOM 2018 delivery data",
      "last-mile delivery analysis",
      "Cainiao logistics dataset",
      "delivery efficiency data",
      "last-mile logistics research"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Meta (Facebook) Research",
    "description": "1.1B+ public FB/IG posts with engagement metrics",
    "category": "Social & Web",
    "url": "https://fort.fb.com/researcher-datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social media",
      "Facebook",
      "Instagram",
      "engagement"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "social media",
      "engagement"
    ],
    "summary": "This dataset contains over 1.1 billion public posts from Facebook and Instagram, along with their engagement metrics. It can be used to analyze social media trends, user engagement, and the impact of posts on audience interaction.",
    "use_cases": [
      "Analyzing user engagement trends over time",
      "Comparing engagement metrics between Facebook and Instagram",
      "Identifying the most effective types of social media content",
      "Studying the impact of social media posts on audience behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the engagement metrics for Facebook posts?",
      "How can I analyze Instagram post interactions?",
      "What trends can be identified in public Facebook posts?",
      "How does engagement vary across different social media platforms?",
      "What insights can be drawn from 1.1B public FB/IG posts?",
      "How to access public posts data from Facebook and Instagram?",
      "What are the most engaging types of posts on social media?",
      "How to visualize engagement metrics from social media data?"
    ],
    "domain_tags": [
      "social media"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "model_score": 0.0002
  },
  {
    "name": "MSOM Data Challenges",
    "description": "Manufacturing & Service Operations Management challenges",
    "category": "Data Portals",
    "url": "https://pubsonline.informs.org/journal/msom",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "MSOM",
      "operations",
      "INFORMS"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The MSOM Data Challenges dataset focuses on challenges in Manufacturing and Service Operations Management. It provides data that can be utilized for analyzing operational efficiencies and decision-making processes in these fields.",
    "use_cases": [
      "Analyzing operational efficiencies in manufacturing",
      "Evaluating service management strategies",
      "Benchmarking performance in operations management"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the MSOM Data Challenges?",
      "How can I access MSOM data?",
      "What operations management data is available?",
      "What challenges are included in the MSOM dataset?",
      "How to analyze MSOM data?",
      "What insights can be gained from MSOM challenges?"
    ],
    "domain_tags": [
      "manufacturing",
      "service operations"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "PatentsView",
    "description": "13M+ US patents (1976-present) with citations, inventors, assignees. Full patent text and claims. innovation research at scale",
    "category": "Data Portals",
    "url": "https://patentsview.org/download/data-download-tables",
    "docs_url": "https://patentsview.org/download/data-download-dictionary",
    "github_url": null,
    "tags": [
      "patents",
      "innovation",
      "USPTO",
      "citations",
      "intellectual property"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "PatentsView is a comprehensive dataset containing over 13 million US patents from 1976 to the present, including detailed information on citations, inventors, and assignees. This dataset allows researchers to conduct innovation research at scale by analyzing patent text and claims.",
    "use_cases": [
      "Analyzing trends in patent filings over time",
      "Identifying key inventors and their contributions",
      "Studying the impact of patents on innovation",
      "Exploring citation networks among patents"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest patents in the field of innovation?",
      "How many patents were filed in 2020?",
      "Who are the top inventors in the patent dataset?",
      "What are the most cited patents?",
      "How can I access full patent text and claims?",
      "What trends can be observed in US patents over the years?",
      "What is the role of patents in intellectual property?",
      "How do patents influence innovation research?"
    ],
    "domain_tags": [
      "intellectual property",
      "innovation"
    ],
    "data_modality": "mixed",
    "temporal_coverage": "1976-present",
    "geographic_scope": "US",
    "size_category": "massive",
    "model_score": 0.0002
  },
  {
    "name": "French Motor TPL (freMTPL2)",
    "description": "French motor third-party liability insurance dataset with 678K policies and claims - the standard benchmark for insurance ML papers",
    "category": "Insurance & Actuarial",
    "url": "https://cran.r-project.org/package=CASdatasets",
    "docs_url": "https://freakonometrics.github.io/CASdatasets/",
    "github_url": null,
    "tags": [
      "motor-insurance",
      "claims-frequency",
      "pricing",
      "benchmark",
      "actuarial"
    ],
    "best_for": "Insurance pricing models, GLM vs ML comparisons, and actuarial research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "insurance",
      "actuarial",
      "machine-learning"
    ],
    "summary": "The French Motor TPL dataset contains 678K policies and claims related to motor third-party liability insurance. It serves as a standard benchmark for machine learning applications in the insurance sector.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "French motor insurance dataset",
      "freMTPL2 dataset",
      "motor third-party liability insurance data",
      "insurance claims frequency dataset",
      "benchmark dataset for insurance ML",
      "actuarial data for motor insurance"
    ],
    "use_cases": [
      "Analyzing claims frequency",
      "Pricing motor insurance policies",
      "Benchmarking machine learning models in insurance",
      "Actuarial analysis of motor insurance"
    ],
    "domain_tags": [
      "insurance"
    ],
    "data_modality": "tabular",
    "geographic_scope": "France",
    "size_category": "medium",
    "benchmark_usage": [
      "standard benchmark for insurance ML papers"
    ],
    "model_score": 0.0002
  },
  {
    "name": "MobilityData GTFS Catalog",
    "description": "Curated directory of 1,327+ GTFS feeds from transit agencies globally with quality metrics, update frequency, and standardized metadata.",
    "category": "Transportation Economics & Technology",
    "url": "https://database.mobilitydata.org/",
    "docs_url": "https://mobilitydata.org/",
    "github_url": null,
    "tags": [
      "transit",
      "GTFS",
      "open-data",
      "schedules",
      "catalog"
    ],
    "best_for": "Finding and comparing transit data quality across cities and agencies",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The MobilityData GTFS Catalog is a curated directory of over 1,327 GTFS feeds from transit agencies worldwide, providing insights into quality metrics and update frequency. Users can leverage this dataset to analyze transit patterns, assess data quality, and enhance transportation planning.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the MobilityData GTFS Catalog?",
      "How many GTFS feeds are included in the MobilityData GTFS Catalog?",
      "What quality metrics are available in the MobilityData GTFS Catalog?",
      "How often are the GTFS feeds updated in the MobilityData GTFS Catalog?",
      "Where can I find GTFS feeds from transit agencies?",
      "What is GTFS and how is it used in transportation?",
      "What kind of metadata is standardized in the MobilityData GTFS Catalog?",
      "How can I access the MobilityData GTFS Catalog?"
    ],
    "use_cases": [
      "Analyzing transit agency performance using GTFS data.",
      "Comparing update frequencies of different transit feeds.",
      "Evaluating the quality of transit data across various regions.",
      "Creating visualizations of transit schedules and routes."
    ],
    "domain_tags": [
      "transportation",
      "technology"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "EPA CEMS (Continuous Emissions Monitoring)",
    "description": "Hourly emissions and generation data from U.S. power plants since 1995",
    "category": "Energy",
    "url": "https://campd.epa.gov/",
    "docs_url": "https://www.epa.gov/power-sector/about-continuous-emissions-monitoring-system-cems",
    "github_url": null,
    "tags": [
      "emissions",
      "hourly",
      "CO2",
      "SO2",
      "NOx"
    ],
    "best_for": "Analyzing power plant emissions patterns and environmental impacts",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EPA CEMS dataset provides hourly emissions and generation data from U.S. power plants since 1995. This data can be used for analyzing trends in emissions over time and evaluating the impact of regulatory policies on air quality.",
    "use_cases": [
      "Analyzing trends in CO2 emissions from power plants over the years.",
      "Evaluating the effectiveness of emissions regulations on air quality.",
      "Comparing emissions data across different states or regions.",
      "Studying the relationship between power generation and emissions."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the EPA CEMS dataset?",
      "How can I access hourly emissions data from U.S. power plants?",
      "What emissions data is available from the EPA since 1995?",
      "Where can I find CO2, SO2, and NOx emissions data?",
      "What are the trends in emissions from U.S. power plants?",
      "How does power generation affect emissions over time?",
      "What tools can I use to analyze EPA CEMS data?",
      "What is the significance of continuous emissions monitoring?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "1995-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "CSIS Significant Cyber Incidents",
    "description": "Curated list of major cyber attacks with losses exceeding $1 million, maintained by leading security think tank",
    "category": "Cybersecurity",
    "url": "https://www.csis.org/programs/strategic-technologies-program/significant-cyber-incidents",
    "docs_url": "https://www.csis.org/programs/strategic-technologies-program/significant-cyber-incidents",
    "github_url": null,
    "tags": [
      "cyber incidents",
      "major attacks",
      "economic impact"
    ],
    "best_for": "Analyzing high-impact cyber events for economic research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "cybersecurity",
      "economic impact"
    ],
    "summary": "This dataset contains a curated list of significant cyber incidents that resulted in financial losses exceeding $1 million. It can be used to analyze trends in cyber attacks and their economic implications.",
    "use_cases": [
      "Analyzing the economic impact of cyber attacks on businesses.",
      "Identifying trends in cyber incidents over time.",
      "Assessing the effectiveness of cybersecurity measures based on incident data.",
      "Comparing the frequency and severity of cyber incidents across different sectors."
    ],
    "audience": [
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the major cyber incidents listed by CSIS?",
      "How do cyber attacks impact the economy?",
      "What is the financial loss threshold for incidents in the CSIS dataset?",
      "Where can I find a list of significant cyber incidents?",
      "What types of cyber incidents are included in the CSIS dataset?",
      "How frequently are the CSIS significant cyber incidents updated?",
      "What organization maintains the CSIS significant cyber incidents list?",
      "What is the significance of cyber incidents with losses over $1 million?"
    ],
    "domain_tags": [
      "cybersecurity"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2006-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Online Retail II (UCI)",
    "description": "1M+ transactions from a UK-based online retailer (2009-2011). Contains invoice number, stock code, description, quantity, invoice date, unit price, customer ID, and country. Standard benchmark for RFM analysis and CLV modeling.",
    "category": "MarTech & Customer Analytics",
    "url": "https://archive.ics.uci.edu/ml/datasets/Online+Retail+II",
    "docs_url": "https://archive.ics.uci.edu/ml/datasets/Online+Retail+II",
    "github_url": null,
    "tags": [
      "CLV",
      "RFM",
      "e-commerce",
      "transaction-data"
    ],
    "best_for": "Learning CLV modeling with BG/NBD, RFM segmentation, and cohort analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "customer analytics",
      "transaction data"
    ],
    "summary": "The Online Retail II dataset contains over 1 million transactions from a UK-based online retailer between 2009 and 2011. It includes detailed information such as invoice number, stock code, description, quantity, invoice date, unit price, customer ID, and country, making it a standard benchmark for RFM analysis and CLV modeling.",
    "use_cases": [
      "Conducting RFM analysis to segment customers.",
      "Modeling customer lifetime value (CLV) based on transaction history.",
      "Analyzing purchasing patterns over time.",
      "Evaluating the impact of pricing strategies on sales."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Online Retail II dataset?",
      "Where can I find transaction data for e-commerce analysis?",
      "How can I use the Online Retail II dataset for RFM analysis?",
      "What are the features included in the Online Retail II dataset?",
      "Where can I access datasets for customer lifetime value modeling?",
      "What is the significance of the Online Retail II dataset in marketing analytics?",
      "How many transactions are in the Online Retail II dataset?",
      "What time period does the Online Retail II dataset cover?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "temporal_coverage": "2009-2011",
    "geographic_scope": "UK",
    "benchmark_usage": [
      "RFM analysis",
      "CLV modeling"
    ],
    "model_score": 0.0002
  },
  {
    "name": "JD.com Search",
    "description": "170,000 users' real search queries (2021-2022) from JD.com",
    "category": "E-Commerce",
    "url": "https://github.com/rucliujn/JDsearch",
    "docs_url": null,
    "github_url": "https://github.com/rucliujn/JDsearch",
    "tags": [
      "search queries",
      "e-commerce search",
      "China"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains 170,000 real search queries from JD.com, reflecting consumer behavior in the e-commerce sector in China during 2021-2022. It can be used to analyze search trends, consumer preferences, and market dynamics.",
    "use_cases": [
      "Analyzing consumer search behavior",
      "Identifying popular products",
      "Understanding market trends",
      "Evaluating the effectiveness of search algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the most common search queries on JD.com?",
      "How do search queries vary by product category on JD.com?",
      "What trends can be observed in JD.com search queries from 2021 to 2022?",
      "How do seasonal events affect search queries on JD.com?",
      "What keywords are most frequently searched by users on JD.com?",
      "How do search queries reflect consumer behavior in China?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "temporal_coverage": "2021-2022",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Criteo Display Advertising",
    "description": "342GB total with 13 integer features, 26 hashed categorical features",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/ressources/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR prediction",
      "advertising",
      "large-scale"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Criteo Display Advertising dataset contains 342GB of data with 13 integer features and 26 hashed categorical features, making it suitable for large-scale advertising analysis. It can be used for click-through rate (CTR) prediction and other advertising-related analyses.",
    "use_cases": [
      "CTR prediction",
      "Advertising campaign optimization",
      "User behavior analysis"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Criteo Display Advertising dataset?",
      "How to use Criteo dataset for CTR prediction?",
      "Criteo dataset features and their significance",
      "Where to find Criteo Display Advertising dataset?",
      "What are the applications of Criteo dataset in advertising?",
      "How large is the Criteo Display Advertising dataset?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "large",
    "model_score": 0.0002
  },
  {
    "name": "Avazu",
    "description": "Dataset for click-through rate prediction on mobile ads",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/avazu-ctr-prediction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR",
      "mobile ads",
      "Kaggle competition"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Avazu dataset is designed for predicting click-through rates on mobile advertisements. It can be utilized to build models that forecast ad performance and optimize advertising strategies.",
    "use_cases": [
      "Predicting click-through rates for mobile ads",
      "Optimizing ad placements based on predicted CTR",
      "Analyzing user engagement with mobile advertisements"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Avazu dataset for click-through rate prediction",
      "mobile ads click-through rate dataset",
      "Kaggle competition datasets for advertising",
      "predicting CTR with Avazu data",
      "Avazu mobile ads dataset download",
      "click-through rate prediction datasets",
      "advertising datasets for machine learning",
      "Avazu dataset analysis"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Stanford Amazon/Beer",
    "description": "Amazon product data and BeerAdvocate reviews from Stanford SNAP",
    "category": "Entertainment & Media",
    "url": "https://snap.stanford.edu/data/#amazon",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Stanford",
      "beer",
      "Amazon"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains Amazon product data and reviews from BeerAdvocate, sourced from Stanford SNAP. It can be used to analyze consumer preferences and trends in the beer market.",
    "use_cases": [
      "Analyzing consumer preferences in beer purchases",
      "Comparing product ratings on Amazon with BeerAdvocate reviews",
      "Identifying trends in beer consumption",
      "Evaluating the impact of reviews on product sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Stanford Amazon/Beer dataset?",
      "How can I access Amazon product data and BeerAdvocate reviews?",
      "What insights can be gained from the Stanford SNAP beer dataset?",
      "What are the consumer behaviors in beer purchasing?",
      "How does Amazon product data relate to beer reviews?",
      "What are the trends in beer reviews on BeerAdvocate?"
    ],
    "domain_tags": [
      "retail",
      "entertainment"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Ukraine eCommerce (Fozzy)",
    "description": "E-commerce sales data from Fozzy Group retail chain in Ukraine",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Ukraine",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "retail",
      "sales"
    ],
    "summary": "This dataset contains e-commerce sales data from the Fozzy Group retail chain in Ukraine. It can be used to analyze sales trends, consumer behavior, and pricing strategies in the grocery and supermarket sector.",
    "use_cases": [
      "Analyze sales trends over time",
      "Evaluate consumer purchasing behavior",
      "Assess pricing strategies",
      "Compare sales performance across different product categories"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Ukraine eCommerce sales data",
      "Fozzy Group retail sales dataset",
      "e-commerce data analysis Ukraine",
      "grocery sales trends in Ukraine",
      "Fozzy Group sales statistics",
      "retail data for Ukraine",
      "Ukraine supermarket sales data",
      "e-commerce trends in grocery sector Ukraine"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Ukraine",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Rossmann Store Sales",
    "description": "1,115 Rossmann drug stores historical sales data",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/rossmann-store-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "Germany",
      "Kaggle competition"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "retail",
      "sales analysis"
    ],
    "summary": "This dataset contains historical sales data from 1,115 Rossmann drug stores in Germany. It can be used to analyze sales trends, forecast future sales, and understand consumer behavior in the retail sector.",
    "use_cases": [
      "Sales forecasting for drug stores",
      "Analyzing consumer purchasing patterns",
      "Evaluating the impact of promotions on sales",
      "Understanding seasonal sales variations"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Rossmann Store Sales dataset?",
      "Where can I find historical sales data for Rossmann drug stores?",
      "How to analyze retail sales data from Rossmann?",
      "What insights can be gained from Rossmann Store Sales?",
      "Is there a Kaggle competition for Rossmann Store Sales?",
      "What are the sales trends in German grocery stores?",
      "How to use Rossmann sales data for forecasting?",
      "What tools can be used to analyze Rossmann Store Sales?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Germany",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "UK Gift Shop (Online Retail)",
    "description": "Online retail transactions (2010-2011) from UK gift retailer",
    "category": "Grocery & Supermarkets",
    "url": "http://archive.ics.uci.edu/dataset/352/online+retail",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "retail",
      "UK",
      "UCI",
      "transactions"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The UK Gift Shop dataset contains online retail transactions from a UK gift retailer during the years 2010-2011. It can be used to analyze consumer purchasing behavior and trends in online retail.",
    "use_cases": [
      "Analyzing seasonal trends in gift purchases",
      "Examining consumer behavior during holidays",
      "Evaluating pricing strategies for online retail"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "UK online retail transactions dataset",
      "gift shop sales data 2010-2011",
      "UK retail transaction analysis",
      "e-commerce data for UK gift shops",
      "consumer behavior in online retail UK",
      "2010 UK gift shop sales trends"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2010-2011",
    "geographic_scope": "UK",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "NYC Shopping",
    "description": "Large sales dataset from New York City retail",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/pigment/big-sales-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NYC",
      "retail",
      "large-scale"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The NYC Shopping dataset contains large sales data from retail stores in New York City. It can be used to analyze consumer behavior, pricing strategies, and retail performance.",
    "use_cases": [
      "Analyze consumer spending patterns",
      "Evaluate pricing strategies in retail",
      "Assess the impact of promotions on sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NYC retail sales dataset",
      "large sales data New York City",
      "NYC grocery sales analysis",
      "New York City supermarket dataset",
      "retail data NYC",
      "NYC shopping trends dataset"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "New York City",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Romania Tenders",
    "description": "Public tender data (2007-2016) from Romania",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/gpreda/public-tenders-romania-20072016",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "tenders",
      "government",
      "Romania"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains public tender data from Romania covering the years 2007 to 2016. It can be used to analyze government procurement processes and market trends in Romania.",
    "use_cases": [
      "Analyzing trends in government procurement",
      "Comparing tender amounts across different sectors",
      "Evaluating the competitiveness of bids"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Romania public tender data",
      "Romania tenders 2007-2016",
      "government procurement Romania",
      "public tenders analysis Romania",
      "Romania auction data",
      "Romanian government tenders"
    ],
    "domain_tags": [
      "government",
      "auctions"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2007-2016",
    "geographic_scope": "Romania",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Outbrain Click Prediction",
    "description": "Click prediction based on browsing history from Outbrain",
    "category": "Advertising",
    "url": "https://www.kaggle.com/competitions/outbrain-click-prediction",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "click prediction",
      "content",
      "Kaggle"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "data science"
    ],
    "summary": "The Outbrain Click Prediction dataset contains click prediction data based on users' browsing history. It can be used to build models that predict user engagement with content, which is valuable for optimizing advertising strategies.",
    "use_cases": [
      "Predicting user clicks on content",
      "Optimizing ad placements based on user behavior",
      "Analyzing the effectiveness of content recommendations"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Outbrain Click Prediction dataset?",
      "How can I use browsing history for click prediction?",
      "What models are suitable for click prediction?",
      "Where can I find datasets for advertising analysis?",
      "What are the features in the Outbrain Click Prediction dataset?",
      "How does click prediction impact advertising effectiveness?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Natural Driving in Ohio",
    "description": "ADAS-equipped vehicles with driving behavior events",
    "category": "Transportation & Mobility",
    "url": "https://data.transportation.gov/Automobiles/Advanced-Driver-Assistance-System-ADAS-Equipped-Si/iie8-uenj/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "driving",
      "ADAS",
      "behavior",
      "government"
    ],
    "best_for": "Learning transportation & mobility analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains information on ADAS-equipped vehicles and their driving behavior events in Ohio. It can be used to analyze driving patterns and behaviors influenced by advanced driver-assistance systems.",
    "use_cases": [
      "Analyzing the impact of ADAS on driving behavior",
      "Studying government regulations on vehicle behavior",
      "Evaluating safety features of ADAS-equipped vehicles"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "ADAS driving behavior events in Ohio",
      "Natural driving dataset Ohio",
      "Driving patterns of ADAS vehicles",
      "Ohio ADAS vehicle data",
      "Behavior analysis of driving events",
      "Transportation data for ADAS vehicles"
    ],
    "domain_tags": [
      "transportation",
      "government"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Ohio",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Yelp Dataset",
    "description": "Business attributes, reviews, user data, and check-ins",
    "category": "Social & Web",
    "url": "https://www.yelp.com/dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "businesses",
      "local",
      "NLP"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Yelp Dataset contains business attributes, user reviews, and check-in data from local businesses. It can be used for sentiment analysis, recommendation systems, and understanding consumer behavior in local markets.",
    "use_cases": [
      "Sentiment analysis of user reviews",
      "Building a recommendation system for local businesses",
      "Analyzing trends in consumer behavior",
      "Comparing business performance based on reviews"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the business attributes in the Yelp Dataset?",
      "How can I analyze user reviews from Yelp?",
      "What insights can I gain from check-in data in the Yelp Dataset?",
      "How does Yelp data reflect local consumer behavior?",
      "What types of businesses are included in the Yelp Dataset?",
      "Can I use Yelp data for NLP projects?",
      "What are the common attributes of businesses in the Yelp Dataset?",
      "How do user reviews vary across different categories in Yelp?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "OpenML",
    "description": "Platform for sharing datasets, tasks, and ML code",
    "category": "Data Portals",
    "url": "https://www.openml.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "ML",
      "open science",
      "benchmarks"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "OpenML is a platform for sharing datasets, tasks, and machine learning code, facilitating collaboration and innovation in the field of machine learning. Users can access a wide range of datasets and benchmarks to enhance their research and projects.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is OpenML?",
      "How to access datasets on OpenML?",
      "What tasks can I perform using OpenML?",
      "What is the purpose of OpenML?",
      "How does OpenML support machine learning?",
      "What are the benchmarks available on OpenML?",
      "How to share datasets on OpenML?",
      "What is the community around OpenML?"
    ],
    "domain_tags": [
      "open science"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "benchmark_usage": [
      "benchmarks"
    ],
    "model_score": 0.0002
  },
  {
    "name": "FCC Spectrum Auctions",
    "description": "87+ auctions (1994-present) with round-by-round bidding data. Complete bid histories, reserve prices, winners. Auction theory empirics",
    "category": "Auctions & Marketplaces",
    "url": "https://www.fcc.gov/auctions-summary",
    "docs_url": "https://www.fcc.gov/auction/",
    "github_url": null,
    "tags": [
      "spectrum auctions",
      "FCC",
      "bidding",
      "auction theory",
      "telecommunications"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The FCC Spectrum Auctions dataset contains over 87 auctions from 1994 to the present, featuring round-by-round bidding data, complete bid histories, reserve prices, and winners. This data can be used to analyze bidding strategies and outcomes in telecommunications auctions.",
    "use_cases": [
      "Analyzing bidding strategies in telecommunications auctions",
      "Studying the impact of reserve prices on auction outcomes",
      "Evaluating the effectiveness of auction theory in real-world scenarios"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What data is available on FCC spectrum auctions?",
      "How can I analyze bidding data from FCC auctions?",
      "What are the winners of past FCC spectrum auctions?",
      "What is the history of reserve prices in FCC auctions?",
      "How does auction theory apply to FCC spectrum auctions?",
      "What insights can be gained from FCC bidding data?"
    ],
    "domain_tags": [
      "telecommunications"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1994-present",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Prosper Loan Data",
    "description": "113K P2P loans with borrower characteristics and outcomes",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/henryokam/prosper-loan-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P",
      "lending",
      "loans"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Prosper Loan Data consists of 113,000 peer-to-peer loans, providing insights into borrower characteristics and their outcomes. This dataset can be used to analyze lending patterns, borrower behavior, and loan performance.",
    "use_cases": [
      "Analyzing borrower default rates",
      "Investigating the impact of borrower characteristics on loan performance",
      "Comparing loan outcomes across different demographics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Prosper Loan Data?",
      "How can I analyze P2P loans?",
      "What borrower characteristics are available in the Prosper dataset?",
      "What outcomes can be derived from the Prosper Loan Data?",
      "Where can I find P2P lending datasets?",
      "What insights can be gained from analyzing peer-to-peer loans?",
      "How do borrower characteristics affect loan outcomes?",
      "What trends exist in P2P lending?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Retrosheet",
    "description": "Play-by-play data for MLB games from 1911-2024 including detailed event files, game logs, and transaction records",
    "category": "Sports & Athletics",
    "url": "https://www.retrosheet.org/",
    "docs_url": "https://www.retrosheet.org/datause.htm",
    "github_url": null,
    "tags": [
      "baseball",
      "play-by-play",
      "MLB",
      "game-logs",
      "historical"
    ],
    "best_for": "Granular game analysis, situational statistics, and historical baseball research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Retrosheet dataset contains play-by-play data for MLB games spanning from 1911 to 2024. It includes detailed event files, game logs, and transaction records, allowing for comprehensive analysis of baseball games and player performance over time.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Retrosheet dataset?",
      "Where can I find MLB play-by-play data?",
      "How to access historical baseball game logs?",
      "What are the transaction records in MLB?",
      "Is there a dataset for MLB events from 1911 to 2024?",
      "What detailed event files are available for baseball?",
      "How can I analyze MLB game data?",
      "What historical data is available for baseball statistics?"
    ],
    "use_cases": [
      "Analyzing player performance trends over decades",
      "Studying the impact of specific events on game outcomes",
      "Comparing game strategies across different eras",
      "Evaluating the historical significance of transactions in MLB"
    ],
    "domain_tags": [
      "sports"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1911-2024",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Criteo 1TB Click Logs",
    "description": "World's largest public ML advertising dataset with 4+ billion events, 13 integer and 26 categorical features across 24 days",
    "category": "Advertising",
    "url": "https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/",
    "docs_url": "https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/",
    "github_url": null,
    "tags": [
      "CTR prediction",
      "click logs",
      "large-scale",
      "Criteo"
    ],
    "best_for": "Training and benchmarking large-scale CTR prediction models",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "advertising",
      "machine-learning"
    ],
    "summary": "The Criteo 1TB Click Logs is the world's largest public machine learning advertising dataset, containing over 4 billion events with various features. It can be used for training models to predict click-through rates and analyze user behavior in advertising.",
    "use_cases": [
      "Click-through rate prediction",
      "User behavior analysis",
      "Ad performance evaluation"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Criteo click logs dataset",
      "public ML advertising datasets",
      "large-scale click logs",
      "CTR prediction datasets",
      "Criteo dataset for machine learning",
      "advertising datasets for research",
      "big data click logs",
      "Criteo 1TB dataset"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "24 days",
    "geographic_scope": "Global",
    "size_category": "massive",
    "model_score": 0.0002
  },
  {
    "name": "Telco Customer Churn (IBM)",
    "description": "7,043 customers from a telecommunications company with 21 features including demographics, services, account information, and churn status. Industry-standard dataset for churn prediction benchmarking.",
    "category": "MarTech & Customer Analytics",
    "url": "https://www.kaggle.com/datasets/blastchar/telco-customer-churn",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "churn",
      "classification",
      "telecom",
      "customer-analytics"
    ],
    "best_for": "Learning churn prediction, classification algorithms, and retention analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "customer-analytics"
    ],
    "summary": "This dataset contains information on 7,043 customers from a telecommunications company, including demographics, services, account information, and churn status. It is commonly used for benchmarking churn prediction models.",
    "use_cases": [
      "Predicting customer churn",
      "Analyzing factors contributing to churn",
      "Benchmarking churn prediction models"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Telco Customer Churn dataset",
      "IBM churn prediction dataset",
      "telecom customer analytics data",
      "churn classification dataset",
      "customer churn analysis dataset",
      "telecommunications churn data"
    ],
    "domain_tags": [
      "telecom"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "KDD Cup 2009 Customer Relationship Prediction",
    "description": "Orange Telecom CRM dataset with 50,000 customers and 230 anonymized features. Predict churn, appetency (propensity to buy), and up-selling. Classic benchmark for CRM analytics.",
    "category": "MarTech & Customer Analytics",
    "url": "https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data",
    "docs_url": "https://www.kdd.org/kdd-cup/view/kdd-cup-2009",
    "github_url": null,
    "tags": [
      "CRM",
      "churn",
      "uplift",
      "classification"
    ],
    "best_for": "Learning CRM analytics, multi-task learning, and handling messy real-world data",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [
      "CRM",
      "customer-analytics",
      "churn-prediction"
    ],
    "summary": "The KDD Cup 2009 Customer Relationship Prediction dataset contains information on 50,000 customers with 230 anonymized features. It is used to predict customer churn, appetency to buy, and up-selling opportunities, making it a classic benchmark for CRM analytics.",
    "use_cases": [
      "Analyzing customer churn rates",
      "Predicting customer buying behavior",
      "Developing up-selling strategies",
      "Benchmarking CRM analytics techniques"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "KDD Cup 2009 Customer Relationship Prediction dataset",
      "Orange Telecom CRM dataset download",
      "customer churn prediction dataset",
      "CRM analytics benchmark dataset",
      "KDD Cup 2009 data for analysis",
      "customer relationship management datasets",
      "predicting customer appetency dataset",
      "up-selling prediction dataset"
    ],
    "domain_tags": [
      "telecommunications",
      "marketing"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "benchmark_usage": [
      "Classic benchmark for CRM analytics"
    ],
    "model_score": 0.0002
  },
  {
    "name": "Papers With Code Datasets",
    "description": "Datasets linked to research papers, code implementations, and SOTA leaderboards",
    "category": "Dataset Aggregators",
    "url": "https://paperswithcode.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reproducibility",
      "SOTA",
      "benchmarks",
      "papers"
    ],
    "best_for": "Tracking which datasets power cutting-edge ML research with code links",
    "difficulty": "null",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Papers With Code Datasets provide a collection of datasets that are linked to research papers, code implementations, and state-of-the-art (SOTA) leaderboards. Researchers and practitioners can use these datasets to benchmark their models and ensure reproducibility in their work.",
    "use_cases": [],
    "audience": [],
    "synthetic_questions": [
      "What datasets are linked to research papers?",
      "How can I find datasets for SOTA benchmarks?",
      "Where can I access datasets for code implementations?",
      "What are the available datasets for reproducibility in research?",
      "Are there any datasets associated with specific research papers?",
      "How do I find datasets for machine learning benchmarks?",
      "What datasets are included in the Papers With Code collection?",
      "How can I explore datasets related to state-of-the-art leaderboards?"
    ],
    "domain_tags": [
      "Research"
    ],
    "data_modality": "null",
    "size_category": "medium",
    "benchmark_usage": [
      "Datasets are used for benchmarking models and ensuring reproducibility."
    ],
    "model_score": 0.0002
  },
  {
    "name": "OpenML",
    "description": "ML benchmarking platform with standardized train-test splits for reproducible comparisons",
    "category": "Dataset Aggregators",
    "url": "https://www.openml.org",
    "docs_url": "https://docs.openml.org",
    "github_url": "https://github.com/openml/openml-python",
    "tags": [
      "benchmarking",
      "reproducibility",
      "ML",
      "AutoML"
    ],
    "best_for": "Reproducible ML benchmarking with standardized experimental setups",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "OpenML is a machine learning benchmarking platform that provides standardized train-test splits for reproducible comparisons. It allows users to evaluate and compare different machine learning models effectively.",
    "use_cases": [
      "Benchmarking machine learning models",
      "Comparing performance of different algorithms",
      "Evaluating reproducibility in machine learning experiments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is OpenML?",
      "How to use OpenML for ML benchmarking?",
      "What datasets are available on OpenML?",
      "How does OpenML support reproducibility in ML?",
      "What are the features of OpenML?",
      "Can I find standardized train-test splits on OpenML?",
      "What is the purpose of OpenML?",
      "How to compare ML models using OpenML?"
    ],
    "domain_tags": [
      "technology"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "benchmark_usage": [
      "Standardized train-test splits for reproducible comparisons"
    ],
    "model_score": 0.0002
  },
  {
    "name": "Zenodo",
    "description": "CERN-operated research data repository with DOI citations, accepts all file types up to 50GB",
    "category": "Dataset Aggregators",
    "url": "https://zenodo.org",
    "docs_url": "https://help.zenodo.org",
    "github_url": null,
    "tags": [
      "DOI",
      "CERN",
      "open science",
      "preservation"
    ],
    "best_for": "Publishing and preserving research data with persistent DOI citations",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Zenodo is a research data repository operated by CERN that allows researchers to upload and share their data with DOI citations. It supports all file types up to 50GB, making it a versatile platform for open science and data preservation.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Zenodo?",
      "How to upload data to Zenodo?",
      "What file types are accepted by Zenodo?",
      "How does Zenodo support open science?",
      "What is a DOI citation?",
      "What is the maximum file size for Zenodo uploads?",
      "How does Zenodo ensure data preservation?",
      "Who operates Zenodo?"
    ],
    "domain_tags": [
      "open science",
      "data preservation"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Alibaba Personalized Re-Ranking",
    "description": "Mobile shopping user click data on recommended items",
    "category": "E-Commerce",
    "url": "http://yongfeng.me/dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "re-ranking",
      "personalization",
      "recommendations"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "This dataset contains mobile shopping user click data on recommended items, allowing for analysis of user behavior and preferences in e-commerce. It can be used to improve recommendation systems and enhance personalization strategies.",
    "use_cases": [
      "Improving recommendation algorithms",
      "Analyzing user engagement with personalized content",
      "Studying the impact of re-ranking on sales"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Alibaba Personalized Re-Ranking dataset?",
      "How can I analyze mobile shopping user click data?",
      "What are the applications of recommendation systems in e-commerce?",
      "How does personalization affect user engagement?",
      "Where can I find datasets on user click behavior?",
      "What insights can be gained from re-ranking algorithms?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Walmart (M5)",
    "description": "Hierarchical sales data for 3,049 products across 10 stores",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/m5-forecasting-accuracy",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "forecasting",
      "hierarchical",
      "Walmart",
      "M5 competition"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "forecasting",
      "sales-analysis",
      "retail"
    ],
    "summary": "The Walmart (M5) dataset contains hierarchical sales data for 3,049 products across 10 stores, making it suitable for forecasting and sales analysis. Users can leverage this data to develop predictive models and analyze sales trends.",
    "use_cases": [
      "Sales forecasting for retail products",
      "Analyzing sales trends across multiple stores",
      "Developing predictive models for inventory management"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Walmart M5 dataset?",
      "How can I access the hierarchical sales data for Walmart?",
      "What are the applications of the Walmart M5 dataset?",
      "Where can I find forecasting datasets for retail?",
      "What products are included in the Walmart M5 dataset?",
      "How many stores are involved in the Walmart M5 dataset?",
      "What tags are associated with the Walmart M5 dataset?",
      "What type of analysis can be performed on the Walmart M5 dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Baidu AI Datasets",
    "description": "AI, NLP, computer vision, and autonomous driving datasets",
    "category": "Data Portals",
    "url": "https://aistudio.baidu.com/datasetoverview",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Baidu",
      "NLP",
      "computer vision",
      "autonomous"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Baidu AI Datasets include a variety of datasets focused on artificial intelligence applications, such as natural language processing, computer vision, and autonomous driving. Researchers and developers can utilize these datasets to train models, conduct experiments, and advance their understanding of AI technologies.",
    "use_cases": [],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Baidu AI Datasets?",
      "Where can I find datasets for NLP from Baidu?",
      "Are there computer vision datasets available from Baidu?",
      "What datasets does Baidu offer for autonomous driving?",
      "How to access Baidu AI Datasets?",
      "What types of AI datasets does Baidu provide?"
    ],
    "domain_tags": [
      "AI",
      "NLP",
      "computer vision",
      "autonomous driving"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Redfin Housing Market Data",
    "description": "Downloadable housing market data: home prices, sales, inventory, listings by metro/city/zip. Updated weekly from MLS",
    "category": "Real Estate",
    "url": "https://www.redfin.com/news/data-center/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "housing prices",
      "large-scale",
      "real-world",
      "time series"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "real estate",
      "housing market",
      "data analysis"
    ],
    "summary": "The Redfin Housing Market Data provides downloadable information on home prices, sales, inventory, and listings across various metro areas, cities, and zip codes. This dataset can be used for analyzing trends in the housing market and making informed decisions based on real estate data.",
    "use_cases": [
      "Analyzing trends in home prices over time.",
      "Comparing inventory levels across different cities.",
      "Evaluating the impact of listings on sales in a specific metro area."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the latest Redfin housing market data?",
      "How can I access Redfin housing prices by metro?",
      "Where can I find downloadable housing market data?",
      "What are the trends in home sales according to Redfin?",
      "How is the inventory of homes changing in my area?",
      "What listings are available in my zip code from Redfin?",
      "How often is the Redfin housing market data updated?",
      "What types of data does Redfin provide for real estate analysis?"
    ],
    "domain_tags": [
      "real estate"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "BLS JOLTS",
    "description": "Monthly job openings, hires, separations by industry since 2000. Bureau of Labor Statistics time series",
    "category": "Labor Markets",
    "url": "https://www.bls.gov/jlt/data.htm",
    "docs_url": "https://www.bls.gov/jlt/jltover.htm",
    "github_url": null,
    "tags": [
      "jobs",
      "labor",
      "openings",
      "hires",
      "BLS"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The BLS JOLTS dataset provides monthly statistics on job openings, hires, and separations across various industries since the year 2000. This data can be used to analyze labor market trends and employment dynamics over time.",
    "use_cases": [
      "Analyzing trends in job openings over time",
      "Comparing hires and separations across industries",
      "Understanding labor market dynamics",
      "Evaluating the impact of economic policies on employment"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the monthly job openings by industry?",
      "How many hires were made in the last year?",
      "What are the trends in job separations since 2000?",
      "How does the job market vary by industry?",
      "What insights can be drawn from BLS JOLTS data?",
      "How to analyze labor market trends using JOLTS data?",
      "What is the significance of job openings in economic analysis?",
      "How do hires and separations correlate in different industries?"
    ],
    "domain_tags": [
      "labor markets"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "2000-present",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "ETHOS Hate Speech",
    "description": "998 online comments labeled for hate speech detection in English. Binary and multi-label annotations",
    "category": "Content Moderation",
    "url": "https://zenodo.org/records/4459923",
    "docs_url": null,
    "github_url": "https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset",
    "tags": [
      "hate speech",
      "NLP",
      "annotations",
      "English"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The ETHOS Hate Speech dataset contains 998 online comments that have been labeled for hate speech detection in English. It can be used for training and evaluating models in natural language processing focused on identifying hate speech.",
    "use_cases": [
      "Training hate speech detection models",
      "Evaluating NLP algorithms for hate speech classification"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "ETHOS Hate Speech dataset",
      "hate speech detection dataset",
      "NLP hate speech annotations",
      "online comments labeled for hate speech",
      "dataset for hate speech analysis",
      "English hate speech dataset"
    ],
    "domain_tags": [
      "content moderation"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Google Dataset Search",
    "description": "Universal search engine for datasets across the web. Meta-tool for discovering research data",
    "category": "Data Portals",
    "url": "https://datasetsearch.research.google.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search engine",
      "datasets",
      "discovery",
      "Google"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Google Dataset Search is a universal search engine designed to help users discover research data across the web. It serves as a meta-tool for finding datasets relevant to various fields of study.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available on Google Dataset Search?",
      "How can I find datasets related to climate change?",
      "Where can I search for economic datasets?",
      "What are the top datasets in healthcare on Google Dataset Search?",
      "How do I use Google Dataset Search to find machine learning datasets?",
      "What datasets are available for social science research?"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "MIMIC-IV",
    "description": "Gold standard for freely accessible critical care EHR data from MIT/Beth Israel. Contains 364,627 unique patients, 546,028 hospitalizations, and 94,458 ICU stays (2008-2022). Includes demographics, vitals, labs, medications, procedures, and clinical notes.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://mimic.mit.edu/",
    "source": "MIT Laboratory for Computational Physiology",
    "type": "EHR Database",
    "access": "Free (PhysioNet credentialing required)",
    "format": "PostgreSQL/CSV",
    "tags": [
      "Healthcare",
      "EHR",
      "ICU",
      "Clinical",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "MIMIC-IV is a comprehensive dataset that provides critical care electronic health record data, including demographics, vitals, labs, medications, procedures, and clinical notes from a large cohort of patients. Researchers and analysts can utilize this dataset to study various aspects of critical care, patient outcomes, and healthcare delivery.",
    "use_cases": [
      "Analyzing patient outcomes in critical care settings",
      "Studying the impact of different medications on ICU stays",
      "Examining trends in vital signs among critically ill patients",
      "Investigating the relationship between demographics and hospitalizations"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the MIMIC-IV dataset?",
      "Where can I find MIMIC-IV critical care data?",
      "How many patients are included in the MIMIC-IV dataset?",
      "What types of data are available in MIMIC-IV?",
      "Is MIMIC-IV freely accessible?",
      "What years does the MIMIC-IV dataset cover?",
      "What are the demographics included in MIMIC-IV?",
      "How can I use MIMIC-IV for healthcare research?"
    ],
    "update_frequency": "Periodic releases",
    "geographic_coverage": "Boston, MA (single hospital)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "mixed",
    "temporal_coverage": "2008-2022",
    "size_category": "large",
    "model_score": 0.0002
  },
  {
    "name": "PJM Data Miner",
    "description": "Comprehensive market data from PJM, the largest U.S. regional transmission organization",
    "category": "Energy",
    "url": "https://dataminer2.pjm.com/",
    "docs_url": "https://www.pjm.com/markets-and-operations/data-dictionary",
    "github_url": null,
    "tags": [
      "PJM",
      "Eastern US",
      "prices",
      "wholesale",
      "capacity"
    ],
    "best_for": "Analyzing the largest U.S. electricity market covering 13 states",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The PJM Data Miner provides comprehensive market data from PJM, the largest U.S. regional transmission organization. Users can analyze wholesale prices and capacity data to understand market dynamics in the energy sector.",
    "use_cases": [
      "Analyzing wholesale energy prices",
      "Evaluating capacity trends in the energy market"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is PJM Data Miner?",
      "How to access PJM market data?",
      "What data does PJM provide?",
      "PJM wholesale prices analysis",
      "Capacity data from PJM",
      "Understanding PJM market trends",
      "PJM energy data resources",
      "PJM data for research"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1999-present",
    "geographic_scope": "Eastern US",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Criteo Uplift Prediction Dataset",
    "description": "~25 million rows with treatment indicators for benchmarking Individual Treatment Effect (ITE) estimation in advertising",
    "category": "Causal Inference",
    "url": "https://ailab.criteo.com/criteo-uplift-prediction-dataset/",
    "docs_url": "https://ailab.criteo.com/criteo-uplift-prediction-dataset/",
    "github_url": null,
    "tags": [
      "uplift modeling",
      "causal inference",
      "ITE",
      "Criteo"
    ],
    "best_for": "Benchmarking uplift and treatment effect models for advertising",
    "difficulty": "intermediate",
    "prerequisites": [
      "pandas-dataframes",
      "regression-analysis"
    ],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Criteo Uplift Prediction Dataset contains approximately 25 million rows with treatment indicators, which can be used for benchmarking Individual Treatment Effect (ITE) estimation in advertising. This dataset is valuable for researchers and practitioners looking to analyze the impact of advertising treatments on consumer behavior.",
    "use_cases": [
      "Estimating the impact of advertising on consumer purchases",
      "Benchmarking different uplift modeling techniques",
      "Analyzing treatment effects in digital marketing",
      "Evaluating the effectiveness of advertising strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Criteo uplift prediction dataset",
      "Individual Treatment Effect estimation dataset",
      "uplift modeling datasets",
      "advertising treatment effect data",
      "benchmark datasets for causal inference",
      "Criteo advertising data",
      "large datasets for regression analysis",
      "datasets for consumer behavior analysis"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "30 days",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "TalkingData AdTracking Fraud Detection",
    "description": "200 million clicks with 0.25% positive fraud class for mobile ad fraud detection benchmarking",
    "category": "Fraud Detection",
    "url": "https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data",
    "docs_url": "https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection",
    "github_url": null,
    "tags": [
      "fraud detection",
      "mobile",
      "imbalanced",
      "TalkingData"
    ],
    "best_for": "Developing and benchmarking ad fraud detection models",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The TalkingData AdTracking Fraud Detection dataset contains 200 million clicks, with a 0.25% positive fraud class, making it suitable for benchmarking mobile ad fraud detection. It can be used to analyze patterns of fraudulent behavior in mobile advertising.",
    "use_cases": [
      "Benchmarking mobile ad fraud detection algorithms",
      "Analyzing fraud patterns in mobile advertising",
      "Developing machine learning models for fraud detection"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the TalkingData AdTracking Fraud Detection dataset?",
      "How can I use the TalkingData dataset for mobile ad fraud detection?",
      "What are the characteristics of the fraud class in the TalkingData dataset?",
      "Where can I find the TalkingData AdTracking Fraud Detection dataset?",
      "What is the size of the TalkingData AdTracking Fraud Detection dataset?",
      "How does the TalkingData dataset help in benchmarking fraud detection?",
      "What types of analyses can be performed with the TalkingData dataset?",
      "What tags are associated with the TalkingData AdTracking Fraud Detection dataset?"
    ],
    "domain_tags": [
      "advertising",
      "technology"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "4 days",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Google Dataset Search",
    "description": "Search engine indexing 45M+ datasets from 13,000+ websites using schema.org metadata",
    "category": "Dataset Aggregators",
    "url": "https://datasetsearch.research.google.com",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search",
      "discovery",
      "meta-search",
      "aggregator"
    ],
    "best_for": "Discovering datasets across government portals, research institutions, and commercial providers",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Google Dataset Search is a search engine that indexes over 45 million datasets from more than 13,000 websites using schema.org metadata. It allows users to discover and access a wide variety of datasets for research and analysis.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available on Google Dataset Search?",
      "How can I find datasets related to climate change?",
      "What types of datasets can I discover using Google Dataset Search?",
      "Where can I search for datasets on economic indicators?",
      "How do I use Google Dataset Search to find health-related datasets?",
      "What is the best way to use Google Dataset Search for academic research?",
      "Can I find datasets on social media trends using Google Dataset Search?",
      "What are the most popular datasets indexed by Google Dataset Search?"
    ],
    "domain_tags": [
      "General"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Kaggle Datasets",
    "description": "50,000+ public datasets with free GPU notebooks and active ML community of 23M members",
    "category": "Dataset Aggregators",
    "url": "https://www.kaggle.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "ML",
      "competitions",
      "notebooks",
      "community"
    ],
    "best_for": "Applied machine learning with financial, economic, and pricing datasets",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Kaggle Datasets is a collection of over 50,000 public datasets that provides users with free GPU notebooks and access to an active machine learning community of 23 million members. Users can explore, analyze, and build machine learning models using these datasets.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the best datasets on Kaggle?",
      "How to find public datasets for machine learning?",
      "What datasets are available for data analysis?",
      "Where can I find free GPU notebooks?",
      "How to participate in Kaggle competitions?",
      "What is the Kaggle community like?",
      "How to use Kaggle datasets for projects?",
      "What are the popular datasets on Kaggle?"
    ],
    "domain_tags": [
      "ML",
      "Data Science"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Amazon Last Mile",
    "description": "9,184 historical routes across 5 US metro areas",
    "category": "Logistics & Supply Chain",
    "url": "https://registry.opendata.aws/amazon-last-mile-challenges/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "routing",
      "last-mile",
      "Amazon",
      "AWS"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "logistics",
      "supply-chain",
      "routing"
    ],
    "summary": "The Amazon Last Mile dataset contains 9,184 historical routes across 5 US metro areas, providing insights into last-mile delivery logistics. Researchers and analysts can use this data to optimize delivery routes and improve supply chain efficiency.",
    "use_cases": [
      "Optimizing delivery routes for efficiency",
      "Analyzing traffic patterns in urban areas",
      "Studying the impact of delivery logistics on customer satisfaction"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What are the historical routes for Amazon last-mile delivery?",
      "How can I analyze last-mile logistics in US metro areas?",
      "What data is available on Amazon delivery routes?",
      "How does routing affect supply chain efficiency?",
      "What insights can be gained from Amazon's last-mile data?",
      "How many last-mile routes does Amazon operate in US metro areas?"
    ],
    "domain_tags": [
      "logistics",
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "US metro areas",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Rakuten Data Release",
    "description": "E-commerce, advertising, and multimedia datasets from Rakuten",
    "category": "Data Portals",
    "url": "https://rit.rakuten.com/data_release/#access",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Rakuten",
      "e-commerce",
      "multimedia"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "advertising",
      "multimedia"
    ],
    "summary": "The Rakuten Data Release includes datasets related to e-commerce, advertising, and multimedia. This data can be used for various analyses in consumer behavior, pricing strategies, and advertising effectiveness.",
    "use_cases": [
      "Analyze consumer behavior in e-commerce",
      "Evaluate advertising effectiveness",
      "Study multimedia content engagement"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Rakuten e-commerce datasets",
      "Rakuten advertising data",
      "Rakuten multimedia datasets",
      "e-commerce datasets from Rakuten",
      "Rakuten data for analysis",
      "Rakuten data release information"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "Marketing Science Databases",
    "description": "INFORMS conference with data-focused opportunities",
    "category": "Data Portals",
    "url": "https://pubsonline.informs.org/page/mksc/online-databases",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "marketing",
      "INFORMS",
      "databases"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "marketing"
    ],
    "summary": "The Marketing Science Databases provide data-focused opportunities presented at the INFORMS conference. Users can leverage this data for various marketing analyses and research.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Marketing Science Databases?",
      "How can I access INFORMS marketing data?",
      "What opportunities are available at the INFORMS conference?",
      "What types of marketing data are included in the databases?",
      "How to use marketing science databases for research?",
      "What are the benefits of using INFORMS databases?"
    ],
    "domain_tags": [
      "marketing"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "NATO Defence Expenditure",
    "description": "Standardized defense spending data for all NATO members enabling alliance burden-sharing analysis and 2% GDP target tracking",
    "category": "Defense Economics",
    "url": "https://www.nato.int/cps/en/natohq/topics_49198.htm",
    "docs_url": "https://www.nato.int/nato_static_fl2014/assets/pdf/2024/3/pdf/240314-def-exp-2023-en.pdf",
    "github_url": null,
    "tags": [
      "NATO",
      "alliance",
      "burden-sharing",
      "Europe"
    ],
    "best_for": "Analyzing NATO burden-sharing and 2% GDP spending targets",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NATO Defence Expenditure dataset provides standardized defense spending data for all NATO members. It enables analysis of alliance burden-sharing and tracking of the 2% GDP target.",
    "use_cases": [
      "Analyzing defense spending trends among NATO countries",
      "Evaluating compliance with the NATO 2% GDP target",
      "Comparing defense expenditures across different NATO members",
      "Assessing the impact of defense spending on alliance cohesion"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NATO Defence Expenditure dataset?",
      "How can I analyze NATO defense spending data?",
      "What is the 2% GDP target for NATO members?",
      "Where can I find standardized defense spending data for NATO?",
      "What are the implications of NATO burden-sharing?",
      "How does NATO defense expenditure vary by country?",
      "What trends exist in NATO defense spending over time?",
      "How can I visualize NATO defense expenditure data?"
    ],
    "domain_tags": [
      "Defense Economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1949-present",
    "geographic_scope": "Europe",
    "size_category": "medium",
    "model_score": 0.0002
  },
  {
    "name": "FI-2010 Limit Order Book",
    "description": "4.3M samples of NASDAQ Nordic limit order book data. 10 depth levels, 5 stocks, normalized features. Benchmark for price prediction",
    "category": "Financial Services",
    "url": "https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "order book",
      "limit orders",
      "NASDAQ",
      "price prediction",
      "benchmark"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "financial services",
      "data analysis",
      "machine learning"
    ],
    "summary": "The FI-2010 Limit Order Book dataset contains 4.3 million samples of NASDAQ Nordic limit order book data, featuring 10 depth levels and 5 stocks with normalized features. It serves as a benchmark for price prediction tasks in financial analysis.",
    "use_cases": [
      "Price prediction modeling using limit order book data",
      "Analyzing market depth and order flow",
      "Benchmarking trading algorithms",
      "Studying the impact of order book dynamics on stock prices"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the FI-2010 Limit Order Book dataset?",
      "How can I use NASDAQ limit order book data for price prediction?",
      "Where can I find limit order book datasets?",
      "What features are included in the FI-2010 Limit Order Book?",
      "What is the significance of depth levels in limit order books?",
      "How many samples does the FI-2010 Limit Order Book dataset contain?",
      "What stocks are included in the FI-2010 Limit Order Book dataset?",
      "What benchmarks exist for price prediction in financial datasets?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "benchmark_usage": [
      "Benchmark for price prediction"
    ],
    "model_score": 0.0001
  },
  {
    "name": "Stack Overflow Developer Survey",
    "description": "49K+ annual responses with salaries, tech adoption, and developer analytics",
    "category": "Labor Markets",
    "url": "https://survey.stackoverflow.co/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "developers",
      "salaries",
      "survey",
      "tech"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Stack Overflow Developer Survey is a collection of over 49,000 annual responses that provide insights into salaries, technology adoption, and developer analytics. This dataset can be used to analyze trends in the tech industry and understand the factors influencing developer compensation.",
    "use_cases": [
      "Analyzing salary trends among different developer roles",
      "Investigating the impact of technology adoption on job market dynamics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the average salaries for developers?",
      "How does tech adoption vary by region?",
      "What technologies are most popular among developers?",
      "What factors influence developer salaries?",
      "How do developer demographics affect job satisfaction?",
      "What trends can be observed in developer analytics over the years?"
    ],
    "domain_tags": [
      "labor markets"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Tesco Grocery 1.0",
    "description": "Grocery purchases from Tesco stores via loyalty cards",
    "category": "Grocery & Supermarkets",
    "url": "https://figshare.com/collections/Tesco_Grocery_1_0/4769354",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "loyalty cards",
      "UK",
      "Tesco"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Tesco Grocery 1.0 dataset contains grocery purchase data collected from Tesco stores through loyalty cards. This dataset can be used to analyze consumer purchasing patterns and loyalty program effectiveness.",
    "use_cases": [
      "Analyzing customer loyalty trends",
      "Studying purchasing behavior in grocery shopping"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Tesco grocery purchase data",
      "Tesco loyalty card transactions",
      "UK grocery shopping data",
      "Tesco supermarket analytics",
      "grocery purchases dataset",
      "consumer behavior in grocery shopping"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "UK",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Expedia Hotel",
    "description": "Hotel booking and search data from Expedia",
    "category": "Travel & Hospitality",
    "url": "https://www.kaggle.com/datasets/vijeetnigam26/expedia-hotel",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hotels",
      "bookings",
      "travel search"
    ],
    "best_for": "Learning travel & hospitality analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Expedia Hotel dataset contains hotel booking and search data from Expedia, allowing users to analyze trends in travel and hospitality. It can be used for various analyses, including understanding consumer behavior and pricing strategies in the hotel industry.",
    "use_cases": [
      "Analyzing consumer booking patterns over time",
      "Comparing hotel prices across different regions",
      "Studying the impact of seasonality on hotel bookings"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Expedia Hotel dataset?",
      "Where can I find hotel booking data from Expedia?",
      "How to access Expedia search data for analysis?",
      "What insights can be derived from Expedia Hotel dataset?",
      "Is there a dataset for hotel bookings on Expedia?",
      "What are the trends in hotel bookings from Expedia data?"
    ],
    "domain_tags": [
      "travel",
      "hospitality"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Alibaba Cloud Theme",
    "description": "Themed dataset related to Alibaba Cloud services",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/9716",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cloud",
      "Alibaba",
      "themed"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce"
    ],
    "summary": "The Alibaba Cloud Theme dataset contains themed data related to Alibaba Cloud services, which can be utilized for various analyses in the e-commerce sector. It provides insights into cloud services and their applications in online retail.",
    "use_cases": [
      "Analyzing the impact of cloud services on e-commerce sales",
      "Exploring consumer behavior in cloud-based retail environments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Alibaba Cloud Theme dataset?",
      "How can I access the Alibaba Cloud services data?",
      "What insights can be derived from the Alibaba Cloud Theme dataset?",
      "What are the applications of Alibaba Cloud in e-commerce?",
      "Where can I find themed datasets related to Alibaba Cloud?",
      "What are the key features of the Alibaba Cloud Theme dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Mexican Grocery",
    "description": "Data from a Mexican grocery store",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/martinezjosegpe/grocery-store",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Mexico",
      "retail"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains data from a Mexican grocery store, providing insights into grocery shopping patterns and consumer preferences in Mexico. It can be used for analyzing retail trends and consumer behavior in the grocery sector.",
    "use_cases": [
      "Analyzing consumer preferences in grocery shopping",
      "Studying pricing strategies in the retail sector"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Mexican grocery store data",
      "grocery shopping data Mexico",
      "retail data from Mexican supermarkets",
      "consumer behavior in Mexican grocery stores",
      "grocery sales data Mexico",
      "data on grocery retail in Mexico"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Mexico",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Ukraine Procurement (ProZorro)",
    "description": "Public procurement data from ProZorro system",
    "category": "Auctions & Marketplaces",
    "url": "https://www.kaggle.com/datasets/oleksastepaniuk/prozorro-public-procurement-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "procurement",
      "government",
      "Ukraine"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "procurement",
      "government",
      "data-analysis"
    ],
    "summary": "This dataset contains public procurement data from the ProZorro system in Ukraine. It can be used to analyze government spending, procurement trends, and market dynamics.",
    "use_cases": [
      "Analyze government spending patterns",
      "Identify procurement trends in Ukraine",
      "Evaluate market competition in public contracts"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the ProZorro procurement data?",
      "How to analyze Ukraine procurement data?",
      "What trends can be found in ProZorro data?",
      "How does government procurement work in Ukraine?",
      "What are the implications of procurement data analysis?",
      "Where can I find public procurement data for Ukraine?"
    ],
    "domain_tags": [
      "government",
      "public sector"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Ukraine",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Netflix Prize",
    "description": "100M+ anonymous movie ratings from 480k users",
    "category": "Entertainment & Media",
    "url": "https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "movies",
      "ratings",
      "recommendations",
      "classic"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "The Netflix Prize dataset consists of over 100 million anonymous movie ratings provided by 480,000 users. This dataset can be used to analyze user preferences, build recommendation systems, and study trends in movie ratings.",
    "use_cases": [
      "Building a movie recommendation system",
      "Analyzing user rating patterns",
      "Studying the impact of ratings on movie success"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Netflix Prize dataset?",
      "How can I access the Netflix Prize data?",
      "What are the key features of the Netflix Prize dataset?",
      "What types of analyses can be performed on movie ratings?",
      "How do I use the Netflix Prize dataset for recommendations?",
      "What insights can be gained from the Netflix Prize ratings?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "YouTube Engagement Dataset",
    "description": "5M videos with watch percentage, engagement maps, Freebase topic labels. Video-level engagement metrics for content research",
    "category": "Entertainment & Media",
    "url": "https://github.com/avalanchesiqi/youtube-engagement",
    "docs_url": null,
    "github_url": "https://github.com/avalanchesiqi/youtube-engagement",
    "tags": [
      "YouTube",
      "engagement",
      "video",
      "watch time",
      "topics"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The YouTube Engagement Dataset contains video-level engagement metrics for 5 million videos, including watch percentage and engagement maps. This dataset can be used for content research and analysis of viewer engagement on YouTube.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the YouTube Engagement Dataset?",
      "How can I analyze video engagement metrics?",
      "What are the engagement maps in the YouTube Engagement Dataset?",
      "Where can I find data on YouTube watch percentage?",
      "What topics are covered in the YouTube Engagement Dataset?",
      "How many videos are included in the YouTube Engagement Dataset?",
      "What metrics are available in the YouTube Engagement Dataset?",
      "How to use the YouTube Engagement Dataset for content research?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Revelio Labs COSMOS",
    "description": "4.1B job postings from 6.6M companies. Deduplicated, parsed, enriched workforce data (commercial/academic partnerships)",
    "category": "Labor Markets",
    "url": "https://www.reveliolabs.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "job postings",
      "workforce",
      "companies",
      "labor",
      "commercial"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Revelio Labs COSMOS is a dataset containing 4.1 billion job postings from 6.6 million companies. It provides deduplicated, parsed, and enriched workforce data that can be utilized for various labor market analyses.",
    "use_cases": [],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Revelio Labs COSMOS dataset?",
      "How many job postings are included in the Revelio Labs COSMOS dataset?",
      "What type of companies are represented in the Revelio Labs COSMOS dataset?",
      "What insights can be gained from analyzing the Revelio Labs COSMOS dataset?",
      "What is the purpose of the Revelio Labs COSMOS dataset?",
      "How is the workforce data in the Revelio Labs COSMOS dataset enriched?",
      "What are the commercial and academic partnerships related to the Revelio Labs COSMOS dataset?",
      "What labor market trends can be analyzed using the Revelio Labs COSMOS dataset?"
    ],
    "domain_tags": [
      "labor"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Alibaba Ads Dataset",
    "description": "Advertising dataset from Alibaba for ad targeting and prediction",
    "category": "Advertising",
    "url": "https://tianchi.aliyun.com/dataset/148347",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "advertising",
      "targeting",
      "Alibaba"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "advertising"
    ],
    "summary": "The Alibaba Ads Dataset is an advertising dataset that provides insights for ad targeting and prediction. It can be used to analyze consumer behavior and optimize advertising strategies.",
    "use_cases": [
      "Ad targeting optimization",
      "Predictive modeling for ad performance"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Alibaba Ads Dataset?",
      "How can I use the Alibaba Ads Dataset for ad targeting?",
      "What insights can be gained from the Alibaba Ads Dataset?",
      "Where can I find the Alibaba Ads Dataset?",
      "What are the applications of the Alibaba Ads Dataset?",
      "Is the Alibaba Ads Dataset suitable for beginners?",
      "What tools can be used to analyze the Alibaba Ads Dataset?",
      "What type of data is included in the Alibaba Ads Dataset?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Hashed Multimodal Banking",
    "description": "Banking transactions and product purchases with hashed identifiers",
    "category": "Financial Services",
    "url": "https://github.com/dzhambo/mbd",
    "docs_url": null,
    "github_url": "https://github.com/dzhambo/mbd",
    "tags": [
      "banking",
      "transactions",
      "privacy-preserving"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains banking transactions and product purchases that are anonymized using hashed identifiers, ensuring privacy. It can be used to analyze consumer behavior and transaction patterns while maintaining confidentiality.",
    "use_cases": [
      "Analyzing consumer spending patterns while preserving privacy",
      "Studying the impact of financial products on transaction behavior",
      "Evaluating transaction trends in a privacy-preserving manner"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are hashed identifiers in banking transactions?",
      "How can I analyze privacy-preserving banking data?",
      "What insights can be gained from multimodal banking transactions?",
      "Where can I find datasets on banking transactions?",
      "What are the benefits of using hashed identifiers in financial data?",
      "How to conduct analysis on product purchases in banking?",
      "What tools are needed for analyzing banking transaction data?",
      "What are the privacy implications of banking data analysis?"
    ],
    "domain_tags": [
      "financial services"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Dressipi Fashion (RecSys 2022)",
    "description": "Session interactions and item features from styling service",
    "category": "Fashion & Apparel",
    "url": "http://www.recsyschallenge.com/2022/dataset.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "RecSys",
      "styling",
      "sessions"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Dressipi Fashion dataset contains session interactions and item features from a styling service. It can be used to analyze consumer behavior in fashion and improve recommendation systems.",
    "use_cases": [
      "Analyzing consumer preferences in fashion",
      "Improving recommendation algorithms",
      "Studying session interactions for user engagement",
      "Evaluating item features for styling services"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Dressipi Fashion dataset?",
      "How can I analyze session interactions in fashion?",
      "What features are included in the Dressipi Fashion dataset?",
      "How does the Dressipi dataset help in styling recommendations?",
      "What insights can be derived from fashion session data?",
      "Where can I find the Dressipi Fashion dataset?"
    ],
    "domain_tags": [
      "fashion"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "German Used Cars",
    "description": "Used car listings or sales in Germany",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/gogotchuri/myautogecardetails",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "used cars",
      "Germany",
      "listings"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "automotive",
      "e-commerce"
    ],
    "summary": "This dataset contains listings or sales of used cars in Germany. It can be used to analyze trends in the automotive market, consumer preferences, and pricing strategies.",
    "use_cases": [
      "Analyze pricing trends for used cars",
      "Explore consumer preferences in the automotive sector"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "used cars listings in Germany",
      "German used car sales data",
      "automotive market trends Germany",
      "analyze used car prices Germany",
      "consumer behavior in used car market",
      "Germany used car statistics"
    ],
    "domain_tags": [
      "automotive"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Germany",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Indian Automobiles (Telangana)",
    "description": "Vehicle sales data for Telangana, India (2023)",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/zubairatha/revving-up-telangana-vehicle-sales-2023",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "vehicles",
      "India",
      "regional sales"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains vehicle sales data specifically for Telangana, India in 2023. It can be used to analyze trends in automotive sales and understand regional market dynamics.",
    "use_cases": [
      "Analyzing the impact of economic factors on vehicle sales in Telangana.",
      "Comparing vehicle sales data with other states in India.",
      "Identifying trends in consumer preferences for different vehicle types.",
      "Forecasting future vehicle sales based on historical data."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the vehicle sales trends in Telangana for 2023?",
      "How do vehicle sales in Telangana compare to other regions in India?",
      "What types of vehicles are most popular in Telangana?",
      "What factors influence vehicle sales in Telangana?",
      "How has the automotive market changed in Telangana in 2023?",
      "What is the growth rate of vehicle sales in Telangana?",
      "What demographics are purchasing vehicles in Telangana?",
      "What are the sales figures for electric vehicles in Telangana?"
    ],
    "domain_tags": [
      "automotive"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2023",
    "geographic_scope": "Telangana, India",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Spotify Music Streaming Sessions (MSSD)",
    "description": "150M+ listening sessions with skips, track features, and playlist context. The largest public music streaming behavior dataset",
    "category": "Entertainment & Media",
    "url": "https://paperswithcode.com/dataset/mssd",
    "docs_url": "https://arxiv.org/abs/1901.09851",
    "github_url": null,
    "tags": [
      "Spotify",
      "streaming",
      "sessions",
      "skips",
      "large-scale"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior"
    ],
    "summary": "The Spotify Music Streaming Sessions (MSSD) dataset contains over 150 million listening sessions, including data on skips, track features, and playlist context. This dataset allows for in-depth analysis of music streaming behavior and user preferences.",
    "use_cases": [
      "Analyzing user engagement with music tracks",
      "Studying the impact of playlist context on listening behavior",
      "Exploring trends in music streaming over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Spotify Music Streaming Sessions dataset?",
      "How can I analyze music streaming behavior with MSSD?",
      "What features are included in the Spotify MSSD?",
      "Where can I find large-scale music streaming datasets?",
      "What insights can be derived from Spotify listening sessions?",
      "How to access the Spotify Music Streaming Sessions dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "RecSys Datasets Collection",
    "description": "Datasets from ACM Recommender Systems challenges",
    "category": "Data Portals",
    "url": "https://github.com/RUCAIBox/RecSysDatasets",
    "docs_url": null,
    "github_url": "https://github.com/RUCAIBox/RecSysDatasets",
    "tags": [
      "RecSys",
      "recommendations",
      "ACM"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "recommendations"
    ],
    "summary": "The RecSys Datasets Collection includes datasets from ACM Recommender Systems challenges, providing a rich resource for analyzing recommendation algorithms. Researchers and practitioners can use this data to develop and test new recommendation techniques.",
    "use_cases": [
      "Testing recommendation algorithms",
      "Analyzing consumer behavior in recommendations",
      "Developing new recommendation strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available in the RecSys Datasets Collection?",
      "How can I access ACM Recommender Systems challenge datasets?",
      "What types of recommendation data can I find on tech-econ.org?",
      "Are there datasets for testing recommendation algorithms?",
      "What are the challenges associated with RecSys datasets?",
      "Where can I find datasets for recommender systems research?"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "USASpending Federal Awards",
    "description": "All federal contracts, grants, loans since 2001. 400+ variables, $50T+ in awards. Government procurement analytics",
    "category": "Data Portals",
    "url": "https://www.usaspending.gov/download_center/award_data_archive",
    "docs_url": "https://www.usaspending.gov/data-dictionary",
    "github_url": null,
    "tags": [
      "government",
      "procurement",
      "contracts",
      "grants",
      "federal spending"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The USASpending Federal Awards dataset contains comprehensive information on all federal contracts, grants, and loans issued since 2001. With over 400 variables and more than $50 trillion in awards, this dataset is valuable for government procurement analytics and understanding federal spending patterns.",
    "use_cases": [
      "Analyzing trends in federal spending over time",
      "Comparing federal contracts across different agencies",
      "Evaluating the impact of federal grants on local economies"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the federal contracts awarded since 2001?",
      "How much funding has been allocated in federal grants?",
      "What variables are included in the USASpending dataset?",
      "Where can I find information on federal loans?",
      "What is the total amount of federal spending in the US?",
      "How to analyze government procurement data?",
      "What are the trends in federal awards over the years?",
      "How can I access the USASpending Federal Awards dataset?"
    ],
    "domain_tags": [
      "government",
      "procurement"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2001-2023",
    "geographic_scope": "United States",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "EU TED Procurement",
    "description": "800K+ procurement notices annually. All EU public contracts above thresholds. Structured XML since 2006. Cross-country procurement research",
    "category": "Auctions & Marketplaces",
    "url": "https://ted.europa.eu/TED/browse/browseByMap.do",
    "docs_url": "https://simap.ted.europa.eu/web/simap/standard-forms-for-public-procurement",
    "github_url": null,
    "tags": [
      "EU",
      "procurement",
      "tenders",
      "government",
      "cross-country"
    ],
    "best_for": "Learning auctions & marketplaces analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EU TED Procurement dataset contains over 800,000 procurement notices annually, covering all EU public contracts above specified thresholds. It provides structured XML data since 2006, making it suitable for cross-country procurement research.",
    "use_cases": [
      "Analyzing trends in EU public procurement over time",
      "Comparing procurement practices across different EU countries",
      "Identifying key sectors receiving government contracts",
      "Assessing the impact of procurement policies on market competition"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest EU procurement notices?",
      "How to access EU public contracts data?",
      "What thresholds apply to EU procurement?",
      "Where can I find structured XML data for EU tenders?",
      "What is the volume of EU procurement notices in 2023?",
      "How to analyze cross-country procurement trends in the EU?"
    ],
    "domain_tags": [
      "government",
      "public sector"
    ],
    "data_modality": "mixed",
    "temporal_coverage": "2006-2023",
    "geographic_scope": "EU",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Prosper Loans",
    "description": "113K P2P loans with borrower characteristics, credit grades, and loan outcomes. Alternative to LendingClub for P2P lending research",
    "category": "Financial Services",
    "url": "https://www.prosper.com/plp/about/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P lending",
      "loans",
      "credit",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Prosper Loans dataset contains 113K peer-to-peer loans, including borrower characteristics, credit grades, and loan outcomes. This dataset serves as an alternative to LendingClub for research in P2P lending.",
    "use_cases": [
      "Analyzing borrower characteristics to improve lending criteria.",
      "Studying the impact of credit grades on loan outcomes.",
      "Comparing P2P lending platforms based on loan performance.",
      "Identifying trends in loan defaults and approvals."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the characteristics of borrowers in the Prosper Loans dataset?",
      "How do credit grades affect loan outcomes in P2P lending?",
      "What insights can be drawn from analyzing 113K P2P loans?",
      "How does Prosper compare to LendingClub in terms of loan performance?",
      "What factors influence loan approval rates in the Prosper Loans dataset?",
      "Can borrower characteristics predict loan defaults in P2P lending?",
      "What trends can be identified in the Prosper Loans dataset over time?",
      "How does the interest rate vary across different credit grades in P2P loans?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Transitland GTFS Feeds",
    "description": "Aggregated GTFS data from 2,500+ transit agencies across 55+ countries. The largest open transit data aggregator with REST and GraphQL APIs.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.transit.land/",
    "docs_url": "https://www.transit.land/documentation",
    "github_url": "https://github.com/transitland",
    "tags": [
      "transit",
      "GTFS",
      "schedules",
      "public-transportation",
      "global"
    ],
    "best_for": "Transit network analysis, accessibility research, and cross-city comparisons",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Transitland GTFS Feeds is an aggregated dataset containing GTFS data from over 2,500 transit agencies worldwide. It allows users to access public transportation schedules and related information through REST and GraphQL APIs.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Transitland GTFS Feeds?",
      "How to access GTFS data from Transitland?",
      "What transit agencies are included in Transitland GTFS Feeds?",
      "What countries are covered by Transitland GTFS Feeds?",
      "How to use REST API for Transitland GTFS Feeds?",
      "What is GTFS data?",
      "How can I analyze public transportation schedules?",
      "What are the benefits of using Transitland GTFS Feeds?"
    ],
    "use_cases": [
      "Analyzing public transportation accessibility in urban areas",
      "Developing applications for real-time transit information",
      "Researching global transit patterns",
      "Creating visualizations of transit data"
    ],
    "domain_tags": [
      "transportation"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NHANES (National Health and Nutrition Examination Survey)",
    "description": "Unique combination of interviews and physical examinations including blood/urine samples. Covers nutrition, chronic diseases, and environmental exposures. ~5,000 participants annually.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://www.cdc.gov/nchs/nhanes/",
    "source": "CDC National Center for Health Statistics",
    "type": "Survey + Biomarkers",
    "access": "Free public use files",
    "format": "SAS/XPT",
    "tags": [
      "Healthcare",
      "Survey",
      "Biomarkers",
      "Nutrition",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NHANES dataset provides a unique combination of interviews and physical examinations, including blood and urine samples, focusing on nutrition, chronic diseases, and environmental exposures. Researchers can use this data to analyze health trends, assess the impact of nutrition on health, and study environmental factors affecting public health.",
    "use_cases": [
      "Analyzing the relationship between nutrition and chronic diseases.",
      "Studying environmental exposures and their health impacts.",
      "Evaluating trends in public health over time.",
      "Investigating biomarkers related to health outcomes."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NHANES dataset?",
      "How can I access the NHANES survey data?",
      "What types of health information are included in NHANES?",
      "What are the key findings from NHANES data?",
      "How does NHANES contribute to healthcare research?",
      "What are the demographics of NHANES participants?",
      "What chronic diseases are covered in NHANES?",
      "How is nutrition assessed in the NHANES dataset?"
    ],
    "update_frequency": "Biennial cycles",
    "geographic_coverage": "United States (national)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Criteo Kaggle CTR Dataset",
    "description": "Standard CTR prediction benchmark with ~45 million records across 7 days, widely used for model comparison",
    "category": "Advertising",
    "url": "https://www.kaggle.com/c/criteo-display-ad-challenge/data",
    "docs_url": "https://www.kaggle.com/c/criteo-display-ad-challenge",
    "github_url": null,
    "tags": [
      "CTR prediction",
      "benchmark",
      "Kaggle",
      "Criteo"
    ],
    "best_for": "Benchmarking CTR prediction models against standard baseline",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "ad-tech",
      "machine-learning"
    ],
    "summary": "The Criteo Kaggle CTR Dataset is a standard benchmark for click-through rate (CTR) prediction, containing approximately 45 million records collected over a span of 7 days. It is widely utilized for model comparison and evaluation in the field of ad tech.",
    "use_cases": [
      "Model comparison for CTR prediction",
      "Evaluating machine learning algorithms",
      "Benchmarking ad tech solutions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Criteo Kaggle CTR Dataset",
      "CTR prediction datasets",
      "click-through rate benchmark datasets",
      "datasets for ad tech",
      "Kaggle datasets for CTR",
      "Criteo datasets for machine learning"
    ],
    "domain_tags": [
      "advertising",
      "technology"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "7 days",
    "geographic_scope": "Global",
    "size_category": "medium",
    "benchmark_usage": [
      "Model comparison"
    ],
    "model_score": 0.0001
  },
  {
    "name": "Multi-Region MMM eCommerce Dataset",
    "description": "Marketing mix modeling data for 100 brands across Google, Meta, and TikTok channels in multiple regions",
    "category": "Marketing Mix",
    "url": "https://figshare.com/articles/dataset/Multi-Region_MMM_Data/21629584",
    "docs_url": "https://figshare.com/articles/dataset/Multi-Region_MMM_Data/21629584",
    "github_url": null,
    "tags": [
      "MMM",
      "marketing mix",
      "ecommerce",
      "multi-channel"
    ],
    "best_for": "Marketing mix modeling with cross-channel and cross-region data",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "marketing",
      "data-analysis"
    ],
    "summary": "The Multi-Region MMM eCommerce Dataset contains marketing mix modeling data for 100 brands across various digital channels. It can be used to analyze the effectiveness of marketing strategies and optimize spending across channels.",
    "use_cases": [
      "Analyze the impact of marketing spend on sales",
      "Optimize advertising budget allocation across channels",
      "Evaluate brand performance across different regions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Multi-Region MMM eCommerce Dataset?",
      "How can I analyze marketing mix modeling data?",
      "What brands are included in the Multi-Region MMM eCommerce Dataset?",
      "What channels are covered in the Multi-Region MMM eCommerce Dataset?",
      "How to use marketing mix data for eCommerce?",
      "What insights can be gained from the Multi-Region MMM eCommerce Dataset?",
      "Where can I find marketing mix modeling datasets?",
      "What is the significance of multi-channel marketing data?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "varies",
    "geographic_scope": "Multiple regions",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Harvard Dataverse",
    "description": "Global network of 120+ Dataverse installations hosting 75,000+ datasets with free 1TB storage",
    "category": "Dataset Aggregators",
    "url": "https://dataverse.harvard.edu",
    "docs_url": "https://guides.dataverse.org",
    "github_url": "https://github.com/IQSS/dataverse",
    "tags": [
      "social science",
      "replication",
      "DOI",
      "academic"
    ],
    "best_for": "Social science data with support for Stata, SPSS, and R formats",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Harvard Dataverse is a global network that hosts over 75,000 datasets across 120+ installations. It provides free storage of up to 1TB, making it a valuable resource for researchers and academics to share and access data.",
    "use_cases": [],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available in the Harvard Dataverse?",
      "How can I access datasets from the Harvard Dataverse?",
      "What is the storage capacity of the Harvard Dataverse?",
      "What types of datasets are hosted in the Harvard Dataverse?",
      "How many Dataverse installations are there globally?",
      "What is the purpose of the Harvard Dataverse?"
    ],
    "domain_tags": [
      "academic",
      "social science"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "PEP Experimental Research",
    "description": "Experimental research datasets from Partnership for Economic Policy",
    "category": "Education",
    "url": "https://www.pep-net.org/publications/datasets/experimental-research-datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "development",
      "RCT",
      "policy"
    ],
    "best_for": "Learning education analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The PEP Experimental Research dataset contains experimental research datasets from the Partnership for Economic Policy. It can be used to analyze the effects of various policies through randomized controlled trials (RCTs).",
    "use_cases": [
      "Analyzing the impact of development policies",
      "Conducting randomized controlled trials",
      "Evaluating educational interventions"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the PEP Experimental Research dataset?",
      "How can I access the PEP Experimental Research datasets?",
      "What types of experiments are included in the PEP dataset?",
      "What is the Partnership for Economic Policy?",
      "How do I use RCT data for policy analysis?",
      "What are the applications of experimental research in development?"
    ],
    "domain_tags": [
      "education",
      "policy"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Rakuten SIGIR",
    "description": "E-commerce dataset for SIGIR workshop from Rakuten",
    "category": "E-Commerce",
    "url": "https://sigir-ecom.github.io/ecom2018/data-task.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "SIGIR",
      "e-commerce",
      "search"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "search"
    ],
    "summary": "The Rakuten SIGIR dataset is an e-commerce dataset specifically created for the SIGIR workshop. It can be used for various analyses related to search and consumer behavior in the e-commerce domain.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Rakuten SIGIR dataset?",
      "How can I access the Rakuten SIGIR dataset?",
      "What types of analyses can be performed with the Rakuten SIGIR dataset?",
      "What are the key features of the Rakuten SIGIR dataset?",
      "Is the Rakuten SIGIR dataset suitable for machine learning?",
      "What insights can be gained from the Rakuten SIGIR dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Amazon Reviews (2023)",
    "description": "571M reviews (1996-2023), 33 categories, 48M items - comprehensive Amazon review dataset",
    "category": "E-Commerce",
    "url": "https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "Amazon",
      "large-scale",
      "sentiment"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "sentiment-analysis"
    ],
    "summary": "This dataset contains 571 million reviews from Amazon spanning from 1996 to 2023 across 33 categories. It can be used for sentiment analysis, consumer behavior research, and large-scale data analysis.",
    "use_cases": [
      "Analyzing sentiment trends over time in Amazon reviews",
      "Comparing review patterns across different product categories",
      "Investigating the relationship between review volume and product pricing",
      "Exploring consumer behavior through review analysis"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the most reviewed products on Amazon?",
      "How do Amazon reviews vary across different categories?",
      "What sentiment trends can be observed in Amazon reviews over time?",
      "What is the distribution of reviews for Amazon items?",
      "How do review counts correlate with product pricing on Amazon?",
      "What are common themes in negative Amazon reviews?",
      "How do customer reviews impact sales on Amazon?",
      "What categories have the highest volume of reviews on Amazon?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "temporal_coverage": "1996-2023",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "Ecuador Grocery (Favorita)",
    "description": "Unit sales data with store/item metadata and oil prices from Ecuador",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "sales forecasting",
      "Ecuador",
      "Kaggle"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "grocery",
      "sales forecasting",
      "Ecuador"
    ],
    "summary": "This dataset contains unit sales data along with store and item metadata, as well as oil prices from Ecuador. It can be used for sales forecasting and analyzing consumer behavior in the grocery sector.",
    "use_cases": [
      "Sales forecasting for grocery items",
      "Analyzing the impact of oil prices on grocery sales",
      "Comparative analysis of store performance",
      "Identifying sales trends over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Ecuador grocery sales dataset",
      "unit sales data Ecuador",
      "grocery sales forecasting dataset",
      "oil prices impact on grocery sales",
      "Favorita grocery dataset",
      "Ecuador supermarket sales analysis",
      "Kaggle grocery datasets"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Ecuador",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Office Supplies (DMDA 2023)",
    "description": "Office supply sales for DMDA 2023 workshop challenge",
    "category": "Grocery & Supermarkets",
    "url": "https://sites.google.com/view/dmdaworkshop2023/data-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "office supplies",
      "forecasting",
      "workshop"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains sales data for office supplies related to the DMDA 2023 workshop challenge. It can be used for forecasting sales trends and analyzing consumer behavior in the office supply market.",
    "use_cases": [
      "Forecasting future sales of office supplies",
      "Analyzing consumer purchasing patterns",
      "Evaluating the effectiveness of marketing strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "office supplies sales data DMDA 2023",
      "forecasting office supply sales",
      "DMDA 2023 workshop challenge dataset",
      "office supplies consumer behavior analysis",
      "sales trends in office supplies",
      "data for office supply forecasting"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Brazilian Drugs (ANVISA)",
    "description": "Sales data for controlled substances reported by ANVISA",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tiagoacardoso/venda-medicamentos-controlados-anvisa",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Brazil",
      "regulated"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "pharmaceuticals",
      "regulation",
      "sales"
    ],
    "summary": "The Brazilian Drugs dataset contains sales data for controlled substances reported by ANVISA. This data can be used to analyze trends in pharmaceutical sales and understand the impact of regulations in Brazil.",
    "use_cases": [
      "Analyzing sales trends over time for specific controlled substances",
      "Comparing sales data before and after regulatory changes",
      "Identifying the most popular pharmaceuticals in Brazil",
      "Studying the relationship between sales and demographic factors"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the sales trends for controlled substances in Brazil?",
      "How do regulations affect pharmaceutical sales in Brazil?",
      "What types of controlled substances are most commonly sold?",
      "What is the impact of ANVISA reporting on drug sales?",
      "How can I analyze sales data for pharmaceuticals in Brazil?",
      "What are the key insights from the Brazilian Drugs dataset?"
    ],
    "domain_tags": [
      "retail",
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Brazil",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Indian Sales",
    "description": "Sales forecasting dataset for small basket items in India",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/girishvutukuri/sales-forecasting-for-small-basket",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "India",
      "forecasting",
      "retail"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "retail"
    ],
    "summary": "The Indian Sales dataset is designed for sales forecasting of small basket items in India. It can be used to analyze sales trends and develop predictive models for retail performance.",
    "use_cases": [
      "Sales trend analysis",
      "Predictive modeling for retail",
      "Inventory management optimization"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Indian sales forecasting dataset",
      "sales data for small basket items in India",
      "retail sales analysis India",
      "forecasting grocery sales India",
      "small basket item sales dataset",
      "India retail sales forecasting"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "India",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Italian Grocers",
    "description": "Receipt-level sales data from Italian grocery stores",
    "category": "Grocery & Supermarkets",
    "url": "https://data.mendeley.com/datasets/s8dgbs3rng/1",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Italy",
      "receipts"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "grocery",
      "consumer-behavior"
    ],
    "summary": "This dataset contains receipt-level sales data from Italian grocery stores, providing insights into consumer purchasing patterns and sales trends. Analysts can use this data to explore pricing strategies and consumer behavior in the grocery sector.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Exploring pricing strategies",
      "Identifying sales trends in the grocery sector"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the sales data from Italian grocery stores?",
      "How can I analyze grocery receipts from Italy?",
      "What consumer behavior insights can be derived from Italian grocery sales?",
      "Where can I find receipt-level data for grocery stores in Italy?",
      "What are the trends in grocery sales in Italy?",
      "How do pricing strategies affect sales in Italian grocery stores?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Italy",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Fashion-MNIST",
    "description": "70,000 28x28 grayscale images of 10 fashion categories from Zalando",
    "category": "Fashion & Apparel",
    "url": "https://github.com/zalandoresearch/fashion-mnist",
    "docs_url": null,
    "github_url": "https://github.com/zalandoresearch/fashion-mnist",
    "tags": [
      "image classification",
      "benchmark",
      "deep learning"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce"
    ],
    "summary": "Fashion-MNIST is a dataset containing 70,000 grayscale images of clothing items categorized into 10 fashion categories. It is commonly used for image classification tasks and serves as a benchmark for deep learning algorithms.",
    "use_cases": [
      "Training image classification models",
      "Benchmarking deep learning algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Fashion-MNIST dataset",
      "Fashion image classification dataset",
      "Zalando fashion dataset",
      "Deep learning fashion dataset",
      "Image classification benchmark dataset",
      "Fashion-MNIST images"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "image",
    "size_category": "medium",
    "benchmark_usage": [
      "Common uses if mentioned in description"
    ],
    "model_score": 0.0001
  },
  {
    "name": "Tencent Social Ads",
    "description": "Social ad CTR prediction dataset from Tencent",
    "category": "Advertising",
    "url": "https://algo.qq.com/index.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social ads",
      "CTR",
      "Tencent",
      "China"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Tencent Social Ads dataset is designed for predicting click-through rates (CTR) for social advertisements. It provides insights into user engagement with ads, which can be leveraged for optimizing advertising strategies.",
    "use_cases": [
      "Predicting click-through rates for social ads",
      "Analyzing user engagement with advertisements",
      "Optimizing ad placement strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Tencent Social Ads dataset?",
      "How can I use the Tencent Social Ads dataset for CTR prediction?",
      "Where can I find the Tencent Social Ads dataset?",
      "What are the features of the Tencent Social Ads dataset?",
      "Is the Tencent Social Ads dataset publicly available?",
      "What type of analysis can I perform with the Tencent Social Ads dataset?",
      "How does Tencent's social ads data compare to other ad datasets?",
      "What tools can I use to analyze the Tencent Social Ads dataset?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Drone Delivery",
    "description": "Drone delivery logistics and operations dataset",
    "category": "Logistics & Supply Chain",
    "url": "https://tianchi.aliyun.com/dataset/89726",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "drones",
      "delivery",
      "autonomous"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Drone Delivery dataset provides insights into logistics and operations related to drone delivery systems. It can be used to analyze efficiency, optimize routes, and understand operational challenges in autonomous delivery.",
    "use_cases": [
      "Analyze delivery efficiency of drones",
      "Optimize drone delivery routes",
      "Study operational challenges in drone logistics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "drone delivery logistics dataset",
      "autonomous delivery operations data",
      "logistics dataset for drones",
      "drone delivery analysis",
      "dataset on drone logistics",
      "operations dataset for drone delivery"
    ],
    "domain_tags": [
      "logistics",
      "supply chain"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Google Trends Datastore",
    "description": "Search interest data for nowcasting. Economic indicators, demand prediction, event detection",
    "category": "Social & Web",
    "url": "https://googletrends.github.io/data/",
    "docs_url": "https://developers.google.com/search/apis/trends",
    "github_url": null,
    "tags": [
      "search trends",
      "nowcasting",
      "research",
      "time-series"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "economic-indicators",
      "demand-prediction",
      "event-detection"
    ],
    "summary": "The Google Trends Datastore provides search interest data that can be used for nowcasting economic indicators and predicting demand. Researchers can analyze trends over time to detect events and understand consumer behavior.",
    "use_cases": [
      "Analyzing economic trends based on search data",
      "Predicting product demand using search interest",
      "Detecting market events through search patterns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest search trends in economic indicators?",
      "How can Google Trends data be used for demand prediction?",
      "What events can be detected using search interest data?",
      "What are the implications of search trends on consumer behavior?",
      "How does Google Trends data relate to time-series analysis?",
      "What research can be conducted using Google Trends data?"
    ],
    "domain_tags": [
      "retail",
      "economics"
    ],
    "data_modality": "time-series",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Yandex Datasets",
    "description": "Search ranking, translation quality, and ML task datasets",
    "category": "Data Portals",
    "url": "https://research.yandex.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search ranking",
      "translation",
      "ML",
      "Russia"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Yandex Datasets includes datasets related to search ranking, translation quality, and various machine learning tasks. These datasets can be utilized for improving search algorithms, enhancing translation systems, and conducting machine learning experiments.",
    "use_cases": [
      "Improving search engine algorithms",
      "Enhancing machine translation systems",
      "Conducting machine learning experiments"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are Yandex Datasets?",
      "Where can I find datasets for search ranking?",
      "How to access translation quality datasets from Yandex?",
      "What machine learning tasks can be performed with Yandex Datasets?",
      "Are there datasets available for ML tasks in Russia?",
      "What types of data does Yandex provide for research?"
    ],
    "domain_tags": [
      "technology",
      "data science"
    ],
    "data_modality": "mixed",
    "geographic_scope": "Russia",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Yongfeng Dataset Collection",
    "description": "E-commerce and recommendation system datasets",
    "category": "Data Portals",
    "url": "https://www.yongfeng.me/dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "recommendations",
      "e-commerce",
      "academic"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "recommendations"
    ],
    "summary": "The Yongfeng Dataset Collection includes various datasets related to e-commerce and recommendation systems. Researchers and practitioners can use this data to analyze consumer behavior and improve recommendation algorithms.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Improving recommendation algorithms",
      "Evaluating e-commerce strategies"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Yongfeng Dataset Collection?",
      "Where can I find e-commerce datasets?",
      "How to use the Yongfeng datasets for recommendations?",
      "What types of data are in the Yongfeng Dataset Collection?",
      "Can I access the Yongfeng Dataset for academic purposes?",
      "What are the applications of e-commerce datasets?",
      "How do I analyze recommendation system data?",
      "What research has been done using the Yongfeng Dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Julian McAuley Datasets",
    "description": "Reviews, recommendations, and social network data",
    "category": "Data Portals",
    "url": "https://cseweb.ucsd.edu/~jmcauley/datasets.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "reviews",
      "recommendations",
      "UCSD",
      "academic"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Julian McAuley Datasets contain reviews, recommendations, and social network data, primarily focused on consumer interactions and preferences. Researchers and data scientists can use this data to analyze trends in consumer behavior and develop recommendation systems.",
    "use_cases": [
      "Analyzing consumer preferences",
      "Building recommendation systems",
      "Studying social network interactions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What are the Julian McAuley Datasets?",
      "Where can I find reviews and recommendations data?",
      "How can I access social network data from UCSD?",
      "What datasets are available for studying consumer behavior?",
      "Are there any academic datasets for e-commerce analysis?",
      "What data is included in the Julian McAuley Datasets?",
      "How to analyze recommendations using Julian McAuley Datasets?",
      "What insights can be gained from UCSD's review datasets?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Makridakis Competitions",
    "description": "Time series data for forecasting competitions (M1-M5)",
    "category": "Data Portals",
    "url": "https://www.mcompetitions.unic.ac.cy/the-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "time series",
      "forecasting",
      "M competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [
      "time series analysis",
      "forecasting techniques"
    ],
    "topic_tags": [],
    "summary": "The Makridakis Competitions dataset provides time series data used in various forecasting competitions. It allows users to test and compare different forecasting methods and models.",
    "use_cases": [
      "Evaluating forecasting models",
      "Comparing time series forecasting techniques"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "Makridakis Competitions dataset",
      "time series forecasting competitions data",
      "M1-M5 forecasting dataset",
      "Makridakis M competitions data",
      "time series data for forecasting",
      "forecasting competition datasets"
    ],
    "domain_tags": [
      "data science",
      "forecasting"
    ],
    "data_modality": "time-series",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "UK Land Registry Price Paid",
    "description": "4.3GB of UK property sales transactions going back decades, messy real-world government data",
    "category": "Real Estate",
    "url": "https://www.gov.uk/government/collections/price-paid-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "UK",
      "government data",
      "large-scale",
      "transactions",
      "messy data"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The UK Land Registry Price Paid dataset contains property sales transactions from the UK, providing a comprehensive view of real estate activity over decades. This messy government data can be used for various analyses related to property pricing trends and market dynamics.",
    "use_cases": [
      "Analyzing property price trends over time",
      "Comparing property sales across different regions in the UK",
      "Identifying factors affecting property prices",
      "Assessing the impact of government policies on real estate transactions"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the UK Land Registry Price Paid dataset?",
      "How to access UK property sales data?",
      "What are the trends in UK property sales over the years?",
      "Where can I find government data on UK real estate transactions?",
      "How to analyze messy real estate data from the UK?",
      "What insights can be gained from UK Land Registry data?",
      "How has the UK property market changed over decades?",
      "What are the challenges in working with UK Land Registry data?"
    ],
    "domain_tags": [
      "real estate",
      "government"
    ],
    "data_modality": "tabular",
    "geographic_scope": "UK",
    "size_category": "large",
    "model_score": 0.0001
  },
  {
    "name": "YouTube User Watch History",
    "description": "1.8M videos watched by 243 users over 1.5 years. Recommendation engine performance, caching research, viewing patterns",
    "category": "Entertainment & Media",
    "url": "https://netsg.cs.sfu.ca/youtubedata/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "YouTube",
      "watch history",
      "recommendations",
      "video",
      "user behavior"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "user-behavior",
      "recommendation-systems"
    ],
    "summary": "This dataset contains the watch history of 1.8 million videos viewed by 243 users over a period of 1.5 years. It can be used to analyze recommendation engine performance, caching strategies, and user viewing patterns.",
    "use_cases": [
      "Analyzing the effectiveness of recommendation algorithms.",
      "Studying user engagement and viewing patterns over time.",
      "Researching the impact of caching on video loading times.",
      "Evaluating the diversity of content consumed by users."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the YouTube user watch history dataset?",
      "How can I analyze user behavior from YouTube watch history?",
      "What insights can be gained from YouTube video recommendations?",
      "How does caching affect video recommendations on YouTube?",
      "What patterns can be observed in user watch history on YouTube?",
      "How many videos were watched by users in the YouTube dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1.5 years",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "YouTube-8M",
    "description": "8M videos with video-level features for large-scale video understanding. Google Research benchmark for video classification",
    "category": "Entertainment & Media",
    "url": "https://research.google.com/youtube8m/",
    "docs_url": "https://research.google.com/youtube8m/download.html",
    "github_url": null,
    "tags": [
      "YouTube",
      "video",
      "classification",
      "benchmark",
      "Google Research"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "YouTube-8M is a dataset containing 8 million videos with video-level features aimed at large-scale video understanding. It serves as a benchmark for video classification tasks, allowing researchers to evaluate and improve their models.",
    "use_cases": [
      "Video classification research",
      "Model evaluation for video understanding",
      "Benchmarking video classification algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the YouTube-8M dataset?",
      "How can I use YouTube-8M for video classification?",
      "What features are available in the YouTube-8M dataset?",
      "Where can I access the YouTube-8M dataset?",
      "What are the benchmarks for video classification using YouTube-8M?",
      "How many videos are included in the YouTube-8M dataset?",
      "What research has been conducted using YouTube-8M?",
      "What is the purpose of the YouTube-8M dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "benchmark_usage": [
      "Google Research benchmark for video classification"
    ],
    "model_score": 0.0001
  },
  {
    "name": "Twitch Streaming Dataset",
    "description": "16 days of viewer counts, stream metadata, game categories from Oct 2017. Live streaming platform dynamics",
    "category": "Entertainment & Media",
    "url": "https://github.com/mingt2019/Twitch-Dataset",
    "docs_url": null,
    "github_url": "https://github.com/mingt2019/Twitch-Dataset",
    "tags": [
      "Twitch",
      "live streaming",
      "viewership",
      "gaming"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "live streaming",
      "gaming",
      "viewership"
    ],
    "summary": "The Twitch Streaming Dataset contains viewer counts, stream metadata, and game categories from a 16-day period in October 2017. It can be used to analyze the dynamics of live streaming platforms and viewer engagement in gaming.",
    "use_cases": [
      "Analyzing viewer trends over time",
      "Comparing game category popularity",
      "Studying the impact of streaming duration on viewer counts"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Twitch Streaming Dataset?",
      "How can I analyze viewer counts on Twitch?",
      "What metadata is available in the Twitch Streaming Dataset?",
      "What game categories are included in the Twitch Streaming Dataset?",
      "How does live streaming affect viewer engagement?",
      "What trends can be observed in Twitch viewership from October 2017?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2017",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "MobileRec",
    "description": "19.3M user reviews from 700K users across 10K apps in 48 categories. Google Play app recommendation research",
    "category": "App Stores",
    "url": "https://github.com/mhmaqbool/mobilerec",
    "docs_url": null,
    "github_url": "https://github.com/mhmaqbool/mobilerec",
    "tags": [
      "mobile apps",
      "reviews",
      "Google Play",
      "recommendations",
      "app store"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior"
    ],
    "summary": "MobileRec contains 19.3 million user reviews from 700,000 users across 10,000 apps in 48 categories. This dataset can be used for analyzing user sentiment, app recommendations, and trends in mobile app usage.",
    "use_cases": [
      "Sentiment analysis of mobile app reviews",
      "Comparative analysis of user feedback across app categories",
      "Recommendation system development based on user reviews",
      "Trend analysis of mobile app usage over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the user reviews for mobile apps in the Google Play store?",
      "How can I analyze app recommendations based on user feedback?",
      "What insights can be gained from 19.3M user reviews?",
      "Which categories have the most user reviews in MobileRec?",
      "How do user ratings vary across different app categories?",
      "What trends can be identified in mobile app reviews?",
      "How many users contributed to the MobileRec dataset?",
      "What is the distribution of reviews across 10,000 apps?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Google Play Store Dataset",
    "description": "2.3M apps with ratings, reviews, categories, sizes, installs. Android app marketplace data",
    "category": "App Stores",
    "url": "https://www.kaggle.com/datasets/gauthamp10/google-playstore-apps",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Google Play",
      "Android",
      "apps",
      "ratings",
      "Kaggle"
    ],
    "best_for": "Learning app stores analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Google Play Store Dataset contains information on 2.3 million Android apps, including their ratings, reviews, categories, sizes, and install counts. This dataset can be used for analyzing app performance, user preferences, and market trends in the Android ecosystem.",
    "use_cases": [
      "Analyzing trends in app ratings over time",
      "Comparing app performance across different categories",
      "Identifying factors that influence user ratings and reviews",
      "Exploring the relationship between app size and install counts"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the top-rated apps in the Google Play Store?",
      "How do app sizes correlate with their ratings?",
      "What categories have the most apps in the Google Play Store?",
      "What is the average number of installs for apps in different categories?",
      "How do user reviews impact app ratings?",
      "What trends can be observed in app ratings over time?",
      "Which apps have the highest number of reviews?",
      "What are the most common tags associated with apps in the Google Play Store?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "JobHop (Flanders)",
    "description": "2.3M occupations and 391K resumes with real career trajectories mapped to ESCO codes. Labor mobility research",
    "category": "Labor Markets",
    "url": "https://huggingface.co/datasets/VDAB/jobhop",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "careers",
      "resumes",
      "occupations",
      "labor mobility",
      "ESCO"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "JobHop (Flanders) provides a dataset of 2.3 million occupations and 391,000 resumes, detailing real career trajectories linked to ESCO codes. This dataset can be utilized for labor mobility research and analysis of career patterns.",
    "use_cases": [
      "Analyzing labor mobility trends in Flanders",
      "Mapping career trajectories to ESCO codes",
      "Studying the relationship between occupations and resumes",
      "Researching the impact of labor mobility on career development"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the JobHop dataset?",
      "How many occupations are in the JobHop dataset?",
      "What type of research can be conducted using JobHop?",
      "What are ESCO codes?",
      "How many resumes are included in JobHop?",
      "What is the focus of labor mobility research?",
      "What insights can be gained from analyzing career trajectories?",
      "What is the significance of the JobHop dataset for labor markets?"
    ],
    "domain_tags": [
      "labor markets"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Flanders",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "HateDay",
    "description": "Global representative sample of real-world hate speech across languages. 2024 benchmark for content moderation",
    "category": "Content Moderation",
    "url": "https://arxiv.org/abs/2404.06465",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hate speech",
      "multilingual",
      "benchmark",
      "content moderation"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "HateDay is a global representative sample of real-world hate speech across multiple languages, serving as a benchmark for content moderation in 2024. This dataset can be used to analyze and improve content moderation systems by providing insights into hate speech patterns.",
    "use_cases": [
      "Analyzing patterns of hate speech across different languages.",
      "Developing and testing content moderation algorithms.",
      "Benchmarking existing content moderation systems against HateDay.",
      "Training machine learning models for hate speech detection."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the HateDay dataset?",
      "How can I access the HateDay hate speech dataset?",
      "What languages are included in the HateDay dataset?",
      "What are the benchmarks for content moderation in HateDay?",
      "How is hate speech defined in the HateDay dataset?",
      "What research can be conducted using the HateDay dataset?",
      "What are the applications of the HateDay dataset in content moderation?",
      "Where can I find multilingual hate speech data?"
    ],
    "domain_tags": [
      "content moderation"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Patreon Creator Data",
    "description": "279K+ active creators with membership tiers and patron counts. Creator economy platform metrics from Graphtreon",
    "category": "Creator Economy",
    "url": "https://graphtreon.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Patreon",
      "creators",
      "memberships",
      "subscriptions",
      "creator economy"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "creator economy",
      "subscriptions",
      "membership"
    ],
    "summary": "The Patreon Creator Data consists of over 279,000 active creators along with their membership tiers and patron counts. This dataset provides insights into the creator economy, allowing for analysis of trends and metrics in creator-driven platforms.",
    "use_cases": [
      "Analyzing trends in creator memberships over time",
      "Comparing patron counts across different creators",
      "Evaluating the effectiveness of different membership tiers",
      "Studying the growth of the creator economy"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the active creators on Patreon?",
      "How many membership tiers do creators have on Patreon?",
      "What is the average patron count for creators on Patreon?",
      "What metrics are available for the creator economy on Graphtreon?",
      "How can I analyze creator memberships on Patreon?",
      "What insights can be derived from Patreon creator data?",
      "What trends exist in the creator economy?",
      "How does Patreon compare to other creator platforms?"
    ],
    "domain_tags": [
      "creator economy"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Lahman Baseball Database",
    "description": "Complete historical baseball statistics from 1871-2024 including batting, pitching, fielding, and salaries for every MLB player and team",
    "category": "Sports & Athletics",
    "url": "https://www.seanlahman.com/baseball-archive/statistics/",
    "docs_url": "https://www.seanlahman.com/baseball-archive/statistics/",
    "github_url": "https://github.com/chadwickbureau/baseballdatabank",
    "tags": [
      "baseball",
      "historical",
      "MLB",
      "player-statistics",
      "sabermetrics"
    ],
    "best_for": "Learning baseball analytics, historical trend analysis, and player valuation",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Lahman Baseball Database contains complete historical baseball statistics from 1871 to 2024, including batting, pitching, fielding, and salaries for every MLB player and team. This dataset can be used for various analyses in sports statistics and sabermetrics.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the historical batting statistics in the Lahman Baseball Database?",
      "How can I access MLB player salaries from the Lahman Baseball Database?",
      "What pitching statistics are available in the Lahman Baseball Database?",
      "Where can I find historical baseball statistics for every MLB player?",
      "What is included in the Lahman Baseball Database?",
      "How does the Lahman Baseball Database support sabermetrics?",
      "Is there a dataset for historical fielding statistics in baseball?",
      "What years does the Lahman Baseball Database cover?"
    ],
    "use_cases": [
      "Analyzing player performance trends over time",
      "Comparing team statistics across different seasons",
      "Conducting sabermetric analyses for player evaluation",
      "Studying the impact of player salaries on team performance"
    ],
    "domain_tags": [
      "sports",
      "athletics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1871-2024",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "MEPS (Medical Expenditure Panel Survey)",
    "description": "Nationally representative survey of healthcare utilization, expenditures, insurance coverage, and health status for the US civilian population",
    "category": "Insurance & Actuarial",
    "url": "https://meps.ahrq.gov/mepsweb/",
    "docs_url": "https://meps.ahrq.gov/mepsweb/data_stats/download_data_files.jsp",
    "github_url": null,
    "tags": [
      "health-insurance",
      "healthcare-costs",
      "expenditure-data",
      "survey-data",
      "panel-data"
    ],
    "best_for": "Health insurance research, healthcare cost modeling, and demand analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The MEPS dataset provides a nationally representative survey of healthcare utilization, expenditures, insurance coverage, and health status for the US civilian population. Researchers can analyze trends in healthcare costs and insurance coverage, as well as assess the impact of health status on expenditures.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Medical Expenditure Panel Survey?",
      "How to access MEPS healthcare expenditure data?",
      "What insights can be gained from MEPS survey data?",
      "What are the key findings from the MEPS on health insurance coverage?",
      "How does MEPS data inform healthcare policy?",
      "What is included in the MEPS dataset?",
      "How to analyze MEPS data using Python?",
      "What are the trends in healthcare costs according to MEPS?"
    ],
    "use_cases": [
      "Analyzing the impact of insurance coverage on healthcare expenditures.",
      "Examining trends in healthcare utilization over time.",
      "Assessing the relationship between health status and medical costs."
    ],
    "domain_tags": [
      "healthcare",
      "insurance"
    ],
    "data_modality": "tabular",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "EM-DAT International Disaster Database",
    "description": "Global database of 26K+ natural and technological disasters since 1900 with human and economic impact data",
    "category": "Insurance & Actuarial",
    "url": "https://www.emdat.be/",
    "docs_url": "https://doc.emdat.be/",
    "github_url": null,
    "tags": [
      "disasters",
      "catastrophe",
      "global-data",
      "economic-losses",
      "humanitarian"
    ],
    "best_for": "Global catastrophe analysis, reinsurance pricing, and disaster trend research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EM-DAT International Disaster Database is a comprehensive global repository of over 26,000 natural and technological disasters recorded since 1900. It provides valuable data on human and economic impacts, making it useful for research and analysis in disaster management and economic studies.",
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the EM-DAT International Disaster Database?",
      "How can I access the EM-DAT disaster data?",
      "What types of disasters are included in the EM-DAT database?",
      "What economic impacts are recorded in the EM-DAT database?",
      "How has the frequency of disasters changed over time according to EM-DAT?",
      "What humanitarian data is available in the EM-DAT database?"
    ],
    "use_cases": [
      "Analyzing the economic losses from natural disasters over the decades.",
      "Studying the humanitarian impacts of technological disasters.",
      "Comparing disaster frequency and impact across different regions."
    ],
    "domain_tags": [
      "insurance",
      "humanitarian"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "CASdatasets R Package",
    "description": "Collection of 40+ actuarial datasets for P&C insurance including freMTPL, ausautoBI, and loss triangles for teaching and research",
    "category": "Insurance & Actuarial",
    "url": "https://cran.r-project.org/package=CASdatasets",
    "docs_url": "https://freakonometrics.github.io/CASdatasets/",
    "github_url": "https://github.com/freakonometrics/CASdatasets",
    "tags": [
      "actuarial",
      "P&C-insurance",
      "loss-triangles",
      "claims-data",
      "teaching-datasets"
    ],
    "best_for": "Learning actuarial methods, pricing model development, and reserving exercises",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The CASdatasets R Package is a collection of over 40 actuarial datasets specifically designed for property and casualty insurance. It includes datasets such as freMTPL, ausautoBI, and various loss triangles, making it suitable for teaching and research purposes.",
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "actuarial datasets for P&C insurance",
      "freMTPL dataset",
      "loss triangles for teaching",
      "ausautoBI dataset",
      "P&C insurance claims data",
      "actuarial teaching datasets",
      "datasets for insurance research",
      "R package for actuarial data"
    ],
    "use_cases": [
      "Teaching actuarial science",
      "Research in property and casualty insurance",
      "Analyzing claims data",
      "Studying loss triangles"
    ],
    "domain_tags": [
      "Insurance",
      "Actuarial"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "OpenStreetMap Road Network",
    "description": "Open-source global road network data including road types, speeds, and connectivity. Downloadable via Overpass API or pre-processed extracts.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.openstreetmap.org/",
    "docs_url": "https://wiki.openstreetmap.org/wiki/Main_Page",
    "github_url": "https://github.com/openstreetmap",
    "tags": [
      "road-network",
      "open-data",
      "global",
      "GIS",
      "routing"
    ],
    "best_for": "Road network analysis, routing, accessibility studies, and urban form research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The OpenStreetMap Road Network dataset provides open-source global road network data, including various road types, speeds, and connectivity information. It can be used for routing applications, urban planning, and transportation analysis.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is OpenStreetMap Road Network data?",
      "How to access OpenStreetMap road data?",
      "What types of roads are included in OpenStreetMap?",
      "What is the speed data available in OpenStreetMap?",
      "How can I use OpenStreetMap for routing?",
      "What are the connectivity features of OpenStreetMap roads?",
      "Where can I download OpenStreetMap road network data?",
      "What is the Overpass API for OpenStreetMap?"
    ],
    "use_cases": [
      "Analyzing traffic patterns using road connectivity data",
      "Developing routing algorithms for navigation systems",
      "Studying the impact of road types on transportation efficiency"
    ],
    "domain_tags": [
      "transportation",
      "technology"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Merative MarketScan",
    "description": "De-identified commercial claims from 273+ million unique patients since 1995. Includes Commercial Claims, Medicare Supplemental, and Multi-State Medicaid databases. Cited in 2,650+ peer-reviewed studies.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://www.merative.com/real-world-evidence",
    "source": "Merative (formerly IBM Watson Health)",
    "type": "Claims Database",
    "access": "Institutional license required",
    "format": "SAS",
    "tags": [
      "Healthcare",
      "Claims",
      "Commercial",
      "Longitudinal"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Merative MarketScan dataset contains de-identified commercial claims data from over 273 million unique patients since 1995. It can be used for various analyses in healthcare economics and health technology, including studying healthcare utilization and costs.",
    "use_cases": [
      "Analyzing healthcare costs and utilization trends over time.",
      "Evaluating the effectiveness of healthcare interventions.",
      "Conducting longitudinal studies on patient outcomes.",
      "Comparing commercial claims with Medicare and Medicaid data."
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Merative MarketScan dataset?",
      "How can I access the Merative MarketScan claims data?",
      "What types of analyses can be performed with MarketScan data?",
      "What is included in the Merative MarketScan database?",
      "How many patients are represented in the MarketScan dataset?",
      "What studies have cited the MarketScan dataset?",
      "What are the key features of the MarketScan claims data?",
      "How does MarketScan data support healthcare research?"
    ],
    "update_frequency": "Quarterly",
    "geographic_coverage": "United States (employer-insured)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1995-present",
    "size_category": "medium",
    "benchmark_usage": [
      "Cited in 2,650+ peer-reviewed studies"
    ],
    "model_score": 0.0001
  },
  {
    "name": "All of Us Research Program",
    "description": "NIH precision medicine initiative enrolling 1+ million diverse U.S. participants. Includes EHR, surveys, wearables, and genomics. Cloud-based Researcher Workbench provides secure access.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://allofus.nih.gov/",
    "source": "NIH",
    "type": "Cohort + Multi-modal",
    "access": "Free (registration required)",
    "format": "Cloud-based (BigQuery)",
    "tags": [
      "Healthcare",
      "Precision Medicine",
      "Diverse",
      "Wearables",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The All of Us Research Program is a NIH initiative aimed at enrolling over a million diverse participants in the U.S. to gather data on health through electronic health records, surveys, wearables, and genomics. This dataset allows researchers to explore precision medicine and its impact on diverse populations.",
    "use_cases": [
      "Analyzing the impact of diverse populations on health outcomes.",
      "Exploring the relationship between wearables data and health metrics."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the All of Us Research Program?",
      "How can I access the All of Us Research Program dataset?",
      "What types of data are included in the All of Us Research Program?",
      "What is the purpose of the All of Us Research Program?",
      "How does the All of Us Research Program support precision medicine?",
      "What research can be conducted using the All of Us Research Program data?",
      "Who can participate in the All of Us Research Program?",
      "What technologies are used in the All of Us Research Program?"
    ],
    "update_frequency": "Ongoing enrollment",
    "geographic_coverage": "United States (national)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "mixed",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "PUDL (Public Utility Data Liberation)",
    "description": "Cleaned and integrated dataset combining EIA, FERC, and EPA energy data into a unified database",
    "category": "Energy",
    "url": "https://catalyst.coop/pudl/",
    "docs_url": "https://catalystcoop-pudl.readthedocs.io/",
    "github_url": "https://github.com/catalyst-cooperative/pudl",
    "tags": [
      "integrated",
      "cleaned",
      "EIA",
      "FERC",
      "EPA"
    ],
    "best_for": "Research requiring integrated energy data without extensive cleaning",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The PUDL dataset is a cleaned and integrated collection of energy data from the EIA, FERC, and EPA, providing a unified database for analysis. Users can utilize this dataset to conduct various analyses related to energy consumption, production, and regulatory compliance.",
    "use_cases": [
      "Analyzing trends in energy consumption over time",
      "Comparing energy production across different states",
      "Evaluating the impact of regulations on energy markets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the PUDL dataset?",
      "How can I access the PUDL energy data?",
      "What types of data are included in the PUDL dataset?",
      "What are the sources of the PUDL dataset?",
      "How is the PUDL dataset cleaned and integrated?",
      "What analyses can be performed using the PUDL dataset?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1994-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "DoD National Defense Budget Estimates (Green Book)",
    "description": "Detailed U.S. defense spending by program element, military department, and appropriation from FY1945 to present",
    "category": "Defense Economics",
    "url": "https://comptroller.defense.gov/Budget-Materials/",
    "docs_url": "https://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2024/FY2024_Green_Book.pdf",
    "github_url": null,
    "tags": [
      "US defense",
      "budget",
      "Pentagon",
      "appropriations"
    ],
    "best_for": "Detailed analysis of U.S. military spending by program and service branch",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The DoD National Defense Budget Estimates (Green Book) provides detailed information on U.S. defense spending categorized by program element, military department, and appropriation from FY1945 to the present. This dataset can be used for analyzing trends in defense spending and understanding budget allocations across different military sectors.",
    "use_cases": [
      "Analyzing historical trends in U.S. defense spending.",
      "Comparing budget allocations across different military departments.",
      "Evaluating the impact of defense spending on the economy.",
      "Researching appropriations for specific defense programs."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the U.S. defense budget estimates?",
      "How has U.S. defense spending changed over the years?",
      "What are the appropriations for different military departments?",
      "Where can I find detailed U.S. defense spending data?",
      "What programs are funded in the U.S. defense budget?",
      "How does the Pentagon allocate its budget?",
      "What are the historical trends in U.S. defense spending?",
      "What is included in the DoD Green Book?"
    ],
    "domain_tags": [
      "defense",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "FY1945 to present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "CelesTrak",
    "description": "Well-organized TLE and OMM orbital data by satellite category including SOCRATES collision assessment tool",
    "category": "Space",
    "url": "https://celestrak.org/",
    "docs_url": "https://celestrak.org/NORAD/documentation/",
    "github_url": null,
    "tags": [
      "satellites",
      "orbital elements",
      "collision",
      "debris"
    ],
    "best_for": "Accessible satellite data organized by mission type and constellation",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "CelesTrak provides well-organized TLE and OMM orbital data categorized by satellite types. Users can utilize this data for collision assessments and to analyze satellite debris.",
    "use_cases": [
      "Collision assessment of satellites",
      "Analysis of orbital elements",
      "Research on space debris",
      "Monitoring satellite categories"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is CelesTrak?",
      "How to access TLE data from CelesTrak?",
      "What are OMM orbital data?",
      "How does SOCRATES collision assessment tool work?",
      "What satellite categories are available in CelesTrak?",
      "How to analyze satellite debris using CelesTrak?"
    ],
    "domain_tags": [
      "space"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "current",
    "geographic_scope": "Global (orbital)",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Outbrain Click Prediction Dataset",
    "description": "Content recommendation dataset with 2 billion page views and user engagement data from Outbrain",
    "category": "Advertising",
    "url": "https://www.kaggle.com/c/outbrain-click-prediction/data",
    "docs_url": "https://www.kaggle.com/c/outbrain-click-prediction",
    "github_url": null,
    "tags": [
      "content recommendation",
      "native advertising",
      "Outbrain",
      "engagement"
    ],
    "best_for": "Native advertising and content recommendation CTR prediction",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "content recommendation",
      "user engagement"
    ],
    "summary": "The Outbrain Click Prediction Dataset is a large-scale content recommendation dataset that includes 2 billion page views and user engagement data. It can be used to analyze user behavior and improve recommendation algorithms in native advertising.",
    "use_cases": [
      "Analyzing user engagement patterns",
      "Improving recommendation algorithms",
      "Evaluating the effectiveness of native advertising",
      "Predicting click-through rates"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Outbrain click prediction dataset",
      "content recommendation datasets",
      "native advertising datasets",
      "user engagement data from Outbrain",
      "datasets for ad tech analysis",
      "large-scale click prediction datasets"
    ],
    "domain_tags": [
      "advertising",
      "technology"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "14 days",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Amazon Fine Foods Reviews",
    "description": "500,000+ food product reviews from Amazon spanning 1999-2012. Includes user/product IDs, ratings, helpfulness votes, and full review text. Popular for sentiment analysis and review-based recommendations.",
    "category": "MarTech & Customer Analytics",
    "url": "https://snap.stanford.edu/data/web-FineFoods.html",
    "docs_url": "https://snap.stanford.edu/data/web-FineFoods.html",
    "github_url": null,
    "tags": [
      "reviews",
      "sentiment",
      "food",
      "NLP",
      "recommendations"
    ],
    "best_for": "Learning sentiment analysis, review mining, and hybrid recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "sentiment-analysis"
    ],
    "summary": "The Amazon Fine Foods Reviews dataset contains over 500,000 food product reviews from Amazon, spanning the years 1999 to 2012. It can be used for sentiment analysis and to develop review-based recommendation systems.",
    "use_cases": [
      "Sentiment analysis of food product reviews",
      "Building recommendation systems based on user reviews",
      "Analyzing consumer behavior in food purchases",
      "Evaluating the helpfulness of reviews based on votes"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Amazon Fine Foods Reviews?",
      "How can I analyze food product reviews from Amazon?",
      "Where can I find sentiment analysis datasets?",
      "What is the size of the Amazon Fine Foods Reviews dataset?",
      "How to perform NLP on Amazon reviews?",
      "What are common use cases for food product reviews?",
      "Can I access Amazon reviews for sentiment analysis?",
      "What data is included in the Amazon Fine Foods Reviews dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "temporal_coverage": "1999-2012",
    "model_score": 0.0001
  },
  {
    "name": "Google Cloud Public Datasets",
    "description": "20+ petabytes across 200+ datasets with 1TB free BigQuery queries monthly",
    "category": "Dataset Aggregators",
    "url": "https://cloud.google.com/datasets",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cloud",
      "BigQuery",
      "climate",
      "blockchain",
      "COVID"
    ],
    "best_for": "SQL-based analysis of climate, blockchain, and Google Trends data",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Google Cloud Public Datasets provides access to over 20 petabytes of data across more than 200 datasets. Users can utilize this extensive data repository for various analyses, including cloud computing, climate studies, and more.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are Google Cloud Public Datasets?",
      "How to access Google Cloud Public Datasets?",
      "What types of data are available in Google Cloud Public Datasets?",
      "Can I use BigQuery with Google Cloud Public Datasets?",
      "What is the size of Google Cloud Public Datasets?",
      "Are there free queries available for Google Cloud Public Datasets?",
      "What topics do Google Cloud Public Datasets cover?",
      "How many datasets are included in Google Cloud Public Datasets?"
    ],
    "domain_tags": [
      "cloud",
      "climate",
      "blockchain",
      "healthcare"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Wayfair Search (WANDS)",
    "description": "233k human-annotated query-product judgments, 43k products",
    "category": "E-Commerce",
    "url": "https://github.com/wayfair/WANDS",
    "docs_url": null,
    "github_url": "https://github.com/wayfair/WANDS",
    "tags": [
      "search relevance",
      "annotations",
      "furniture"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "search relevance",
      "annotations"
    ],
    "summary": "The Wayfair Search (WANDS) dataset contains 233k human-annotated query-product judgments across 43k products. It can be used to analyze search relevance in e-commerce contexts, particularly for furniture products.",
    "use_cases": [
      "Analyzing search relevance for furniture products",
      "Improving product recommendations based on query judgments",
      "Studying consumer behavior in e-commerce",
      "Evaluating the effectiveness of search algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Wayfair Search dataset?",
      "How many products are included in the Wayfair Search dataset?",
      "What types of judgments are included in the Wayfair Search dataset?",
      "What is the focus of the Wayfair Search dataset?",
      "How can I use the Wayfair Search dataset for search relevance analysis?",
      "What are the tags associated with the Wayfair Search dataset?",
      "What is the size of the Wayfair Search dataset?",
      "Where can I find the Wayfair Search dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Ele.me Clickstream",
    "description": "Clickstream data from Ele.me food delivery platform",
    "category": "Food & Delivery",
    "url": "https://tianchi.aliyun.com/dataset/131047",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "clickstream",
      "food delivery",
      "user behavior"
    ],
    "best_for": "Learning food & delivery analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Ele.me Clickstream dataset contains clickstream data from the Ele.me food delivery platform, providing insights into user behavior and interactions with the platform. Analysts can use this data to understand consumer preferences and improve service offerings.",
    "use_cases": [
      "Analyzing user behavior patterns",
      "Improving food delivery service efficiency",
      "Understanding consumer preferences in food delivery"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is Ele.me clickstream data?",
      "How can I analyze user behavior in food delivery?",
      "What insights can be gained from Ele.me's clickstream data?",
      "Where can I find Ele.me clickstream datasets?",
      "What are common analysis methods for clickstream data?",
      "How does Ele.me data inform food delivery trends?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Home Depot Product Search",
    "description": "Human-rated relevance scores (1-3) for search terms and products",
    "category": "E-Commerce",
    "url": "https://www.kaggle.com/datasets/thedevastator/the-home-depot-products-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "search relevance",
      "retail",
      "Kaggle"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "search relevance"
    ],
    "summary": "This dataset contains human-rated relevance scores for search terms and products from Home Depot. It can be used to analyze how well search terms match products and improve search algorithms.",
    "use_cases": [
      "Analyzing search term effectiveness",
      "Improving product recommendations",
      "Optimizing search algorithms"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the relevance score for 'lawn mower'?",
      "How do search terms correlate with product sales?",
      "Which products have the highest relevance scores?",
      "What are the most common search terms?",
      "How can I improve search relevance for home improvement products?",
      "What factors influence search relevance scores?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Innerwear Data",
    "description": "Data scraped from Victoria's Secret and other innerwear retailers",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "retail",
      "scraped data"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Innerwear Data consists of information scraped from Victoria's Secret and other innerwear retailers. This dataset can be used to analyze trends in fashion retail, consumer preferences, and pricing strategies.",
    "use_cases": [
      "Analyzing pricing strategies of innerwear brands",
      "Studying consumer preferences in fashion",
      "Comparing sales data across different retailers"
    ],
    "audience": [
      "Junior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Innerwear Data dataset?",
      "Where can I find data on innerwear retail?",
      "How to analyze fashion retail data?",
      "What insights can be gained from Victoria's Secret sales data?",
      "Is there a dataset for innerwear consumer behavior?",
      "What are the trends in innerwear fashion?",
      "Where to access scraped data on fashion?",
      "What data is available on innerwear pricing?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Metacritic Video Games",
    "description": "Video game reviews and metadata from Metacritic",
    "category": "Entertainment & Media",
    "url": "https://tianchi.aliyun.com/dataset/144719",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "video games",
      "reviews",
      "ratings"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Metacritic Video Games dataset contains reviews and metadata for various video games aggregated from Metacritic. This dataset can be used to analyze trends in video game ratings and consumer preferences.",
    "use_cases": [
      "Analyzing video game ratings over time",
      "Comparing critic and user reviews",
      "Identifying trends in video game genres",
      "Evaluating the impact of reviews on sales"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest video game reviews on Metacritic?",
      "How do video game ratings vary by genre?",
      "What is the average rating for top-rated video games?",
      "Which video games have the most reviews on Metacritic?",
      "How do user ratings compare to critic ratings for video games?",
      "What are the trends in video game reviews over the years?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Montgomery Liquor",
    "description": "Warehouse and retail liquor sales from Montgomery County, Maryland",
    "category": "Grocery & Supermarkets",
    "url": "https://data.montgomerycountymd.gov/Community-Recreation/Warehouse-and-Retail-Sales/v76h-r7br",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "liquor",
      "retail",
      "government data"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "pricing"
    ],
    "summary": "The Montgomery Liquor dataset contains information on warehouse and retail liquor sales in Montgomery County, Maryland. It can be used to analyze consumer purchasing patterns, pricing strategies, and the impact of government regulations on liquor sales.",
    "use_cases": [
      "Analyzing the impact of pricing on liquor sales.",
      "Studying consumer behavior in liquor purchasing.",
      "Evaluating the effects of government policies on retail liquor sales."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the liquor sales trends in Montgomery County?",
      "How do government regulations affect liquor retail sales?",
      "What is the average price of liquor in Montgomery County?",
      "What types of liquor are most popular in Montgomery County?",
      "How do seasonal changes impact liquor sales?",
      "What demographic factors influence liquor purchasing behavior in Montgomery County?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Montgomery County, Maryland",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Brazil Medical",
    "description": "Medicine sales data in Brazil",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tgomesjuliana/brazil-medicine-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Brazil",
      "healthcare"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains medicine sales data in Brazil, providing insights into the pharmaceutical market. Analysts can use this data to study sales trends, consumer behavior, and market dynamics in the healthcare sector.",
    "use_cases": [
      "Analyzing sales trends in the pharmaceutical market",
      "Studying consumer behavior in healthcare purchases"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Brazil medicine sales data",
      "pharmaceutical sales in Brazil",
      "healthcare market data Brazil",
      "Brazil grocery sales statistics",
      "medicine sales trends Brazil",
      "Brazil healthcare data analysis"
    ],
    "domain_tags": [
      "retail",
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Brazil",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Turkish Drugs",
    "description": "Drug sales data from Turkey",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/emrahaydemr/drug-sales-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "pharmaceuticals",
      "Turkey",
      "sales"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains drug sales data from Turkey, providing insights into the pharmaceutical market. It can be used for analyzing sales trends, consumer behavior, and market dynamics in the grocery and supermarket sector.",
    "use_cases": [
      "Analyzing sales trends over time",
      "Comparing pharmaceutical sales across different regions in Turkey"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Turkish drug sales data",
      "pharmaceutical sales in Turkey",
      "Turkey grocery sales statistics",
      "drug market analysis Turkey",
      "pharmaceutical industry data Turkey",
      "sales trends in Turkish supermarkets"
    ],
    "domain_tags": [
      "retail",
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Turkey",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Vietnam Supermarket",
    "description": "Sales and inventory snapshot data from Vietnamese supermarket",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/tienanh2003/sales-and-inventory-snapshot-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "supermarket",
      "Vietnam",
      "inventory"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains sales and inventory snapshot data from a Vietnamese supermarket. It can be used to analyze consumer purchasing patterns and inventory management strategies.",
    "use_cases": [
      "Analyzing sales trends over time",
      "Evaluating inventory turnover rates",
      "Understanding consumer purchasing behavior"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Vietnam supermarket sales data",
      "Vietnam inventory dataset",
      "supermarket sales analysis Vietnam",
      "Vietnam grocery store inventory",
      "Vietnamese supermarket data",
      "sales trends in Vietnamese supermarkets"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Vietnam",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Israeli Grocery",
    "description": "Grocery purchase data from Israel",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/arielpazsawicki/kimonaim",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Israel",
      "purchases"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "The Israeli Grocery dataset contains grocery purchase data from Israel, providing insights into consumer buying habits and trends in the grocery sector. It can be used for analysis of purchasing patterns, price sensitivity, and market segmentation.",
    "use_cases": [
      "Analyzing consumer purchasing trends",
      "Evaluating price sensitivity in grocery shopping",
      "Market segmentation based on grocery purchases"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Israeli grocery purchase data",
      "grocery data from Israel",
      "Israel supermarket purchases dataset",
      "consumer behavior in Israeli grocery shopping",
      "grocery spending trends in Israel",
      "data on grocery purchases in Israel"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Israel",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Indonesian Fashion",
    "description": "Fashion items for image classification tasks from Indonesia",
    "category": "Fashion & Apparel",
    "url": "https://www.kaggle.com/datasets/latifahhukma/fashion-campus",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fashion",
      "image classification",
      "Indonesia"
    ],
    "best_for": "Learning fashion & apparel analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Indonesian Fashion dataset contains fashion items specifically curated for image classification tasks in the context of Indonesian fashion. This dataset can be utilized to train models for recognizing and categorizing various fashion items.",
    "use_cases": [
      "Training image classification models",
      "Analyzing fashion trends in Indonesia"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "Indonesian fashion image dataset",
      "fashion items for image classification Indonesia",
      "image classification dataset Indonesia",
      "fashion dataset for machine learning",
      "Indonesian apparel image classification",
      "fashion image dataset for training models"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "image",
    "geographic_scope": "Indonesia",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Russian Car Market",
    "description": "Car sales information in Russia",
    "category": "Automotive",
    "url": "https://www.kaggle.com/datasets/ekibee/car-sales-information",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cars",
      "Russia",
      "sales"
    ],
    "best_for": "Learning automotive analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains information on car sales in Russia, providing insights into market trends and consumer preferences. It can be used for analysis of sales patterns and forecasting future market behavior.",
    "use_cases": [
      "Analyzing sales trends over time",
      "Comparing sales data across different car brands",
      "Forecasting future car sales in Russia"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the latest car sales figures in Russia?",
      "How do car sales in Russia compare to previous years?",
      "What are the most popular car brands in Russia?",
      "What factors influence car sales in Russia?",
      "What trends are emerging in the Russian car market?",
      "How do economic conditions affect car sales in Russia?"
    ],
    "domain_tags": [
      "automotive"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Russia",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Ipinyou RTB",
    "description": "Real-time bidding (RTB) dataset for CTR prediction",
    "category": "Advertising",
    "url": "https://github.com/wnzhang/make-ipinyou-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "RTB",
      "advertising",
      "CTR",
      "programmatic"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Ipinyou RTB dataset provides data for real-time bidding in advertising, specifically aimed at predicting click-through rates (CTR). It can be used to analyze bidding strategies and improve advertising effectiveness.",
    "use_cases": [
      "Predicting click-through rates for online ads",
      "Analyzing bidding strategies in real-time advertising"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Ipinyou RTB dataset?",
      "How to use the Ipinyou RTB dataset for CTR prediction?",
      "Where can I find the Ipinyou RTB dataset?",
      "What are the applications of the Ipinyou RTB dataset?",
      "Is the Ipinyou RTB dataset publicly available?",
      "What are the features of the Ipinyou RTB dataset?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Chicago Property Data",
    "description": "Property assessment values and sales data from Cook County",
    "category": "Real Estate",
    "url": "https://datacatalog.cookcountyil.gov/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "property",
      "Chicago",
      "assessments",
      "government"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Chicago Property Data includes property assessment values and sales data from Cook County. This dataset can be used for analyzing real estate trends, property valuation, and market dynamics in Chicago.",
    "use_cases": [
      "Analyzing property value trends over time",
      "Comparing assessment values to sales prices",
      "Identifying neighborhoods with rising property values"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Chicago property assessment data",
      "Cook County sales data",
      "property values in Chicago",
      "real estate trends Chicago",
      "Cook County property data analysis",
      "Chicago government property assessments"
    ],
    "domain_tags": [
      "real estate"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Cook County, Chicago",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Wikipedia Pageviews",
    "description": "296B views/year since 2007. Hourly pageview data for all Wikimedia projects. attention metrics at scale",
    "category": "Social & Web",
    "url": "https://dumps.wikimedia.org/other/pageviews/",
    "docs_url": "https://dumps.wikimedia.org/other/pageviews/readme.html",
    "github_url": null,
    "tags": [
      "Wikipedia",
      "pageviews",
      "attention",
      "time-series",
      "large-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Wikipedia Pageviews dataset provides hourly pageview data for all Wikimedia projects, capturing attention metrics at scale. It allows for analysis of trends in user engagement and content popularity over time.",
    "use_cases": [
      "Analyzing trends in user engagement on Wikipedia over time.",
      "Comparing pageviews across different Wikimedia projects.",
      "Investigating the impact of events on Wikipedia pageviews.",
      "Studying content popularity based on pageview metrics."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the hourly pageviews for Wikipedia?",
      "How can I analyze trends in Wikipedia pageviews?",
      "What metrics are available in the Wikipedia Pageviews dataset?",
      "How has Wikipedia's traffic changed over the years?",
      "What are the attention metrics for Wikimedia projects?",
      "Where can I find large-scale pageview data for Wikipedia?",
      "What is the significance of pageviews in understanding user engagement?",
      "How do I access hourly pageview data for Wikimedia?"
    ],
    "domain_tags": [
      "media",
      "education"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "2007-present",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Amazon AWS Open Data",
    "description": "Registry of Open Data with analysis-ready datasets",
    "category": "Data Portals",
    "url": "https://registry.opendata.aws/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "AWS",
      "open data",
      "cloud",
      "various"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Amazon AWS Open Data is a registry that provides access to various open datasets that are ready for analysis. Users can leverage these datasets for a wide range of applications, including research and data analysis in cloud environments.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Amazon AWS Open Data?",
      "How to access datasets on Amazon AWS Open Data?",
      "What types of datasets are available in AWS Open Data?",
      "How can I analyze datasets from Amazon AWS Open Data?",
      "What is the purpose of Amazon AWS Open Data?",
      "Where can I find open data on AWS?"
    ],
    "domain_tags": [
      "cloud"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NeurIPS Competition Data",
    "description": "Top-tier conference with competitions and benchmarks",
    "category": "Data Portals",
    "url": "https://nips.cc/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "NeurIPS",
      "ML",
      "benchmarks"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NeurIPS Competition Data is associated with a top-tier conference that features various competitions and benchmarks in machine learning. This dataset can be used to evaluate algorithms and compare performance across different tasks.",
    "use_cases": [
      "Evaluating machine learning algorithms",
      "Comparing performance across benchmarks"
    ],
    "audience": [
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NeurIPS Competition Data?",
      "How can I access NeurIPS competition datasets?",
      "What benchmarks are included in NeurIPS Competition Data?",
      "What machine learning tasks are covered by NeurIPS competitions?",
      "Where can I find NeurIPS datasets for research?",
      "What are the competitions held at NeurIPS?"
    ],
    "domain_tags": [
      "technology",
      "education"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Data Mining Cup",
    "description": "Industry-sponsored data mining competitions",
    "category": "Data Portals",
    "url": "https://www.data-mining-cup.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "data mining",
      "industry",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Data Mining Cup is a series of industry-sponsored competitions focused on data mining. Participants can engage in solving real-world problems using data mining techniques.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Data Mining Cup?",
      "How to participate in data mining competitions?",
      "What are industry-sponsored data mining competitions?",
      "Data Mining Cup past competitions",
      "Data Mining Cup challenges",
      "Data Mining Cup results"
    ],
    "domain_tags": [
      "industry"
    ],
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "DrivenData",
    "description": "Data science competitions for social impact",
    "category": "Data Portals",
    "url": "https://www.drivendata.org/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "social impact",
      "competitions",
      "non-profit"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "DrivenData hosts data science competitions aimed at creating social impact. Participants can engage in various challenges that leverage data to solve pressing social issues.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is DrivenData?",
      "How to participate in DrivenData competitions?",
      "What types of data science competitions are available on DrivenData?",
      "What is the focus of DrivenData?",
      "How does DrivenData contribute to social impact?",
      "What skills are needed for DrivenData competitions?",
      "Where can I find data science competitions for social good?",
      "What are the benefits of joining DrivenData?"
    ],
    "domain_tags": [
      "non-profit"
    ],
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "CodaLab",
    "description": "Platform for competitions, benchmarks, and reproducible research",
    "category": "Data Portals",
    "url": "https://codalab.lisn.upsaclay.fr/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "benchmarks",
      "reproducibility",
      "competitions"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "CodaLab is a platform designed for hosting competitions, benchmarks, and facilitating reproducible research. Users can engage in various challenges and utilize the platform to validate their research findings.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is CodaLab?",
      "How to participate in CodaLab competitions?",
      "What benchmarks are available on CodaLab?",
      "How does CodaLab support reproducible research?",
      "What types of competitions can be found on CodaLab?",
      "How to use CodaLab for research validation?"
    ],
    "domain_tags": [
      "research",
      "technology"
    ],
    "size_category": "medium",
    "benchmark_usage": [
      "Competitions",
      "Benchmarks",
      "Reproducible research"
    ],
    "model_score": 0.0001
  },
  {
    "name": "NBER Public Use Data Archive",
    "description": "Eclectic mix of economic, demographic, and enterprise data from NBER-affiliated research projects",
    "category": "Data Portals",
    "url": "https://www.nber.org/research/data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "research",
      "research",
      "NBER",
      "demographics",
      "enterprise"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NBER Public Use Data Archive provides an eclectic mix of economic, demographic, and enterprise data sourced from various NBER-affiliated research projects. Researchers can utilize this dataset for a wide range of analyses related to economic trends and demographic studies.",
    "use_cases": [
      "Analyzing economic trends over time",
      "Studying demographic changes in specific populations",
      "Evaluating enterprise performance using NBER data"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the NBER Public Use Data Archive?",
      "How can I access NBER economic data?",
      "What types of data are available in the NBER archive?",
      "Where can I find demographic data from NBER?",
      "What research projects are affiliated with NBER?",
      "How to use NBER data for enterprise analysis?",
      "What are the key features of the NBER Public Use Data Archive?",
      "What economic data does NBER provide?"
    ],
    "domain_tags": [
      "economics",
      "demographics",
      "enterprise"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Census Business Dynamics Statistics",
    "description": "8M+ establishments with firm age data. Job creation/destruction, startups, exits. Longitudinal firm dynamics since 1977",
    "category": "Data Portals",
    "url": "https://www.census.gov/programs-surveys/bds.html",
    "docs_url": "https://www.census.gov/programs-surveys/bds/documentation.html",
    "github_url": null,
    "tags": [
      "Census",
      "firm dynamics",
      "startups",
      "employment",
      "longitudinal"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Census Business Dynamics Statistics dataset provides extensive data on over 8 million establishments, focusing on firm age, job creation and destruction, startups, and exits. This longitudinal dataset allows for in-depth analysis of firm dynamics since 1977.",
    "use_cases": [
      "Analyzing trends in job creation and destruction over time.",
      "Studying the impact of firm age on startup success rates.",
      "Investigating the dynamics of business exits in various sectors."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Census Business Dynamics Statistics?",
      "How can I access firm age data from the Census?",
      "What insights can be gained from job creation and destruction statistics?",
      "Where can I find data on startups and exits?",
      "What longitudinal firm dynamics data is available since 1977?",
      "How many establishments are included in the Census Business Dynamics dataset?"
    ],
    "domain_tags": [
      "business",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1977-present",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "YFCC100M",
    "description": "100M Flickr photos/videos with metadata under Creative Commons. Yahoo/Flickr dataset for multimedia research",
    "category": "Entertainment & Media",
    "url": "https://multimediacommons.wordpress.com/yfcc100m-core-dataset/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Flickr",
      "photos",
      "video",
      "multimedia",
      "Creative Commons"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The YFCC100M dataset consists of 100 million Flickr photos and videos along with their metadata, available under Creative Commons licenses. It is primarily used for multimedia research, allowing users to analyze and explore a vast collection of visual content.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Where can I find the YFCC100M dataset?",
      "What is the YFCC100M dataset used for?",
      "How to access the YFCC100M Flickr dataset?",
      "What types of media are included in the YFCC100M dataset?",
      "Is the YFCC100M dataset available under Creative Commons?",
      "What metadata is available in the YFCC100M dataset?",
      "How large is the YFCC100M dataset?",
      "What research can be conducted using the YFCC100M dataset?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "SNAP Facebook Ego Networks",
    "description": "4K users with social circles and anonymized node features. Stanford Network Analysis Project dataset",
    "category": "Social & Web",
    "url": "https://snap.stanford.edu/data/ego-Facebook.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "social network",
      "ego networks",
      "SNAP",
      "Stanford"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The SNAP Facebook Ego Networks dataset contains data from 4,000 users, including their social circles and anonymized node features. This dataset can be used to analyze social network structures and user interactions within Facebook.",
    "use_cases": [
      "Analyzing social network dynamics",
      "Studying user behavior in online communities",
      "Investigating the structure of social circles",
      "Exploring anonymized user features"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the SNAP Facebook Ego Networks dataset?",
      "How can I analyze Facebook user interactions?",
      "What features are included in the SNAP dataset?",
      "Where can I find social network datasets?",
      "What are ego networks in social media?",
      "How to use SNAP datasets for research?",
      "What insights can be gained from Facebook ego networks?",
      "What is the Stanford Network Analysis Project?"
    ],
    "domain_tags": [
      "social media",
      "network analysis"
    ],
    "data_modality": "graph",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "US 2020 Election Study",
    "description": "Facebook/Instagram impact on political attitudes. Published in Science/Nature 2023. SOMAR Michigan access",
    "category": "Social & Web",
    "url": "https://www.icpsr.umich.edu/web/ICPSR/series/2045",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Facebook",
      "Instagram",
      "elections",
      "politics",
      "social media"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The US 2020 Election Study examines the impact of Facebook and Instagram on political attitudes during the 2020 election. This dataset can be used to analyze social media's influence on voter behavior and political engagement.",
    "use_cases": [
      "Analyze the influence of social media on political engagement",
      "Study the relationship between social media usage and voting behavior"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the impact of Facebook on political attitudes?",
      "How does Instagram influence voter behavior?",
      "What are the effects of social media on elections?",
      "US 2020 Election Study dataset",
      "Political attitudes and social media",
      "Facebook elections study 2020"
    ],
    "domain_tags": [
      "politics",
      "social media"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Glassdoor Reviews",
    "description": "Company ratings, salary reports, interview experiences. Employer review platform data for labor analytics",
    "category": "Labor Markets",
    "url": "https://www.glassdoor.com/research/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "salaries",
      "company reviews",
      "interviews",
      "employer ratings"
    ],
    "best_for": "Learning labor markets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Glassdoor Reviews dataset contains company ratings, salary reports, and interview experiences, providing insights into employer performance and employee satisfaction. This data can be used for labor analytics to assess workplace conditions and compensation trends.",
    "use_cases": [
      "Analyzing salary trends across different companies",
      "Comparing employer ratings within a specific industry",
      "Evaluating interview experiences to improve recruitment processes"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the average salaries reported on Glassdoor?",
      "How do company ratings vary by industry?",
      "What interview experiences are shared by candidates?",
      "What trends can be observed in employer ratings over time?",
      "How do salaries compare between different companies?",
      "What factors influence employee reviews on Glassdoor?"
    ],
    "domain_tags": [
      "labor markets"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "HateXplain",
    "description": "20K social media posts with human rationales across 10 hate speech target categories. Explainable AI for content moderation",
    "category": "Content Moderation",
    "url": "https://github.com/hate-alert/HateXplain",
    "docs_url": null,
    "github_url": "https://github.com/hate-alert/HateXplain",
    "tags": [
      "hate speech",
      "explainability",
      "NLP",
      "content moderation",
      "annotations"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "intermediate",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "HateXplain is a dataset containing 20,000 social media posts annotated with human rationales across 10 categories of hate speech. It can be used for developing explainable AI models for content moderation and understanding hate speech dynamics.",
    "use_cases": [
      "Training models for hate speech detection",
      "Analyzing hate speech trends on social media",
      "Developing explainable AI for content moderation"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the HateXplain dataset?",
      "How can I access the HateXplain dataset?",
      "What types of hate speech does HateXplain cover?",
      "What are the applications of the HateXplain dataset?",
      "How is explainability achieved in HateXplain?",
      "What are the key features of the HateXplain dataset?",
      "Can HateXplain be used for NLP tasks?",
      "What is the size of the HateXplain dataset?"
    ],
    "domain_tags": [
      "social media",
      "AI",
      "NLP"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Hate Speech Data Catalogue",
    "description": "50+ hate speech datasets across languages compiled at hatespeechdata.com. Meta-resource for content moderation research",
    "category": "Content Moderation",
    "url": "https://hatespeechdata.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hate speech",
      "catalogue",
      "multilingual",
      "meta-dataset"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Hate Speech Data Catalogue is a compilation of over 50 datasets related to hate speech across various languages. It serves as a meta-resource for researchers focusing on content moderation and the analysis of hate speech.",
    "use_cases": [
      "Analyzing hate speech trends across languages",
      "Developing content moderation algorithms",
      "Researching the impact of hate speech on social media",
      "Comparative analysis of hate speech in different cultures"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the available hate speech datasets?",
      "How can I access multilingual hate speech data?",
      "What is the Hate Speech Data Catalogue?",
      "What datasets are included in content moderation research?",
      "Where can I find hate speech datasets?",
      "What languages are covered in the hate speech datasets?"
    ],
    "domain_tags": [
      "content moderation"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "LIAR Fact-Checking",
    "description": "12.8K fact-checked political statements with speaker metadata and 6-way truthfulness labels. Politifact benchmark",
    "category": "Content Moderation",
    "url": "https://www.cs.ucsb.edu/~william/data/liar_dataset.zip",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fact-checking",
      "politics",
      "misinformation",
      "NLP",
      "Politifact"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "fact-checking",
      "politics",
      "misinformation",
      "NLP"
    ],
    "summary": "The LIAR Fact-Checking dataset contains 12.8K fact-checked political statements along with speaker metadata and six truthfulness labels. It can be used for training models in natural language processing and evaluating the accuracy of political statements.",
    "use_cases": [
      "Training NLP models for fact-checking",
      "Analyzing political statement accuracy",
      "Evaluating misinformation in political discourse"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the LIAR Fact-Checking dataset?",
      "How can I access the LIAR Fact-Checking dataset?",
      "What are the truthfulness labels in the LIAR dataset?",
      "What type of statements are included in the LIAR dataset?",
      "How many entries are in the LIAR Fact-Checking dataset?",
      "What metadata is available in the LIAR dataset?",
      "How does the LIAR dataset compare to Politifact?",
      "What are common use cases for the LIAR dataset?"
    ],
    "domain_tags": [
      "politics"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "benchmark_usage": [
      "Politifact benchmark"
    ],
    "model_score": 0.0001
  },
  {
    "name": "FakeNewsNet",
    "description": "23K news articles labeled fake/real with social context. Includes PolitiFact and GossipCop sources",
    "category": "Content Moderation",
    "url": "https://github.com/KaiDMML/FakeNewsNet",
    "docs_url": null,
    "github_url": "https://github.com/KaiDMML/FakeNewsNet",
    "tags": [
      "fake news",
      "misinformation",
      "social media",
      "fact-checking"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "FakeNewsNet is a dataset containing 23,000 news articles labeled as fake or real, along with their social context. It can be used for analyzing misinformation, training models for fact-checking, and studying the spread of fake news on social media.",
    "use_cases": [
      "Analyzing the spread of misinformation on social media",
      "Training machine learning models for fact-checking",
      "Studying the characteristics of fake news articles",
      "Evaluating the effectiveness of content moderation tools"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the FakeNewsNet dataset?",
      "How can I access the FakeNewsNet dataset?",
      "What are the sources of the FakeNewsNet dataset?",
      "What types of articles are included in the FakeNewsNet dataset?",
      "How is the FakeNewsNet dataset labeled?",
      "What research can be done using the FakeNewsNet dataset?",
      "What is the size of the FakeNewsNet dataset?",
      "What is the purpose of the FakeNewsNet dataset?"
    ],
    "domain_tags": [
      "media",
      "technology"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Social Blade",
    "description": "Public subscriber/follower counts and growth metrics across YouTube, Twitch, Instagram, Twitter, TikTok",
    "category": "Creator Economy",
    "url": "https://socialblade.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "YouTube",
      "Twitch",
      "Instagram",
      "followers",
      "growth metrics"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Social Blade provides public subscriber and follower counts along with growth metrics for various social media platforms. This data can be used to analyze trends in social media growth and engagement across platforms like YouTube, Twitch, and Instagram.",
    "use_cases": [
      "Analyzing social media growth trends over time.",
      "Comparing follower counts across different platforms.",
      "Evaluating the impact of content strategies on subscriber growth.",
      "Identifying popular creators in the creator economy."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the subscriber counts for YouTube channels?",
      "How can I track follower growth on Instagram?",
      "What metrics does Social Blade provide for Twitch?",
      "How to analyze TikTok follower growth?",
      "What are the growth metrics for Twitter accounts?",
      "How does Social Blade calculate social media metrics?"
    ],
    "domain_tags": [
      "creator economy"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Creator Economy Reports",
    "description": "Survey-based earnings breakdowns by platform (YouTube, TikTok, Instagram, Twitch). Influencer Marketing Factory research",
    "category": "Creator Economy",
    "url": "https://theinfluencermarketingfactory.com/creator-economy/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "creator economy",
      "earnings",
      "influencers",
      "surveys"
    ],
    "best_for": "Learning creator economy analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Creator Economy Reports provide survey-based earnings breakdowns for influencers across various platforms such as YouTube, TikTok, Instagram, and Twitch. This dataset can be used to analyze earnings trends and platform-specific performance in the creator economy.",
    "use_cases": [
      "Analyzing earnings trends by platform",
      "Comparing influencer earnings across different social media",
      "Understanding the impact of platform choice on influencer income"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the earnings of influencers on YouTube?",
      "How do TikTok earnings compare to Instagram?",
      "What platforms are most profitable for influencers?",
      "What trends can be observed in influencer earnings?",
      "How does the creator economy vary by platform?",
      "What factors influence earnings in the creator economy?",
      "What are the survey results for Twitch influencers?",
      "How do earnings differ among various social media platforms?"
    ],
    "domain_tags": [
      "creator economy"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Criteo Terabyte",
    "description": "342GB, 45M samples with 13 integer features and 26 hashed categorical features for CTR prediction",
    "category": "Advertising",
    "url": "https://huggingface.co/datasets/criteo/CriteoClickLogs",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "CTR",
      "advertising",
      "large-scale",
      "benchmark"
    ],
    "best_for": "Learning advertising analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Criteo Terabyte dataset contains 342GB of data with 45 million samples, featuring 13 integer and 26 hashed categorical features, primarily used for click-through rate (CTR) prediction in advertising. It serves as a benchmark for large-scale machine learning tasks in the advertising domain.",
    "use_cases": [
      "Predicting click-through rates for online advertisements",
      "Benchmarking machine learning algorithms on large-scale datasets"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Criteo Terabyte dataset?",
      "How can I use the Criteo dataset for CTR prediction?",
      "What features are included in the Criteo Terabyte dataset?",
      "Where can I download the Criteo Terabyte dataset?",
      "What is the size of the Criteo Terabyte dataset?",
      "What are the applications of the Criteo dataset in advertising?",
      "How many samples are in the Criteo Terabyte dataset?",
      "What types of features does the Criteo dataset contain?"
    ],
    "domain_tags": [
      "advertising"
    ],
    "data_modality": "tabular",
    "size_category": "large",
    "benchmark_usage": [
      "CTR prediction"
    ],
    "model_score": 0.0001
  },
  {
    "name": "NBA Stats API",
    "description": "Official NBA statistics including shot charts, play-by-play, player tracking data, and historical records",
    "category": "Sports & Athletics",
    "url": "https://www.nba.com/stats/",
    "docs_url": "https://github.com/swar/nba_api/blob/master/docs/table_of_contents.md",
    "github_url": null,
    "tags": [
      "basketball",
      "NBA",
      "shot-charts",
      "tracking-data",
      "play-by-play"
    ],
    "best_for": "Basketball analytics, shot analysis, and player performance evaluation",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NBA Stats API provides official NBA statistics, including detailed shot charts, play-by-play data, player tracking information, and historical records. Users can analyze player performance, game outcomes, and trends in basketball statistics.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the official NBA statistics?",
      "How to access NBA shot charts?",
      "Where can I find NBA player tracking data?",
      "What is included in the NBA play-by-play data?",
      "How to analyze historical NBA records?",
      "What data does the NBA Stats API provide?",
      "How to use NBA statistics for analysis?",
      "Where to find basketball statistics online?"
    ],
    "use_cases": [
      "Analyzing player performance over a season",
      "Comparing team statistics in a specific game",
      "Visualizing shot distribution on the court",
      "Studying trends in player tracking data"
    ],
    "domain_tags": [
      "sports"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "StatsBomb Open Data",
    "description": "Free soccer event data with 3,400+ events per match including xG, freeze-frame data, and 360 player positioning. Includes Messi's complete La Liga career and multiple World Cups",
    "category": "Sports & Athletics",
    "url": "https://github.com/statsbomb/open-data",
    "docs_url": "https://github.com/statsbomb/open-data/tree/master/doc",
    "github_url": "https://github.com/statsbomb/open-data",
    "tags": [
      "soccer",
      "football",
      "event-data",
      "xG",
      "tracking-data"
    ],
    "best_for": "Soccer analytics, expected goals modeling, and tactical analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "StatsBomb Open Data provides free soccer event data with over 3,400 events per match, including metrics like expected goals (xG) and player positioning. This dataset can be utilized for in-depth analysis of soccer matches, player performance, and tactical insights.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is StatsBomb Open Data?",
      "Where can I find free soccer event data?",
      "How to analyze soccer match events using StatsBomb data?",
      "What metrics are included in StatsBomb Open Data?",
      "Can I access Messi's La Liga career statistics?",
      "What is xG in soccer analytics?",
      "How to use tracking data for soccer analysis?",
      "What are the applications of soccer event data?"
    ],
    "use_cases": [
      "Analyzing player performance over a season",
      "Studying tactical formations and strategies in soccer matches",
      "Comparing player statistics across different leagues",
      "Evaluating the impact of specific events on match outcomes"
    ],
    "domain_tags": [
      "sports",
      "analytics"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NHL API",
    "description": "Official NHL statistics and play-by-play data from 2010-present including shot locations, player stats, and game events",
    "category": "Sports & Athletics",
    "url": "https://api-web.nhle.com/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "hockey",
      "NHL",
      "play-by-play",
      "shot-locations",
      "player-stats"
    ],
    "best_for": "Hockey analytics, expected goals modeling, and player evaluation",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NHL API provides official statistics and play-by-play data for NHL games from 2010 to the present. Users can analyze player stats, shot locations, and game events to gain insights into hockey performance.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the official NHL statistics from 2010?",
      "How can I access NHL play-by-play data?",
      "What player stats are available in the NHL API?",
      "Where can I find shot location data for NHL games?",
      "What game events are tracked in the NHL API?",
      "How to analyze NHL statistics using the API?"
    ],
    "use_cases": [
      "Analyzing player performance over multiple seasons",
      "Visualizing shot locations for specific games",
      "Comparing team statistics in a given season"
    ],
    "domain_tags": [
      "sports",
      "athletics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2010-present",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NHTSA FARS (Fatality Analysis Reporting System)",
    "description": "Complete census of fatal traffic crashes in the United States since 1975 with vehicle, person, and crash-level details",
    "category": "Insurance & Actuarial",
    "url": "https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars",
    "docs_url": "https://crashstats.nhtsa.dot.gov/",
    "github_url": null,
    "tags": [
      "traffic-safety",
      "auto-insurance",
      "crash-data",
      "fatality-data",
      "vehicle-safety"
    ],
    "best_for": "Auto insurance risk modeling, safety analysis, and claims severity research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NHTSA FARS dataset provides a complete census of fatal traffic crashes in the United States since 1975, including detailed information about vehicles, individuals involved, and crash circumstances. This dataset can be used for analysis related to traffic safety, vehicle safety improvements, and insurance risk assessments.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NHTSA FARS dataset?",
      "How can I access the Fatality Analysis Reporting System data?",
      "What information is included in the NHTSA FARS dataset?",
      "What trends can be analyzed using fatal traffic crash data?",
      "How does the FARS dataset help in understanding vehicle safety?",
      "What are the implications of fatality data for auto insurance?",
      "Where can I find crash data for the United States?",
      "What years does the NHTSA FARS dataset cover?"
    ],
    "use_cases": [
      "Analyzing trends in fatal traffic crashes over time",
      "Assessing the impact of vehicle safety features on crash outcomes",
      "Evaluating the effectiveness of traffic safety regulations",
      "Conducting risk assessments for auto insurance pricing"
    ],
    "domain_tags": [
      "insurance",
      "transportation"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1975-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NOAA Storm Events Database",
    "description": "Detailed records of significant weather events including property and crop damage estimates from 1950-present",
    "category": "Insurance & Actuarial",
    "url": "https://www.ncdc.noaa.gov/stormevents/",
    "docs_url": "https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/",
    "github_url": null,
    "tags": [
      "weather-data",
      "catastrophe",
      "natural-disasters",
      "property-damage",
      "climate"
    ],
    "best_for": "Catastrophe modeling, climate risk assessment, and property insurance pricing",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NOAA Storm Events Database contains detailed records of significant weather events, including estimates of property and crop damage from 1950 to the present. This dataset can be used for analysis of the impact of natural disasters on property and agriculture, as well as for research in climate-related studies.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NOAA Storm Events Database?",
      "How can I access the NOAA Storm Events Database?",
      "What types of data are included in the NOAA Storm Events Database?",
      "What years does the NOAA Storm Events Database cover?",
      "How can I analyze property damage from weather events?",
      "What are the significant weather events recorded in the NOAA database?",
      "Where can I find data on natural disasters in the US?",
      "What is the significance of the NOAA Storm Events Database for climate research?"
    ],
    "use_cases": [
      "Analyzing trends in property damage due to natural disasters over time.",
      "Assessing the economic impact of significant weather events on agriculture.",
      "Researching the correlation between climate change and the frequency of severe weather events."
    ],
    "domain_tags": [
      "insurance",
      "agriculture",
      "climate"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1950-present",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Human Mortality Database",
    "description": "Detailed mortality and population data for 40+ countries with life tables and exposure-to-risk calculations",
    "category": "Insurance & Actuarial",
    "url": "https://www.mortality.org/",
    "docs_url": "https://www.mortality.org/Data/DataAvailability",
    "github_url": null,
    "tags": [
      "mortality",
      "life-insurance",
      "demographics",
      "life-tables",
      "longevity"
    ],
    "best_for": "Life insurance pricing, longevity research, and demographic modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Human Mortality Database provides detailed mortality and population data for over 40 countries, including life tables and exposure-to-risk calculations. This dataset can be used for various analyses related to demographics, life insurance, and longevity studies.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Human Mortality Database?",
      "How can I access mortality data for different countries?",
      "What are life tables and how are they calculated?",
      "What demographic information is available in the Human Mortality Database?",
      "How does the Human Mortality Database support life insurance analysis?",
      "What countries are included in the Human Mortality Database?",
      "Where can I find exposure-to-risk calculations?",
      "What are the applications of mortality data in research?"
    ],
    "use_cases": [
      "Analyzing trends in life expectancy across different countries.",
      "Studying the impact of demographics on mortality rates.",
      "Evaluating the effectiveness of life insurance policies based on mortality data.",
      "Conducting research on longevity and its influencing factors."
    ],
    "domain_tags": [
      "healthcare",
      "insurance"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "National Household Travel Survey (NHTS)",
    "description": "Comprehensive US travel behavior data since 1969 capturing daily non-commercial travel by all modes. The authoritative source on American travel patterns.",
    "category": "Transportation Economics & Technology",
    "url": "https://nhts.ornl.gov/",
    "docs_url": "https://nhts.ornl.gov/documentation",
    "github_url": null,
    "tags": [
      "travel-behavior",
      "survey",
      "mode-choice",
      "demographics",
      "commuting"
    ],
    "best_for": "Understanding travel demand patterns, mode choice analysis, and transportation planning",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The National Household Travel Survey (NHTS) provides comprehensive data on daily non-commercial travel behavior in the US since 1969. This dataset can be used to analyze travel patterns, mode choices, and demographic trends related to commuting.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the National Household Travel Survey?",
      "How can I access the NHTS data?",
      "What insights can be gained from the NHTS dataset?",
      "What modes of travel are included in the NHTS?",
      "How has travel behavior changed over the years according to the NHTS?",
      "What demographics are covered in the NHTS?",
      "What is the significance of the NHTS in transportation economics?",
      "Where can I find analysis based on the NHTS data?"
    ],
    "use_cases": [
      "Analyzing trends in commuting patterns over the decades.",
      "Studying the impact of demographics on mode choice for travel.",
      "Evaluating the effectiveness of transportation policies based on travel behavior.",
      "Comparing travel behavior across different regions in the US."
    ],
    "domain_tags": [
      "transportation"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1969-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "Medicare Claims (ResDAC)",
    "description": "Comprehensive claims data covering 98%+ of adults 65+ in the United States. Includes inpatient, outpatient, physician, and prescription drug claims. Research Identifiable Files require 6-12 month DUA approval.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://resdac.org/",
    "source": "CMS via Research Data Assistance Center",
    "type": "Claims Database",
    "access": "Fee-based (DUA required)",
    "format": "SAS/CSV",
    "tags": [
      "Healthcare",
      "Claims",
      "Medicare",
      "Administrative"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Medicare Claims dataset provides comprehensive claims data for over 98% of adults aged 65 and older in the United States. It includes various types of claims such as inpatient, outpatient, physician, and prescription drug claims, making it valuable for healthcare economics research.",
    "use_cases": [
      "Analyzing healthcare costs for the elderly",
      "Evaluating the effectiveness of Medicare programs",
      "Studying prescription drug usage among seniors",
      "Assessing trends in inpatient and outpatient care"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Medicare Claims dataset?",
      "How can I access Medicare claims data?",
      "What types of claims are included in the Medicare dataset?",
      "What is ResDAC?",
      "How to analyze Medicare claims data?",
      "What are Research Identifiable Files in Medicare claims?",
      "What is the approval process for accessing Medicare claims data?",
      "What insights can be gained from Medicare claims data?"
    ],
    "update_frequency": "Annual",
    "geographic_coverage": "United States (national)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "National Health Interview Survey (NHIS)",
    "description": "CDC's flagship health survey covering ~35,000 households annually since 1957. Monitors health status, healthcare access, and health behaviors. Free public use files with extensive documentation.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://www.cdc.gov/nchs/nhis/",
    "source": "CDC National Center for Health Statistics",
    "type": "Survey",
    "access": "Free public use files",
    "format": "SAS/Stata/CSV",
    "tags": [
      "Healthcare",
      "Survey",
      "Health Status",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The National Health Interview Survey (NHIS) is a comprehensive health survey that collects data on health status, healthcare access, and health behaviors from approximately 35,000 households annually. This dataset can be used for various analyses related to public health trends and healthcare utilization.",
    "use_cases": [
      "Analyzing trends in healthcare access over time",
      "Studying the relationship between health behaviors and health outcomes",
      "Evaluating the impact of public health interventions",
      "Comparing health status across different demographic groups"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the National Health Interview Survey?",
      "How can I access the NHIS public use files?",
      "What kind of data does the NHIS collect?",
      "What are the health behaviors monitored by the NHIS?",
      "How has healthcare access changed over the years according to NHIS?",
      "What is the significance of the NHIS in public health research?",
      "Where can I find documentation for the NHIS dataset?",
      "What trends can be analyzed using NHIS data?"
    ],
    "update_frequency": "Annual",
    "geographic_coverage": "United States (national)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "UK Biobank",
    "description": "Prospective cohort of 500,000 UK participants aged 40-69 with genetic data, imaging, and longitudinal health records. Extensive phenotyping including MRI, accelerometry, and linked hospital records.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://www.ukbiobank.ac.uk/",
    "source": "UK Biobank",
    "type": "Cohort + Biobank",
    "access": "Application required (fees apply)",
    "format": "Various",
    "tags": [
      "Healthcare",
      "Genomics",
      "Imaging",
      "Longitudinal"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The UK Biobank is a prospective cohort study involving 500,000 participants from the UK aged 40-69, providing extensive genetic data, imaging, and longitudinal health records. Researchers can utilize this dataset for various analyses related to health outcomes, genetics, and disease progression.",
    "use_cases": [
      "Analyzing the impact of genetics on health outcomes.",
      "Studying the relationship between imaging data and disease progression.",
      "Investigating longitudinal health trends in a large population.",
      "Exploring the effects of lifestyle factors on health using accelerometry data."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the UK Biobank dataset?",
      "How can I access genetic data from the UK Biobank?",
      "What types of health records are included in the UK Biobank?",
      "What imaging data is available in the UK Biobank?",
      "How many participants are in the UK Biobank?",
      "What is the age range of participants in the UK Biobank?",
      "What phenotyping methods are used in the UK Biobank?",
      "How can I use the UK Biobank for health-tech research?"
    ],
    "update_frequency": "Ongoing linkage",
    "geographic_coverage": "United Kingdom",
    "domain_tags": [
      "healthcare",
      "genomics",
      "imaging"
    ],
    "data_modality": "mixed",
    "geographic_scope": "UK",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "FDA Adverse Event Reporting System (FAERS)",
    "description": "Database of 21+ million adverse event reports for drugs and therapeutic biologics. Free API access through openFDA. Supports pharmacovigilance and drug safety research.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://open.fda.gov/data/faers/",
    "source": "FDA",
    "type": "Adverse Event Database",
    "access": "Free (API available)",
    "format": "JSON API/Downloads",
    "tags": [
      "Healthcare",
      "Drug Safety",
      "Pharmacovigilance",
      "Free",
      "API"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "healthcare",
      "drug-safety",
      "pharmacovigilance"
    ],
    "summary": "The FDA Adverse Event Reporting System (FAERS) is a comprehensive database containing over 21 million reports of adverse events related to drugs and therapeutic biologics. It provides free API access through openFDA, making it a valuable resource for pharmacovigilance and drug safety research.",
    "use_cases": [
      "Analyzing trends in drug-related adverse events",
      "Conducting safety assessments for new drug approvals",
      "Researching the effectiveness of pharmacovigilance practices"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the FDA Adverse Event Reporting System?",
      "How can I access the FAERS database?",
      "What data does the FAERS contain?",
      "What is pharmacovigilance?",
      "How can FAERS data be used in drug safety research?",
      "What are the adverse events reported in FAERS?"
    ],
    "update_frequency": "Quarterly",
    "geographic_coverage": "United States (primarily)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "EIA-860 Generator Inventory",
    "description": "Annual survey of all U.S. electric generators including capacity, technology, ownership, and location",
    "category": "Energy",
    "url": "https://www.eia.gov/electricity/data/eia860/",
    "docs_url": "https://www.eia.gov/electricity/data/eia860/",
    "github_url": null,
    "tags": [
      "generators",
      "capacity",
      "technology",
      "annual"
    ],
    "best_for": "Understanding the U.S. electricity generation fleet composition and trends",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EIA-860 Generator Inventory is an annual survey that provides comprehensive data on all electric generators in the U.S., including their capacity, technology, ownership, and location. This dataset can be utilized for analyzing trends in energy production, understanding the distribution of energy technologies, and assessing ownership structures in the electric generation sector.",
    "use_cases": [
      "Analyzing the capacity of different types of electric generators in the U.S.",
      "Studying trends in renewable energy technology adoption.",
      "Assessing the ownership distribution of electric generators.",
      "Evaluating the geographic distribution of electric generation capacity."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the EIA-860 Generator Inventory?",
      "How can I access the EIA-860 dataset?",
      "What information is included in the EIA-860 Generator Inventory?",
      "What technologies are represented in the EIA-860 dataset?",
      "How does the EIA-860 dataset help in energy analysis?",
      "What is the geographic coverage of the EIA-860 Generator Inventory?",
      "What types of generators are included in the EIA-860 dataset?",
      "How often is the EIA-860 Generator Inventory updated?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2001-present",
    "geographic_scope": "U.S.",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NREL NSRDB (National Solar Radiation Database)",
    "description": "High-resolution solar irradiance data covering the Americas with 30-minute temporal resolution",
    "category": "Energy",
    "url": "https://nsrdb.nrel.gov/",
    "docs_url": "https://nsrdb.nrel.gov/data-sets/api-instructions.html",
    "github_url": null,
    "tags": [
      "solar",
      "irradiance",
      "renewable",
      "weather",
      "API"
    ],
    "best_for": "Solar energy potential assessment and renewable energy forecasting",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NREL NSRDB provides high-resolution solar irradiance data for the Americas, allowing users to analyze solar energy potential and weather patterns. This dataset can be utilized for renewable energy research, solar panel optimization, and climate studies.",
    "use_cases": [
      "Analyzing solar energy potential for a specific location",
      "Optimizing solar panel placement based on irradiance data",
      "Studying the impact of weather on solar energy generation",
      "Conducting research on renewable energy trends"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NREL NSRDB?",
      "How can I access solar irradiance data?",
      "What are the applications of the National Solar Radiation Database?",
      "Where can I find high-resolution solar data for the Americas?",
      "What is the temporal resolution of the NREL NSRDB?",
      "How does solar irradiance data impact renewable energy projects?",
      "What types of data are included in the NREL NSRDB?",
      "Is there an API for accessing the National Solar Radiation Database?"
    ],
    "domain_tags": [
      "energy",
      "renewable"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "1998-present",
    "geographic_scope": "Americas",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "SIPRI Military Expenditure Database",
    "description": "Comprehensive annual military spending data covering all countries since 1949 in local currency, constant/current USD, and GDP shares",
    "category": "Defense Economics",
    "url": "https://www.sipri.org/databases/milex",
    "docs_url": "https://www.sipri.org/databases/milex/sources-and-methods",
    "github_url": null,
    "tags": [
      "military spending",
      "defense budgets",
      "international",
      "SIPRI"
    ],
    "best_for": "Cross-country defense spending analysis and burden-sharing studies",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The SIPRI Military Expenditure Database provides comprehensive annual data on military spending across all countries since 1949. This dataset allows for analysis of military budgets in various currencies and their relation to GDP.",
    "use_cases": [
      "Analyzing trends in military spending over decades",
      "Comparing military budgets of different countries",
      "Assessing the impact of military expenditure on national economies"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the SIPRI Military Expenditure Database?",
      "How has military spending changed since 1949?",
      "What are the defense budgets of different countries?",
      "How does military spending relate to GDP?",
      "What currencies are used in the SIPRI Military Expenditure Database?",
      "Where can I find historical military expenditure data?"
    ],
    "domain_tags": [
      "defense",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1949-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "SIPRI Arms Transfers Database",
    "description": "Most comprehensive public source on international transfers of major conventional weapons since 1950",
    "category": "Defense Economics",
    "url": "https://www.sipri.org/databases/armstransfers",
    "docs_url": "https://www.sipri.org/databases/armstransfers/sources-and-methods",
    "github_url": null,
    "tags": [
      "arms trade",
      "weapons transfers",
      "international",
      "SIPRI"
    ],
    "best_for": "Analyzing global arms trade patterns and supplier-recipient relationships",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The SIPRI Arms Transfers Database is the most comprehensive public source on international transfers of major conventional weapons since 1950. It allows users to analyze trends in arms trade and understand the dynamics of global security.",
    "use_cases": [
      "Analyzing trends in global arms transfers over time",
      "Studying the impact of arms trade on international relations",
      "Researching the economic implications of defense spending",
      "Evaluating the effectiveness of arms control agreements"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the SIPRI Arms Transfers Database?",
      "How can I access the SIPRI Arms Transfers Database?",
      "What data is included in the SIPRI Arms Transfers Database?",
      "What are the trends in arms transfers since 1950?",
      "How does SIPRI track international weapons transfers?",
      "What are the implications of arms trade data from SIPRI?"
    ],
    "domain_tags": [
      "defense",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1950-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "NIST National Vulnerability Database (NVD)",
    "description": "Comprehensive database of 500,000+ CVE vulnerability entries with CVSS severity scores and free API access",
    "category": "Cybersecurity",
    "url": "https://nvd.nist.gov/",
    "docs_url": "https://nvd.nist.gov/developers",
    "github_url": null,
    "tags": [
      "vulnerabilities",
      "CVE",
      "CVSS",
      "security"
    ],
    "best_for": "Vulnerability research and security investment prioritization",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NIST National Vulnerability Database (NVD) is a comprehensive database containing over 500,000 CVE vulnerability entries, each with associated CVSS severity scores. It provides free API access for users to retrieve and analyze vulnerability data.",
    "use_cases": [
      "Analyzing trends in cybersecurity vulnerabilities over time",
      "Assessing the severity of vulnerabilities for risk management"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NIST National Vulnerability Database?",
      "How to access the NVD API?",
      "What are CVE entries in the NVD?",
      "How to interpret CVSS severity scores?",
      "What vulnerabilities are listed in the NVD?",
      "How to use NVD data for cybersecurity analysis?"
    ],
    "domain_tags": [
      "cybersecurity"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1999-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "MovieLens 25M",
    "description": "25 million ratings and 1 million tag applications across 62,000 movies by 162,000 users. The gold-standard benchmark for collaborative filtering research with rich metadata including genres, tags, and timestamps.",
    "category": "MarTech & Customer Analytics",
    "url": "https://grouplens.org/datasets/movielens/25m/",
    "docs_url": "https://files.grouplens.org/datasets/movielens/ml-25m-README.html",
    "github_url": null,
    "tags": [
      "recommendations",
      "collaborative-filtering",
      "movies",
      "ratings"
    ],
    "best_for": "Learning recommendation systems, matrix factorization, and collaborative filtering",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "recommendations",
      "collaborative-filtering",
      "movies",
      "ratings"
    ],
    "summary": "The MovieLens 25M dataset contains 25 million ratings and 1 million tag applications across 62,000 movies by 162,000 users. It serves as a gold-standard benchmark for collaborative filtering research, allowing users to analyze movie preferences and improve recommendation systems.",
    "use_cases": [
      "Building a movie recommendation system",
      "Analyzing user preferences in film",
      "Evaluating collaborative filtering algorithms",
      "Exploring trends in movie ratings over time"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the MovieLens 25M dataset?",
      "How can I access the MovieLens 25M ratings?",
      "What types of analyses can be performed with MovieLens 25M?",
      "Where can I find collaborative filtering datasets?",
      "What are the features of the MovieLens 25M dataset?",
      "How many movies are included in the MovieLens 25M dataset?",
      "What is the significance of the MovieLens 25M dataset in research?",
      "How can I use MovieLens 25M for recommendation systems?"
    ],
    "domain_tags": [
      "entertainment"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "benchmark_usage": [
      "Collaborative filtering research"
    ],
    "model_score": 0.0001
  },
  {
    "name": "Retail Rocket Recommender System Dataset",
    "description": "4.5 months of behavior data from a real e-commerce site: 2.7M sessions, item properties, and purchase events. Designed for session-based recommendation research.",
    "category": "MarTech & Customer Analytics",
    "url": "https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "session-based",
      "e-commerce",
      "recommendations",
      "behavior"
    ],
    "best_for": "Learning session-based recommendations and real-time personalization",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "The Retail Rocket Recommender System Dataset contains 4.5 months of behavior data from a real e-commerce site, including 2.7 million sessions, item properties, and purchase events. It is designed for research in session-based recommendation systems.",
    "use_cases": [
      "Session-based recommendation analysis",
      "Behavioral pattern analysis in e-commerce",
      "Item property impact on purchasing decisions"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS"
    ],
    "synthetic_questions": [
      "What is the Retail Rocket Recommender System Dataset?",
      "How can I use the Retail Rocket dataset for session-based recommendations?",
      "What kind of behavior data is included in the Retail Rocket dataset?",
      "Where can I find the Retail Rocket Recommender System Dataset?",
      "What are the item properties in the Retail Rocket dataset?",
      "How many sessions are in the Retail Rocket dataset?",
      "What research can be conducted with the Retail Rocket dataset?",
      "What is the duration of the data collection for the Retail Rocket dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "UCI Machine Learning Repository",
    "description": "688 curated benchmark datasets since 1987 - gold standard for ML research",
    "category": "Dataset Aggregators",
    "url": "https://archive.ics.uci.edu",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "benchmarks",
      "classic",
      "ML",
      "academic"
    ],
    "best_for": "Benchmark datasets with extensive documentation for reproducible ML research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The UCI Machine Learning Repository is a collection of 688 curated benchmark datasets that have been available since 1987. It serves as a gold standard for machine learning research, providing researchers and practitioners with a diverse set of data for experimentation and validation.",
    "use_cases": [
      "Data exploration and analysis for machine learning projects",
      "Benchmarking algorithms against established datasets",
      "Educational purposes for teaching machine learning concepts"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are benchmark datasets for machine learning?",
      "Where can I find curated datasets for ML research?",
      "What is the UCI Machine Learning Repository?",
      "How many datasets are available in the UCI repository?",
      "What types of datasets are included in the UCI Machine Learning Repository?",
      "What is the significance of UCI datasets in ML?"
    ],
    "domain_tags": [
      "academic"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "OECD Data",
    "description": "Harmonized indicators for 38 member countries - gold standard for advanced economy comparisons",
    "category": "Dataset Aggregators",
    "url": "https://data-explorer.oecd.org",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "OECD",
      "international",
      "harmonized",
      "SDMX",
      "API"
    ],
    "best_for": "Harmonized cross-country comparisons for advanced economies",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The OECD Data provides harmonized indicators for 38 member countries, serving as a gold standard for advanced economy comparisons. Users can leverage this dataset for comparative analysis across various economic indicators.",
    "use_cases": [
      "Comparative analysis of economic indicators across countries",
      "Research in international economics",
      "Policy analysis for member countries"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "OECD Data indicators",
      "harmonized economic indicators",
      "OECD member countries data",
      "international economic comparisons",
      "SDMX API for OECD",
      "OECD dataset for analysis",
      "advanced economy indicators",
      "OECD data access"
    ],
    "domain_tags": [
      "economics",
      "international relations"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "EU Open Data Portal",
    "description": "2 million datasets from 205 catalogues across 36 European countries",
    "category": "Dataset Aggregators",
    "url": "https://data.europa.eu",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "EU",
      "Europe",
      "Eurostat",
      "open data"
    ],
    "best_for": "European economic data including comprehensive Eurostat statistics",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EU Open Data Portal provides access to 2 million datasets from 205 catalogues across 36 European countries. Users can explore a wide range of data related to various sectors, facilitating research and analysis in multiple domains.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available in the EU Open Data Portal?",
      "How can I access datasets from Eurostat?",
      "What types of open data are provided by the EU?",
      "Are there datasets related to healthcare in the EU Open Data Portal?",
      "How many datasets are available across European countries?",
      "What are the main categories of datasets in the EU Open Data Portal?",
      "Can I find economic data in the EU Open Data Portal?",
      "What is the scope of datasets available in the EU Open Data Portal?"
    ],
    "domain_tags": [
      "government",
      "research"
    ],
    "data_modality": "mixed",
    "size_category": "medium",
    "geographic_scope": "Europe",
    "model_score": 0.0001
  },
  {
    "name": "AWS Open Data Registry",
    "description": "300+ petabytes across hundreds of datasets - Common Crawl, satellite imagery, genomics",
    "category": "Dataset Aggregators",
    "url": "https://registry.opendata.aws",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "cloud",
      "petabyte",
      "Common Crawl",
      "satellite",
      "genomics"
    ],
    "best_for": "Large-scale data - Common Crawl (300B+ web pages), satellite imagery, genomics",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The AWS Open Data Registry provides access to over 300 petabytes of data across various datasets, including Common Crawl, satellite imagery, and genomics. Users can leverage this extensive data for research, analysis, and development in diverse fields.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available in the AWS Open Data Registry?",
      "How can I access satellite imagery data on AWS?",
      "What is Common Crawl and how can I use it?",
      "Where can I find genomics data in the AWS Open Data Registry?",
      "What types of data are included in AWS Open Data?",
      "How much data is available in the AWS Open Data Registry?"
    ],
    "domain_tags": [
      "cloud",
      "satellite",
      "genomics"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "model_score": 0.0001
  },
  {
    "name": "FHWA Highway Statistics",
    "description": "Annual data on US highway system including vehicle miles traveled, fuel consumption, road infrastructure, and highway financing since 1945.",
    "category": "Transportation Economics & Technology",
    "url": "https://www.fhwa.dot.gov/policyinformation/statistics.cfm",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "highways",
      "VMT",
      "infrastructure",
      "federal",
      "fuel"
    ],
    "best_for": "Aggregate transportation trends, infrastructure analysis, and policy research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The FHWA Highway Statistics dataset provides annual data on the US highway system, including metrics such as vehicle miles traveled, fuel consumption, and road infrastructure. This dataset can be used for analyzing trends in transportation economics and evaluating the impact of highway financing.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the FHWA Highway Statistics dataset?",
      "Where can I find annual data on US highway systems?",
      "How does vehicle miles traveled relate to fuel consumption?",
      "What are the trends in highway financing since 1945?",
      "What data does the FHWA provide on road infrastructure?",
      "How can I analyze transportation economics using FHWA data?"
    ],
    "use_cases": [
      "Analyzing trends in vehicle miles traveled over the decades.",
      "Evaluating the relationship between fuel consumption and highway infrastructure.",
      "Assessing the impact of federal funding on highway maintenance and development."
    ],
    "domain_tags": [
      "transportation",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1945-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0001
  },
  {
    "name": "World Inequality Database",
    "description": "Income and wealth inequality data for 100+ countries by Piketty, Saez, and Zucman",
    "category": "Dataset Aggregators",
    "url": "https://wid.world",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "inequality",
      "wealth",
      "income",
      "Piketty"
    ],
    "best_for": "Income and wealth distribution research with free visualization tools",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The World Inequality Database provides comprehensive data on income and wealth inequality across more than 100 countries, compiled by renowned economists Piketty, Saez, and Zucman. This dataset can be used for analyzing trends in inequality, comparing different countries, and informing policy discussions.",
    "use_cases": [
      "Analyzing income distribution trends over time",
      "Comparing wealth inequality across different countries",
      "Informing policy decisions regarding taxation and social programs"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the World Inequality Database?",
      "Where can I find income inequality data?",
      "How does wealth inequality vary by country?",
      "Who are the authors of the World Inequality Database?",
      "What data does Piketty, Saez, and Zucman provide?",
      "What are the trends in global income inequality?"
    ],
    "domain_tags": [
      "economics",
      "social science"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "LastFM-1B",
    "description": "1 billion listening events with long-term user histories. Music recommendation and listening behavior research",
    "category": "Entertainment & Media",
    "url": "http://www.cp.jku.at/datasets/LFM-1b/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "listening",
      "recommendations",
      "large-scale",
      "LastFM"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "music",
      "listening",
      "recommendations"
    ],
    "summary": "The LastFM-1B dataset contains 1 billion listening events that provide insights into long-term user histories. It can be used for music recommendation systems and analyzing listening behavior patterns.",
    "use_cases": [
      "Analyzing user listening habits",
      "Developing music recommendation algorithms",
      "Studying trends in music consumption"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the LastFM-1B dataset?",
      "How can I access the LastFM-1B listening events?",
      "What insights can be gained from the LastFM-1B dataset?",
      "What are the applications of the LastFM-1B dataset in music recommendations?",
      "How does LastFM-1B help in understanding user listening behavior?",
      "Where can I find datasets similar to LastFM-1B?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "massive",
    "model_score": 0.0
  },
  {
    "name": "IMF Data",
    "description": "International macroeconomic forecasts, BOP, and financial statistics for 195 countries",
    "category": "Dataset Aggregators",
    "url": "https://data.imf.org",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "macro",
      "international",
      "forecasts",
      "BOP",
      "IFS"
    ],
    "best_for": "World Economic Outlook forecasts and International Financial Statistics",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The IMF Data provides international macroeconomic forecasts, balance of payments (BOP), and financial statistics for 195 countries. It can be used for economic analysis, forecasting trends, and understanding global financial dynamics.",
    "use_cases": [
      "Analyzing global economic trends using IMF forecasts.",
      "Comparing balance of payments data across different countries.",
      "Forecasting financial outcomes based on historical IMF statistics.",
      "Studying the impact of macroeconomic indicators on national economies."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Senior-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the international macroeconomic forecasts for 195 countries?",
      "How can I access IMF financial statistics?",
      "What data does the IMF provide on balance of payments?",
      "Where can I find macroeconomic data for different countries?",
      "What are the key financial statistics available from the IMF?",
      "How to analyze international forecasts using IMF data?",
      "What is included in the IMF Data dataset?",
      "How does the IMF categorize its financial statistics?"
    ],
    "domain_tags": [
      "finance",
      "economics"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Alibaba Industrial Dump (150GB)",
    "description": "Large-scale industrial dataset from Alibaba (150GB)",
    "category": "E-Commerce",
    "url": "https://tianchi.aliyun.com/dataset/81505",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "large-scale",
      "industrial",
      "Alibaba"
    ],
    "best_for": "Practicing customer analytics, demand forecasting, and recommendation systems",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce"
    ],
    "summary": "The Alibaba Industrial Dump is a large-scale industrial dataset that provides insights into various aspects of e-commerce operations. Researchers and data scientists can analyze this dataset to understand consumer behavior, pricing strategies, and market trends.",
    "use_cases": [
      "Analyzing consumer purchasing patterns",
      "Evaluating pricing strategies in e-commerce",
      "Studying market trends in the industrial sector"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Alibaba Industrial Dump dataset?",
      "How can I access the Alibaba Industrial Dump?",
      "What insights can be gained from the Alibaba Industrial Dump?",
      "What are the applications of the Alibaba Industrial Dump dataset?",
      "Is the Alibaba Industrial Dump suitable for machine learning?",
      "What size is the Alibaba Industrial Dump dataset?",
      "What types of data are included in the Alibaba Industrial Dump?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "size_category": "large",
    "model_score": 0.0
  },
  {
    "name": "Polish Grocery",
    "description": "Yearly sales data (2018) from Polish grocery shop",
    "category": "Grocery & Supermarkets",
    "url": "https://www.kaggle.com/datasets/agatii/total-sale-2018-yearly-data-of-grocery-shop",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "grocery",
      "Poland",
      "yearly data"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "grocery",
      "sales data",
      "Poland"
    ],
    "summary": "This dataset contains yearly sales data from a Polish grocery shop for the year 2018. It can be used to analyze consumer purchasing patterns, sales trends, and inventory management in the grocery sector.",
    "use_cases": [
      "Analyzing sales trends over the year",
      "Understanding consumer behavior in grocery shopping",
      "Forecasting future sales based on past data"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Polish grocery sales data 2018",
      "yearly sales data Poland",
      "grocery shop sales analysis",
      "Poland grocery market trends",
      "2018 grocery sales dataset",
      "Polish supermarket sales data"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2018",
    "geographic_scope": "Poland",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Dominicks Soft Drinks",
    "description": "Weekly scanner data on soft drink purchases from Dominick's Finer Foods",
    "category": "Grocery & Supermarkets",
    "url": "https://www.chicagobooth.edu/research/kilts/research-data/dominicks",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "scanner data",
      "soft drinks",
      "Chicago Booth"
    ],
    "best_for": "Learning grocery & supermarkets analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "consumer-behavior",
      "pricing"
    ],
    "summary": "This dataset contains weekly scanner data on soft drink purchases from Dominick's Finer Foods, providing insights into consumer purchasing behavior. Analysts can use this data to study trends in soft drink sales and pricing strategies.",
    "use_cases": [
      "Analyzing consumer purchasing trends in soft drinks",
      "Evaluating the impact of promotions on soft drink sales",
      "Studying seasonal variations in soft drink purchases"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Dominick's Soft Drinks dataset?",
      "How to analyze soft drink purchases from Dominick's?",
      "What insights can be drawn from scanner data on soft drinks?",
      "Where can I find weekly scanner data for soft drinks?",
      "What trends exist in soft drink purchases at Dominick's?",
      "How does pricing affect soft drink sales in grocery stores?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "tabular",
    "geographic_scope": "Chicago",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Bandcamp Music Sales",
    "description": "Music sales data (digital/physical) from Bandcamp platform",
    "category": "Entertainment & Media",
    "url": "https://components.one/datasets/bandcamp-sales",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "sales",
      "independent artists"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior"
    ],
    "summary": "This dataset contains music sales data from the Bandcamp platform, including both digital and physical sales. It can be used to analyze trends in independent music sales and the behavior of consumers in the music industry.",
    "use_cases": [
      "Analyze sales trends for independent artists",
      "Compare digital and physical sales performance",
      "Investigate consumer behavior in music purchasing"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "Bandcamp music sales data",
      "independent artist sales on Bandcamp",
      "music sales trends Bandcamp",
      "digital vs physical music sales Bandcamp",
      "Bandcamp sales statistics",
      "analyzing music sales data Bandcamp"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "DataCo Supply Chain",
    "description": "Synthetic supply chain dataset covering sales and returns",
    "category": "Logistics & Supply Chain",
    "url": "https://tianchi.aliyun.com/dataset/89959",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "supply chain",
      "synthetic",
      "returns"
    ],
    "best_for": "Learning logistics & supply chain analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The DataCo Supply Chain dataset is a synthetic dataset that includes information on sales and returns within a supply chain context. It can be used for various analyses related to supply chain management, forecasting, and optimization.",
    "use_cases": [
      "Analyzing sales trends",
      "Forecasting returns",
      "Optimizing inventory management"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "supply chain dataset",
      "synthetic supply chain data",
      "sales and returns dataset",
      "logistics data",
      "supply chain analysis dataset",
      "returns data for supply chain"
    ],
    "domain_tags": [
      "logistics",
      "supply chain"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "NYC Property Sales",
    "description": "NYC property sales transactions across all boroughs",
    "category": "Real Estate",
    "url": "https://data.cityofnewyork.us/Housing-Development/NYC-Calendar-Sales-Archive-/uzf5-f8n2/about_data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "NYC",
      "transactions",
      "government"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The NYC Property Sales dataset contains transactions of property sales across all boroughs of New York City. This data can be used to analyze market trends, property values, and investment opportunities in the real estate sector.",
    "use_cases": [
      "Analyzing property value trends over time",
      "Identifying investment opportunities in NYC",
      "Studying the impact of government policies on real estate",
      "Comparing sales across different boroughs"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "NYC property sales dataset",
      "real estate transactions NYC",
      "property sales data New York",
      "NYC real estate market analysis",
      "government property sales NYC",
      "NYC property transaction history",
      "real estate sales data",
      "New York City property sales"
    ],
    "domain_tags": [
      "real estate"
    ],
    "data_modality": "tabular",
    "geographic_scope": "New York City",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Pushshift Reddit Archive",
    "description": "5.6B comments, 651M posts since 2005. Full Reddit history for social/economic research. 100+ papers published",
    "category": "Social & Web",
    "url": "https://arxiv.org/abs/2001.08435",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Reddit",
      "social media",
      "comments",
      "NLP",
      "large-scale"
    ],
    "best_for": "Learning social & web analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Pushshift Reddit Archive contains 5.6 billion comments and 651 million posts from Reddit since 2005, providing a comprehensive dataset for social and economic research. Researchers can analyze trends, sentiments, and behaviors within the Reddit community.",
    "use_cases": [
      "Sentiment analysis of Reddit comments",
      "Trend analysis of social issues over time",
      "NLP applications for comment classification"
    ],
    "audience": [
      "Early-PhD",
      "Junior-DS",
      "Mid-DS"
    ],
    "synthetic_questions": [
      "What is the Pushshift Reddit Archive?",
      "How can I access the Reddit comment dataset?",
      "What research has been done using the Pushshift Reddit Archive?",
      "What types of analyses can be performed on Reddit data?",
      "How many posts are in the Pushshift Reddit Archive?",
      "What is the historical coverage of Reddit comments?",
      "Can I use the Pushshift Reddit Archive for NLP tasks?",
      "What are the key features of the Pushshift Reddit Archive?"
    ],
    "domain_tags": [
      "social media"
    ],
    "data_modality": "text",
    "size_category": "massive",
    "benchmark_usage": [
      "100+ papers published"
    ],
    "model_score": 0.0
  },
  {
    "name": "DrivenData Water Supply Forecasting (2024)",
    "description": "Western US water supply data from Bureau of Reclamation, $500K prize pool for seasonal forecasting",
    "category": "Data Portals",
    "url": "https://www.drivendata.org/competitions/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "climate",
      "forecasting",
      "2024",
      "government data",
      "real-world",
      "time series"
    ],
    "best_for": "Learning data portals analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "This dataset contains water supply data from the Bureau of Reclamation in the Western US, aimed at seasonal forecasting. It can be used for developing forecasting models and analyzing climate impacts on water supply.",
    "use_cases": [
      "Developing predictive models for seasonal water supply",
      "Analyzing the impact of climate change on water resources"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the DrivenData Water Supply Forecasting dataset?",
      "How can I access the Bureau of Reclamation water supply data?",
      "What are the applications of seasonal forecasting in water supply?",
      "What is the prize pool for the DrivenData Water Supply Forecasting competition?",
      "Where can I find real-world time series data on water supply?",
      "What climate data is available for the Western US?",
      "How to participate in the DrivenData water supply forecasting challenge?"
    ],
    "domain_tags": [
      "government data",
      "climate"
    ],
    "data_modality": "time-series",
    "temporal_coverage": "2024",
    "geographic_scope": "Western US",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Zillow Research Data",
    "description": "Home values (ZHVI), rents (ZORI), inventory, and market heat indices across US metros and zip codes",
    "category": "Real Estate",
    "url": "https://www.zillow.com/research/data/",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "real estate",
      "housing prices",
      "rents",
      "large-scale",
      "time series"
    ],
    "best_for": "Learning real estate analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Zillow Research Data provides insights into home values, rents, inventory, and market heat indices across various US metros and zip codes. This dataset can be used to analyze housing market trends and make informed decisions in real estate.",
    "use_cases": [
      "Analyzing trends in home values over time",
      "Comparing rental prices across different zip codes",
      "Assessing inventory levels in various metros",
      "Evaluating market heat indices for investment decisions"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Zillow Research Data?",
      "How to access Zillow home values data?",
      "Where can I find US housing market data?",
      "What are the trends in ZHVI and ZORI?",
      "How to analyze real estate inventory data?",
      "What is the market heat index for US metros?"
    ],
    "domain_tags": [
      "real estate"
    ],
    "data_modality": "time-series",
    "geographic_scope": "US",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "LendingClub Loans",
    "description": "2.7M loans (2007-2019) with 151 features. Interest rates, credit scores, defaults. The canonical P2P lending dataset for credit risk modeling",
    "category": "Financial Services",
    "url": "https://www.kaggle.com/datasets/wordsforthewise/lending-club",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "P2P lending",
      "credit risk",
      "loans",
      "defaults",
      "fintech"
    ],
    "best_for": "Learning financial services analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The LendingClub Loans dataset contains 2.7 million loans from 2007 to 2019, featuring 151 attributes such as interest rates, credit scores, and defaults. It serves as a canonical dataset for credit risk modeling in peer-to-peer lending.",
    "use_cases": [
      "Analyzing credit risk for loan approvals",
      "Predicting loan defaults based on borrower characteristics",
      "Evaluating the impact of interest rates on loan performance"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the LendingClub Loans dataset?",
      "How can I analyze credit risk using LendingClub data?",
      "What features are included in the LendingClub Loans dataset?",
      "Where can I find the LendingClub Loans dataset?",
      "What insights can be gained from analyzing LendingClub loans?",
      "How does interest rate affect loan defaults in LendingClub data?",
      "What time period does the LendingClub Loans dataset cover?",
      "What is P2P lending?"
    ],
    "domain_tags": [
      "fintech"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2007-2019",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Spotify Million Playlist",
    "description": "1M playlists with 2M unique tracks from 300K artists. RecSys 2018 Challenge for playlist continuation research",
    "category": "Entertainment & Media",
    "url": "https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "Spotify",
      "playlists",
      "music",
      "recommendations",
      "RecSys"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Spotify Million Playlist dataset contains 1 million playlists featuring 2 million unique tracks from 300,000 artists. It can be used for research in playlist continuation and recommendation systems.",
    "use_cases": [
      "Analyzing playlist continuation patterns",
      "Developing music recommendation algorithms",
      "Studying user behavior in music streaming",
      "Evaluating the diversity of music in playlists"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Spotify Million Playlist dataset?",
      "How can I access the Spotify Million Playlist data?",
      "What are the unique tracks in the Spotify Million Playlist?",
      "How many artists are included in the Spotify Million Playlist?",
      "What research can be done with the Spotify Million Playlist dataset?",
      "What are the main features of the Spotify Million Playlist?",
      "How does the Spotify Million Playlist relate to music recommendations?",
      "What is the significance of the RecSys 2018 Challenge?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "LIAR",
    "description": "12.8K fact-checked political statements with speaker metadata",
    "category": "Content Moderation",
    "url": "https://sites.cs.ucsb.edu/~william/software.html",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "fact-checking",
      "politics",
      "misinformation"
    ],
    "best_for": "Learning content moderation analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The LIAR dataset contains 12.8K fact-checked political statements along with metadata about the speakers. It can be used for analyzing misinformation in political discourse and developing models for fact-checking.",
    "use_cases": [
      "Analyzing the accuracy of political statements",
      "Developing machine learning models for fact-checking",
      "Studying the impact of misinformation on public opinion"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the LIAR dataset?",
      "Where can I find fact-checked political statements?",
      "How can I analyze misinformation in politics?",
      "What metadata is included in the LIAR dataset?",
      "What are the applications of the LIAR dataset?",
      "How many statements are in the LIAR dataset?",
      "What is the focus of the LIAR dataset?",
      "What types of analysis can be performed with the LIAR dataset?"
    ],
    "domain_tags": [
      "politics"
    ],
    "data_modality": "text",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Jeff Sackmann Tennis Data",
    "description": "Comprehensive tennis match results and point-by-point data from 1973-present for ATP, WTA, and Grand Slam tournaments",
    "category": "Sports & Athletics",
    "url": "https://github.com/JeffSackmann/tennis_atp",
    "docs_url": null,
    "github_url": "https://github.com/JeffSackmann/tennis_atp",
    "tags": [
      "tennis",
      "ATP",
      "WTA",
      "match-results",
      "point-by-point"
    ],
    "best_for": "Tennis analytics, player performance analysis, and tournament prediction",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Jeff Sackmann Tennis Data provides comprehensive match results and point-by-point data for tennis tournaments from 1973 to the present. This dataset can be used to analyze player performance, match outcomes, and trends in tennis over time.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the match results for ATP tournaments?",
      "How can I analyze point-by-point data in tennis?",
      "What is the historical performance of WTA players?",
      "Where can I find tennis match data from 1973?",
      "What statistics are available in the Jeff Sackmann Tennis Data?",
      "How to visualize tennis match results?",
      "What insights can be drawn from Grand Slam tournament data?",
      "Is there a dataset for tennis match analysis?"
    ],
    "use_cases": [
      "Analyzing player performance over time",
      "Comparing match outcomes between ATP and WTA",
      "Studying trends in Grand Slam tournaments",
      "Visualizing point-by-point match data"
    ],
    "domain_tags": [
      "sports",
      "athletics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1973-present",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Citi Bike System Data",
    "description": "Trip-level records for NYC's bike-share system since 2013. ~2 million trips monthly in peak season with station-level origin-destination and duration data.",
    "category": "Transportation Economics & Technology",
    "url": "https://citibikenyc.com/system-data",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "bike-share",
      "NYC",
      "micromobility",
      "trip-data",
      "cycling"
    ],
    "best_for": "Bike-share demand analysis, first/last mile research, and micromobility studies",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Citi Bike System Data provides trip-level records for NYC's bike-share system since 2013, capturing station-level origin-destination and duration data. This dataset allows for analysis of biking patterns, usage trends, and the impact of micromobility on urban transportation.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Citi Bike System Data?",
      "How can I analyze NYC bike-share trip data?",
      "What are the trends in micromobility in NYC?",
      "Where can I find trip-level records for NYC's bike-share system?",
      "What data is available for cycling in New York City?",
      "How many trips does the Citi Bike system have monthly?",
      "What are the origin-destination patterns in NYC bike-share?",
      "What is the duration data for Citi Bike trips?"
    ],
    "use_cases": [
      "Analyzing seasonal trends in bike usage",
      "Studying the impact of bike-share on urban traffic",
      "Evaluating the effectiveness of bike-share stations",
      "Investigating demographic patterns in bike usage"
    ],
    "domain_tags": [
      "transportation",
      "urban planning"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2013-present",
    "geographic_scope": "New York City",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Behavioral Risk Factor Surveillance System (BRFSS)",
    "description": "World's largest ongoing health survey with 400,000+ adults annually across all states. Covers chronic conditions, risk behaviors, and preventive health. State-level estimates available.",
    "category": "Healthcare Economics & Health-Tech",
    "url": "https://www.cdc.gov/brfss/",
    "source": "CDC",
    "type": "Survey",
    "access": "Free public use files",
    "format": "SAS/ASCII",
    "tags": [
      "Healthcare",
      "Survey",
      "Behavioral",
      "State-level",
      "Free"
    ],
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Behavioral Risk Factor Surveillance System (BRFSS) is the world's largest ongoing health survey, collecting data from over 400,000 adults annually across all states. It provides insights into chronic conditions, risk behaviors, and preventive health measures, allowing for state-level estimates.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Behavioral Risk Factor Surveillance System?",
      "How does the BRFSS collect data on health behaviors?",
      "What chronic conditions are covered in the BRFSS?",
      "Where can I find state-level estimates from the BRFSS?",
      "Is the BRFSS data available for free?",
      "How many adults participate in the BRFSS each year?",
      "What types of health surveys are conducted in the US?",
      "What are the main topics covered by the BRFSS?"
    ],
    "update_frequency": "Annual",
    "geographic_coverage": "United States (state-level)",
    "domain_tags": [
      "healthcare"
    ],
    "data_modality": "tabular",
    "geographic_scope": "all states",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "EIA-923 Power Plant Operations",
    "description": "Monthly power plant fuel consumption, generation, and emissions data for all U.S. generators",
    "category": "Energy",
    "url": "https://www.eia.gov/electricity/data/eia923/",
    "docs_url": "https://www.eia.gov/electricity/data/eia923/",
    "github_url": null,
    "tags": [
      "power plants",
      "generation",
      "fuel",
      "emissions",
      "monthly"
    ],
    "best_for": "Analyzing power plant operations, fuel mix trends, and emissions patterns",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The EIA-923 Power Plant Operations dataset provides monthly data on fuel consumption, generation, and emissions for all U.S. power plants. This dataset can be used to analyze trends in energy production and environmental impact over time.",
    "use_cases": [
      "Analyzing the impact of fuel type on emissions across different power plants.",
      "Comparing monthly power generation outputs from various energy sources.",
      "Studying trends in fuel consumption over time to inform energy policy.",
      "Evaluating the environmental impact of power generation in the U.S."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the EIA-923 Power Plant Operations dataset?",
      "How can I access monthly power plant fuel consumption data?",
      "What information does the EIA-923 dataset provide about U.S. generators?",
      "Where can I find emissions data for power plants in the U.S.?",
      "What are the trends in power generation based on the EIA-923 dataset?",
      "How does fuel consumption vary among U.S. power plants?",
      "What is the significance of the EIA-923 dataset in energy analysis?",
      "How can I use the EIA-923 data for environmental studies?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2001-present",
    "geographic_scope": "U.S.",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Ember Global Electricity Data",
    "description": "Monthly electricity generation, capacity, and emissions data for 200+ countries",
    "category": "Energy",
    "url": "https://ember-climate.org/data/",
    "docs_url": "https://ember-climate.org/data-catalogue/",
    "github_url": "https://github.com/ember-climate/data-guidelines",
    "tags": [
      "global",
      "electricity",
      "emissions",
      "monthly",
      "countries"
    ],
    "best_for": "Cross-country energy transition analysis and global electricity trends",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The Ember Global Electricity Data provides monthly data on electricity generation, capacity, and emissions for over 200 countries. This dataset can be used to analyze trends in energy production and its environmental impact across different nations.",
    "use_cases": [
      "Analyzing trends in electricity generation over time.",
      "Comparing emissions from electricity generation across countries.",
      "Evaluating the capacity of renewable vs. non-renewable energy sources."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the Ember Global Electricity Data?",
      "How can I access monthly electricity generation data for countries?",
      "What are the emissions statistics for global electricity generation?",
      "Where can I find electricity capacity data for over 200 countries?",
      "What trends can be analyzed using the Ember Global Electricity Data?",
      "How does electricity generation vary across different countries?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2000-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "USAspending.gov",
    "description": "User-friendly interface to federal spending data with bulk downloads in CSV/JSON and visualization tools",
    "category": "Defense Economics",
    "url": "https://www.usaspending.gov/",
    "docs_url": "https://api.usaspending.gov/",
    "github_url": "https://github.com/fedspendingtransparency/usaspending-api",
    "tags": [
      "spending",
      "contracts",
      "grants",
      "government"
    ],
    "best_for": "Accessible exploration of federal defense spending without FPDS complexity",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "USAspending.gov provides a user-friendly interface to access federal spending data, allowing users to explore contracts and grants. The platform also offers bulk downloads in CSV/JSON formats and includes visualization tools for data analysis.",
    "use_cases": [
      "Analyzing federal spending trends over time",
      "Comparing government contracts across different sectors",
      "Visualizing grant distributions by state",
      "Exploring spending patterns in defense economics"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is USAspending.gov?",
      "How to access federal spending data?",
      "Where can I download federal spending data in CSV?",
      "What visualization tools are available on USAspending.gov?",
      "How to analyze government contracts using USAspending.gov?",
      "What types of grants are listed on USAspending.gov?",
      "Is there a user-friendly interface for federal spending data?",
      "What data formats are available for download on USAspending.gov?"
    ],
    "domain_tags": [
      "government"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2000-present",
    "geographic_scope": "United States",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "CFR Cyber Operations Tracker",
    "description": "Database of publicly known state-sponsored cyber incidents since 2005 with threat actor attribution",
    "category": "Cybersecurity",
    "url": "https://www.cfr.org/cyber-operations/",
    "docs_url": "https://www.cfr.org/cyber-operations/",
    "github_url": null,
    "tags": [
      "cyber attacks",
      "nation-state",
      "attribution",
      "incidents"
    ],
    "best_for": "Tracking state-sponsored cyber operations and attack patterns",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The CFR Cyber Operations Tracker is a database that catalogs publicly known state-sponsored cyber incidents since 2005, providing insights into threat actor attribution. Users can analyze trends in cyber attacks and understand the actors behind these incidents.",
    "use_cases": [
      "Analyzing trends in state-sponsored cyber attacks over time.",
      "Identifying patterns of attribution for different threat actors."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the CFR Cyber Operations Tracker?",
      "How can I access the CFR Cyber Operations Tracker?",
      "What types of cyber incidents are included in the CFR Cyber Operations Tracker?",
      "Who are the threat actors identified in the CFR Cyber Operations Tracker?",
      "What is the timeline of cyber incidents in the CFR Cyber Operations Tracker?",
      "How does the CFR Cyber Operations Tracker attribute cyber attacks?"
    ],
    "domain_tags": [
      "cybersecurity"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2005-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Amazon Reviews 2023",
    "description": "233 million product reviews across all Amazon categories with user IDs, timestamps, ratings, and review text. The largest public e-commerce review dataset for recommendation research.",
    "category": "MarTech & Customer Analytics",
    "url": "https://amazon-reviews-2023.github.io/",
    "docs_url": "https://amazon-reviews-2023.github.io/",
    "github_url": "https://github.com/hyp1231/AmazonReviews2023",
    "tags": [
      "recommendations",
      "e-commerce",
      "reviews",
      "NLP",
      "sentiment"
    ],
    "best_for": "Large-scale recommendation systems, sentiment analysis, and cross-domain recommendations",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "e-commerce",
      "consumer-behavior",
      "recommendations"
    ],
    "summary": "The Amazon Reviews 2023 dataset contains 233 million product reviews across all Amazon categories, including user IDs, timestamps, ratings, and review text. This dataset can be utilized for recommendation research and sentiment analysis in the e-commerce domain.",
    "use_cases": [
      "Sentiment analysis of product reviews",
      "Building recommendation systems based on user reviews",
      "Analyzing consumer behavior through review patterns"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the Amazon Reviews 2023 dataset?",
      "How to analyze Amazon product reviews?",
      "Where can I find large e-commerce review datasets?",
      "What insights can be gained from Amazon reviews?",
      "How to perform sentiment analysis on Amazon reviews?",
      "What is the largest public e-commerce review dataset?"
    ],
    "domain_tags": [
      "retail"
    ],
    "data_modality": "text",
    "size_category": "large",
    "model_score": 0.0
  },
  {
    "name": "FRED (Federal Reserve Economic Data)",
    "description": "816,000+ US macroeconomic time series from 100+ sources with free API",
    "category": "Dataset Aggregators",
    "url": "https://fred.stlouisfed.org",
    "docs_url": "https://fred.stlouisfed.org/docs/api/fred/",
    "github_url": null,
    "tags": [
      "macro",
      "economics",
      "time series",
      "Fed",
      "API"
    ],
    "best_for": "US macroeconomic research - Paul Krugman called it 'the most amazing economics website'",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "FRED (Federal Reserve Economic Data) provides access to over 816,000 US macroeconomic time series from more than 100 sources. Users can leverage this extensive dataset through a free API for various economic analyses.",
    "use_cases": [
      "Analyzing trends in US economic indicators",
      "Comparing historical economic data across different time periods",
      "Visualizing macroeconomic data for presentations"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is FRED?",
      "How to access Federal Reserve Economic Data?",
      "What macroeconomic time series are available in FRED?",
      "How to use FRED API for economic analysis?",
      "What sources contribute to FRED data?",
      "Where can I find US macroeconomic data?",
      "What are the benefits of using FRED for research?"
    ],
    "domain_tags": [
      "economics"
    ],
    "data_modality": "time-series",
    "size_category": "massive",
    "geographic_scope": "US",
    "model_score": 0.0
  },
  {
    "name": "World Bank Open Data",
    "description": "1,400+ development indicators for 217 economies spanning 50+ years with free API",
    "category": "Dataset Aggregators",
    "url": "https://data.worldbank.org",
    "docs_url": "https://datahelpdesk.worldbank.org",
    "github_url": null,
    "tags": [
      "development",
      "international",
      "poverty",
      "GDP",
      "API"
    ],
    "best_for": "Cross-country comparisons in development economics and poverty research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The World Bank Open Data provides over 1,400 development indicators for 217 economies, covering more than 50 years. Users can access this data through a free API for various analyses related to development, poverty, and economic performance.",
    "use_cases": [
      "Analyzing poverty trends across different countries over time.",
      "Comparing GDP growth rates among various economies."
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the development indicators available in the World Bank Open Data?",
      "How can I access the World Bank Open Data API?",
      "What economies are covered in the World Bank Open Data?",
      "What is the historical range of data in the World Bank Open Data?",
      "How does the World Bank Open Data relate to GDP and poverty analysis?",
      "Where can I find international development statistics?"
    ],
    "domain_tags": [
      "international",
      "development"
    ],
    "data_modality": "tabular",
    "size_category": "medium",
    "temporal_coverage": "50+ years",
    "geographic_scope": "217 economies",
    "model_score": 0.0
  },
  {
    "name": "NetEase Music (INFORMS)",
    "description": "Data from NetEase Cloud Music for INFORMS competition",
    "category": "Entertainment & Media",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3554826",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "music",
      "streaming",
      "INFORMS",
      "China"
    ],
    "best_for": "Learning entertainment & media analytics and modeling",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [
      "music",
      "streaming",
      "data-analysis"
    ],
    "summary": "This dataset contains data from NetEase Cloud Music, specifically curated for the INFORMS competition. It can be used to analyze music streaming trends and user behavior in the context of the Chinese market.",
    "use_cases": [
      "Analyzing user engagement with music tracks",
      "Identifying popular genres in China",
      "Examining trends in music consumption",
      "Comparing streaming behaviors across different demographics"
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is the NetEase Music dataset?",
      "How can I analyze streaming data from NetEase?",
      "What insights can be gained from the INFORMS music dataset?",
      "What are the trends in music streaming in China?",
      "How does user behavior vary in music streaming?",
      "What data is available in the NetEase Cloud Music dataset?",
      "How can I use this dataset for a competition?",
      "What are the applications of music streaming data analysis?"
    ],
    "domain_tags": [
      "entertainment",
      "media"
    ],
    "data_modality": "tabular",
    "geographic_scope": "China",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Statcast / Baseball Savant",
    "description": "MLB's official tracking data including pitch velocity, spin rate, exit velocity, launch angle, and player positioning from 2015-present",
    "category": "Sports & Athletics",
    "url": "https://baseballsavant.mlb.com/",
    "docs_url": "https://baseballsavant.mlb.com/csv-docs",
    "github_url": null,
    "tags": [
      "baseball",
      "tracking-data",
      "MLB",
      "pitch-tracking",
      "batted-ball"
    ],
    "best_for": "Modern baseball analytics, player evaluation, and biomechanical analysis",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Statcast / Baseball Savant provides detailed tracking data for Major League Baseball, including metrics such as pitch velocity and exit velocity. This data can be used for performance analysis, player evaluation, and game strategy development.",
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Statcast data?",
      "How to access Baseball Savant data?",
      "What metrics are included in MLB tracking data?",
      "How to analyze pitch velocity in baseball?",
      "What is the significance of launch angle in baseball?",
      "Where can I find MLB tracking data from 2015?",
      "How is player positioning tracked in MLB?",
      "What are the applications of batted-ball data in baseball?"
    ],
    "use_cases": [
      "Analyzing player performance over seasons",
      "Evaluating pitching strategies based on pitch tracking",
      "Studying the impact of launch angle on batting success"
    ],
    "domain_tags": [
      "sports",
      "athletics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2015-present",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "gridstatus",
    "description": "Unified Python API for accessing real-time and historical data from all major U.S. ISOs",
    "category": "Energy",
    "url": "https://www.gridstatus.io/",
    "docs_url": "https://docs.gridstatus.io/",
    "github_url": "https://github.com/gridstatus/gridstatus",
    "tags": [
      "ISO",
      "API",
      "real-time",
      "Python",
      "unified"
    ],
    "best_for": "Accessing standardized data across multiple U.S. electricity markets",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The gridstatus dataset provides a unified Python API for accessing both real-time and historical data from all major U.S. Independent System Operators (ISOs). This allows users to analyze energy data effectively and integrate it into their applications.",
    "use_cases": [
      "Analyzing real-time energy consumption patterns.",
      "Comparing historical energy data across different ISOs.",
      "Integrating ISO data into energy management applications."
    ],
    "audience": [
      "Junior-DS",
      "Mid-DS",
      "Curious-browser"
    ],
    "synthetic_questions": [
      "How to access real-time data from U.S. ISOs using Python?",
      "What historical energy data is available through the gridstatus API?",
      "How can I analyze ISO data with Python?",
      "What are the features of the gridstatus API?",
      "Is there a unified API for U.S. energy data?",
      "How to use Python for accessing ISO data?",
      "What is the gridstatus dataset?",
      "How to retrieve historical data from U.S. ISOs?"
    ],
    "domain_tags": [
      "energy"
    ],
    "data_modality": "mixed",
    "temporal_coverage": "varies by ISO",
    "geographic_scope": "U.S.",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "SIPRI Arms Industry Database",
    "description": "Financial data on the 100 largest defense companies worldwide including revenue, profits, and employment",
    "category": "Defense Economics",
    "url": "https://www.sipri.org/databases/armsindustry",
    "docs_url": "https://www.sipri.org/databases/armsindustry/sources-and-methods",
    "github_url": null,
    "tags": [
      "defense industry",
      "contractors",
      "companies",
      "SIPRI"
    ],
    "best_for": "Analyzing defense industry concentration and contractor performance",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "The SIPRI Arms Industry Database contains financial data on the 100 largest defense companies worldwide, including metrics such as revenue, profits, and employment. This dataset can be used to analyze trends in the defense industry and assess the economic impact of defense contractors.",
    "use_cases": [
      "Analyzing the financial performance of defense companies over time",
      "Comparing revenue and profits across different defense contractors",
      "Assessing employment trends in the defense industry"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What are the largest defense companies worldwide?",
      "How much revenue do the top defense contractors generate?",
      "What is the employment data for major defense firms?",
      "What are the profit margins of defense companies?",
      "How has the defense industry evolved over the years?",
      "What financial metrics are available for defense contractors?"
    ],
    "domain_tags": [
      "defense",
      "economics"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "2002-present",
    "geographic_scope": "Global",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Space-Track.org",
    "description": "Official U.S. Space Force data on tracked orbital objects with 138+ million historical element sets",
    "category": "Space",
    "url": "https://www.space-track.org/",
    "docs_url": "https://www.space-track.org/documentation",
    "github_url": null,
    "tags": [
      "satellites",
      "orbital debris",
      "TLE",
      "space situational awareness"
    ],
    "best_for": "Tracking satellites and debris for space economics research",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Space-Track.org provides official data from the U.S. Space Force on tracked orbital objects, including over 138 million historical element sets. This dataset can be used for analyzing satellite movements, understanding orbital debris, and enhancing space situational awareness.",
    "use_cases": [
      "Analyzing the trajectory of satellites over time",
      "Studying the impact of orbital debris on space missions",
      "Developing models for predicting satellite collisions",
      "Enhancing situational awareness for space operations"
    ],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What is Space-Track.org?",
      "How can I access U.S. Space Force orbital data?",
      "What data does Space-Track.org provide on satellites?",
      "Where can I find historical element sets for orbital objects?",
      "What is TLE data and how is it used?",
      "How does Space-Track.org contribute to space situational awareness?"
    ],
    "domain_tags": [
      "space"
    ],
    "data_modality": "tabular",
    "temporal_coverage": "1957-present",
    "geographic_scope": "Global (orbital)",
    "size_category": "medium",
    "model_score": 0.0
  },
  {
    "name": "Data.gov",
    "description": "370,000+ datasets from US federal, state, and local agencies",
    "category": "Dataset Aggregators",
    "url": "https://data.gov",
    "docs_url": null,
    "github_url": null,
    "tags": [
      "government",
      "US",
      "open data",
      "CKAN"
    ],
    "best_for": "Central clearinghouse for BLS, Census, BEA, and trade data",
    "difficulty": "beginner",
    "prerequisites": [],
    "topic_tags": [],
    "summary": "Data.gov provides access to over 370,000 datasets from various US federal, state, and local agencies. This extensive collection allows users to explore a wide range of government data for research, analysis, and decision-making.",
    "use_cases": [],
    "audience": [
      "Curious-browser"
    ],
    "synthetic_questions": [
      "What datasets are available on Data.gov?",
      "How can I access government datasets?",
      "What types of data does Data.gov provide?",
      "Where can I find open data from US agencies?",
      "What is the purpose of Data.gov?",
      "How many datasets are available on Data.gov?",
      "What categories of data are included in Data.gov?",
      "Is Data.gov a reliable source for government data?"
    ],
    "domain_tags": [
      "government"
    ],
    "data_modality": "mixed",
    "size_category": "massive",
    "geographic_scope": "US",
    "model_score": 0.0
  },
  {
    "name": "World Bank Light Every Night",
    "description": "30 years of nighttime satellite imagery (250 terabytes) from DMSP and VIIRS sensors. Foundational dataset for using lights as GDP proxy.",
    "category": "Geospatial",
    "url": "https://registry.opendata.aws/wb-light-every-night/",
    "docs_url": "https://worldbank.github.io/OpenNightLights/welcome.html",
    "github_url": "https://github.com/worldbank/OpenNightLights",
    "tags": ["satellite", "nighttime-lights", "GDP", "development", "World Bank"],
    "best_for": "Economic measurement using satellite imagery, development economics research"
  },
  {
    "name": "Predicting Poverty Replication Data",
    "description": "Satellite imagery and survey data from Jean et al. (Science 2016) for predicting poverty in African countries using deep learning.",
    "category": "Geospatial",
    "url": "https://github.com/nealjean/predicting-poverty",
    "docs_url": null,
    "github_url": "https://github.com/nealjean/predicting-poverty",
    "tags": ["satellite", "poverty", "deep-learning", "Africa", "development"],
    "best_for": "Replicating and extending satellite-based poverty prediction research"
  },
  {
    "name": "LOBSTER (Limit Order Book System)",
    "description": "High-frequency limit order book tick data for NASDAQ stocks reconstructed from ITCH messages. Gold standard for market microstructure research.",
    "category": "Financial Services",
    "url": "https://lobsterdata.com/",
    "docs_url": "https://lobsterdata.com/info/DataStructure.php",
    "github_url": null,
    "tags": ["high-frequency", "limit-order-book", "NASDAQ", "tick-data", "market-microstructure"],
    "best_for": "Market microstructure research, algorithmic trading backtesting, LOB simulation validation"
  }
]