[
  {
    "name": "BayesianBandits",
    "description": "Lightweight microframework for Bayesian bandits (Thompson Sampling) with support for contextual/restless/delayed rewards.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://bayesianbandits.readthedocs.io/en/latest/",
    "github_url": "https://github.com/bayesianbandits/bayesianbandits",
    "url": "https://github.com/bayesianbandits/bayesianbandits",
    "install": "pip install bayesianbandits",
    "tags": [
      "A/B testing",
      "experimentation",
      "Bayesian"
    ],
    "best_for": "Sharing knowledge across arms for sparse high-dimensional features",
    "language": "Python"
  },
  {
    "name": "ContextualBandits",
    "description": "Implements a wide range of contextual bandit algorithms (linear, tree-based, neural) and off-policy evaluation methods.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://contextual-bandits.readthedocs.io/",
    "github_url": "https://github.com/david-cortes/contextualbandits",
    "url": "https://github.com/david-cortes/contextualbandits",
    "install": "pip install contextualbandits",
    "tags": [
      "A/B testing",
      "experimentation",
      "machine learning"
    ],
    "best_for": "Off-policy learning from logged data with any sklearn classifier",
    "language": "Python"
  },
  {
    "name": "MABWiser",
    "description": "Production-ready, scikit-learn style library for contextual & stochastic bandits with parallelism and simulation tools.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://fidelity.github.io/mabwiser/",
    "github_url": "https://github.com/fidelity/mabwiser",
    "url": "https://github.com/fidelity/mabwiser",
    "install": "pip install mabwiser",
    "tags": [
      "A/B testing",
      "experimentation"
    ],
    "best_for": "Fidelity-tested with built-in parallelization and policy tuning",
    "language": "Python"
  },
  {
    "name": "Open Bandit Pipeline (OBP)",
    "description": "Framework for **offline evaluation (OPE)** of bandit policies using logged data. Implements IPS, DR, DM estimators.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://zr-obp.readthedocs.io/en/latest/",
    "github_url": "https://github.com/st-tech/zr-obp",
    "url": "https://github.com/st-tech/zr-obp",
    "install": "pip install obp",
    "tags": [
      "A/B testing",
      "experimentation"
    ],
    "best_for": "Benchmarking OPE methods with real ZOZO e-commerce dataset",
    "language": "Python"
  },
  {
    "name": "PyXAB",
    "description": "Library for advanced bandit problems: X-armed bandits (continuous/structured action spaces) and online optimization.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://pyxab.readthedocs.io/en/latest/",
    "github_url": "https://github.com/WilliamLwj/PyXAB",
    "url": "https://github.com/WilliamLwj/PyXAB",
    "install": "pip install pyxab",
    "tags": [
      "A/B testing",
      "experimentation"
    ],
    "best_for": "Continuous action spaces with hierarchical partitioning",
    "language": "Python"
  },
  {
    "name": "SMPyBandits",
    "description": "Comprehensive research framework for single/multi-player MAB algorithms (stochastic, adversarial, contextual).",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://smpybandits.github.io/",
    "github_url": "https://github.com/SMPyBandits/SMPyBandits",
    "url": "https://github.com/SMPyBandits/SMPyBandits",
    "install": "pip install SMPyBandits",
    "tags": [
      "A/B testing",
      "experimentation"
    ],
    "best_for": "Multi-player bandits with collision handling (65+ algorithms)",
    "language": "Python"
  },
  {
    "name": "Bambi",
    "description": "High-level interface for building Bayesian GLMMs, built on top of PyMC. Uses formula syntax similar to R's `lme4`.",
    "category": "Bayesian Econometrics",
    "docs_url": "https://bambinos.github.io/bambi/",
    "github_url": "https://github.com/bambinos/bambi",
    "url": "https://github.com/bambinos/bambi",
    "install": "pip install bambi",
    "tags": [
      "Bayesian",
      "inference"
    ],
    "best_for": "Mixed-effects models with auto priors and R-style formulas",
    "language": "Python"
  },
  {
    "name": "LightweightMMM",
    "description": "Bayesian Marketing Mix Modeling (see Marketing Mix Models section).",
    "category": "Bayesian Econometrics",
    "docs_url": null,
    "github_url": "https://github.com/google/lightweight_mmm",
    "url": "https://github.com/google/lightweight_mmm",
    "install": "pip install lightweight_mmm",
    "tags": [
      "Bayesian",
      "inference"
    ],
    "best_for": "Google's MMM with geo-level modeling and budget optimizer",
    "language": "Python"
  },
  {
    "name": "NumPyro",
    "description": "Probabilistic programming library built on JAX for scalable Bayesian inference, often faster than PyMC.",
    "category": "Bayesian Econometrics",
    "docs_url": "https://num.pyro.ai/",
    "github_url": "https://github.com/pyro-ppl/numpyro",
    "url": "https://github.com/pyro-ppl/numpyro",
    "install": "pip install numpyro",
    "tags": [
      "Bayesian",
      "inference"
    ],
    "best_for": "JAX backend with JIT-compiled NUTS for GPU/TPU speed",
    "language": "Python"
  },
  {
    "name": "PyMC",
    "description": "Flexible probabilistic programming library for Bayesian modeling and inference using MCMC algorithms (NUTS).",
    "category": "Bayesian Econometrics",
    "docs_url": "https://www.pymc.io/",
    "github_url": "https://github.com/pymc-devs/pymc",
    "url": "https://github.com/pymc-devs/pymc",
    "install": "pip install pymc",
    "tags": [
      "Bayesian",
      "inference"
    ],
    "best_for": "Largest ecosystem with books, tutorials, and domain extensions",
    "language": "Python"
  },
  {
    "name": "Ananke",
    "description": "Causal inference using graphical models (DAGs), including identification theory and effect estimation.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://ananke.readthedocs.io/",
    "github_url": "https://github.com/ghosthamlet/ananke",
    "url": "https://github.com/ghosthamlet/ananke",
    "install": "pip install ananke-causal",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "ID algorithm checking if causal effects are identifiable from DAG",
    "language": "Python"
  },
  {
    "name": "Causal Discovery Toolbox (CDT)",
    "description": "Implements algorithms for causal discovery (recovering causal graph structure) from observational data.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://fentechsolutions.github.io/CausalDiscoveryToolbox/html/index.html",
    "github_url": "https://github.com/FenTechSolutions/CausalDiscoveryToolbox",
    "url": "https://github.com/FenTechSolutions/CausalDiscoveryToolbox",
    "install": "pip install cdt",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "Wraps R packages (bnlearn, pcalg) with GPU and pairwise methods",
    "language": "Python"
  },
  {
    "name": "CausalNex",
    "description": "Uses Bayesian Networks for causal reasoning, combining ML with expert knowledge to model relationships.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": null,
    "github_url": "https://github.com/mckinsey/causalnex",
    "url": "https://github.com/mckinsey/causalnex",
    "install": "pip install causalnex",
    "tags": [
      "causal inference",
      "graphs",
      "Bayesian"
    ],
    "best_for": "McKinsey's BN tool with expert knowledge and what-if analysis",
    "language": "Python"
  },
  {
    "name": "LiNGAM",
    "description": "Specialized package for learning non-Gaussian linear causal models, implementing various versions of the LiNGAM algorithm including ICA-based methods.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://lingam.readthedocs.io/",
    "github_url": "https://github.com/cdt15/lingam",
    "url": "https://github.com/cdt15/lingam",
    "install": "pip install lingam",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "Exploits non-Gaussianity to identify causal direction",
    "language": "Python"
  },
  {
    "name": "Tigramite",
    "description": "Specialized package for causal inference in time series data implementing PCMCI, PCMCIplus, LPCMCI algorithms with conditional independence tests.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://jakobrunge.github.io/tigramite/",
    "github_url": "https://github.com/jakobrunge/tigramite",
    "url": "https://github.com/jakobrunge/tigramite",
    "install": "pip install tigramite",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "PCMCI algorithm for time series with lagged causal links",
    "language": "Python"
  },
  {
    "name": "causal-learn",
    "description": "Comprehensive Python package serving as Python translation and extension of Java-based Tetrad toolkit for causal discovery algorithms.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://causal-learn.readthedocs.io/",
    "github_url": "https://github.com/py-why/causal-learn",
    "url": "https://github.com/py-why/causal-learn",
    "install": "pip install causal-learn",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "PyWhy's native Python port of Tetrad (PC, GES, FCI, etc.)",
    "language": "Python"
  },
  {
    "name": "gCastle",
    "description": "Huawei Noah's Ark Lab end-to-end causal structure learning toolchain emphasizing gradient-based methods with GPU acceleration (NOTEARS, GOLEM).",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://gcastle.readthedocs.io/",
    "github_url": "https://github.com/huawei-noah/trustworthyAI",
    "url": "https://github.com/huawei-noah/trustworthyAI",
    "install": "pip install gcastle",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "Huawei's gradient-based discovery (NOTEARS, GOLEM, neural)",
    "language": "Python"
  },
  {
    "name": "py-tetrad",
    "description": "Python interface to Tetrad Java library using JPype, providing direct access to Tetrad's causal discovery algorithms with efficient data translation.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": null,
    "github_url": "https://github.com/cmu-phil/py-tetrad",
    "url": "https://github.com/cmu-phil/py-tetrad",
    "install": "Available on GitHub (installation via git clone)",
    "tags": [
      "causal inference",
      "graphs"
    ],
    "best_for": "JPype bridge to full Tetrad Java for exclusive algorithms",
    "language": "Python"
  },
  {
    "name": "CausalInference",
    "description": "Implements classical causal inference methods like propensity score matching, inverse probability weighting, stratification.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://causalinferenceinpython.org",
    "github_url": "https://github.com/laurencium/causalinference",
    "url": "https://github.com/laurencium/causalinference",
    "install": "pip install CausalInference",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "Simple API for matching, blocking, weighting, and stratification",
    "language": "Python"
  },
  {
    "name": "CausalLib",
    "description": "IBM-developed package that provides a scikit-learn-inspired API for causal inference with meta-algorithms supporting arbitrary machine learning models.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://causallib.readthedocs.io/",
    "github_url": "https://github.com/IBM/causallib",
    "url": "https://github.com/IBM/causallib",
    "install": "pip install causallib",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "IBM's modular meta-learners with any sklearn estimator",
    "language": "Python"
  },
  {
    "name": "CausalML",
    "description": "Focuses on uplift modeling and heterogeneous treatment effect estimation using machine learning techniques.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://causalml.readthedocs.io/",
    "github_url": "https://github.com/uber/causalml",
    "url": "https://github.com/uber/causalml",
    "install": "pip install causalml",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "Uber's production CATE/ITE with T-learner, X-learner, SHAP",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "CausalMatch",
    "description": "Implements Propensity Score Matching (PSM) and Coarsened Exact Matching (CEM) with ML flexibility for propensity score estimation.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://github.com/bytedance/CausalMatch",
    "github_url": "https://github.com/bytedance/CausalMatch",
    "url": "https://github.com/bytedance/CausalMatch",
    "install": "pip install causalmatch",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "ByteDance's PSM/CEM with auto model selection and balance checks",
    "language": "Python"
  },
  {
    "name": "CausalPy",
    "description": "Developed by PyMC Labs, focuses specifically on causal inference in quasi-experimental settings. Specializes in scenarios where randomization is impossible or expensive.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://causalpy.readthedocs.io/",
    "github_url": "https://github.com/pymc-labs/CausalPy",
    "url": "https://github.com/pymc-labs/CausalPy",
    "install": "pip install CausalPy",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "PyMC Labs' Bayesian DiD, RDD, SC, and IV with credible intervals",
    "language": "Python"
  },
  {
    "name": "DoWhy",
    "description": "End-to-end framework for causal inference based on causal graphs (DAGs) and potential outcomes. Covers identification, estimation, refutation.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://www.pywhy.org/dowhy/",
    "github_url": "https://github.com/py-why/dowhy",
    "url": "https://github.com/py-why/dowhy",
    "install": "pip install dowhy",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "End-to-end workflow with refutation tests and assumption checking",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "fastmatch",
    "description": "Fast k-nearest-neighbor matching for large datasets using Facebook's FAISS library.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://github.com/py-econometrics/fastmatch",
    "github_url": "https://github.com/py-econometrics/fastmatch",
    "url": "https://github.com/py-econometrics/fastmatch",
    "install": "pip install fastmatch",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "FAISS/Voyager GPU-accelerated matching at massive scale",
    "language": "Python"
  },
  {
    "name": "scikit-uplift",
    "description": "Focuses on uplift modeling and estimating heterogeneous treatment effects using various ML-based methods.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://scikit-uplift.readthedocs.io/en/latest/",
    "github_url": "https://github.com/maks-sh/scikit-uplift",
    "url": "https://github.com/maks-sh/scikit-uplift",
    "install": "pip install scikit-uplift",
    "tags": [
      "causal inference",
      "matching"
    ],
    "best_for": "Most uplift metrics (AUUC, Qini) with sklearn pipelines",
    "language": "Python"
  },
  {
    "name": "Scikit-learn",
    "description": "Foundational ML library with regression models (incl. regularized), model selection, cross-validation, evaluation metrics.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://scikit-learn.org/",
    "github_url": "https://github.com/scikit-learn/scikit-learn",
    "url": "https://github.com/scikit-learn/scikit-learn",
    "install": "pip install scikit-learn",
    "tags": [
      "regression",
      "linear models"
    ],
    "best_for": "ML-based prediction, cross-validation, feature engineering",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "Statsmodels",
    "description": "Comprehensive library for estimating statistical models (OLS, GLM, etc.), conducting tests, and data exploration. Core tool.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://www.statsmodels.org/",
    "github_url": "https://github.com/statsmodels/statsmodels",
    "url": "https://github.com/statsmodels/statsmodels",
    "install": "pip install statsmodels",
    "tags": [
      "regression",
      "linear models"
    ],
    "best_for": "Statistical inference with interpretable coefficients",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "FactorAnalyzer",
    "description": "Specialized library for Exploratory (EFA) and Confirmatory (CFA) Factor Analysis with rotation options for interpretability.",
    "category": "Dimensionality Reduction",
    "docs_url": "https://factor-analyzer.readthedocs.io/en/latest/",
    "github_url": "https://github.com/EducationalTestingService/factor_analyzer",
    "url": "https://github.com/EducationalTestingService/factor_analyzer",
    "install": "pip install factor_analyzer",
    "tags": [
      "machine learning",
      "dimensionality"
    ],
    "best_for": "EFA/CFA with rotation for latent construct extraction",
    "language": "Python"
  },
  {
    "name": "openTSNE",
    "description": "Optimized, parallel implementation of t-distributed Stochastic Neighbor Embedding (t-SNE) for large datasets.",
    "category": "Dimensionality Reduction",
    "docs_url": "https://opentsne.readthedocs.io/en/stable/",
    "github_url": "https://github.com/pavlin-policar/openTSNE",
    "url": "https://github.com/pavlin-policar/openTSNE",
    "install": "pip install opentsne",
    "tags": [
      "machine learning",
      "dimensionality"
    ],
    "best_for": "Large-scale t-SNE with partial fitting capability",
    "language": "Python"
  },
  {
    "name": "umap-learn",
    "description": "Fast and scalable implementation of Uniform Manifold Approximation and Projection (UMAP) for non-linear reduction.",
    "category": "Dimensionality Reduction",
    "docs_url": "https://umap-learn.readthedocs.io/en/latest/",
    "github_url": "https://github.com/lmcinnes/umap",
    "url": "https://github.com/lmcinnes/umap",
    "install": "pip install umap-learn",
    "tags": [
      "machine learning",
      "dimensionality"
    ],
    "best_for": "Fast visualization preserving both local and global structure",
    "language": "Python"
  },
  {
    "name": "Biogeme",
    "description": "Maximum likelihood estimation of parametric models, with strong support for complex discrete choice models.",
    "category": "Discrete Choice Models",
    "docs_url": "https://biogeme.epfl.ch/index.html",
    "github_url": "https://github.com/michelbierlaire/biogeme",
    "url": "https://github.com/michelbierlaire/biogeme",
    "install": "pip install biogeme",
    "tags": [
      "discrete choice",
      "logit"
    ],
    "best_for": "Complex nested logit and mixed logit specifications",
    "language": "Python"
  },
  {
    "name": "PyBLP",
    "description": "Tools for estimating demand for differentiated products using the Berry-Levinsohn-Pakes (BLP) method.",
    "category": "Discrete Choice Models",
    "docs_url": "https://pyblp.readthedocs.io/",
    "github_url": "https://github.com/jeffgortmaker/pyblp",
    "url": "https://github.com/jeffgortmaker/pyblp",
    "install": "pip install pyblp",
    "tags": [
      "discrete choice",
      "logit"
    ],
    "best_for": "BLP demand estimation with price endogeneity",
    "language": "Python"
  },
  {
    "name": "PyLogit",
    "description": "Flexible implementation of conditional/multinomial logit models with utilities for data preparation.",
    "category": "Discrete Choice Models",
    "docs_url": null,
    "github_url": "https://github.com/timothyb0912/pylogit",
    "url": "https://github.com/timothyb0912/pylogit",
    "install": "pip install pylogit",
    "tags": [
      "discrete choice",
      "logit"
    ],
    "best_for": "Flexible conditional logit with panel data support",
    "language": "Python"
  },
  {
    "name": "XLogit",
    "description": "Fast estimation of Multinomial Logit and Mixed Logit models, optimized for performance.",
    "category": "Discrete Choice Models",
    "docs_url": "https://xlogit.readthedocs.io/",
    "github_url": "https://github.com/arteagac/xlogit",
    "url": "https://github.com/arteagac/xlogit",
    "install": "pip install xlogit",
    "tags": [
      "discrete choice",
      "logit"
    ],
    "best_for": "GPU-accelerated large-scale mixed logit estimation",
    "language": "Python"
  },
  {
    "name": "torch-choice",
    "description": "PyTorch framework for flexible estimation of complex discrete choice models, leveraging GPU acceleration.",
    "category": "Discrete Choice Models",
    "docs_url": "https://gsbdbi.github.io/torch-choice/",
    "github_url": "https://github.com/gsbDBI/torch-choice",
    "url": "https://github.com/gsbDBI/torch-choice",
    "install": "pip install torch-choice",
    "tags": [
      "discrete choice",
      "logit"
    ],
    "best_for": "Neural network extensions to choice models",
    "language": "Python"
  },
  {
    "name": "DoubleML",
    "description": "Implements the double/debiased ML framework (Chernozhukov et al.) for estimating causal parameters (ATE, LATE, POM) with ML nuisances.",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://docs.doubleml.org/",
    "github_url": "https://github.com/DoubleML/doubleml-for-py",
    "url": "https://github.com/DoubleML/doubleml-for-py",
    "install": "pip install DoubleML",
    "tags": [
      "machine learning",
      "causal inference"
    ],
    "best_for": "Chernozhukov et al. DML with Neyman orthogonal scores",
    "language": "Python"
  },
  {
    "name": "EconML",
    "description": "Microsoft toolkit for estimating heterogeneous treatment effects using DML, causal forests, meta-learners, and orthogonal ML methods.",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://econml.azurewebsites.net/",
    "github_url": "https://github.com/py-why/EconML",
    "url": "https://github.com/py-why/EconML",
    "install": "pip install econml",
    "tags": [
      "machine learning",
      "causal inference"
    ],
    "best_for": "Microsoft's causal forests with valid confidence intervals",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "pydoublelasso",
    "description": "Double\u2011post\u00a0Lasso estimator for high\u2011dimensional treatment effects (Belloni\u2011Chernozhukov\u2011Hansen\u202f2014).",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://pypi.org/project/pydoublelasso/",
    "github_url": null,
    "url": "https://pypi.org/project/pydoublelasso/",
    "install": "pip install pydoublelasso",
    "tags": [
      "machine learning",
      "causal inference"
    ],
    "best_for": "Double-post-selection Lasso for high-dimensional controls",
    "language": "Python"
  },
  {
    "name": "pyhtelasso",
    "description": "Debiased\u2011Lasso detector of heterogeneous treatment effects in randomized experiments.",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://pypi.org/project/pyhtelasso/",
    "github_url": null,
    "url": "https://pypi.org/project/pyhtelasso/",
    "install": "pip install pyhtelasso",
    "tags": [
      "machine learning",
      "causal inference"
    ],
    "best_for": "Testing for treatment effect heterogeneity in RCTs",
    "language": "Python"
  },
  {
    "name": "py-econometrics `gmm`",
    "description": "Lightweight package for setting up and estimating custom GMM models based on user-defined moment conditions.",
    "category": "Instrumental Variables (IV) & GMM",
    "docs_url": "https://github.com/py-econometrics/gmm",
    "github_url": "https://github.com/py-econometrics/gmm",
    "url": "https://github.com/py-econometrics/gmm",
    "install": "pip install gmm",
    "tags": [
      "IV",
      "GMM"
    ],
    "best_for": "Custom GMM with user-defined moment conditions",
    "language": "Python"
  },
  {
    "name": "Lifetimes",
    "description": "Analyze customer lifetime value (CLV) using probabilistic models (BG/NBD, Pareto/NBD) to predict purchases.",
    "category": "Marketing Mix Models (MMM) & Business Analytics",
    "docs_url": "https://lifetimes.readthedocs.io/en/latest/",
    "github_url": "https://github.com/CamDavidsonPilon/lifetimes",
    "url": "https://github.com/CamDavidsonPilon/lifetimes",
    "install": "pip install lifetimes",
    "tags": [
      "marketing",
      "analytics"
    ],
    "best_for": "Customer lifetime value prediction with BG/NBD models",
    "language": "Python"
  },
  {
    "name": "MaMiMo",
    "description": "Lightweight Python library focused specifically on Marketing Mix Modeling implementation.",
    "category": "Marketing Mix Models (MMM) & Business Analytics",
    "docs_url": null,
    "github_url": "https://github.com/Garve/mamimo",
    "url": "https://github.com/Garve/mamimo",
    "install": "pip install mamimo",
    "tags": [
      "marketing",
      "analytics"
    ],
    "best_for": "Quick MMM prototyping with sklearn compatibility",
    "language": "Python"
  },
  {
    "name": "PyMC Marketing",
    "description": "Collection of Bayesian marketing models built with PyMC, including MMM, CLV, and attribution.",
    "category": "Marketing Mix Models (MMM) & Business Analytics",
    "docs_url": "https://www.pymc-marketing.io/",
    "github_url": "https://github.com/pymc-labs/pymc-marketing",
    "url": "https://github.com/pymc-labs/pymc-marketing",
    "install": "pip install pymc-marketing",
    "tags": [
      "marketing",
      "analytics",
      "Bayesian"
    ],
    "best_for": "Full Bayesian MMM with CLV and attribution",
    "language": "Python"
  },
  {
    "name": "mmm_stan",
    "description": "Python/STAN implementation of Bayesian Marketing Mix Models.",
    "category": "Marketing Mix Models (MMM) & Business Analytics",
    "docs_url": null,
    "github_url": "https://github.com/sibylhe/mmm_stan",
    "url": "https://github.com/sibylhe/mmm_stan",
    "install": "GitHub Repository",
    "tags": [
      "marketing",
      "analytics",
      "Bayesian"
    ],
    "best_for": "Learning MMM internals with transparent Stan code",
    "language": "Python"
  },
  {
    "name": "Gensim",
    "description": "Library focused on topic modeling (LDA, LSI) and document similarity analysis.",
    "category": "Natural Language Processing for Economics",
    "docs_url": "https://radimrehurek.com/gensim/",
    "github_url": "https://github.com/RaRe-Technologies/gensim",
    "url": "https://github.com/RaRe-Technologies/gensim",
    "install": "pip install gensim",
    "tags": [
      "NLP",
      "text analysis"
    ],
    "best_for": "Topic modeling (LDA) and word embeddings on large corpora",
    "language": "Python"
  },
  {
    "name": "Transformers",
    "description": "Access to thousands of pre-trained models for NLP tasks like text classification, summarization, embeddings, etc.",
    "category": "Natural Language Processing for Economics",
    "docs_url": "https://huggingface.co/transformers/",
    "github_url": "https://github.com/huggingface/transformers",
    "url": "https://github.com/huggingface/transformers",
    "install": "pip install transformers",
    "tags": [
      "NLP",
      "text analysis"
    ],
    "best_for": "State-of-the-art NLP with pre-trained transformer models",
    "language": "Python"
  },
  {
    "name": "spaCy",
    "description": "Industrial-strength NLP library for efficient text processing pipelines (NER, POS tagging, etc.).",
    "category": "Natural Language Processing for Economics",
    "docs_url": "https://spacy.io/",
    "github_url": "https://github.com/explosion/spaCy",
    "url": "https://github.com/explosion/spaCy",
    "install": "pip install spacy",
    "tags": [
      "NLP",
      "text analysis"
    ],
    "best_for": "Fast NLP pipelines for NER and entity extraction",
    "language": "Python"
  },
  {
    "name": "JAX",
    "description": "High-performance numerical computing with autograd and XLA compilation on CPU/GPU/TPU.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": "https://jax.readthedocs.io/",
    "github_url": "https://github.com/google/jax",
    "url": "https://github.com/google/jax",
    "install": "pip install jax",
    "tags": [
      "optimization",
      "computation"
    ],
    "best_for": "GPU-accelerated autodiff with functional composition",
    "language": "Python"
  },
  {
    "name": "PyTorch",
    "description": "Popular deep learning framework with flexible automatic differentiation.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": "https://pytorch.org/",
    "github_url": "https://github.com/pytorch/pytorch",
    "url": "https://github.com/pytorch/pytorch",
    "install": "(See PyTorch website)",
    "tags": [
      "optimization",
      "computation",
      "machine learning"
    ],
    "best_for": "Deep learning and neural network estimation",
    "language": "Python"
  },
  {
    "name": "FixedEffectModelPyHDFE",
    "description": "Solves linear models with high-dimensional fixed effects, supporting robust variance calculation and IV.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://pypi.org/project/FixedEffectModelPyHDFE/",
    "github_url": "https://github.com/ksecology/FixedEffectModel",
    "url": "https://pypi.org/project/FixedEffectModelPyHDFE/",
    "install": "pip install FixedEffectModelPyHDFE",
    "tags": [
      "panel data",
      "fixed effects"
    ],
    "best_for": "Millions of fixed effects (reghdfe-style absorption)",
    "language": "Python"
  },
  {
    "name": "Linearmodels",
    "description": "Estimation of fixed, random, pooled OLS models for panel data. Also Fama-MacBeth and between/first-difference estimators.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://bashtage.github.io/linearmodels/",
    "github_url": "https://github.com/bashtage/linearmodels",
    "url": "https://github.com/bashtage/linearmodels",
    "install": "pip install linearmodels",
    "tags": [
      "panel data",
      "fixed effects"
    ],
    "best_for": "Panel, IV, SUR, 3SLS, and Fama-MacBeth in one package",
    "language": "Python"
  },
  {
    "name": "PyFixest",
    "description": "Fast estimation of linear models with multiple high-dimensional fixed effects (like R's `fixest`). Supports OLS, IV, Poisson, robust/cluster SEs.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://github.com/py-econometrics/pyfixest",
    "github_url": "https://github.com/py-econometrics/pyfixest",
    "url": "https://github.com/py-econometrics/pyfixest",
    "install": "pip install pyfixest",
    "tags": [
      "panel data",
      "fixed effects"
    ],
    "best_for": "R fixest port with multi-way FE and wild bootstrap",
    "language": "Python"
  },
  {
    "name": "duckreg",
    "description": "Out-of-core regression (OLS/IV) for very large datasets using DuckDB aggregation. Handles data that doesn't fit in memory.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://github.com/py-econometrics/duckreg",
    "github_url": "https://github.com/py-econometrics/duckreg",
    "url": "https://github.com/py-econometrics/duckreg",
    "install": "pip install duckreg",
    "tags": [
      "panel data",
      "fixed effects"
    ],
    "best_for": "Out-of-core regression on datasets too large for memory",
    "language": "Python"
  },
  {
    "name": "pydynpd",
    "description": "Estimation of dynamic panel data models using Arellano-Bond (Difference GMM) and Blundell-Bond (System GMM). Includes Windmeijer correction & tests.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://doi.org/10.21105/joss.04416",
    "github_url": "https://github.com/dazhwu/pydynpd",
    "url": "https://github.com/dazhwu/pydynpd",
    "install": "pip install pydynpd",
    "tags": [
      "panel data",
      "fixed effects"
    ],
    "best_for": "Dynamic panels with Arellano-Bond/Blundell-Bond GMM",
    "language": "Python"
  },
  {
    "name": "fixest",
    "description": "Fast and comprehensive package for estimating econometric models with multiple high-dimensional fixed effects, including OLS, GLM, Poisson, and negative binomial models. Features native support for clustered standard errors (up to four-way), instrumental variables, and modern difference-in-differences estimators including Sun-Abraham for staggered treatments.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://lrberge.github.io/fixest/",
    "github_url": "https://github.com/lrberge/fixest",
    "url": "https://cran.r-project.org/package=fixest",
    "install": "install.packages(\"fixest\")",
    "tags": [
      "fixed-effects",
      "panel-data",
      "clustered-standard-errors",
      "difference-in-differences",
      "instrumental-variables"
    ],
    "best_for": "Fast, production-ready estimation of linear/GLM models with multiple high-dimensional fixed effects and publication-quality regression tables via etable()",
    "language": "R"
  },
  {
    "name": "plm",
    "description": "Comprehensive econometrics package for linear panel models providing fixed effects (within), random effects, between, first-difference, Hausman-Taylor, and nested random effects estimators. Includes GMM, FGLS, and extensive diagnostic tests for serial correlation, cross-sectional dependence, and panel unit roots.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/plm/vignettes/",
    "github_url": "https://github.com/ycroissant/plm",
    "url": "https://cran.r-project.org/package=plm",
    "install": "install.packages(\"plm\")",
    "tags": [
      "panel-data",
      "econometrics",
      "fixed-effects",
      "random-effects",
      "hausman-test"
    ],
    "best_for": "Comprehensive panel data analysis requiring within/between/random effects estimation, Hausman tests, and extensive diagnostic testing",
    "language": "R"
  },
  {
    "name": "lfe",
    "description": "Efficiently estimates linear models with multiple high-dimensional fixed effects using the Method of Alternating Projections. Designed for datasets with factors having thousands of levels (hundreds of thousands of dummy variables), with full support for 2SLS instrumental variables and multi-way clustered standard errors.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/lfe/lfe.pdf",
    "github_url": "https://github.com/r-econometrics/lfe",
    "url": "https://cran.r-project.org/package=lfe",
    "install": "install.packages(\"lfe\")",
    "tags": [
      "high-dimensional-fe",
      "worker-firm",
      "memory-efficient",
      "instrumental-variables",
      "clustered-se"
    ],
    "best_for": "AKM-style wage decompositions and matched employer-employee data with hundreds of thousands of worker/firm fixed effects",
    "language": "R"
  },
  {
    "name": "panelr",
    "description": "Automates within-between (hybrid) model specification for panel/longitudinal data, combining fixed effects robustness to time-invariant confounding with random effects ability to estimate time-invariant coefficients. Uses lme4 for multilevel estimation with optional Bayesian (brms) and GEE (geepack) backends.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://panelr.jacob-long.com/",
    "github_url": "https://github.com/jacob-long/panelr",
    "url": "https://cran.r-project.org/package=panelr",
    "install": "install.packages(\"panelr\")",
    "tags": [
      "hybrid-models",
      "within-between",
      "panel-data",
      "longitudinal-analysis",
      "bell-jones"
    ],
    "best_for": "Researchers needing fixed effects-equivalent estimates while retaining time-invariant predictors and random slopes",
    "language": "R"
  },
  {
    "name": "bife",
    "description": "Estimates fixed effects binary choice models (logit and probit) with potentially many individual fixed effects using a pseudo-demeaning algorithm. Addresses the incidental parameters problem through analytical bias correction based on Fern√°ndez-Val (2009) and computes average partial effects.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/bife/vignettes/howto.html",
    "github_url": "https://github.com/amrei-stammann/bife",
    "url": "https://cran.r-project.org/package=bife",
    "install": "install.packages(\"bife\")",
    "tags": [
      "binary-choice",
      "fixed-effects",
      "logit-probit",
      "bias-correction",
      "panel-data"
    ],
    "best_for": "Fast estimation of fixed effects logit/probit models on large panel data with analytical bias correction for the incidental parameters problem",
    "language": "R"
  },
  {
    "name": "alpaca",
    "description": "Fits generalized linear models (Poisson, negative binomial, logit, probit, Gamma) with high-dimensional k-way fixed effects. Partials out factors during log-likelihood optimization and provides robust/multi-way clustered standard errors, fixed effects recovery, and analytical bias corrections for binary choice models.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/alpaca/vignettes/howto.html",
    "github_url": "https://github.com/amrei-stammann/alpaca",
    "url": "https://cran.r-project.org/package=alpaca",
    "install": "install.packages(\"alpaca\")",
    "tags": [
      "glm",
      "fixed-effects",
      "poisson-regression",
      "negative-binomial",
      "gravity-models"
    ],
    "best_for": "Nonlinear panel models (Poisson, logit, probit, negative binomial) with multiple high-dimensional fixed effects, especially structural gravity models for international trade",
    "language": "R"
  },
  {
    "name": "ADOpy",
    "description": "Bayesian Adaptive Design Optimization (ADO) for tuning experiments in real-time, with models for psychometric tasks.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": null,
    "github_url": "https://github.com/adopy/adopy",
    "url": "https://github.com/adopy/adopy",
    "install": "pip install adopy",
    "tags": [
      "power analysis",
      "experiments",
      "Bayesian"
    ],
    "best_for": "Bayesian adaptive experiment design in real-time",
    "language": "Python"
  },
  {
    "name": "Adaptive",
    "description": "Parallel active learning library for adaptive function sampling/evaluation, with live plotting for monitoring.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": "https://adaptive.readthedocs.io/en/latest/",
    "github_url": "https://github.com/python-adaptive/adaptive",
    "url": "https://github.com/python-adaptive/adaptive",
    "install": "pip install adaptive",
    "tags": [
      "power analysis",
      "experiments"
    ],
    "best_for": "Active learning with adaptive function sampling",
    "language": "Python"
  },
  {
    "name": "DoEgen",
    "description": "Automates generation and optimization of designs, especially for mixed factor-level experiments; computes efficiency metrics.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": null,
    "github_url": "https://github.com/sebhaan/DoEgen",
    "url": "https://github.com/sebhaan/DoEgen",
    "install": "pip install DoEgen",
    "tags": [
      "power analysis",
      "experiments"
    ],
    "best_for": "Optimizing mixed factor-level experimental designs",
    "language": "Python"
  },
  {
    "name": "pyDOE2",
    "description": "Implements classical Design of Experiments: factorial (full/fractional), response surface (Box-Behnken, CCD), Latin Hypercube.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": "https://github.com/clicumu/pyDOE2",
    "github_url": "https://github.com/clicumu/pyDOE2",
    "url": "https://github.com/clicumu/pyDOE2",
    "install": "pip install pyDOE2",
    "tags": [
      "power analysis",
      "experiments"
    ],
    "best_for": "Classical factorial and response surface designs",
    "language": "Python"
  },
  {
    "name": "CausalImpact",
    "description": "Python port of Google's R package for estimating causal effects of interventions on time series using Bayesian structural time-series models.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://github.com/WillianFuks/tfcausalimpact",
    "github_url": "https://github.com/tcassou/causal_impact",
    "url": "https://github.com/tcassou/causal_impact",
    "install": "pip install causalimpact",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD",
      "Bayesian"
    ],
    "best_for": "Time series intervention effects with Bayesian STS",
    "language": "Python"
  },
  {
    "name": "Differences",
    "description": "Implements modern difference-in-differences methods for staggered adoption designs (e.g., Callaway & Sant'Anna).",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://bernardodionisi.github.io/differences/",
    "github_url": "https://github.com/bernardodionisi/differences",
    "url": "https://github.com/bernardodionisi/differences",
    "install": "pip install differences",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD"
    ],
    "best_for": "Modern staggered DiD (Callaway-Sant'Anna, Sun-Abraham)",
    "language": "Python"
  },
  {
    "name": "SyntheticControlMethods",
    "description": "Implementation of synthetic control methods for comparative case studies when panel data is available.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": null,
    "github_url": "https://github.com/OscarEngelbrektson/SyntheticControlMethods",
    "url": "https://github.com/OscarEngelbrektson/SyntheticControlMethods",
    "install": "pip install SyntheticControlMethods",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD"
    ],
    "best_for": "Classic Abadie-Hainmueller synthetic control",
    "language": "Python"
  },
  {
    "name": "csdid",
    "description": "Python adaptation of the R `did` package. Implements multi-period DiD with staggered treatment timing (Callaway & Sant\u2019Anna).",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": null,
    "github_url": "https://github.com/d2cml-ai/csdid",
    "url": "https://github.com/d2cml-ai/csdid",
    "install": "pip install csdid",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD"
    ],
    "best_for": "Exact R `did` package replication in Python",
    "language": "Python"
  },
  {
    "name": "mlsynth",
    "description": "Machine-Learning Synthetic Control. The most comprehensive SC package with 10+ methods: Forward DiD, Cluster SC, Factor Models, Two-Step SC, Proximal SC, Synthetic Interventions, and more.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://mlsynth.readthedocs.io/en/latest/",
    "github_url": "https://github.com/jgreathouse9/mlsynth",
    "url": "https://github.com/jgreathouse9/mlsynth",
    "install": "pip install mlsynth",
    "tags": [
      "synthetic control",
      "causal inference",
      "program evaluation",
      "DiD"
    ],
    "best_for": "Largest open-source synthetic control package with multiple estimators",
    "language": "Python"
  },
  {
    "name": "pycinc",
    "description": "Changes\u2011in\u2011Changes (CiC) estimator for distributional treatment effects (Athey\u00a0&\u00a0Imbens\u202f2006).",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://pypi.org/project/pycinc/",
    "github_url": "https://github.com/vyasenov/pycinc",
    "url": "https://pypi.org/project/pycinc/",
    "install": "pip install pycinc",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD",
      "causal inference"
    ],
    "best_for": "Distributional treatment effects (Changes-in-Changes)",
    "language": "Python"
  },
  {
    "name": "pyleebounds",
    "description": "Lee\u00a0(2009) sample\u2011selection bounds for treatment effects; trims treated distribution to match selection rates.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://pypi.org/project/pyleebounds/",
    "github_url": null,
    "url": "https://pypi.org/project/pyleebounds/",
    "install": "pip install pyleebounds",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD",
      "causal inference"
    ],
    "best_for": "Bounds under sample selection (Lee 2009)",
    "language": "Python"
  },
  {
    "name": "rdd",
    "description": "Toolkit for sharp RDD analysis, including bandwidth calculation and estimation, integrating with pandas.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": null,
    "github_url": "https://github.com/evan-magnusson/rdd",
    "url": "https://github.com/evan-magnusson/rdd",
    "install": "pip install rdd",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD"
    ],
    "best_for": "Quick sharp RDD with Imbens-Kalyanaraman bandwidth",
    "language": "Python"
  },
  {
    "name": "rdrobust",
    "description": "Comprehensive tools for Regression Discontinuity Designs (RDD), including optimal bandwidth selection, estimation, inference.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://pypi.org/project/rdrobust/",
    "github_url": "https://github.com/rdpackages/rdrobust",
    "url": "https://github.com/rdpackages/rdrobust",
    "install": "pip install rdrobust",
    "tags": [
      "DiD",
      "synthetic control",
      "RDD"
    ],
    "best_for": "Rigorous RDD with robust bias-corrected inference",
    "language": "Python"
  },
  {
    "name": "pyqreg",
    "description": "Fast quantile regression solver using interior point methods, supporting robust and clustered standard errors.",
    "category": "Quantile Regression & Distributional Methods",
    "docs_url": "https://github.com/mozjay0619/pyqreg",
    "github_url": "https://github.com/mozjay0619/pyqreg",
    "url": "https://github.com/mozjay0619/pyqreg",
    "install": "pip install pyqreg",
    "tags": [
      "quantile",
      "regression"
    ],
    "best_for": "Fast conditional quantile regression with clustered SEs",
    "language": "Python"
  },
  {
    "name": "pyrifreg",
    "description": "Recentered Influence\u2011Function (RIF) regression for unconditional quantile & distributional effects (Firpo\u202fet\u202fal.,\u202f2008).",
    "category": "Quantile Regression & Distributional Methods",
    "docs_url": "https://github.com/vyasenov/pyrifreg",
    "github_url": "https://github.com/vyasenov/pyrifreg",
    "url": "https://github.com/vyasenov/pyrifreg",
    "install": "pip install pyrifreg",
    "tags": [
      "quantile",
      "regression"
    ],
    "best_for": "Unconditional quantile effects (RIF regression)",
    "language": "Python"
  },
  {
    "name": "quantile-forest",
    "description": "Scikit-learn compatible implementation of Quantile Regression Forests for non-parametric estimation.",
    "category": "Quantile Regression & Distributional Methods",
    "docs_url": "https://zillow.github.io/quantile-forest/",
    "github_url": "https://github.com/zillow/quantile-forest",
    "url": "https://github.com/zillow/quantile-forest",
    "install": "pip install quantile-forest",
    "tags": [
      "quantile",
      "regression"
    ],
    "best_for": "Non-parametric quantile prediction with random forests",
    "language": "Python"
  },
  {
    "name": "(PySAL Core)",
    "description": "The broader PySAL ecosystem contains many tools for spatial data handling, weights, visualization, and analysis.",
    "category": "Spatial Econometrics",
    "docs_url": "https://pysal.org/",
    "github_url": "https://github.com/pysal/pysal",
    "url": "https://github.com/pysal/pysal",
    "install": "pip install pysal",
    "tags": [
      "spatial",
      "geography"
    ],
    "best_for": "Broad spatial ecosystem (weights, visualization, analysis)",
    "language": "Python"
  },
  {
    "name": "PySAL (spreg)",
    "description": "The spatial regression `spreg` module of PySAL. Implements spatial lag, error, IV models, and diagnostics.",
    "category": "Spatial Econometrics",
    "docs_url": "https://pysal.org/spreg/",
    "github_url": "https://github.com/pysal/spreg",
    "url": "https://github.com/pysal/spreg",
    "install": "pip install spreg",
    "tags": [
      "spatial",
      "geography"
    ],
    "best_for": "Spatial lag/error models with IV and diagnostics",
    "language": "Python"
  },
  {
    "name": "SciPy Bootstrap",
    "description": "(`scipy.stats.bootstrap`) Computes bootstrap confidence intervals for various statistics using percentile, BCa methods.",
    "category": "Inference & Reporting Tools",
    "docs_url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html",
    "github_url": "https://github.com/scipy/scipy",
    "url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html",
    "install": "pip install scipy",
    "tags": [
      "bootstrap",
      "standard errors"
    ],
    "best_for": "Standard bootstrap confidence intervals",
    "language": "Python"
  },
  {
    "name": "Stargazer",
    "description": "Python port of R's stargazer for creating publication-quality regression tables (HTML, LaTeX) from `statsmodels` & `linearmodels` results.",
    "category": "Inference & Reporting Tools",
    "docs_url": null,
    "github_url": "https://github.com/StatsReporting/stargazer",
    "url": "https://github.com/StatsReporting/stargazer",
    "install": "pip install stargazer",
    "tags": [
      "bootstrap",
      "standard errors"
    ],
    "best_for": "Publication-quality regression tables (LaTeX/HTML)",
    "language": "Python"
  },
  {
    "name": "wildboottest",
    "description": "Fast implementation of various wild cluster bootstrap algorithms (WCR, WCU) for robust inference, especially with few clusters.",
    "category": "Inference & Reporting Tools",
    "docs_url": "https://py-econometrics.github.io/wildboottest/",
    "github_url": "https://github.com/py-econometrics/wildboottest",
    "url": "https://github.com/py-econometrics/wildboottest",
    "install": "pip install wildboottest",
    "tags": [
      "bootstrap",
      "standard errors"
    ],
    "best_for": "Wild cluster bootstrap for few-cluster inference",
    "language": "Python"
  },
  {
    "name": "FilterPy",
    "description": "Focuses on Kalman filters (standard, EKF, UKF) and smoothers with a clear, pedagogical implementation style.",
    "category": "State Space & Volatility Models",
    "docs_url": "https://filterpy.readthedocs.io/en/latest/",
    "github_url": "https://github.com/rlabbe/filterpy",
    "url": "https://github.com/rlabbe/filterpy",
    "install": "pip install filterpy",
    "tags": [
      "volatility",
      "state space"
    ],
    "best_for": "Learning Kalman filters with pedagogical implementation",
    "language": "Python"
  },
  {
    "name": "Metran",
    "description": "Specialized package for estimating Dynamic Factor Models (DFM) using state-space methods and Kalman filtering.",
    "category": "State Space & Volatility Models",
    "docs_url": null,
    "github_url": "https://github.com/pastas/metran",
    "url": "https://github.com/pastas/metran",
    "install": "pip install metran",
    "tags": [
      "volatility",
      "state space"
    ],
    "best_for": "Dynamic Factor Models with state-space methods",
    "language": "Python"
  },
  {
    "name": "PyKalman",
    "description": "Implements Kalman filter, smoother, and EM algorithm for parameter estimation, including support for missing values and UKF.",
    "category": "State Space & Volatility Models",
    "docs_url": "https://pypi.org/project/pykalman/",
    "github_url": "https://github.com/pykalman/pykalman",
    "url": "https://github.com/pykalman/pykalman",
    "install": "pip install pykalman",
    "tags": [
      "volatility",
      "state space"
    ],
    "best_for": "Kalman filtering with missing values and EM estimation",
    "language": "Python"
  },
  {
    "name": "PyMC Statespace",
    "description": "(See Bayesian) Bayesian state-space modeling using PyMC, integrating Kalman filtering within MCMC for parameter estimation.",
    "category": "State Space & Volatility Models",
    "docs_url": "https://www.pymc.io/projects/extras/en/latest/statespace/generated/pymc_extras.statespace.core.PyMCStateSpace.html",
    "github_url": "https://github.com/pymc-devs/pymc-extras",
    "url": "https://github.com/pymc-devs/pymc-extras",
    "install": "pip install pymc-statespace",
    "tags": [
      "volatility",
      "state space",
      "Bayesian"
    ],
    "best_for": "Bayesian state-space with MCMC parameter estimation",
    "language": "Python"
  },
  {
    "name": "Pingouin",
    "description": "User-friendly interface for common statistical tests (ANOVA, ANCOVA, t-tests, correlations, chi\u00b2, reliability) built on pandas & scipy.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://pingouin-stats.org/",
    "github_url": "https://github.com/raphaelvallat/pingouin",
    "url": "https://github.com/raphaelvallat/pingouin",
    "install": "pip install pingouin",
    "tags": [
      "inference",
      "hypothesis testing"
    ],
    "best_for": "Easy ANOVA, t-tests, correlations with pandas",
    "language": "Python"
  },
  {
    "name": "PyWhy-Stats",
    "description": "Part of the PyWhy ecosystem providing statistical methods specifically for causal applications, including various independence tests and power-divergence methods.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://github.com/py-why/pywhy-stats",
    "github_url": "https://github.com/py-why/pywhy-stats",
    "url": "https://github.com/py-why/pywhy-stats",
    "install": "pip install pywhy-stats",
    "tags": [
      "inference",
      "hypothesis testing"
    ],
    "best_for": "Independence tests for causal applications",
    "language": "Python"
  },
  {
    "name": "Scipy.stats",
    "description": "Foundational module within SciPy for a wide range of statistical functions, distributions, and hypothesis tests (t-tests, ANOVA, chi\u00b2, KS, etc.).",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://docs.scipy.org/doc/scipy/reference/stats.html",
    "github_url": "https://github.com/scipy/scipy",
    "url": "https://docs.scipy.org/doc/scipy/reference/stats.html",
    "install": "pip install scipy",
    "tags": [
      "inference",
      "hypothesis testing"
    ],
    "best_for": "Foundational distributions and hypothesis tests",
    "language": "Python"
  },
  {
    "name": "hypothetical",
    "description": "Library focused on hypothesis testing: ANOVA/MANOVA, t-tests, chi-square, Fisher's exact, nonparametric tests (Mann-Whitney, Kruskal-Wallis, etc.).",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": null,
    "github_url": "https://github.com/aschleg/hypothetical",
    "url": "https://github.com/aschleg/hypothetical",
    "install": "pip install hypothetical",
    "tags": [
      "inference",
      "hypothesis testing"
    ],
    "best_for": "Comprehensive hypothesis testing library",
    "language": "Python"
  },
  {
    "name": "lifelines",
    "description": "Comprehensive library for survival analysis: Kaplan-Meier, Nelson-Aalen, Cox regression, AFT models, handling censored data.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://lifelines.readthedocs.io/en/latest/",
    "github_url": "https://github.com/CamDavidsonPilon/lifelines",
    "url": "https://github.com/CamDavidsonPilon/lifelines",
    "install": "pip install lifelines",
    "tags": [
      "inference",
      "hypothesis testing"
    ],
    "best_for": "Survival analysis with Cox regression and AFT models",
    "language": "Python"
  },
  {
    "name": "Dolo",
    "description": "Framework for describing and solving economic models (DSGE, OLG, etc.) using a declarative YAML-based format.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://dolo.readthedocs.io/en/latest/",
    "github_url": "https://github.com/EconForge/dolo",
    "url": "https://github.com/EconForge/dolo",
    "install": "pip install dolo",
    "tags": [
      "structural",
      "estimation"
    ],
    "best_for": "DSGE/OLG models with YAML-based specification",
    "language": "Python"
  },
  {
    "name": "HARK",
    "description": "Toolkit for solving, simulating, and estimating models with heterogeneous agents (e.g., consumption-saving).",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://docs.econ-ark.org/",
    "github_url": "https://github.com/econ-ark/HARK",
    "url": "https://github.com/econ-ark/HARK",
    "install": "pip install econ-ark",
    "tags": [
      "structural",
      "estimation"
    ],
    "best_for": "Heterogeneous agent consumption-saving models",
    "language": "Python"
  },
  {
    "name": "QuantEcon.py",
    "description": "Core library for quantitative economics: dynamic programming, Markov chains, game theory, numerical methods.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://quantecon.org/python-lectures/",
    "github_url": "https://github.com/QuantEcon/QuantEcon.py",
    "url": "https://github.com/QuantEcon/QuantEcon.py",
    "install": "pip install quantecon",
    "tags": [
      "structural",
      "estimation"
    ],
    "best_for": "Dynamic programming, Markov chains, game theory",
    "language": "Python"
  },
  {
    "name": "respy",
    "description": "Simulation and estimation of finite-horizon dynamic discrete choice (DDC) models (e.g., labor/education choice).",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://respy.readthedocs.io/en/latest/",
    "github_url": "https://github.com/OpenSourceEconomics/respy",
    "url": "https://github.com/OpenSourceEconomics/respy",
    "install": "pip install respy",
    "tags": [
      "structural",
      "estimation"
    ],
    "best_for": "Dynamic discrete choice (labor/education) estimation",
    "language": "Python"
  },
  {
    "name": "SDV (Synthetic Data Vault)",
    "description": "Comprehensive library for generating synthetic tabular, relational, and time series data using various models.",
    "category": "Synthetic Data Generation",
    "docs_url": "https://sdv.dev/",
    "github_url": "https://github.com/sdv-dev/SDV",
    "url": "https://github.com/sdv-dev/SDV",
    "install": "pip install sdv",
    "tags": [
      "synthetic data",
      "simulation"
    ],
    "best_for": "Comprehensive synthetic tabular/relational data",
    "language": "Python"
  },
  {
    "name": "Synthpop",
    "description": "Port of the R package for generating synthetic populations based on sample survey data.",
    "category": "Synthetic Data Generation",
    "docs_url": null,
    "github_url": "https://github.com/alan-turing-institute/synthpop",
    "url": "https://github.com/alan-turing-institute/synthpop",
    "install": "pip install synthpop",
    "tags": [
      "synthetic data",
      "simulation"
    ],
    "best_for": "Synthetic survey populations from sample data",
    "language": "Python"
  },
  {
    "name": "ARCH",
    "description": "Specialized library for modeling and forecasting conditional volatility using ARCH, GARCH, EGARCH, and related models.",
    "category": "Time Series Econometrics",
    "docs_url": "https://arch.readthedocs.io/",
    "github_url": "https://github.com/bashtage/arch",
    "url": "https://github.com/bashtage/arch",
    "install": "pip install arch",
    "tags": [
      "time series",
      "econometrics"
    ],
    "best_for": "GARCH/ARCH volatility modeling and forecasting",
    "language": "Python"
  },
  {
    "name": "Kats",
    "description": "Broad toolkit for time series analysis, including multivariate analysis, detection (outliers, change points, trends), feature extraction.",
    "category": "Time Series Econometrics",
    "docs_url": "https://facebookresearch.github.io/Kats/",
    "github_url": "https://github.com/facebookresearch/Kats",
    "url": "https://github.com/facebookresearch/Kats",
    "install": "pip install kats",
    "tags": [
      "time series",
      "econometrics"
    ],
    "best_for": "Anomaly detection, change points, and feature extraction",
    "language": "Python"
  },
  {
    "name": "LocalProjections",
    "description": "Community implementations of Jord\u00e0 (2005) Local Projections for estimating impulse responses without VAR assumptions.",
    "category": "Time Series Econometrics",
    "docs_url": null,
    "github_url": "https://github.com/elenev/localprojections",
    "url": "https://github.com/elenev/localprojections",
    "install": "Install from source",
    "tags": [
      "time series",
      "econometrics"
    ],
    "best_for": "Local projections impulse responses",
    "language": "Python"
  },
  {
    "name": "MLForecast",
    "description": "Scalable time series forecasting using machine learning models (e.g., LightGBM, XGBoost) as regressors.",
    "category": "Time Series Forecasting",
    "docs_url": "https://nixtla.github.io/mlforecast/",
    "github_url": "https://github.com/Nixtla/mlforecast",
    "url": "https://github.com/Nixtla/mlforecast",
    "install": "pip install mlforecast",
    "tags": [
      "forecasting",
      "time series",
      "machine learning"
    ],
    "best_for": "ML-based forecasting with LightGBM/XGBoost",
    "language": "Python"
  },
  {
    "name": "NeuralForecast",
    "description": "Deep learning models (N-BEATS, N-HiTS, Transformers, RNNs) for time series forecasting, built on PyTorch Lightning.",
    "category": "Time Series Forecasting",
    "docs_url": "https://nixtlaverse.nixtla.io/neuralforecast/",
    "github_url": "https://github.com/Nixtla/neuralforecast",
    "url": "https://github.com/Nixtla/neuralforecast",
    "install": "pip install neuralforecast",
    "tags": [
      "forecasting",
      "time series",
      "machine learning"
    ],
    "best_for": "Deep learning forecasting (N-BEATS, Transformers)",
    "language": "Python"
  },
  {
    "name": "Prophet",
    "description": "Forecasting procedure for time series with strong seasonality and trend components, developed by Facebook.",
    "category": "Time Series Forecasting",
    "docs_url": "https://facebook.github.io/prophet/",
    "github_url": "https://github.com/facebook/prophet",
    "url": "https://github.com/facebook/prophet",
    "install": "pip install prophet",
    "tags": [
      "forecasting",
      "time series"
    ],
    "best_for": "Meta's holidays + seasonality for non-statisticians",
    "language": "Python"
  },
  {
    "name": "StatsForecast",
    "description": "Fast, scalable implementations of popular statistical forecasting models (ETS, ARIMA, Theta, etc.) optimized for performance.",
    "category": "Time Series Forecasting",
    "docs_url": "https://nixtla.github.io/statsforecast/",
    "github_url": "https://github.com/Nixtla/statsforecast",
    "url": "https://github.com/Nixtla/statsforecast",
    "install": "pip install statsforecast",
    "tags": [
      "forecasting",
      "time series"
    ],
    "best_for": "20x faster than pmdarima with Spark/Dask/Ray scaling",
    "language": "Python"
  },
  {
    "name": "pmdarima",
    "description": "ARIMA modeling with automatic parameter selection (auto-ARIMA), similar to R's `forecast::auto.arima`.",
    "category": "Time Series Forecasting",
    "docs_url": "https://alkaline-ml.com/pmdarima/",
    "github_url": "https://github.com/alkaline-ml/pmdarima",
    "url": "https://github.com/alkaline-ml/pmdarima",
    "install": "pip install pmdarima",
    "tags": [
      "forecasting",
      "time series"
    ],
    "best_for": "Auto-ARIMA with automatic parameter selection",
    "language": "Python"
  },
  {
    "name": "sktime",
    "description": "Unified framework for various time series tasks, including forecasting with classical, ML, and deep learning models.",
    "category": "Time Series Forecasting",
    "docs_url": "https://www.sktime.net/en/latest/",
    "github_url": "https://github.com/sktime/sktime",
    "url": "https://github.com/sktime/sktime",
    "install": "pip install sktime",
    "tags": [
      "forecasting",
      "time series",
      "machine learning"
    ],
    "best_for": "Unified sklearn-style time series framework",
    "language": "Python"
  },
  {
    "name": "CatBoost",
    "description": "Gradient boosting library excelling with categorical features (minimal preprocessing needed). Robust against overfitting.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://catboost.ai/docs/",
    "github_url": "https://github.com/catboost/catboost",
    "url": "https://github.com/catboost/catboost",
    "install": "pip install catboost",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "Native categorical encoding with ordered boosting",
    "language": "Python"
  },
  {
    "name": "LightGBM",
    "description": "Fast, distributed gradient boosting (also supports RF). Known for speed, low memory usage, and handling large datasets.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://lightgbm.readthedocs.io/",
    "github_url": "https://github.com/microsoft/LightGBM",
    "url": "https://github.com/microsoft/LightGBM",
    "install": "pip install lightgbm",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "Histogram + leaf-wise growth for speed and low memory",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "NGBoost",
    "description": "Extends gradient boosting to probabilistic prediction, providing uncertainty estimates alongside point predictions. Built on scikit-learn.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://stanfordmlgroup.github.io/ngboost/",
    "github_url": "https://github.com/stanfordmlgroup/ngboost",
    "url": "https://github.com/stanfordmlgroup/ngboost",
    "install": "pip install ngboost",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "Probabilistic predictions with uncertainty estimates",
    "language": "Python"
  },
  {
    "name": "Scikit-learn Ens.",
    "description": "(`RandomForestClassifier`/`Regressor`) Widely-used, versatile implementation of Random Forests. Easy API and parallel processing support.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://scikit-learn.org/stable/modules/ensemble.html#random-forests",
    "github_url": "https://github.com/scikit-learn/scikit-learn",
    "url": "https://scikit-learn.org/stable/modules/ensemble.html#random-forests",
    "install": "pip install scikit-learn",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "General-purpose random forests in sklearn ecosystem",
    "language": "Python"
  },
  {
    "name": "XGBoost",
    "description": "High-performance, optimized gradient boosting library (also supports RF). Known for speed, efficiency, and winning competitions.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://xgboost.readthedocs.io/",
    "github_url": "https://github.com/dmlc/xgboost",
    "url": "https://github.com/dmlc/xgboost",
    "install": "pip install xgboost",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "Optimized gradient boosting, competition winner",
    "staffPick": true,
    "language": "Python"
  },
  {
    "name": "cuML (RAPIDS)",
    "description": "GPU-accelerated implementation of Random Forests for significant speedups on large datasets. Scikit-learn compatible API.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://docs.rapids.ai/api/cuml/stable/",
    "github_url": "https://github.com/rapidsai/cuml",
    "url": "https://github.com/rapidsai/cuml",
    "install": "conda install ... (See RAPIDS docs)",
    "tags": [
      "machine learning",
      "prediction"
    ],
    "best_for": "GPU-accelerated random forests for massive scale",
    "language": "Python"
  },
  {
    "name": "synthlearners",
    "description": "Fast synthetic control estimators for panel data problems. Optimized ATT estimation with multiple SC algorithms.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": null,
    "github_url": "https://github.com/apoorvalal/synthlearners",
    "url": "https://github.com/apoorvalal/synthlearners",
    "install": "pip install synthlearners",
    "tags": [
      "synthetic control",
      "causal inference",
      "panel data"
    ],
    "best_for": "Optimized synthetic control with multiple algorithm options",
    "language": "Python"
  },
  {
    "name": "aipyw",
    "description": "Minimal, fast AIPW (Augmented Inverse Probability Weighting) implementation for discrete treatments. Sklearn-compatible with cross-fitting.",
    "category": "Causal Inference & Matching",
    "docs_url": null,
    "github_url": "https://github.com/apoorvalal/aipyw",
    "url": "https://github.com/apoorvalal/aipyw",
    "install": "pip install aipyw",
    "tags": [
      "causal inference",
      "AIPW",
      "treatment effects"
    ],
    "best_for": "Fast AIPW estimation with sklearn models",
    "language": "Python"
  },
  {
    "name": "torchonometrics",
    "description": "Econometrics implementations in PyTorch. Leverages autodiff and GPU acceleration for econometric methods.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": null,
    "github_url": "https://github.com/apoorvalal/torchonometrics",
    "url": "https://github.com/apoorvalal/torchonometrics",
    "install": "GitHub Repository",
    "tags": [
      "optimization",
      "computation",
      "PyTorch"
    ],
    "best_for": "GPU-accelerated econometrics with PyTorch autodiff",
    "language": "Python"
  },
  {
    "name": "econpizza",
    "description": "Solve nonlinear heterogeneous agent models (HANK) with perfect foresight. Efficient perturbation and projection methods.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://econpizza.readthedocs.io/",
    "github_url": "https://github.com/gboehl/econpizza",
    "url": "https://github.com/gboehl/econpizza",
    "install": "pip install econpizza",
    "tags": [
      "structural",
      "DSGE",
      "HANK"
    ],
    "best_for": "Nonlinear HANK models with aggregate shocks",
    "language": "Python"
  },
  {
    "name": "pydsge",
    "description": "DSGE model simulation, filtering, and Bayesian estimation. Handles occasionally binding constraints.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/gboehl/pydsge",
    "url": "https://github.com/gboehl/pydsge",
    "install": "pip install pydsge",
    "tags": [
      "structural",
      "DSGE",
      "Bayesian"
    ],
    "best_for": "DSGE estimation with occasionally binding constraints",
    "language": "Python"
  },
  {
    "name": "gEconpy",
    "description": "DSGE modeling tools inspired by R's gEcon. Automatic first-order condition derivation with Dynare export.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/jessegrabowski/gEconpy",
    "url": "https://github.com/jessegrabowski/gEconpy",
    "install": "pip install gEconpy",
    "tags": [
      "structural",
      "DSGE",
      "estimation"
    ],
    "best_for": "Symbolic DSGE derivation with Dynare compatibility",
    "language": "Python"
  },
  {
    "name": "pynare",
    "description": "Python wrapper/interface to Dynare for DSGE model solving. Bridge between Python workflows and Dynare.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/gboehl/pynare",
    "url": "https://github.com/gboehl/pynare",
    "install": "pip install pynare",
    "tags": [
      "structural",
      "DSGE",
      "Dynare"
    ],
    "best_for": "Running Dynare models from Python",
    "language": "Python"
  },
  {
    "name": "dcegm",
    "description": "JAX-compatible DC-EGM algorithm for discrete-continuous dynamic programming (Iskhakov et al. 2017).",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/OpenSourceEconomics/dcegm",
    "url": "https://github.com/OpenSourceEconomics/dcegm",
    "install": "pip install dcegm",
    "tags": [
      "structural",
      "dynamic programming",
      "JAX"
    ],
    "best_for": "Discrete-continuous choice models with EGM",
    "language": "Python"
  },
  {
    "name": "upper-envelope",
    "description": "Fast upper envelope scan for discrete-continuous dynamic programming. JAX and numba implementations.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/OpenSourceEconomics/upper-envelope",
    "url": "https://github.com/OpenSourceEconomics/upper-envelope",
    "install": "pip install upper-envelope",
    "tags": [
      "structural",
      "dynamic programming",
      "optimization"
    ],
    "best_for": "Fast upper envelope computation for DC-EGM",
    "language": "Python"
  },
  {
    "name": "maketables",
    "description": "Publication-ready regression tables for pyfixest, statsmodels, linearmodels. Outputs HTML (great-tables), LaTeX, Word.",
    "category": "Inference & Reporting Tools",
    "docs_url": null,
    "github_url": "https://github.com/py-econometrics/maketables",
    "url": "https://github.com/py-econometrics/maketables",
    "install": "pip install maketables",
    "tags": [
      "reporting",
      "tables",
      "visualization"
    ],
    "best_for": "Multi-format regression tables from pyfixest/statsmodels",
    "language": "Python"
  },
  {
    "name": "jaxonometrics",
    "description": "JAX-ecosystem implementations of standard econometrics routines for GPU computation.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": null,
    "github_url": "https://github.com/py-econometrics/jaxonometrics",
    "url": "https://github.com/py-econometrics/jaxonometrics",
    "install": "GitHub Repository",
    "tags": [
      "optimization",
      "JAX",
      "GPU"
    ],
    "best_for": "GPU-accelerated econometrics with JAX",
    "language": "Python"
  },
  {
    "name": "y0",
    "description": "Causal inference framework providing tools for causal graph manipulation and effect identification.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://y0.readthedocs.io/",
    "github_url": "https://github.com/y0-causal-inference/y0",
    "url": "https://github.com/y0-causal-inference/y0",
    "install": "pip install y0",
    "tags": [
      "causal inference",
      "graphs",
      "identification"
    ],
    "best_for": "Causal graph manipulation and do-calculus",
    "language": "Python"
  },
  {
    "name": "pysyncon",
    "description": "Synthetic control method implementation compatible with R's Synth and augsynth packages.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": null,
    "github_url": "https://github.com/sdfordham/pysyncon",
    "url": "https://github.com/sdfordham/pysyncon",
    "install": "pip install pysyncon",
    "tags": [
      "synthetic control",
      "causal inference",
      "panel data"
    ],
    "best_for": "R Synth-compatible synthetic control in Python",
    "language": "Python"
  },
  {
    "name": "synthdid",
    "description": "Synthetic difference-in-differences (Arkhangelsky et al. 2019). Combines SC and DiD for staggered adoption.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://github.com/d2cml-ai/synthdid.py",
    "github_url": "https://github.com/d2cml-ai/synthdid.py",
    "url": "https://pypi.org/project/synthdid/",
    "install": "pip install synthdid",
    "tags": [
      "DiD",
      "synthetic control",
      "causal inference"
    ],
    "best_for": "Synthetic DiD combining SC and DiD methods",
    "language": "Python"
  },
  {
    "name": "FixedEffectModel",
    "description": "Panel data modeling with IV tests (weak IV, over-identification, endogeneity) and 2-step GMM estimation.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": null,
    "github_url": "https://github.com/ksecology/FixedEffectModel",
    "url": "https://github.com/ksecology/FixedEffectModel",
    "install": "pip install FixedEffectModel",
    "tags": [
      "panel data",
      "fixed effects",
      "IV"
    ],
    "best_for": "Panel regression with comprehensive IV diagnostics",
    "language": "Python"
  },
  {
    "name": "appelpy",
    "description": "Applied Econometrics Library bridging Stata-like syntax with Python. Built on statsmodels with convenient API.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://appelpy.readthedocs.io/",
    "github_url": "https://github.com/mfarragher/appelpy",
    "url": "https://github.com/mfarragher/appelpy",
    "install": "pip install appelpy",
    "tags": [
      "regression",
      "linear models",
      "Stata"
    ],
    "best_for": "Stata-like econometrics workflow in Python",
    "language": "Python"
  },
  {
    "name": "First Course in Causal Inference (Python)",
    "description": "Python implementation of Peng Ding's textbook 'A First Course in Causal Inference'. Educational resource with code examples.",
    "category": "Inference & Reporting Tools",
    "docs_url": "https://github.com/apoorvalal/ding_causalInference_python",
    "github_url": "https://github.com/apoorvalal/ding_causalInference_python",
    "url": "https://github.com/apoorvalal/ding_causalInference_python",
    "install": "",
    "tags": [
      "causal inference",
      "education",
      "textbook"
    ],
    "best_for": "Learning causal inference with Peng Ding's textbook",
    "language": "Python"
  },
  {
    "name": "Computational Methods for practitioners",
    "description": "Open-source textbook by Richard Evans on computational methods for researchers using Python.",
    "category": "Inference & Reporting Tools",
    "docs_url": "https://opensourceecon.github.io/CompMethods/",
    "github_url": "https://github.com/OpenSourceEcon/CompMethods",
    "url": "https://opensourceecon.github.io/CompMethods/",
    "install": "",
    "tags": [
      "education",
      "computation",
      "textbook"
    ],
    "best_for": "Comprehensive computational economics course",
    "language": "Python"
  },
  {
    "name": "Econ Project Templates",
    "description": "Cookiecutter templates for reproducible economics research projects. Standardized project structure.",
    "category": "Inference & Reporting Tools",
    "docs_url": "https://econ-project-templates.readthedocs.io/",
    "github_url": "https://github.com/OpenSourceEconomics/econ-project-templates",
    "url": "https://github.com/OpenSourceEconomics/econ-project-templates",
    "install": "",
    "tags": [
      "reproducibility",
      "templates",
      "workflow"
    ],
    "best_for": "Starting reproducible economics projects",
    "language": "Python"
  },
  {
    "name": "Python Packages for Applied Economists",
    "description": "Curated collection of Python packages for applied researchers organized by functionality.",
    "category": "Inference & Reporting Tools",
    "docs_url": null,
    "github_url": "https://github.com/clibassi/python-packages-for-applied-economists",
    "url": "https://github.com/clibassi/python-packages-for-applied-economists",
    "install": "",
    "tags": [
      "curated list",
      "resources"
    ],
    "best_for": "Discovering econometrics packages by use case",
    "language": "Python"
  },
  {
    "name": "Awesome Economics",
    "description": "Curated list of economics resources including datasets, software, courses, and blogs.",
    "category": "Inference & Reporting Tools",
    "docs_url": null,
    "github_url": "https://github.com/antontarasenko/awesome-economics",
    "url": "https://github.com/antontarasenko/awesome-economics",
    "install": "",
    "tags": [
      "curated list",
      "resources"
    ],
    "best_for": "Comprehensive economics resource directory",
    "language": "Python"
  },
  {
    "name": "mcf (Modified Causal Forest)",
    "description": "Comprehensive Python implementation for heterogeneous treatment effect estimation. Handles binary/multiple discrete treatments with optimal policy learning via Policy Trees.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://mcf-docs.readthedocs.io/",
    "github_url": "https://github.com/MCFpy/mcf",
    "url": "https://github.com/MCFpy/mcf",
    "install": "pip install mcf",
    "tags": [
      "causal inference",
      "treatment effects",
      "policy learning"
    ],
    "best_for": "CATE estimation with policy tree optimization",
    "language": "Python"
  },
  {
    "name": "CATENets",
    "description": "JAX-accelerated neural network CATE estimators implementing SNet, FlexTENet, TARNet, CFRNet, and DragonNet architectures.",
    "category": "Causal Inference & Matching",
    "docs_url": null,
    "github_url": "https://github.com/AliciaCurth/CATENets",
    "url": "https://github.com/AliciaCurth/CATENets",
    "install": "pip install catenets",
    "tags": [
      "causal inference",
      "deep learning",
      "JAX"
    ],
    "best_for": "GPU-accelerated neural CATE estimation",
    "language": "Python"
  },
  {
    "name": "NetworkCausalTree",
    "description": "Estimates both direct treatment effects and spillover effects under clustered network interference (Bargagli-Stoffi et al. 2025).",
    "category": "Causal Inference & Matching",
    "docs_url": null,
    "github_url": "https://github.com/fbargaglistoffi/NetworkCausalTree",
    "url": "https://github.com/fbargaglistoffi/NetworkCausalTree",
    "install": "pip install networkcausaltree",
    "tags": [
      "causal inference",
      "networks",
      "spillovers"
    ],
    "best_for": "Treatment effects with network interference",
    "language": "Python"
  },
  {
    "name": "PySensemakr",
    "description": "Implements Cinelli-Hazlett framework for assessing robustness to unobserved confounding. Computes confounder strength needed to invalidate results.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://github.com/carloscinelli/PySensemakr",
    "github_url": "https://github.com/carloscinelli/PySensemakr",
    "url": "https://github.com/carloscinelli/PySensemakr",
    "install": "pip install pysensemakr",
    "tags": [
      "causal inference",
      "sensitivity analysis",
      "robustness"
    ],
    "best_for": "Sensitivity analysis with publication-ready contour plots",
    "language": "Python"
  },
  {
    "name": "gcimpute",
    "description": "Gaussian copula imputation for mixed variable types with streaming capability (Journal of Statistical Software 2024).",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": null,
    "github_url": "https://github.com/udellgroup/gcimpute",
    "url": "https://github.com/udellgroup/gcimpute",
    "install": "pip install gcimpute",
    "tags": [
      "missing data",
      "imputation"
    ],
    "best_for": "Mixed-type missing data imputation with copulas",
    "language": "Python"
  },
  {
    "name": "miceforest",
    "description": "LightGBM-accelerated multiple imputation by chained equations. Fast MICE for large datasets.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://miceforest.readthedocs.io/",
    "github_url": "https://github.com/AnotherSamWilson/miceforest",
    "url": "https://github.com/AnotherSamWilson/miceforest",
    "install": "pip install miceforest",
    "tags": [
      "missing data",
      "imputation",
      "machine learning"
    ],
    "best_for": "Fast MICE imputation with LightGBM",
    "language": "Python"
  },
  {
    "name": "tea-tasting",
    "description": "Calculate A/B test statistics directly within data warehouses (BigQuery, ClickHouse, Snowflake, Spark) via Ibis interface. Supports CUPED/CUPAC.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": "https://tea-tasting.readthedocs.io/",
    "github_url": "https://github.com/e10v/tea-tasting",
    "url": "https://github.com/e10v/tea-tasting",
    "install": "pip install tea-tasting",
    "tags": [
      "A/B testing",
      "experimentation",
      "data warehouses"
    ],
    "best_for": "In-warehouse A/B test analysis with variance reduction",
    "language": "Python"
  },
  {
    "name": "Ambrosia",
    "description": "End-to-end A/B testing from MobileTeleSystems with PySpark support. Covers experiment design, multi-group splitting, matching, and inference.",
    "category": "Power Simulation & Design of Experiments",
    "docs_url": null,
    "github_url": "https://github.com/MobileTeleSystems/Ambrosia",
    "url": "https://github.com/MobileTeleSystems/Ambrosia",
    "install": "pip install ambrosia",
    "tags": [
      "A/B testing",
      "experimentation",
      "Spark"
    ],
    "best_for": "End-to-end A/B testing with PySpark",
    "language": "Python"
  },
  {
    "name": "savvi",
    "description": "Safe Anytime Valid Inference using e-processes and confidence sequences (Ramdas et al. 2023). Valid inference at any stopping time.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": null,
    "github_url": "https://github.com/spotify/savvi",
    "url": "https://pypi.org/project/savvi/",
    "install": "pip install savvi",
    "tags": [
      "sequential testing",
      "A/B testing",
      "anytime valid"
    ],
    "best_for": "Always-valid sequential inference for experiments",
    "language": "Python"
  },
  {
    "name": "expectation",
    "description": "E-values and game-theoretic probability for sequential testing. Enables early signal detection with proper error control.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": null,
    "github_url": "https://github.com/zalando/expectation",
    "url": "https://pypi.org/project/expectation/",
    "install": "pip install expectation",
    "tags": [
      "sequential testing",
      "e-values",
      "hypothesis testing"
    ],
    "best_for": "E-value based sequential hypothesis testing",
    "language": "Python"
  },
  {
    "name": "GeoLift",
    "description": "Meta's end-to-end synthetic control for geo experiments with multi-cell testing and power calculations.",
    "category": "Geo-Experiments & Lift Measurement",
    "docs_url": "https://facebookincubator.github.io/GeoLift/",
    "github_url": "https://github.com/facebookincubator/GeoLift",
    "url": "https://github.com/facebookincubator/GeoLift",
    "install": "pip install geolift",
    "tags": [
      "geo-experiments",
      "synthetic control",
      "incrementality"
    ],
    "best_for": "Meta's geo-level incrementality measurement",
    "language": "Python"
  },
  {
    "name": "trimmed_match",
    "description": "Google's robust analysis for paired geo experiments using trimmed statistics. Handles outliers in geo-level data.",
    "category": "Geo-Experiments & Lift Measurement",
    "docs_url": null,
    "github_url": "https://github.com/google/trimmed_match",
    "url": "https://github.com/google/trimmed_match",
    "install": "pip install trimmed-match",
    "tags": [
      "geo-experiments",
      "robust statistics",
      "incrementality"
    ],
    "best_for": "Robust paired geo experiment analysis",
    "language": "Python"
  },
  {
    "name": "matched_markets",
    "description": "Google's time-based regression with greedy search for optimal geo experiment groups.",
    "category": "Geo-Experiments & Lift Measurement",
    "docs_url": null,
    "github_url": "https://github.com/google/matched_markets",
    "url": "https://github.com/google/matched_markets",
    "install": "pip install matched-markets",
    "tags": [
      "geo-experiments",
      "market matching",
      "incrementality"
    ],
    "best_for": "Optimal geo experiment group selection",
    "language": "Python"
  },
  {
    "name": "matching",
    "description": "Implements Stable Marriage, Hospital-Resident, Student-Allocation, and Stable Roommates using Gale-Shapley (JOSS paper).",
    "category": "Matching & Market Design",
    "docs_url": "https://matching.readthedocs.io/",
    "github_url": "https://github.com/daffidwilde/matching",
    "url": "https://github.com/daffidwilde/matching",
    "install": "pip install matching",
    "tags": [
      "matching",
      "market design",
      "Gale-Shapley"
    ],
    "best_for": "Classic two-sided matching algorithms",
    "language": "Python"
  },
  {
    "name": "algmatch",
    "description": "Student-Project Allocation with lecturer preferences. Extends matching to three-sided markets.",
    "category": "Matching & Market Design",
    "docs_url": null,
    "github_url": "https://github.com/daffidwilde/algmatch",
    "url": "https://pypi.org/project/algmatch/",
    "install": "pip install algmatch",
    "tags": [
      "matching",
      "market design",
      "allocation"
    ],
    "best_for": "Student-project-lecturer allocation",
    "language": "Python"
  },
  {
    "name": "kep_solver",
    "description": "Kidney exchange optimization with hierarchical objectives. Production-ready for kidney paired donation.",
    "category": "Matching & Market Design",
    "docs_url": null,
    "github_url": "https://github.com/jamestrimble/kep_solver",
    "url": "https://pypi.org/project/kep_solver/",
    "install": "pip install kep-solver",
    "tags": [
      "matching",
      "market design",
      "kidney exchange"
    ],
    "best_for": "Kidney exchange program optimization",
    "language": "Python"
  },
  {
    "name": "scarfmatch",
    "description": "Matching with couples using Scarf's algorithm. Essential for NRMP-style medical residency matching.",
    "category": "Matching & Market Design",
    "docs_url": null,
    "github_url": "https://github.com/NiklasPhawornsak/scarfmatch",
    "url": "https://pypi.org/project/scarfmatch/",
    "install": "pip install scarfmatch",
    "tags": [
      "matching",
      "market design",
      "couples"
    ],
    "best_for": "Residency matching with couples",
    "language": "Python"
  },
  {
    "name": "Nashpy",
    "description": "Computation of Nash equilibria for 2-player games. Support enumeration and Lemke-Howson algorithm.",
    "category": "Game Theory & Mechanism Design",
    "docs_url": "https://nashpy.readthedocs.io/",
    "github_url": "https://github.com/drvinceknight/Nashpy",
    "url": "https://github.com/drvinceknight/Nashpy",
    "install": "pip install nashpy",
    "tags": [
      "game theory",
      "Nash equilibrium"
    ],
    "best_for": "2-player Nash equilibrium computation",
    "language": "Python"
  },
  {
    "name": "pygambit",
    "description": "N-player extensive form games with Alan Turing Institute support. Computes Nash, perfect, and sequential equilibria.",
    "category": "Game Theory & Mechanism Design",
    "docs_url": "https://gambitproject.readthedocs.io/",
    "github_url": "https://github.com/gambitproject/gambit",
    "url": "https://github.com/gambitproject/gambit",
    "install": "pip install pygambit",
    "tags": [
      "game theory",
      "extensive form",
      "equilibrium"
    ],
    "best_for": "N-player extensive form game solving",
    "language": "Python"
  },
  {
    "name": "OpenSpiel",
    "description": "DeepMind's 70+ game environments with multi-agent RL algorithms including Alpha-Rank, Neural Fictitious Self-Play, and CFR variants.",
    "category": "Game Theory & Mechanism Design",
    "docs_url": "https://openspiel.readthedocs.io/",
    "github_url": "https://github.com/deepmind/open_spiel",
    "url": "https://github.com/deepmind/open_spiel",
    "install": "pip install open_spiel",
    "tags": [
      "game theory",
      "reinforcement learning",
      "multi-agent"
    ],
    "best_for": "Multi-agent RL and game-theoretic algorithms",
    "language": "Python"
  },
  {
    "name": "fairpy",
    "description": "Fair division algorithms from academic papers. Implements cake-cutting and item allocation procedures.",
    "category": "Game Theory & Mechanism Design",
    "docs_url": "https://fairpy.readthedocs.io/",
    "github_url": "https://github.com/erelsgl/fairpy",
    "url": "https://github.com/erelsgl/fairpy",
    "install": "pip install fairpy",
    "tags": [
      "fair division",
      "allocation",
      "mechanism design"
    ],
    "best_for": "Fair division and cake-cutting algorithms",
    "language": "Python"
  },
  {
    "name": "fairpyx",
    "description": "Course-seat allocation with capacity constraints. Practical fair division for university course assignment.",
    "category": "Game Theory & Mechanism Design",
    "docs_url": null,
    "github_url": "https://github.com/ariel-research/fairpyx",
    "url": "https://github.com/ariel-research/fairpyx",
    "install": "pip install fairpyx",
    "tags": [
      "fair division",
      "course allocation",
      "mechanism design"
    ],
    "best_for": "Course-seat allocation with constraints",
    "language": "Python"
  },
  {
    "name": "UpliftML",
    "description": "Booking.com's enterprise uplift modeling via PySpark and H2O. Six meta-learners plus Uplift Random Forest with ROI-constrained optimization.",
    "category": "Uplift Modeling",
    "docs_url": null,
    "github_url": "https://github.com/bookingcom/upliftml",
    "url": "https://github.com/bookingcom/upliftml",
    "install": "pip install upliftml",
    "tags": [
      "uplift modeling",
      "treatment effects",
      "marketing"
    ],
    "best_for": "Enterprise-scale uplift with ROI optimization",
    "language": "Python"
  },
  {
    "name": "pylift",
    "description": "Wayfair's uplift modeling wrapping sklearn for speed with rigorous Qini curve evaluation.",
    "category": "Uplift Modeling",
    "docs_url": "https://pylift.readthedocs.io/",
    "github_url": "https://github.com/wayfair/pylift",
    "url": "https://github.com/wayfair/pylift",
    "install": "pip install pylift",
    "tags": [
      "uplift modeling",
      "treatment effects",
      "marketing"
    ],
    "best_for": "Fast uplift with Qini curve evaluation",
    "language": "Python"
  },
  {
    "name": "CausalLift",
    "description": "Uplift modeling for observational (non-RCT) data using inverse probability weighting.",
    "category": "Uplift Modeling",
    "docs_url": "https://causallift.readthedocs.io/",
    "github_url": "https://github.com/Minyus/causallift",
    "url": "https://github.com/Minyus/causallift",
    "install": "pip install causallift",
    "tags": [
      "uplift modeling",
      "observational data",
      "IPW"
    ],
    "best_for": "Uplift from observational data with IPW",
    "language": "Python"
  },
  {
    "name": "ziln_cltv",
    "description": "Google's Zero-Inflated Lognormal loss for heavily-tailed LTV distributions. Outputs both predicted LTV and churn probability.",
    "category": "Marketing Mix Models (MMM) & Business Analytics",
    "docs_url": null,
    "github_url": "https://github.com/google/lifetime_value",
    "url": "https://github.com/google/lifetime_value",
    "install": "pip install lifetime-value",
    "tags": [
      "LTV",
      "customer analytics",
      "churn"
    ],
    "best_for": "Customer LTV with zero-inflated distributions",
    "language": "Python"
  },
  {
    "name": "pydtr",
    "description": "Dynamic treatment regimes using Iterative Q-Learning. Scikit-learn compatible for multi-stage optimal treatment sequencing.",
    "category": "Causal Inference & Matching",
    "docs_url": null,
    "github_url": "https://github.com/fullfact/pydtr",
    "url": "https://pypi.org/project/pydtr/",
    "install": "pip install pydtr",
    "tags": [
      "dynamic treatment",
      "reinforcement learning",
      "causal inference"
    ],
    "best_for": "Multi-stage dynamic treatment regimes",
    "language": "Python"
  },
  {
    "name": "gegravity",
    "description": "General equilibrium structural gravity modeling for trade policy analysis. Only Python package for Anderson-van Wincoop GE gravity.",
    "category": "Structural Econometrics & Estimation",
    "docs_url": null,
    "github_url": "https://github.com/USITC-Gravity-Group/gegravity",
    "url": "https://pypi.org/project/gegravity/",
    "install": "pip install gegravity",
    "tags": [
      "trade",
      "gravity models",
      "structural"
    ],
    "best_for": "GE structural gravity for trade policy",
    "language": "Python"
  },
  {
    "name": "KECENI",
    "description": "Doubly robust, non-parametric estimation of node-wise counterfactual means under network interference (arXiv 2024).",
    "category": "Causal Inference & Matching",
    "docs_url": null,
    "github_url": "https://github.com/mayscortez/keceni",
    "url": "https://pypi.org/project/KECENI/",
    "install": "pip install keceni",
    "tags": [
      "networks",
      "spillovers",
      "causal inference"
    ],
    "best_for": "Network interference with node heterogeneity",
    "language": "Python"
  },
  {
    "name": "CausalNLP",
    "description": "Causal inference for text data. Estimate treatment effects from unstructured text using NLP.",
    "category": "Natural Language Processing for Economics",
    "docs_url": null,
    "github_url": "https://github.com/amaiya/causalnlp",
    "url": "https://github.com/amaiya/causalnlp",
    "install": "pip install causalnlp",
    "tags": [
      "NLP",
      "causal inference",
      "text"
    ],
    "best_for": "Causal effects from text data",
    "language": "Python"
  },
  {
    "name": "clusterbootstraps",
    "description": "Wild cluster bootstrap and pairs cluster bootstrap implementations for clustered standard errors.",
    "category": "Inference & Reporting Tools",
    "docs_url": null,
    "github_url": "https://github.com/jmonteroers/clusterbootstraps",
    "url": "https://pypi.org/project/clusterbootstraps/",
    "install": "pip install clusterbootstraps",
    "tags": [
      "bootstrap",
      "clustered errors",
      "inference"
    ],
    "best_for": "Alternative cluster bootstrap implementations",
    "language": "Python"
  },
  {
    "name": "MCD",
    "description": "Mixture of Causal Graphs discovery for heterogeneous time series (ICML 2024). Finds time-varying causal structures.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": null,
    "github_url": "https://github.com/causal-disentanglement/mcd",
    "url": "https://pypi.org/project/MCD/",
    "install": "pip install mcd",
    "tags": [
      "causal discovery",
      "time series",
      "heterogeneous"
    ],
    "best_for": "Time-varying causal structure discovery",
    "language": "Python"
  },
  {
    "name": "SDCI",
    "description": "State-dependent causal inference for conditionally stationary processes (ICML 2025). Handles regime-switching causal graphs.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": null,
    "github_url": "https://github.com/causal-disentanglement/sdci",
    "url": "https://pypi.org/project/SDCI/",
    "install": "pip install sdci",
    "tags": [
      "causal discovery",
      "time series",
      "regime switching"
    ],
    "best_for": "State-dependent causal discovery",
    "language": "Python"
  },
  {
    "name": "MAPIE",
    "description": "Scikit-learn-contrib library for conformal prediction intervals. Provides model-agnostic uncertainty quantification for regression and classification.",
    "category": "Conformal Prediction & Uncertainty",
    "docs_url": "https://mapie.readthedocs.io/",
    "github_url": "https://github.com/scikit-learn-contrib/MAPIE",
    "url": "https://github.com/scikit-learn-contrib/MAPIE",
    "install": "pip install mapie",
    "tags": [
      "conformal prediction",
      "uncertainty",
      "intervals"
    ],
    "best_for": "Model-agnostic prediction intervals",
    "language": "Python"
  },
  {
    "name": "TorchCP",
    "description": "PyTorch-native conformal prediction for DNNs, GNNs, and LLMs with GPU acceleration.",
    "category": "Conformal Prediction & Uncertainty",
    "docs_url": "https://torchcp.readthedocs.io/",
    "github_url": "https://github.com/thu-ml/TorchCP",
    "url": "https://github.com/ml-stat-Sustech/TorchCP",
    "install": "pip install torchcp",
    "tags": [
      "conformal prediction",
      "PyTorch",
      "deep learning"
    ],
    "best_for": "Conformal prediction for neural networks",
    "language": "Python"
  },
  {
    "name": "crepes",
    "description": "Lightweight library for conformal regressors and predictive systems. Simple API for calibrated prediction intervals.",
    "category": "Conformal Prediction & Uncertainty",
    "docs_url": "https://github.com/henrikbostrom/crepes",
    "github_url": "https://github.com/henrikbostrom/crepes",
    "url": "https://github.com/henrikbostrom/crepes",
    "install": "pip install crepes",
    "tags": [
      "conformal prediction",
      "regression",
      "intervals"
    ],
    "best_for": "Simple conformal regressors",
    "language": "Python"
  },
  {
    "name": "puncc",
    "description": "IRT Lab's library for predictive uncertainty with conformal prediction. Supports various conformal methods.",
    "category": "Conformal Prediction & Uncertainty",
    "docs_url": "https://github.com/deel-ai/puncc",
    "github_url": "https://github.com/deel-ai/puncc",
    "url": "https://github.com/deel-ai/puncc",
    "install": "pip install puncc",
    "tags": [
      "conformal prediction",
      "uncertainty",
      "calibration"
    ],
    "best_for": "Calibrated prediction sets",
    "language": "Python"
  },
  {
    "name": "fortuna",
    "description": "AWS library for uncertainty quantification in deep learning. Bayesian and conformal methods.",
    "category": "Conformal Prediction & Uncertainty",
    "docs_url": "https://aws-fortuna.readthedocs.io/",
    "github_url": "https://github.com/awslabs/fortuna",
    "url": "https://github.com/awslabs/fortuna",
    "install": "pip install fortuna",
    "tags": [
      "uncertainty",
      "Bayesian",
      "deep learning"
    ],
    "best_for": "Deep learning uncertainty quantification",
    "language": "Python"
  },
  {
    "name": "CausalMotifs",
    "description": "Meta's library for estimating heterogeneous spillover effects in A/B tests. Handles network interference.",
    "category": "Interference & Spillovers",
    "docs_url": "https://github.com/facebookresearch/CausalMotifs",
    "github_url": "https://github.com/facebookresearch/CausalMotifs",
    "url": "https://github.com/facebookresearch/CausalMotifs",
    "install": "pip install causal-motifs",
    "tags": [
      "network interference",
      "spillovers",
      "A/B testing"
    ],
    "best_for": "Spillover effects in social networks",
    "language": "Python"
  },
  {
    "name": "latenetwork",
    "description": "Causal inference under noncompliance and network interference. Handles partial compliance in networked settings.",
    "category": "Interference & Spillovers",
    "docs_url": "https://github.com/tkhdyanagi/latenetwork",
    "github_url": "https://github.com/tkhdyanagi/latenetwork",
    "url": "https://github.com/tkhdyanagi/latenetwork",
    "install": "pip install latenetwork",
    "tags": [
      "network interference",
      "noncompliance",
      "causal inference"
    ],
    "best_for": "LATE with network effects",
    "language": "Python"
  },
  {
    "name": "testinterference",
    "description": "Statistical tests for SUTVA violations and spillover hypotheses. Detects network interference in experiments.",
    "category": "Interference & Spillovers",
    "docs_url": "https://github.com/tkhdyanagi/testinterference",
    "github_url": "https://github.com/tkhdyanagi/testinterference",
    "url": "https://github.com/tkhdyanagi/testinterference",
    "install": "pip install testinterference",
    "tags": [
      "SUTVA",
      "spillovers",
      "hypothesis testing"
    ],
    "best_for": "Testing for spillover effects",
    "language": "Python"
  },
  {
    "name": "spilled_t",
    "description": "Treatment and spillover effect estimation under network interference. Separates direct and indirect effects.",
    "category": "Interference & Spillovers",
    "docs_url": "https://github.com/mpleung/spilled_t",
    "github_url": "https://github.com/mpleung/spilled_t",
    "url": "https://github.com/mpleung/spilled_t",
    "install": "pip install spilled_t",
    "tags": [
      "network interference",
      "spillovers",
      "treatment effects"
    ],
    "best_for": "Separating direct and spillover effects",
    "language": "Python"
  },
  {
    "name": "didet",
    "description": "DiD with general treatment patterns. Handles effective treatment timing beyond simple staggered adoption.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://github.com/tkhdyanagi/didet",
    "github_url": "https://github.com/tkhdyanagi/didet",
    "url": "https://github.com/tkhdyanagi/didet",
    "install": "pip install didet",
    "tags": [
      "DiD",
      "treatment timing",
      "causal inference"
    ],
    "best_for": "DiD with general treatment patterns",
    "language": "Python"
  },
  {
    "name": "didhetero",
    "description": "Doubly robust estimation for group-time conditional average treatment effects. UCB for heterogeneous DiD.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://github.com/tkhdyanagi/didhetero",
    "github_url": "https://github.com/tkhdyanagi/didhetero",
    "url": "https://github.com/tkhdyanagi/didhetero",
    "install": "pip install didhetero",
    "tags": [
      "DiD",
      "heterogeneous effects",
      "doubly robust"
    ],
    "best_for": "Heterogeneous treatment effects in DiD",
    "language": "Python"
  },
  {
    "name": "panelhetero",
    "description": "Heterogeneity analysis across units in panel data. Detects and characterizes unit-level variation.",
    "category": "Panel Data & Fixed Effects",
    "docs_url": "https://github.com/tkhdyanagi/panelhetero",
    "github_url": "https://github.com/tkhdyanagi/panelhetero",
    "url": "https://github.com/tkhdyanagi/panelhetero",
    "install": "pip install panelhetero",
    "tags": [
      "panel data",
      "heterogeneity",
      "unit effects"
    ],
    "best_for": "Unit heterogeneity in panels",
    "language": "Python"
  },
  {
    "name": "abracadabra",
    "description": "Sequential testing with always-valid inference. Supports continuous monitoring of A/B tests.",
    "category": "Adaptive Experimentation & Bandits",
    "docs_url": "https://github.com/quizlet/abracadabra",
    "github_url": "https://github.com/quizlet/abracadabra",
    "url": "https://pypi.org/project/abracadabra/",
    "install": "pip install abracadabra",
    "tags": [
      "sequential testing",
      "A/B testing",
      "always-valid"
    ],
    "best_for": "Continuous experiment monitoring",
    "language": "Python"
  },
  {
    "name": "TFP CausalImpact",
    "description": "TensorFlow Probability port of Google's CausalImpact. Bayesian structural time-series for intervention effects.",
    "category": "Program Evaluation Methods (DiD, SC, RDD)",
    "docs_url": "https://github.com/google/tfp-causalimpact",
    "github_url": "https://github.com/google/tfp-causalimpact",
    "url": "https://github.com/google/tfp-causalimpact",
    "install": "pip install tfcausalimpact",
    "tags": [
      "causal impact",
      "time series",
      "Bayesian"
    ],
    "best_for": "TensorFlow-based causal impact analysis",
    "language": "Python"
  },
  {
    "name": "Benchpress",
    "description": "Benchmarking 41+ structure learning algorithms for causal discovery. Standardized evaluation framework.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://benchpressdocs.readthedocs.io/",
    "github_url": "https://github.com/felixleopoldo/benchpress",
    "url": "https://github.com/felixleopoldo/benchpress",
    "install": "pip install benchpress",
    "tags": [
      "causal discovery",
      "benchmarking",
      "structure learning"
    ],
    "best_for": "Comparing causal discovery algorithms",
    "language": "Python"
  },
  {
    "name": "causal-llm-bfs",
    "description": "LLM + BFS hybrid for efficient causal graph discovery. Uses language models to guide structure search.",
    "category": "Causal Discovery & Graphical Models",
    "docs_url": "https://github.com/superkaiba/causal-llm-bfs",
    "github_url": "https://github.com/superkaiba/causal-llm-bfs",
    "url": "https://github.com/superkaiba/causal-llm-bfs",
    "install": "pip install causal-llm-bfs",
    "tags": [
      "causal discovery",
      "LLM",
      "graphs"
    ],
    "best_for": "LLM-assisted causal discovery",
    "language": "Python"
  },
  {
    "name": "Doubly-Debiased-Lasso",
    "description": "High-dimensional inference under hidden confounding. Doubly debiased Lasso for valid inference.",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://github.com/zijguo/Doubly-Debiased-Lasso",
    "github_url": "https://github.com/zijguo/Doubly-Debiased-Lasso",
    "url": "https://github.com/zijguo/Doubly-Debiased-Lasso",
    "install": "Install from GitHub",
    "tags": [
      "high-dimensional",
      "Lasso",
      "debiased"
    ],
    "best_for": "High-dim inference with confounding",
    "language": "Python"
  },
  {
    "name": "deep-opt-auctions",
    "description": "Neural network optimal auction design. Implements RegretNet, RochetNet for mechanism design.",
    "category": "Matching & Market Design",
    "docs_url": "https://github.com/saisrivatsan/deep-opt-auctions",
    "github_url": "https://github.com/saisrivatsan/deep-opt-auctions",
    "url": "https://github.com/saisrivatsan/deep-opt-auctions",
    "install": "Install from GitHub",
    "tags": [
      "auctions",
      "mechanism design",
      "deep learning"
    ],
    "best_for": "Neural network auction design",
    "language": "Python"
  },
  {
    "name": "causal-curve",
    "description": "Continuous treatment dose-response curve estimation. GPS and TMLE methods for continuous treatments.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://causal-curve.readthedocs.io/",
    "github_url": "https://github.com/ronikobrosly/causal-curve",
    "url": "https://github.com/ronikobrosly/causal-curve",
    "install": "pip install causal-curve",
    "tags": [
      "dose-response",
      "continuous treatment",
      "GPS"
    ],
    "best_for": "Dose-response curves for continuous treatments",
    "language": "Python"
  },
  {
    "name": "pyregadj",
    "description": "Regression and ML adjustments to treatment effects in RCTs. Implements List et al. (2024) methods.",
    "category": "Causal Inference & Matching",
    "docs_url": "https://github.com/vyasenov/pyregadj",
    "github_url": "https://github.com/vyasenov/pyregadj",
    "url": "https://github.com/vyasenov/pyregadj",
    "install": "pip install pyregadj",
    "tags": [
      "RCT",
      "regression adjustment",
      "treatment effects"
    ],
    "best_for": "Covariate adjustment in experiments",
    "language": "Python"
  },
  {
    "name": "cvxpy",
    "description": "Domain-specific language for convex optimization problems. Write math as code \u2014 the standard for convex problems.",
    "category": "Optimization",
    "docs_url": "https://www.cvxpy.org/",
    "github_url": "https://github.com/cvxpy/cvxpy",
    "url": "https://www.cvxpy.org/",
    "install": "pip install cvxpy",
    "tags": [
      "convex optimization",
      "linear programming",
      "quadratic programming"
    ],
    "best_for": "Convex optimization with intuitive syntax",
    "language": "Python"
  },
  {
    "name": "scipy.optimize",
    "description": "Optimization algorithms built into SciPy. Minimization, root finding, curve fitting, and linear programming.",
    "category": "Optimization",
    "docs_url": "https://docs.scipy.org/doc/scipy/reference/optimize.html",
    "github_url": "https://github.com/scipy/scipy",
    "url": "https://docs.scipy.org/doc/scipy/reference/optimize.html",
    "install": "pip install scipy",
    "tags": [
      "optimization",
      "minimization",
      "root finding"
    ],
    "best_for": "General-purpose optimization \u2014 start here for basics",
    "language": "Python"
  },
  {
    "name": "ortools",
    "description": "Google's operations research toolkit. Constraint programming, routing, linear/integer programming, and scheduling.",
    "category": "Optimization",
    "docs_url": "https://developers.google.com/optimization",
    "github_url": "https://github.com/google/or-tools",
    "url": "https://developers.google.com/optimization",
    "install": "pip install ortools",
    "tags": [
      "OR",
      "routing",
      "scheduling",
      "constraint programming"
    ],
    "best_for": "Production-ready combinatorial optimization",
    "language": "Python"
  },
  {
    "name": "gurobipy",
    "description": "Python interface for Gurobi, the best-in-class commercial solver. LP, QP, MIP, and MIQP.",
    "category": "Optimization",
    "docs_url": "https://www.gurobi.com/documentation/",
    "github_url": null,
    "url": "https://www.gurobi.com/",
    "install": "pip install gurobipy",
    "tags": [
      "optimization",
      "solver",
      "MIP",
      "commercial"
    ],
    "best_for": "Best-in-class solver \u2014 free for academics",
    "language": "Python"
  },
  {
    "name": "langgraph",
    "description": "Framework for building stateful, multi-actor LLM applications. Graph-based agent workflows with persistence.",
    "category": "Agentic AI",
    "docs_url": "https://langchain-ai.github.io/langgraph/",
    "github_url": "https://github.com/langchain-ai/langgraph",
    "url": "https://langchain-ai.github.io/langgraph/",
    "install": "pip install langgraph",
    "tags": [
      "agents",
      "LLM",
      "workflows",
      "multi-agent"
    ],
    "best_for": "Production agent workflows with state management",
    "language": "Python"
  },
  {
    "name": "langchain",
    "description": "Framework for developing LLM-powered applications. Chains, tools, memory, and retrieval.",
    "category": "Agentic AI",
    "docs_url": "https://python.langchain.com/",
    "github_url": "https://github.com/langchain-ai/langchain",
    "url": "https://python.langchain.com/",
    "install": "pip install langchain",
    "tags": [
      "LLM",
      "chains",
      "tools",
      "RAG"
    ],
    "best_for": "LLM framework \u2014 chains, tools, memory",
    "language": "Python"
  },
  {
    "name": "crewai",
    "description": "Framework for orchestrating role-playing autonomous AI agents. Multi-agent collaboration made intuitive.",
    "category": "Agentic AI",
    "docs_url": "https://docs.crewai.com/",
    "github_url": "https://github.com/crewAIInc/crewAI",
    "url": "https://www.crewai.com/",
    "install": "pip install crewai",
    "tags": [
      "agents",
      "multi-agent",
      "orchestration",
      "roles"
    ],
    "best_for": "Role-based multi-agent teams",
    "language": "Python"
  },
  {
    "name": "openai-agents",
    "description": "OpenAI's lightweight, production-ready SDK for building agentic AI applications. Fast prototyping.",
    "category": "Agentic AI",
    "docs_url": "https://openai.github.io/openai-agents-python/",
    "github_url": "https://github.com/openai/openai-agents-python",
    "url": "https://openai.github.io/openai-agents-python/",
    "install": "pip install openai-agents",
    "tags": [
      "agents",
      "OpenAI",
      "tools",
      "lightweight"
    ],
    "best_for": "OpenAI's lightweight SDK \u2014 fast prototyping",
    "language": "Python"
  },
  {
    "name": "SynapseML",
    "description": "Microsoft's distributed ML library with native Double ML (DoubleMLEstimator) for heterogeneous treatment effects at scale.",
    "category": "Double/Debiased Machine Learning (DML)",
    "docs_url": "https://microsoft.github.io/SynapseML/",
    "github_url": "https://github.com/microsoft/SynapseML",
    "url": "https://github.com/microsoft/SynapseML",
    "install": "pip install synapseml",
    "tags": [
      "spark",
      "causal inference",
      "double ML",
      "distributed"
    ],
    "best_for": "Causal inference at 100M+ rows on Spark clusters",
    "language": "Python"
  },
  {
    "name": "TS-Flint",
    "description": "Two Sigma's time-series library for Spark with optimized temporal joins, as-of joins, and distributed OLS for high-frequency data.",
    "category": "Time Series Econometrics",
    "docs_url": "https://ts-flint.readthedocs.io/",
    "github_url": "https://github.com/twosigma/flint",
    "url": "https://github.com/twosigma/flint",
    "install": "pip install ts-flint",
    "tags": [
      "spark",
      "time series",
      "temporal joins",
      "fintech"
    ],
    "best_for": "High-frequency financial data with inexact timestamp matching",
    "language": "Python"
  },
  {
    "name": "Apache Sedona",
    "description": "Distributed spatial analytics engine (formerly GeoSpark) with spatial SQL, K-NN joins, and range queries for spatial econometrics.",
    "category": "Spatial Econometrics",
    "docs_url": "https://sedona.apache.org/",
    "github_url": "https://github.com/apache/sedona",
    "url": "https://github.com/apache/sedona",
    "install": "pip install apache-sedona",
    "tags": [
      "spark",
      "spatial",
      "GIS",
      "distributed"
    ],
    "best_for": "Constructing spatial weight matrices and distance-based instruments at scale",
    "language": "Python"
  },
  {
    "name": "H2O Sparkling Water",
    "description": "H2O's distributed ML engine on Spark with GLM/GAM that provides p-values, confidence intervals, and Tweedie/Gamma distributions.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://docs.h2o.ai/sparkling-water/",
    "github_url": "https://github.com/h2oai/sparkling-water",
    "url": "https://github.com/h2oai/sparkling-water",
    "install": "pip install h2o_pysparkling_3.4",
    "tags": [
      "spark",
      "GLM",
      "GAM",
      "distributed",
      "p-values"
    ],
    "best_for": "Econometric inference (p-values, CIs) at Spark scale",
    "language": "Python"
  },
  {
    "name": "Greeners",
    "description": "Comprehensive Rust econometrics library with OLS, IV, panel data estimators, fixed effects, DiD, and heteroskedasticity-robust standard errors (HC0-HC3).",
    "category": "Structural Econometrics & Estimation",
    "docs_url": "https://docs.rs/greeners",
    "github_url": "https://github.com/greeners-rs/greeners",
    "url": "https://crates.io/crates/greeners",
    "install": "cargo add greeners",
    "tags": [
      "rust",
      "econometrics",
      "IV",
      "panel data",
      "robust SE"
    ],
    "best_for": "Academic econometrics in Rust: IV, DiD, robust SEs",
    "language": "Rust"
  },
  {
    "name": "Linregress",
    "description": "Simple linear regression for Rust with R-style formula syntax, standard errors, t-stats, and p-values.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://docs.rs/linregress",
    "github_url": "https://github.com/n1m3/linregress",
    "url": "https://crates.io/crates/linregress",
    "install": "cargo add linregress",
    "tags": [
      "rust",
      "regression",
      "OLS",
      "statistics"
    ],
    "best_for": "Simple no-frills OLS regression in Rust",
    "language": "Rust"
  },
  {
    "name": "Augurs",
    "description": "Time series forecasting and analysis for Rust with ETS, MSTL decomposition, seasonality detection, outlier detection, and Prophet-style models.",
    "category": "Time Series Forecasting",
    "docs_url": "https://docs.augu.rs/",
    "github_url": "https://github.com/grafana/augurs",
    "url": "https://crates.io/crates/augurs",
    "install": "cargo add augurs",
    "tags": [
      "rust",
      "time series",
      "forecasting",
      "ETS",
      "MSTL"
    ],
    "best_for": "Time series forecasting and structural analysis in Rust",
    "language": "Rust"
  },
  {
    "name": "Statrs",
    "description": "Comprehensive statistical distributions for Rust (Normal, T, Gamma, etc.) with PDF, CDF, quantile functions‚Äîthe scipy.stats equivalent.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://docs.rs/statrs",
    "github_url": "https://github.com/statrs-dev/statrs",
    "url": "https://crates.io/crates/statrs",
    "install": "cargo add statrs",
    "tags": [
      "rust",
      "statistics",
      "distributions",
      "probability"
    ],
    "best_for": "Probability distributions and basic statistics in Rust",
    "language": "Rust"
  },
  {
    "name": "HypoRS",
    "description": "Hypothesis testing library for Rust with T-tests, Z-tests, ANOVA, Chi-square, designed to work seamlessly with Polars DataFrames.",
    "category": "Statistical Inference & Hypothesis Testing",
    "docs_url": "https://lib.rs/crates/hypors",
    "github_url": "https://github.com/astronights/hypors",
    "url": "https://crates.io/crates/hypors",
    "install": "cargo add hypors",
    "tags": [
      "rust",
      "hypothesis testing",
      "t-test",
      "ANOVA",
      "polars"
    ],
    "best_for": "Statistical hypothesis testing with Polars integration",
    "language": "Rust"
  },
  {
    "name": "Polars",
    "description": "Blazingly fast DataFrame library for Rust and Python with SQL-like syntax, lazy evaluation, and excellent time series handling.",
    "category": "Core Libraries & Linear Models",
    "docs_url": "https://pola.rs/",
    "github_url": "https://github.com/pola-rs/polars",
    "url": "https://crates.io/crates/polars",
    "install": "cargo add polars",
    "tags": [
      "rust",
      "dataframe",
      "data manipulation",
      "performance"
    ],
    "best_for": "High-performance data manipulation (pandas alternative)",
    "language": "Rust"
  },
  {
    "name": "Linfa",
    "description": "Rust ML toolkit inspired by scikit-learn with GLMs, clustering (K-Means), PCA, SVM, and regularization (Lasso/Ridge).",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://rust-ml.github.io/linfa/",
    "github_url": "https://github.com/rust-ml/linfa",
    "url": "https://crates.io/crates/linfa",
    "install": "cargo add linfa",
    "tags": [
      "rust",
      "machine learning",
      "clustering",
      "PCA",
      "SVM"
    ],
    "best_for": "scikit-learn style ML in Rust",
    "language": "Rust"
  },
  {
    "name": "SmartCore",
    "description": "Rust ML library with regression, classification, clustering, matrix decomposition (SVD, PCA), and model selection tools.",
    "category": "Tree & Ensemble Methods for Prediction",
    "docs_url": "https://docs.rs/smartcore",
    "github_url": "https://github.com/smartcorelib/smartcore",
    "url": "https://crates.io/crates/smartcore",
    "install": "cargo add smartcore",
    "tags": [
      "rust",
      "machine learning",
      "regression",
      "classification"
    ],
    "best_for": "Comprehensive ML algorithms in pure Rust",
    "language": "Rust"
  },
  {
    "name": "Faer",
    "description": "State-of-the-art linear algebra for Rust with Cholesky, QR, SVD decompositions and multithreaded solvers for large systems.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": "https://docs.rs/faer",
    "github_url": "https://github.com/sarah-quinones/faer-rs",
    "url": "https://crates.io/crates/faer",
    "install": "cargo add faer",
    "tags": [
      "rust",
      "linear algebra",
      "matrix",
      "performance"
    ],
    "best_for": "High-performance matrix decompositions for custom estimators",
    "language": "Rust"
  },
  {
    "name": "Nalgebra",
    "description": "General-purpose linear algebra library for Rust with dense and sparse matrices, widely used in graphics and physics.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": "https://www.nalgebra.org/",
    "github_url": "https://github.com/dimforge/nalgebra",
    "url": "https://crates.io/crates/nalgebra",
    "install": "cargo add nalgebra",
    "tags": [
      "rust",
      "linear algebra",
      "matrix",
      "sparse"
    ],
    "best_for": "General-purpose linear algebra in Rust",
    "language": "Rust"
  },
  {
    "name": "Ndarray",
    "description": "N-dimensional array library for Rust‚Äîthe NumPy equivalent with slicing, broadcasting, and BLAS/LAPACK integration.",
    "category": "Numerical Optimization & Computational Tools",
    "docs_url": "https://docs.rs/ndarray",
    "github_url": "https://github.com/rust-ndarray/ndarray",
    "url": "https://crates.io/crates/ndarray",
    "install": "cargo add ndarray",
    "tags": [
      "rust",
      "arrays",
      "numpy",
      "scientific computing"
    ],
    "best_for": "NumPy-style N-dimensional arrays in Rust",
    "language": "Rust"
  },
  {
    "name": "Argmin",
    "description": "Numerical optimization framework for Rust with Newton, BFGS, L-BFGS, trust region, and derivative-free methods for MLE/GMM.",
    "category": "Optimization",
    "docs_url": "https://docs.rs/argmin",
    "github_url": "https://github.com/argmin-rs/argmin",
    "url": "https://crates.io/crates/argmin",
    "install": "cargo add argmin",
    "tags": [
      "rust",
      "optimization",
      "BFGS",
      "MLE",
      "GMM"
    ],
    "best_for": "Maximum Likelihood and GMM estimation in Rust",
    "language": "Rust"
  },
  {
    "name": "did",
    "description": "Implements group-time average treatment effects (ATT(g,t)) for staggered DiD designs with multiple periods and variation in treatment timing. Provides flexible aggregation into event-study plots or overall treatment effect estimates, addressing the well-documented negative weighting issues with conventional TWFE under staggered adoption.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://bcallaway11.github.io/did/",
    "github_url": "https://github.com/bcallaway11/did",
    "url": "https://cran.r-project.org/package=did",
    "install": "install.packages(\"did\")",
    "tags": [
      "difference-in-differences",
      "staggered-adoption",
      "event-study",
      "treatment-effects",
      "panel-data"
    ],
    "best_for": "Staggered rollout designs where different units adopt treatment at different times, implementing the Callaway & Sant'Anna (2021) estimator",
    "language": "R"
  },
  {
    "name": "DRDID",
    "description": "Implements locally efficient doubly robust DiD estimators that combine inverse probability weighting and outcome regression for improved statistical properties. Handles both panel data and repeated cross-sections in the canonical 2x2 DiD setting with covariates, providing robustness against model misspecification.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://psantanna.com/DRDID/",
    "github_url": "https://github.com/pedrohcgs/DRDID",
    "url": "https://cran.r-project.org/package=DRDID",
    "install": "install.packages(\"DRDID\")",
    "tags": [
      "doubly-robust",
      "difference-in-differences",
      "inverse-probability-weighting",
      "ATT",
      "covariates"
    ],
    "best_for": "Two-period DiD with covariates requiring robust estimation against model misspecification, implementing Sant'Anna & Zhao (2020)",
    "language": "R"
  },
  {
    "name": "staggered",
    "description": "Provides the efficient estimator for randomized staggered rollout designs, offering optimal weighting schemes for treatment effect estimation. Also implements Callaway & Sant'Anna and Sun & Abraham estimators with design-based Fisher inference for randomized experiments.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://cran.r-project.org/web/packages/staggered/readme/README.html",
    "github_url": "https://github.com/jonathandroth/staggered",
    "url": "https://cran.r-project.org/package=staggered",
    "install": "install.packages(\"staggered\")",
    "tags": [
      "staggered-rollout",
      "randomized-experiments",
      "efficient-estimation",
      "event-study",
      "fisher-inference"
    ],
    "best_for": "Randomized experiments with staggered treatment timing where efficiency gains matter, implementing Roth & Sant'Anna (2023)",
    "language": "R"
  },
  {
    "name": "didimputation",
    "description": "Implements the imputation-based DiD estimator that first estimates Y(0) counterfactuals from untreated observations using two-way fixed effects, then imputes treatment effects for treated units. Avoids negative weighting problems of conventional TWFE under heterogeneous treatment effects.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://github.com/kylebutts/didimputation",
    "github_url": "https://github.com/kylebutts/didimputation",
    "url": "https://cran.r-project.org/package=didimputation",
    "install": "install.packages(\"didimputation\")",
    "tags": [
      "imputation",
      "two-way-fixed-effects",
      "event-study",
      "counterfactual",
      "robust-estimation"
    ],
    "best_for": "Event-study designs where imputation-based correction for TWFE bias is preferred, implementing Borusyak, Jaravel & Spiess (2024)",
    "language": "R"
  },
  {
    "name": "HonestDiD",
    "description": "Constructs robust confidence intervals for DiD and event-study designs under violations of parallel trends. Allows researchers to conduct sensitivity analysis by relaxing the parallel trends assumption using smoothness or relative magnitude restrictions on pre-trend violations.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://github.com/asheshrambachan/HonestDiD",
    "github_url": "https://github.com/asheshrambachan/HonestDiD",
    "url": "https://cran.r-project.org/package=HonestDiD",
    "install": "install.packages(\"HonestDiD\")",
    "tags": [
      "sensitivity-analysis",
      "parallel-trends",
      "robust-inference",
      "confidence-intervals",
      "event-study"
    ],
    "best_for": "Assessing how treatment effect conclusions change under plausible parallel trends violations, implementing Rambachan & Roth (2023)",
    "language": "R"
  },
  {
    "name": "fastdid",
    "description": "High-performance implementation of Callaway & Sant'Anna estimators optimized for large datasets with millions of observations. Reduces computation time from hours to seconds while supporting time-varying covariates and multiple events per unit.",
    "category": "Causal Inference (DiD)",
    "docs_url": "https://tsailintung.github.io/fastdid",
    "github_url": "https://github.com/TsaiLintung/fastdid",
    "url": "https://cran.r-project.org/package=fastdid",
    "install": "install.packages(\"fastdid\")",
    "tags": [
      "high-performance",
      "large-scale",
      "staggered-DiD",
      "time-varying-covariates",
      "fast-computation"
    ],
    "best_for": "Large-scale applications where standard did package is computationally prohibitive, with support for time-varying covariates",
    "language": "R"
  },
  {
    "name": "Synth",
    "description": "The original synthetic control method implementation for comparative case studies. Constructs a weighted combination of comparison units to create a synthetic counterfactual for estimating effects of interventions on a single treated unit, as used in seminal studies of California tobacco program and German reunification.",
    "category": "Causal Inference (Synthetic Control)",
    "docs_url": "https://web.stanford.edu/~jhain/",
    "github_url": "https://github.com/cran/Synth",
    "url": "https://cran.r-project.org/package=Synth",
    "install": "install.packages(\"Synth\")",
    "tags": [
      "synthetic-control",
      "comparative-case-studies",
      "counterfactual",
      "policy-evaluation",
      "single-unit-treatment"
    ],
    "best_for": "Classic single-treated-unit policy evaluations, implementing Abadie, Diamond & Hainmueller (2010, 2011, 2015)",
    "language": "R"
  },
  {
    "name": "synthdid",
    "description": "Implements synthetic difference-in-differences, a hybrid method combining insights from both DiD and synthetic control that reweights and matches pre-treatment trends. Provides improved robustness properties compared to either method alone by combining their strengths.",
    "category": "Causal Inference (Synthetic Control)",
    "docs_url": "https://synth-inference.github.io/synthdid/",
    "github_url": "https://github.com/synth-inference/synthdid",
    "url": "https://cran.r-project.org/package=synthdid",
    "install": "install.packages(\"synthdid\")",
    "tags": [
      "synthetic-control",
      "difference-in-differences",
      "hybrid-estimator",
      "panel-data",
      "robust-estimation"
    ],
    "best_for": "Settings where neither pure DiD nor pure SC is ideal, implementing Arkhangelsky, Athey, Hirshberg, Imbens & Wager (2021)",
    "language": "R"
  },
  {
    "name": "gsynth",
    "description": "Implements generalized synthetic control with interactive fixed effects, extending SCM to multiple treated units with variable treatment timing. Uses factor models to impute counterfactuals, handling unbalanced panels and complex treatment patterns with latent factor structures.",
    "category": "Causal Inference (Synthetic Control)",
    "docs_url": "https://yiqingxu.org/packages/gsynth/",
    "github_url": "https://github.com/xuyiqing/gsynth",
    "url": "https://cran.r-project.org/package=gsynth",
    "install": "install.packages(\"gsynth\")",
    "tags": [
      "generalized-synthetic-control",
      "interactive-fixed-effects",
      "factor-models",
      "multiple-treated-units",
      "unbalanced-panels"
    ],
    "best_for": "Multiple treated units with staggered treatment timing and latent factor structures, implementing Xu (2017)",
    "language": "R"
  },
  {
    "name": "augsynth",
    "description": "Implements the Augmented Synthetic Control Method, which uses an outcome model (ridge regression by default) to correct for bias when pre-treatment fit is imperfect. Uniquely supports staggered adoption across multiple treated units via multisynth() function.",
    "category": "Causal Inference (Synthetic Control)",
    "docs_url": "https://github.com/ebenmichael/augsynth/blob/master/vignettes/singlesynth-vignette.md",
    "github_url": "https://github.com/ebenmichael/augsynth",
    "url": "https://github.com/ebenmichael/augsynth",
    "install": "devtools::install_github(\"ebenmichael/augsynth\")",
    "tags": [
      "augmented-synthetic-control",
      "bias-correction",
      "staggered-adoption",
      "ridge-regression",
      "imperfect-fit"
    ],
    "best_for": "SC applications with imperfect pre-treatment fit or staggered adoption across units, implementing Ben-Michael, Feller & Rothstein (2021)",
    "language": "R"
  },
  {
    "name": "MatchIt",
    "description": "Comprehensive matching package that selects matched samples of treated and control groups with similar covariate distributions. Provides a unified interface to multiple matching methods including nearest neighbor, optimal pair, optimal full, genetic, exact, coarsened exact (CEM), cardinality matching, and subclassification with propensity score estimation via GLM, GAM, random forest, and BART.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://kosukeimai.github.io/MatchIt/",
    "github_url": "https://github.com/kosukeimai/MatchIt",
    "url": "https://cran.r-project.org/package=MatchIt",
    "install": "install.packages(\"MatchIt\")",
    "tags": [
      "propensity-score-matching",
      "causal-inference",
      "observational-studies",
      "covariate-balance",
      "treatment-effects"
    ],
    "best_for": "Preprocessing observational data via matching to reduce confounding before estimating causal treatment effects, implementing Ho et al. (2007, 2011)",
    "language": "R"
  },
  {
    "name": "WeightIt",
    "description": "Unified interface for generating balancing weights for causal effect estimation in observational studies. Supports binary, multi-category, and continuous treatments for point and longitudinal/marginal structural models. Methods include inverse probability weighting (IPW), entropy balancing, covariate balancing propensity score (CBPS), energy balancing, stable balancing weights, BART, and SuperLearner.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://ngreifer.github.io/WeightIt/",
    "github_url": "https://github.com/ngreifer/WeightIt",
    "url": "https://cran.r-project.org/package=WeightIt",
    "install": "install.packages(\"WeightIt\")",
    "tags": [
      "propensity-score-weighting",
      "inverse-probability-weighting",
      "entropy-balancing",
      "CBPS",
      "marginal-structural-models"
    ],
    "best_for": "Generating balancing weights using modern weighting methods (IPW, entropy balancing, CBPS, etc.) for point or longitudinal treatments",
    "language": "R"
  },
  {
    "name": "cobalt",
    "description": "Generates standardized balance tables and plots for covariates after preprocessing via matching, weighting, or subclassification. Provides unified balance assessment across multiple R packages (MatchIt, WeightIt, twang, Matching, optmatch, CBPS, ebal, cem, sbw, designmatch). Supports multi-category, continuous, and longitudinal treatments with clustered and multiply imputed data.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://ngreifer.github.io/cobalt/",
    "github_url": "https://github.com/ngreifer/cobalt",
    "url": "https://cran.r-project.org/package=cobalt",
    "install": "install.packages(\"cobalt\")",
    "tags": [
      "covariate-balance",
      "balance-diagnostics",
      "love-plot",
      "standardized-mean-difference",
      "balance-tables"
    ],
    "best_for": "Assessing and visualizing covariate balance before/after matching or weighting to validate causal inference preprocessing",
    "language": "R"
  },
  {
    "name": "optmatch",
    "description": "Distance-based bipartite matching using minimum cost network flow algorithms, oriented to matching treatment and control groups in observational studies. Provides optimal full matching and pair matching with support for propensity score distances, Mahalanobis distance, calipers, and exact matching constraints.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://markmfredrickson.github.io/optmatch",
    "github_url": "https://github.com/markmfredrickson/optmatch",
    "url": "https://cran.r-project.org/package=optmatch",
    "install": "install.packages(\"optmatch\")",
    "tags": [
      "optimal-matching",
      "propensity-score",
      "network-flow",
      "observational-studies",
      "full-matching"
    ],
    "best_for": "When you need mathematically optimal matching solutions that minimize total matched distance with flexible control:treatment ratios (full matching), implementing Hansen & Klopfer (2006)",
    "language": "R"
  },
  {
    "name": "CBPS",
    "description": "Implements Covariate Balancing Propensity Score, which estimates propensity scores by jointly optimizing treatment prediction and covariate balance via generalized method of moments (GMM). Supports binary, multi-valued, and continuous treatments, as well as longitudinal settings for marginal structural models.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://cran.r-project.org/web/packages/CBPS/CBPS.pdf",
    "github_url": "https://github.com/kosukeimai/CBPS",
    "url": "https://cran.r-project.org/package=CBPS",
    "install": "install.packages(\"CBPS\")",
    "tags": [
      "propensity-score",
      "covariate-balance",
      "GMM",
      "weighting",
      "treatment-effects"
    ],
    "best_for": "When propensity score model specification is uncertain and you want simultaneous balance optimization, implementing Imai & Ratkovic (2014)",
    "language": "R"
  },
  {
    "name": "ebal",
    "description": "Implements entropy balancing, a reweighting method that finds weights for control units such that specified covariate moment conditions (means, variances) are exactly satisfied while staying as close as possible to uniform weights by minimizing Kullback-Leibler divergence. Primarily designed for ATT estimation.",
    "category": "Causal Inference (Matching)",
    "docs_url": "https://cran.r-project.org/web/packages/ebal/ebal.pdf",
    "github_url": null,
    "url": "https://cran.r-project.org/package=ebal",
    "install": "install.packages(\"ebal\")",
    "tags": [
      "entropy-balancing",
      "reweighting",
      "covariate-balance",
      "observational-studies",
      "ATT"
    ],
    "best_for": "When you need exact covariate balance on specified moments (means, variances) with minimal weight dispersion, implementing Hainmueller (2012)",
    "language": "R"
  },
  {
    "name": "rdrobust",
    "description": "Provides tools for data-driven graphical and analytical statistical inference in RD designs: rdrobust() constructs local-polynomial point estimators and robust confidence intervals for average treatment effects at the cutoff in Sharp, Fuzzy, and Kink RD settings; rdbwselect() performs bandwidth selection; rdplot() conducts exploratory data analysis.",
    "category": "Causal Inference (RDD)",
    "docs_url": "https://rdpackages.github.io/rdrobust/",
    "github_url": "https://github.com/rdpackages/rdrobust",
    "url": "https://cran.r-project.org/package=rdrobust",
    "install": "install.packages(\"rdrobust\")",
    "tags": [
      "regression-discontinuity",
      "causal-inference",
      "local-polynomial",
      "bandwidth-selection",
      "treatment-effects"
    ],
    "best_for": "Standard RD analysis with robust bias-corrected inference and data-driven bandwidth selection, implementing Calonico, Cattaneo & Titiunik (2014)",
    "language": "R"
  },
  {
    "name": "rddensity",
    "description": "Implements manipulation testing (density discontinuity testing) procedures using local polynomial density estimators to detect perfect self-selection around a cutoff. Provides rddensity() for hypothesis testing, rdbwdensity() for bandwidth selection, and rdplotdensity() for density plots with confidence bands.",
    "category": "Causal Inference (RDD)",
    "docs_url": "https://rdpackages.github.io/rddensity/",
    "github_url": "https://github.com/rdpackages/rddensity",
    "url": "https://cran.r-project.org/package=rddensity",
    "install": "install.packages(\"rddensity\")",
    "tags": [
      "manipulation-testing",
      "density-discontinuity",
      "McCrary-test",
      "falsification",
      "sorting"
    ],
    "best_for": "Testing RDD validity by detecting bunching/manipulation around the cutoff (McCrary-type tests), implementing Cattaneo, Jansson & Ma (2020)",
    "language": "R"
  },
  {
    "name": "rdlocrand",
    "description": "Provides tools for RD analysis under local randomization: rdrandinf() performs hypothesis testing using randomization inference, rdwinselect() selects a window around the cutoff where randomization likely holds, rdsensitivity() assesses sensitivity to different windows, and rdrbounds() constructs Rosenbaum bounds for unobserved confounders.",
    "category": "Causal Inference (RDD)",
    "docs_url": "https://rdpackages.github.io/rdlocrand/",
    "github_url": "https://github.com/rdpackages/rdlocrand",
    "url": "https://cran.r-project.org/package=rdlocrand",
    "install": "install.packages(\"rdlocrand\")",
    "tags": [
      "local-randomization",
      "randomization-inference",
      "finite-sample",
      "window-selection",
      "sensitivity-analysis"
    ],
    "best_for": "Finite-sample inference in RDD when local randomization assumption is plausible near the cutoff, implementing Cattaneo, Frandsen & Titiunik (2015)",
    "language": "R"
  },
  {
    "name": "rdmulti",
    "description": "Provides tools for RD designs with multiple cutoffs or scores: rdmc() estimates pooled and cutoff-specific effects in multi-cutoff designs, rdmcplot() draws RD plots for multi-cutoff designs, and rdms() estimates effects in cumulative cutoffs or multi-score (geographic/boundary) designs.",
    "category": "Causal Inference (RDD)",
    "docs_url": "https://rdpackages.github.io/rdmulti/",
    "github_url": "https://github.com/rdpackages/rdmulti",
    "url": "https://cran.r-project.org/package=rdmulti",
    "install": "install.packages(\"rdmulti\")",
    "tags": [
      "multiple-cutoffs",
      "multi-score",
      "geographic-RD",
      "pooled-effects",
      "extrapolation"
    ],
    "best_for": "RDD with multiple cutoffs (e.g., different thresholds across regions) or multiple running variables (geographic boundaries), implementing Cattaneo, Titiunik & Vazquez-Bare (2020)",
    "language": "R"
  },
  {
    "name": "rdpower",
    "description": "Provides tools for power, sample size, and minimum detectable effects (MDE) calculations in RD designs using robust bias-corrected local polynomial inference: rdpower() calculates power, rdsampsi() calculates required sample size for desired power, and rdmde() computes minimum detectable effects.",
    "category": "Causal Inference (RDD)",
    "docs_url": "https://rdpackages.github.io/rdpower/",
    "github_url": "https://github.com/rdpackages/rdpower",
    "url": "https://cran.r-project.org/package=rdpower",
    "install": "install.packages(\"rdpower\")",
    "tags": [
      "power-analysis",
      "sample-size",
      "MDE",
      "study-design",
      "ex-ante-analysis"
    ],
    "best_for": "Planning RDD studies‚Äîcalculating required sample sizes, statistical power, or minimum detectable effects, implementing Cattaneo, Titiunik & Vazquez-Bare (2019)",
    "language": "R"
  },
  {
    "name": "grf",
    "description": "Forest-based statistical estimation and inference for heterogeneous treatment effects, supporting multiple treatment arms, instrumental variables, survival outcomes, and quantile regression‚Äîall with honest estimation and valid confidence intervals. The most widely-used R package for CATE estimation.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://grf-labs.github.io/grf/",
    "github_url": "https://github.com/grf-labs/grf",
    "url": "https://cran.r-project.org/package=grf",
    "install": "install.packages(\"grf\")",
    "tags": [
      "causal-forest",
      "heterogeneous-treatment-effects",
      "CATE",
      "machine-learning",
      "econometrics"
    ],
    "best_for": "Estimating individual-level treatment effects (CATE) with valid statistical inference in RCTs or observational studies, implementing Athey, Tibshirani & Wager (2019)",
    "language": "R"
  },
  {
    "name": "causalweight",
    "description": "Semiparametric causal inference methods based on inverse probability weighting and double machine learning for average treatment effects, causal mediation analysis (direct/indirect effects), and dynamic treatment evaluation. Supports LATE estimation with instrumental variables.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://cran.r-project.org/web/packages/causalweight/causalweight.pdf",
    "github_url": "https://github.com/hbodory/causalweight",
    "url": "https://cran.r-project.org/package=causalweight",
    "install": "install.packages(\"causalweight\")",
    "tags": [
      "inverse-probability-weighting",
      "causal-mediation",
      "double-machine-learning",
      "LATE",
      "instrumental-variables"
    ],
    "best_for": "Mediation analysis and LATE estimation using weighting-based approaches with flexible nuisance estimation, implementing Huber (2014) and Fr√∂lich & Huber (2017)",
    "language": "R"
  },
  {
    "name": "causalToolbox",
    "description": "Implements meta-learner algorithms (S-learner, T-learner, X-learner) for heterogeneous treatment effect estimation using flexible base learners including honest Random Forests and BART for personalized CATE estimation.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://rdrr.io/github/soerenkuenzel/causalToolbox/",
    "github_url": "https://github.com/forestry-labs/causalToolbox",
    "url": "https://github.com/forestry-labs/causalToolbox",
    "install": "devtools::install_github(\"forestry-labs/causalToolbox\")",
    "tags": [
      "metalearners",
      "X-learner",
      "T-learner",
      "S-learner",
      "CATE"
    ],
    "best_for": "Comparing and benchmarking different CATE meta-learner strategies (S/T/X-learner) with BART or RF base learners, implementing K√ºnzel et al. (2019)",
    "language": "R"
  },
  {
    "name": "DoubleML",
    "description": "Object-oriented implementation of the double/debiased machine learning framework for partially linear regression, interactive regression, and instrumental variable models. Built on mlr3 with R6 classes for flexible, extensible model specification with any mlr3-compatible ML learner.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://docs.doubleml.org/r/stable/",
    "github_url": "https://github.com/DoubleML/doubleml-for-r",
    "url": "https://cran.r-project.org/package=DoubleML",
    "install": "install.packages(\"DoubleML\")",
    "tags": [
      "double-machine-learning",
      "mlr3",
      "cross-fitting",
      "treatment-effects",
      "econometrics"
    ],
    "best_for": "Production-grade DML estimation with cross-fitting, hyperparameter tuning, and any mlr3-compatible ML learner, implementing Chernozhukov et al. (2018)",
    "language": "R"
  },
  {
    "name": "hdm",
    "description": "High-dimensional statistical methods featuring heteroscedasticity-robust LASSO with theoretically-grounded penalty selection, post-double-selection inference, and treatment effect estimation under sparsity assumptions for high-dimensional controls.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://cran.r-project.org/web/packages/hdm/vignettes/hdm.html",
    "github_url": "https://github.com/MartinSpindler/hdm",
    "url": "https://cran.r-project.org/package=hdm",
    "install": "install.packages(\"hdm\")",
    "tags": [
      "lasso",
      "post-double-selection",
      "high-dimensional",
      "instrumental-variables",
      "sparsity"
    ],
    "best_for": "Post-double-selection LASSO inference and treatment effect estimation when the true model is sparse, implementing Belloni, Chernozhukov & Hansen (2014)",
    "language": "R"
  },
  {
    "name": "ddml",
    "description": "Streamlined double/debiased machine learning estimation with emphasis on (short-)stacking to combine multiple base learners, increasing robustness to unknown data generating processes. Designed as a complement to DoubleML with simpler syntax.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://thomaswiemann.com/ddml/",
    "github_url": "https://github.com/thomaswiemann/ddml",
    "url": "https://cran.r-project.org/package=ddml",
    "install": "install.packages(\"ddml\")",
    "tags": [
      "double-machine-learning",
      "stacking",
      "model-averaging",
      "treatment-effects",
      "causal-inference"
    ],
    "best_for": "Quick, robust DML estimation using short-stacking to ensemble multiple ML learners without extensive tuning, implementing Ahrens, Hansen, Schaffer & Wiemann (2024)",
    "language": "R"
  },
  {
    "name": "tmle",
    "description": "Implements targeted maximum likelihood estimation for point treatment effects with binary or continuous outcomes. Estimates ATE, ATT, ATC, and supports marginal structural models. Integrates SuperLearner for data-adaptive nuisance parameter estimation.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://cran.r-project.org/web/packages/tmle/tmle.pdf",
    "github_url": null,
    "url": "https://cran.r-project.org/package=tmle",
    "install": "install.packages(\"tmle\")",
    "tags": [
      "TMLE",
      "causal-inference",
      "ATE",
      "doubly-robust",
      "propensity-score"
    ],
    "best_for": "Estimating point treatment effects (ATE/ATT/ATC) in observational studies with binary treatments, implementing Gruber & van der Laan (2012)",
    "language": "R"
  },
  {
    "name": "tmle3",
    "description": "A modular, extensible framework for targeted minimum loss-based estimation supporting custom TMLE parameters through a unified interface. Part of the tlverse ecosystem, designed to be as general as the mathematical TMLE framework itself for complex analyses.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://tlverse.org/tmle3/",
    "github_url": "https://github.com/tlverse/tmle3",
    "url": "https://github.com/tlverse/tmle3",
    "install": "remotes::install_github(\"tlverse/tmle3\")",
    "tags": [
      "TMLE",
      "tlverse",
      "modular",
      "extensible",
      "stochastic-interventions"
    ],
    "best_for": "Complex TMLE analyses requiring custom parameters, mediation, stochastic interventions, or optimal treatment regimes",
    "language": "R"
  },
  {
    "name": "ltmle",
    "description": "Targeted maximum likelihood estimation for treatment/censoring-specific mean outcomes with time-varying treatments and confounders. Supports longitudinal settings, marginal structural models, and dynamic treatment regimes alongside IPTW and G-computation.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://joshuaschwab.github.io/ltmle/",
    "github_url": "https://github.com/joshuaschwab/ltmle",
    "url": "https://cran.r-project.org/package=ltmle",
    "install": "install.packages(\"ltmle\")",
    "tags": [
      "TMLE",
      "longitudinal",
      "time-varying-treatment",
      "dynamic-regimes",
      "MSM"
    ],
    "best_for": "Causal inference with time-varying treatments, time-varying confounders, and right-censored longitudinal data, implementing Lendle et al. (2017)",
    "language": "R"
  },
  {
    "name": "SuperLearner",
    "description": "Implements the Super Learner algorithm for optimal ensemble prediction via cross-validation. Creates weighted combinations of multiple ML algorithms (XGBoost, Random Forest, glmnet, neural networks, SVM, BART) with guaranteed asymptotic optimality.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html",
    "github_url": "https://github.com/ecpolley/SuperLearner",
    "url": "https://cran.r-project.org/package=SuperLearner",
    "install": "install.packages(\"SuperLearner\")",
    "tags": [
      "ensemble-learning",
      "cross-validation",
      "stacking",
      "prediction",
      "model-selection"
    ],
    "best_for": "Building optimal prediction ensembles for nuisance parameter estimation (propensity scores, outcome models) in causal inference, implementing van der Laan, Polley & Hubbard (2007)",
    "language": "R"
  },
  {
    "name": "sensemakr",
    "description": "Suite of sensitivity analysis tools extending the traditional omitted variable bias framework, computing robustness values, bias-adjusted estimates, and sensitivity contour plots for OLS regression to assess how strong unmeasured confounders would need to be to overturn conclusions.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://carloscinelli.com/sensemakr/",
    "github_url": "https://github.com/carloscinelli/sensemakr",
    "url": "https://cran.r-project.org/package=sensemakr",
    "install": "install.packages(\"sensemakr\")",
    "tags": [
      "sensitivity-analysis",
      "omitted-variable-bias",
      "robustness-value",
      "causal-inference",
      "regression"
    ],
    "best_for": "Assessing how strong unmeasured confounders would need to be to overturn regression-based causal conclusions, implementing Cinelli & Hazlett (2020)",
    "language": "R"
  },
  {
    "name": "EValue",
    "description": "Conducts sensitivity analyses for unmeasured confounding, selection bias, and measurement error in observational studies and meta-analyses. Computes E-values representing the minimum strength of association unmeasured confounders would need to fully explain away an observed effect.",
    "category": "Causal Inference (ML)",
    "docs_url": "https://louisahsmith.github.io/evalue/",
    "github_url": "https://github.com/mayamathur/evalue_package",
    "url": "https://cran.r-project.org/package=EValue",
    "install": "install.packages(\"EValue\")",
    "tags": [
      "E-value",
      "unmeasured-confounding",
      "sensitivity-analysis",
      "selection-bias",
      "meta-analysis"
    ],
    "best_for": "Quantifying the minimum confounding strength on the risk ratio scale needed to explain away observed treatment-outcome associations, implementing VanderWeele & Ding (2017)",
    "language": "R"
  },
  {
    "name": "brms",
    "description": "High-level interface for fitting Bayesian generalized multilevel models using Stan, with lme4-style formula syntax supporting linear, count, survival, ordinal, zero-inflated, hurdle, and mixture models with flexible prior specification.",
    "category": "Bayesian Inference",
    "docs_url": "https://paul-buerkner.github.io/brms/",
    "github_url": "https://github.com/paul-buerkner/brms",
    "url": "https://cran.r-project.org/package=brms",
    "install": "install.packages(\"brms\")",
    "tags": [
      "Bayesian",
      "multilevel-models",
      "Stan",
      "regression",
      "distributional-regression"
    ],
    "best_for": "Complex hierarchical Bayesian regression with familiar R formula syntax, implementing B√ºrkner (2017)",
    "language": "R"
  },
  {
    "name": "rstanarm",
    "description": "Pre-compiled Bayesian regression models using Stan that mimic familiar R functions (lm, glm, lmer) with customary formula syntax, weakly informative default priors, and zero model compilation time.",
    "category": "Bayesian Inference",
    "docs_url": "https://mc-stan.org/rstanarm/",
    "github_url": "https://github.com/stan-dev/rstanarm",
    "url": "https://cran.r-project.org/package=rstanarm",
    "install": "install.packages(\"rstanarm\")",
    "tags": [
      "Bayesian",
      "Stan",
      "regression",
      "mixed-effects",
      "pre-compiled"
    ],
    "best_for": "Applied Bayesian regression with minimal learning curve for lm/glm/lmer users",
    "language": "R"
  },
  {
    "name": "rstan",
    "description": "Core R interface to the Stan probabilistic programming language, providing full Bayesian inference via NUTS/HMC, approximate inference via ADVI, and penalized maximum likelihood via L-BFGS for custom Bayesian models.",
    "category": "Bayesian Inference",
    "docs_url": "https://mc-stan.org/rstan/",
    "github_url": "https://github.com/stan-dev/rstan",
    "url": "https://cran.r-project.org/package=rstan",
    "install": "install.packages(\"rstan\")",
    "tags": [
      "Stan",
      "MCMC",
      "HMC",
      "probabilistic-programming",
      "Bayesian"
    ],
    "best_for": "Custom Bayesian models requiring direct Stan language access for maximum flexibility, implementing Carpenter et al. (2017)",
    "language": "R"
  },
  {
    "name": "bayesplot",
    "description": "Extensive library of ggplot2-based plotting functions for posterior analysis, MCMC diagnostics, and prior/posterior predictive checks supporting the applied Bayesian workflow for any MCMC-fitted model.",
    "category": "Bayesian Inference",
    "docs_url": "https://mc-stan.org/bayesplot/",
    "github_url": "https://github.com/stan-dev/bayesplot",
    "url": "https://cran.r-project.org/package=bayesplot",
    "install": "install.packages(\"bayesplot\")",
    "tags": [
      "visualization",
      "MCMC-diagnostics",
      "posterior-predictive-checks",
      "ggplot2",
      "Bayesian"
    ],
    "best_for": "Diagnostic plots and posterior visualization for MCMC-based Bayesian models, implementing Gabry et al. (2019)",
    "language": "R"
  },
  {
    "name": "lme4",
    "description": "Fit linear and generalized linear mixed-effects models using S4 classes with Eigen C++ library for efficient computation, supporting arbitrarily nested and crossed random effects structures for hierarchical and longitudinal data.",
    "category": "Mixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/lme4/vignettes/",
    "github_url": "https://github.com/lme4/lme4",
    "url": "https://cran.r-project.org/package=lme4",
    "install": "install.packages(\"lme4\")",
    "tags": [
      "linear-mixed-models",
      "GLMM",
      "random-effects",
      "hierarchical-models",
      "repeated-measures"
    ],
    "best_for": "Standard linear and generalized linear mixed-effects modeling with crossed/nested random effects, implementing Bates et al. (2015)",
    "language": "R"
  },
  {
    "name": "glmmTMB",
    "description": "Fit generalized linear mixed models with extensions including zero-inflation, hurdle models, heteroscedasticity, and autocorrelation using Template Model Builder (TMB) with automatic differentiation and Laplace approximation.",
    "category": "Mixed Effects",
    "docs_url": "https://glmmtmb.github.io/glmmTMB/",
    "github_url": "https://github.com/glmmTMB/glmmTMB",
    "url": "https://cran.r-project.org/package=glmmTMB",
    "install": "install.packages(\"glmmTMB\")",
    "tags": [
      "GLMM",
      "zero-inflation",
      "negative-binomial",
      "TMB",
      "overdispersion"
    ],
    "best_for": "Zero-inflated, overdispersed, or complex GLMMs beyond lme4 capabilities, implementing Brooks et al. (2017)",
    "language": "R"
  },
  {
    "name": "nlme",
    "description": "Fit Gaussian linear and nonlinear mixed-effects models with flexible correlation structures, variance functions for heteroscedasticity, and nested random effects. Ships with base R and offers more variance-covariance flexibility than lme4.",
    "category": "Mixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/nlme/nlme.pdf",
    "github_url": null,
    "url": "https://cran.r-project.org/package=nlme",
    "install": "install.packages(\"nlme\")",
    "tags": [
      "nonlinear-mixed-models",
      "autocorrelation",
      "heteroscedasticity",
      "repeated-measures",
      "longitudinal"
    ],
    "best_for": "Models requiring custom correlation structures, variance functions, or nonlinear mixed effects, implementing Pinheiro & Bates (2000)",
    "language": "R"
  },
  {
    "name": "lmerTest",
    "description": "Provides p-values for lme4 model fits via Satterthwaite's or Kenward-Roger degrees of freedom methods, with Type I/II/III ANOVA tables, model selection tools (step, drop1), and least-squares means calculations.",
    "category": "Mixed Effects",
    "docs_url": "https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf",
    "github_url": "https://github.com/runehaubo/lmerTestR",
    "url": "https://cran.r-project.org/package=lmerTest",
    "install": "install.packages(\"lmerTest\")",
    "tags": [
      "p-values",
      "Satterthwaite",
      "Kenward-Roger",
      "ANOVA",
      "hypothesis-testing"
    ],
    "best_for": "Getting p-values and formal hypothesis tests for lme4 linear mixed models, implementing Kuznetsova et al. (2017)",
    "language": "R"
  },
  {
    "name": "lavaan",
    "description": "Free, open-source latent variable analysis providing commercial-quality functionality for path analysis, confirmatory factor analysis, structural equation modeling, and growth curve models with intuitive model syntax.",
    "category": "Structural Equation Modeling",
    "docs_url": "https://lavaan.ugent.be/",
    "github_url": "https://github.com/yrosseel/lavaan",
    "url": "https://cran.r-project.org/package=lavaan",
    "install": "install.packages(\"lavaan\")",
    "tags": [
      "SEM",
      "CFA",
      "path-analysis",
      "latent-variables",
      "psychometrics"
    ],
    "best_for": "General-purpose structural equation modeling with accessible syntax for researchers, implementing Rosseel (2012)",
    "language": "R"
  },
  {
    "name": "OpenMx",
    "description": "Extended SEM software with programmatic model specification via paths (RAM) or matrix algebra, supporting mixture distributions, item factor analysis, state space models, and behavior genetics twin studies.",
    "category": "Structural Equation Modeling",
    "docs_url": "https://openmx.ssri.psu.edu/",
    "github_url": "https://github.com/OpenMx/OpenMx",
    "url": "https://cran.r-project.org/package=OpenMx",
    "install": "install.packages(\"OpenMx\")",
    "tags": [
      "SEM",
      "matrix-algebra",
      "twin-studies",
      "behavior-genetics",
      "IFA"
    ],
    "best_for": "Complex/advanced SEM, behavior genetics, and researchers needing maximum specification flexibility, implementing Neale et al. (2016)",
    "language": "R"
  },
  {
    "name": "blavaan",
    "description": "Bayesian latent variable analysis extending lavaan with MCMC estimation via Stan or JAGS, supporting Bayesian CFA, SEM, growth models, and model comparison with WAIC, LOO, and Bayes factors.",
    "category": "Structural Equation Modeling",
    "docs_url": "https://ecmerkle.github.io/blavaan/",
    "github_url": "https://github.com/ecmerkle/blavaan",
    "url": "https://cran.r-project.org/package=blavaan",
    "install": "install.packages(\"blavaan\")",
    "tags": [
      "Bayesian-SEM",
      "Stan",
      "JAGS",
      "MCMC",
      "latent-variables"
    ],
    "best_for": "Bayesian inference for SEM models using familiar lavaan syntax, implementing Merkle & Rosseel (2018)",
    "language": "R"
  },
  {
    "name": "mgcv",
    "description": "The definitive GAM implementation providing generalized additive (mixed) models with automatic smoothness estimation via REML/GCV/ML, supporting thin plate splines, tensor products, multiple distributions, and scalable fitting for large datasets.",
    "category": "Generalized Additive Models",
    "docs_url": "https://cran.r-project.org/web/packages/mgcv/mgcv.pdf",
    "github_url": null,
    "url": "https://cran.r-project.org/package=mgcv",
    "install": "install.packages(\"mgcv\")",
    "tags": [
      "GAM",
      "splines",
      "smoothing",
      "penalized-regression",
      "mixed-models"
    ],
    "best_for": "Flexible nonparametric regression with automatic smoothing parameter selection, implementing Wood (2017)",
    "language": "R"
  },
  {
    "name": "gamlss",
    "description": "Distributional regression where all parameters of a response distribution (location, scale, shape) can be modeled as functions of predictors, supporting 100+ distributions including highly skewed and kurtotic continuous and discrete distributions.",
    "category": "Generalized Additive Models",
    "docs_url": "https://www.gamlss.com/",
    "github_url": "https://github.com/gamlss-dev/gamlss",
    "url": "https://cran.r-project.org/package=gamlss",
    "install": "install.packages(\"gamlss\")",
    "tags": [
      "distributional-regression",
      "location-scale-shape",
      "flexible-distributions",
      "centile-estimation",
      "beyond-mean-modeling"
    ],
    "best_for": "Modeling non-normal responses where variance, skewness, or kurtosis depend on predictors, implementing Rigby & Stasinopoulos (2005)",
    "language": "R"
  }
]