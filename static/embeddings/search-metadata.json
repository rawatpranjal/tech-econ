{"version":4,"model":"gte-small","dimensions":384,"count":3026,"generatedAt":"2025-12-30T20:31:14.680724Z","contentHash":"68d3da1b337cd9f9","items":[{"id":"package-bayesianbandits","type":"package","name":"BayesianBandits","description":"Lightweight microframework for Bayesian bandits (Thompson Sampling) with support for contextual/restless/delayed rewards.","category":"Adaptive Experimentation & Bandits","url":"https://github.com/IntelyCare/bayesianbandits","difficulty":"intermediate","prerequisites":"python-scipy, bayesian-inference, A/B-testing","topic_tags":"thompson-sampling, contextual-bandits, online-experiments, bayesian-optimization, adaptive-testing","summary":"BayesianBandits is a lightweight Python framework implementing Thompson Sampling for multi-armed bandit problems. It supports advanced scenarios like contextual bandits, restless bandits, and delayed reward feedback. Data scientists use it to optimize real-time decision making in experiments where traditional A/B testing is too slow or inefficient.","use_cases":"Dynamically allocating traffic to website variants based on real-time conversion performance, Personalizing content recommendations by learning user preferences through contextual bandit feedback","audience":"Mid-DS, Senior-DS"},{"id":"package-contextualbandits","type":"package","name":"ContextualBandits","description":"Implements a wide range of contextual bandit algorithms (linear, tree-based, neural) and off-policy evaluation methods.","category":"Adaptive Experimentation & Bandits","url":"https://github.com/david-cortes/contextualbandits","difficulty":"intermediate","prerequisites":"python-scikit-learn, multi-armed-bandits, numpy-arrays","topic_tags":"contextual-bandits, off-policy-evaluation, adaptive-algorithms, reinforcement-learning, python-package","summary":"A comprehensive Python package that implements contextual bandit algorithms including linear, tree-based, and neural network approaches, plus off-policy evaluation methods. Used by data scientists and researchers to optimize sequential decision-making problems where actions depend on context. Enables practical implementation of adaptive experimentation beyond traditional A/B testing.","use_cases":"Personalizing content recommendations where user features influence which articles/products to show, Optimizing ad targeting by adapting bidding strategies based on user demographics and behavior patterns","audience":"Mid-DS, Senior-DS"},{"id":"package-mabwiser","type":"package","name":"MABWiser","description":"Production-ready, scikit-learn style library for contextual & stochastic bandits with parallelism and simulation tools.","category":"Adaptive Experimentation & Bandits","url":"https://github.com/fidelity/mabwiser","difficulty":"intermediate","prerequisites":"python-scikit-learn, hypothesis-testing, statistical-inference","topic_tags":"multi-armed-bandits, contextual-bandits, production-ready, experimentation-framework, adaptive-testing","summary":"MABWiser is a production-ready Python library that implements multi-armed bandit algorithms with contextual and stochastic capabilities, built in scikit-learn style for easy adoption. It provides parallelized execution and simulation tools for running adaptive experiments that optimize decisions in real-time. The library is designed for practitioners who need to move beyond traditional A/B testing to more sophisticated adaptive experimentation methods.","use_cases":"Optimizing product recommendation algorithms by learning which recommendations work best for different user segments, Dynamic pricing experiments where prices adapt based on user behavior and market conditions","audience":"Mid-DS, Senior-DS"},{"id":"package-open-bandit-pipeline-(obp)","type":"package","name":"Open Bandit Pipeline (OBP)","description":"Framework for **offline evaluation (OPE)** of bandit policies using logged data. Implements IPS, DR, DM estimators.","category":"Adaptive Experimentation & Bandits","url":"https://github.com/st-tech/zr-obp","difficulty":"intermediate","prerequisites":"multi-armed-bandits, python-scikit-learn, causal-inference","topic_tags":"offline-policy-evaluation, bandit-algorithms, causal-inference, python-package, experimentation-framework","summary":"Open Bandit Pipeline (OBP) is a Python framework for evaluating bandit policies using historical logged data without running live experiments. It implements key offline policy evaluation methods like Inverse Propensity Scoring (IPS), Doubly Robust (DR), and Direct Method (DM) estimators. Data scientists and researchers use it to safely test new recommendation or treatment assignment policies before deployment.","use_cases":"Evaluating new recommendation algorithms using past user interaction logs before A/B testing, Assessing personalized treatment policies in healthcare using historical patient data","audience":"Mid-DS, Senior-DS"},{"id":"package-pyxab","type":"package","name":"PyXAB","description":"Library for advanced bandit problems: X-armed bandits (continuous/structured action spaces) and online optimization.","category":"Adaptive Experimentation & Bandits","url":"https://github.com/huanzhang12/pyxab","difficulty":"advanced","prerequisites":"multi-armed-bandits, convex-optimization, python-numpy","topic_tags":"continuous-bandits, optimization, reinforcement-learning, python-package","summary":"PyXAB is a Python library for solving X-armed bandit problems where actions exist in continuous or structured spaces rather than discrete options. It's designed for researchers and practitioners working on online optimization problems that require sequential decision-making with complex action spaces. The library implements advanced algorithms for scenarios where traditional multi-armed bandits are insufficient due to infinite or highly structured action sets.","use_cases":"Dynamic pricing optimization where price points form a continuous space, Hyperparameter tuning for machine learning models with structured parameter spaces","audience":"Senior-DS, Early-PhD"},{"id":"package-smpybandits","type":"package","name":"SMPyBandits","description":"Comprehensive research framework for single/multi-player MAB algorithms (stochastic, adversarial, contextual).","category":"Adaptive Experimentation & Bandits","url":"https://github.com/SMPyBandits/SMPyBandits","difficulty":"intermediate","prerequisites":"python-numpy, multi-armed-bandits, hypothesis-testing","topic_tags":"multi-armed-bandits, online-learning, reinforcement-learning, python-package","summary":"SMPyBandits is a comprehensive Python research framework implementing various multi-armed bandit algorithms for both single and multi-player scenarios. It supports stochastic, adversarial, and contextual bandits with extensive simulation capabilities. Researchers and data scientists use it to prototype, benchmark, and deploy adaptive experimentation strategies.","use_cases":"Dynamic pricing optimization where algorithms learn optimal prices through customer interactions, Content recommendation systems that adaptively allocate traffic to different article types based on engagement","audience":"Mid-DS, Senior-DS"},{"id":"package-abracadabra","type":"package","name":"abracadabra","description":"Sequential testing with always-valid inference. Supports continuous monitoring of A/B tests.","category":"Adaptive Experimentation & Bandits","url":"https://pypi.org/project/abracadabra/","difficulty":"intermediate","prerequisites":"hypothesis-testing, python-programming, A-B-testing-fundamentals","topic_tags":"sequential-testing, A-B-testing, continuous-monitoring, always-valid-inference, experimentation","summary":"Abracadabra is a Python package for sequential A/B testing that allows continuous monitoring of experiments without inflating Type I error rates. It implements always-valid inference methods, enabling data scientists to peek at results anytime and stop experiments early when significant effects are detected. The package is particularly useful for teams running online experiments who want flexibility in monitoring without statistical penalties.","use_cases":"Monitoring conversion rate experiments on e-commerce platforms where you need to check results daily and stop early if a clear winner emerges, Running product feature tests where business stakeholders want regular updates and the ability to halt experiments based on interim results","audience":"Mid-DS, Junior-DS"},{"id":"package-crewai","type":"package","name":"crewai","description":"Framework for orchestrating role-playing autonomous AI agents. Multi-agent collaboration made intuitive.","category":"Agentic AI","url":"https://www.crewai.com/","difficulty":"intermediate","prerequisites":"python-programming, large-language-models, API-integration","topic_tags":"multi-agent-systems, ai-orchestration, autonomous-agents, llm-workflows, collaborative-ai","summary":"CrewAI is a Python framework that enables multiple AI agents to work together on complex tasks, with each agent having specific roles and responsibilities. It simplifies the coordination of autonomous AI agents that can collaborate, delegate tasks, and combine their outputs. Data scientists and AI practitioners use it to build sophisticated multi-agent systems without dealing with low-level orchestration complexity.","use_cases":"Building a research pipeline where different agents handle data collection, analysis, and report writing, Creating a customer service system where agents specialize in different domains and escalate issues between each other","audience":"Mid-DS, Senior-DS"},{"id":"package-langchain","type":"package","name":"langchain","description":"Framework for developing LLM-powered applications. Chains, tools, memory, and retrieval.","category":"Agentic AI","url":"https://python.langchain.com/","difficulty":"intermediate","prerequisites":"python-programming, OpenAI-API, prompt-engineering","topic_tags":"large-language-models, agentic-ai, retrieval-augmented-generation, application-framework","summary":"LangChain is a Python framework for building applications powered by large language models, providing modular components for chaining prompts, integrating external tools, and managing conversation memory. It's widely used by data scientists and developers to create chatbots, document Q&A systems, and AI agents that can interact with databases and APIs. The framework simplifies complex LLM workflows through pre-built chains and retrieval-augmented generation capabilities.","use_cases":"Building a customer support chatbot that queries company databases and documentation, Creating a research assistant that can summarize papers and answer questions about uploaded documents","audience":"Junior-DS, Mid-DS"},{"id":"package-langgraph","type":"package","name":"langgraph","description":"Framework for building stateful, multi-actor LLM applications. Graph-based agent workflows with persistence.","category":"Agentic AI","url":"https://langchain-ai.github.io/langgraph/","difficulty":"intermediate","prerequisites":"python-langchain, LLM-APIs, graph-theory-basics","topic_tags":"multi-agent-systems, LLM-orchestration, stateful-workflows, graph-based-AI, conversational-AI","summary":"LangGraph is a framework for building complex, stateful applications with multiple LLM agents that can interact and maintain conversation history. It enables developers to create graph-based workflows where different agents handle specialized tasks and coordinate through defined relationships. The framework is particularly useful for building sophisticated AI assistants and automated reasoning systems that require persistent state management.","use_cases":"Building a customer service system where different AI agents handle billing, technical support, and sales inquiries while maintaining conversation context, Creating a research assistant that coordinates multiple specialized agents for literature search, data analysis, and report generation with persistent workflow state","audience":"Mid-DS, Senior-DS"},{"id":"package-openai-agents","type":"package","name":"openai-agents","description":"OpenAI's lightweight, production-ready SDK for building agentic AI applications. Fast prototyping.","category":"Agentic AI","url":"https://openai.github.io/openai-agents-python/","difficulty":"beginner","prerequisites":"python-programming, OpenAI-API, async-programming","topic_tags":"agentic-ai, openai-sdk, production-tools, ai-agents, rapid-prototyping","summary":"OpenAI's official SDK for building AI agents that can use tools and maintain conversations across multiple interactions. Designed for production use with minimal setup, making it easy to create agents that can perform tasks like web searches, data analysis, or API calls. Ideal for developers who want to quickly prototype and deploy agentic AI applications without heavy framework overhead.","use_cases":"Building a customer support agent that can search knowledge bases and escalate to humans, Creating a data analysis assistant that can query databases and generate reports","audience":"Junior-DS, Mid-DS"},{"id":"package-bsts","type":"package","name":"bsts","description":"Bayesian Structural Time Series providing the foundation for CausalImpact. Supports spike-and-slab variable selection, multiple state components (trend, seasonality, regression), and non-Gaussian outcomes. Developed at Google.","category":"Bayesian Causal Inference","url":"https://cran.r-project.org/package=bsts","difficulty":"intermediate","prerequisites":"time-series-analysis, bayesian-statistics, R-programming","topic_tags":"bayesian-inference, time-series, causal-impact, state-space-models, R-package","summary":"BSTS is an R package for Bayesian structural time series modeling that serves as the foundation for Google's CausalImpact package. It enables flexible time series analysis with automatic variable selection through spike-and-slab priors and supports complex state components like trends and seasonality. Particularly valuable for causal inference in time series data and intervention analysis.","use_cases":"Measuring the causal impact of a marketing campaign on sales by modeling pre-intervention time series, Forecasting business metrics while accounting for multiple seasonal patterns and external covariates","audience":"Mid-DS, Senior-DS"},{"id":"package-bambi","type":"package","name":"Bambi","description":"High-level interface for building Bayesian GLMMs, built on top of PyMC. Uses formula syntax similar to R's `lme4`.","category":"Bayesian Econometrics","url":"https://github.com/bambinos/bambi","difficulty":"intermediate","prerequisites":"python-pymc, generalized-linear-models, R-formula-syntax","topic_tags":"bayesian-inference, mixed-effects-models, generalized-linear-models, hierarchical-modeling, python-package","summary":"Bambi provides a high-level, R-like interface for building Bayesian generalized linear mixed models (GLMMs) using PyMC as the backend. It allows economists and data scientists to specify complex hierarchical models using familiar formula syntax without writing low-level PyMC code. The package is particularly useful for multilevel regression analysis with partial pooling and uncertainty quantification.","use_cases":"Analyzing user engagement across different product features with random effects for user groups, Estimating treatment effects in A/B tests with hierarchical structure across market segments","audience":"Mid-DS, Senior-DS"},{"id":"package-lightweightmmm","type":"package","name":"LightweightMMM","description":"Bayesian Marketing Mix Modeling (see Marketing Mix Models section).","category":"Bayesian Econometrics","url":"https://github.com/google/lightweight_mmm","difficulty":"intermediate","prerequisites":"python-programming, bayesian-statistics, marketing-attribution","topic_tags":"marketing-mix-modeling, bayesian-inference, media-attribution, python-package, causal-inference","summary":"LightweightMMM is a Google-developed Python package for Bayesian Marketing Mix Modeling that helps quantify the incremental impact of different marketing channels on business outcomes. It uses probabilistic methods to estimate media effectiveness, budget allocation, and diminishing returns curves while accounting for uncertainty in the estimates.","use_cases":"Optimizing marketing budget allocation across channels like TV, digital ads, and social media, Measuring incrementality and ROI of marketing campaigns while controlling for seasonality and external factors","audience":"Mid-DS, Senior-DS"},{"id":"package-numpyro","type":"package","name":"NumPyro","description":"Probabilistic programming library built on JAX for scalable Bayesian inference, often faster than PyMC.","category":"Bayesian Econometrics","url":"https://github.com/pyro-ppl/numpyro","difficulty":"intermediate","prerequisites":"python-programming, bayesian-statistics, MCMC-sampling","topic_tags":"probabilistic-programming, bayesian-inference, JAX, MCMC, scalable-computing","summary":"NumPyro is a probabilistic programming library that leverages JAX's GPU acceleration and automatic differentiation for fast Bayesian inference. It's particularly useful for economists who need to fit complex hierarchical models or run computationally intensive MCMC sampling. The library offers similar modeling capabilities to PyMC but with significantly better performance on large datasets.","use_cases":"Estimating hierarchical demand models with thousands of products and markets, Running sensitivity analysis on structural economic models with multiple parameters","audience":"Mid-DS, Senior-DS"},{"id":"package-pymc","type":"package","name":"PyMC","description":"Flexible probabilistic programming library for Bayesian modeling and inference using MCMC algorithms (NUTS).","category":"Bayesian Econometrics","url":"https://github.com/pymc-devs/pymc","difficulty":"intermediate","prerequisites":"python-basics, probability-distributions, linear-regression","topic_tags":"bayesian-inference, mcmc-sampling, probabilistic-programming, uncertainty-quantification, hierarchical-modeling","summary":"PyMC is a Python library for Bayesian statistical modeling that allows users to build complex probabilistic models and perform inference using advanced MCMC sampling algorithms. It's particularly powerful for handling uncertainty quantification and hierarchical models in econometric applications. The library provides an intuitive interface for specifying priors, likelihoods, and posterior sampling.","use_cases":"Estimating treatment effects with uncertainty bounds in A/B testing, Building hierarchical models for customer lifetime value across different segments","audience":"Mid-DS, Senior-DS"},{"id":"package-bayesplot","type":"package","name":"bayesplot","description":"Extensive library of ggplot2-based plotting functions for posterior analysis, MCMC diagnostics, and prior/posterior predictive checks supporting the applied Bayesian workflow for any MCMC-fitted model.","category":"Bayesian Inference","url":"https://cran.r-project.org/package=bayesplot","difficulty":"intermediate","prerequisites":"R-ggplot2, MCMC-sampling, Bayesian-statistics","topic_tags":"Bayesian-visualization, MCMC-diagnostics, posterior-analysis, R-package, statistical-graphics","summary":"bayesplot is an R package that provides comprehensive visualization tools for Bayesian analysis workflows. It offers specialized plots for diagnosing MCMC chains, visualizing posterior distributions, and conducting predictive checks. The package integrates seamlessly with popular Bayesian modeling packages like Stan, brms, and rstanarm.","use_cases":"Diagnosing convergence issues in MCMC chains from Stan models, Creating publication-ready posterior distribution plots for research papers","audience":"Mid-DS, Senior-DS"},{"id":"package-brms","type":"package","name":"brms","description":"High-level interface for fitting Bayesian generalized multilevel models using Stan, with lme4-style formula syntax supporting linear, count, survival, ordinal, zero-inflated, hurdle, and mixture models with flexible prior specification.","category":"Bayesian Inference","url":"https://cran.r-project.org/package=brms","difficulty":"intermediate","prerequisites":"hierarchical-models, R-programming, MCMC-basics","topic_tags":"bayesian-regression, multilevel-models, stan-interface, mixed-effects, distributional-modeling","summary":"brms is an R package that provides an intuitive interface for fitting complex Bayesian multilevel models using Stan as the computational backend. It allows data scientists and researchers to specify sophisticated hierarchical models using familiar lme4-style syntax while leveraging Stan's powerful MCMC sampling capabilities. The package supports a wide range of response distributions and model types, making it accessible for practitioners who want Bayesian inference without writing Stan code directly.","use_cases":"Analyzing user engagement across different product features with varying baseline rates by geographic region, Modeling patient treatment responses in clinical trials accounting for hospital-level effects and individual covariates","audience":"Mid-DS, Senior-DS"},{"id":"package-rstan","type":"package","name":"rstan","description":"Core R interface to the Stan probabilistic programming language, providing full Bayesian inference via NUTS/HMC, approximate inference via ADVI, and penalized maximum likelihood via L-BFGS for custom Bayesian models.","category":"Bayesian Inference","url":"https://cran.r-project.org/package=rstan","difficulty":"intermediate","prerequisites":"R-programming, Bayesian-statistics, MCMC-fundamentals","topic_tags":"probabilistic-programming, Bayesian-inference, MCMC-sampling, hierarchical-models, R-package","summary":"RStan is the R interface to Stan, a powerful probabilistic programming language for Bayesian statistical modeling. It enables data scientists and researchers to specify custom Bayesian models using intuitive syntax and performs efficient inference using advanced sampling algorithms like Hamiltonian Monte Carlo. The package is widely used in academic research and industry for complex statistical modeling where standard frequentist approaches fall short.","use_cases":"Hierarchical modeling for A/B test analysis with user-level random effects, Custom attribution modeling with prior knowledge about marketing channel effectiveness","audience":"Mid-DS, Senior-DS"},{"id":"package-rstanarm","type":"package","name":"rstanarm","description":"Pre-compiled Bayesian regression models using Stan that mimic familiar R functions (lm, glm, lmer) with customary formula syntax, weakly informative default priors, and zero model compilation time.","category":"Bayesian Inference","url":"https://cran.r-project.org/package=rstanarm","difficulty":"beginner","prerequisites":"R-programming, linear-regression, glm-models","topic_tags":"bayesian-regression, stan, R-package, mixed-effects, pre-compiled","summary":"rstanarm provides pre-compiled Bayesian regression models that work like familiar R functions (lm, glm, lmer) but with built-in uncertainty quantification and credible intervals. It eliminates the complexity of writing Stan code while providing access to Bayesian inference with sensible default priors. Perfect for analysts who want Bayesian benefits without the steep learning curve of probabilistic programming.","use_cases":"A/B testing analysis where you need credible intervals and want to incorporate prior beliefs about effect sizes, Hierarchical modeling of user behavior across different market segments with automatic shrinkage","audience":"Junior-DS, Mid-DS"},{"id":"package-boot","type":"package","name":"boot","description":"Classic bootstrap methods implementing the approaches described in Davison & Hinkley (1997). Provides functions for both parametric and nonparametric resampling with various confidence interval methods.","category":"Bootstrap & Inference","url":"https://cran.r-project.org/package=boot","difficulty":"intermediate","prerequisites":"R-programming, sampling-distributions, hypothesis-testing","topic_tags":"bootstrap, resampling, confidence-intervals, nonparametric-statistics, R-package","summary":"The boot package implements classical bootstrap resampling methods from Davison & Hinkley's seminal 1997 textbook. It provides functions for generating bootstrap samples, calculating bias-corrected estimates, and constructing various types of confidence intervals without distributional assumptions. This is the go-to R package for practitioners needing robust uncertainty quantification when traditional parametric methods don't apply.","use_cases":"Estimating confidence intervals for complex statistics like correlation coefficients when sample sizes are small, Creating robust uncertainty estimates for machine learning model performance metrics when distributional assumptions are violated","audience":"Junior-DS, Mid-DS"},{"id":"package-fwildclusterboot","type":"package","name":"fwildclusterboot","description":"Fast wild cluster bootstrap implementation following Roodman et al. (2019)\u2014up to 1000\u00d7 faster than alternatives. Critical for panel data with few clusters. Integrates with fixest and lfe for efficient inference.","category":"Bootstrap & Inference","url":"https://cran.r-project.org/package=fwildclusterboot","difficulty":"intermediate","prerequisites":"fixed-effects-regression, clustered-standard-errors, R-programming","topic_tags":"wild-bootstrap, cluster-inference, panel-data, standard-errors, econometrics","summary":"Fast implementation of wild cluster bootstrap for statistical inference when you have few clusters in panel data. Solves the problem where traditional clustered standard errors become unreliable with small numbers of clusters. Integrates seamlessly with popular R packages like fixest and lfe for efficient econometric analysis.","use_cases":"Running difference-in-differences with only 8-15 states as treatment units, Analyzing firm-level panel data where clustering by industry leaves only 12 sectors","audience":"Mid-DS, Senior-DS"},{"id":"package-rsample","type":"package","name":"rsample","description":"Modern tidyverse-compatible resampling infrastructure. Provides functions for creating resamples (bootstrap, cross-validation, time series splits) that integrate seamlessly with tidymodels workflows.","category":"Bootstrap & Inference","url":"https://cran.r-project.org/package=rsample","difficulty":"beginner","prerequisites":"R-dplyr, cross-validation, bootstrap-sampling","topic_tags":"resampling, tidymodels, cross-validation, bootstrap, model-validation","summary":"rsample is an R package that provides a consistent framework for creating resamples like bootstrap samples, cross-validation folds, and time series splits. It integrates seamlessly with the tidymodels ecosystem, making it easy to incorporate resampling into machine learning workflows. The package handles common resampling scenarios with intuitive functions that return tidy data structures.","use_cases":"Setting up 10-fold cross-validation to evaluate model performance before production deployment, Creating bootstrap samples to estimate confidence intervals for A/B test effect sizes","audience":"Junior-DS, Mid-DS"},{"id":"package-bunching","type":"package","name":"bunching","description":"Implements Kleven-Waseem style bunching estimation for kink and notch designs. Calculates parametric elasticities from bunching at tax thresholds with publication-ready output.","category":"Bunching Estimation","url":"https://cran.r-project.org/package=bunching","difficulty":"intermediate","prerequisites":"regression-discontinuity, python-pandas, tax-policy-basics","topic_tags":"bunching-estimation, tax-elasticity, kink-design, notch-design, public-economics","summary":"This package implements the Kleven-Waseem bunching estimation method for measuring behavioral responses at tax kinks and notches. It's designed for economists studying how taxpayers respond to tax thresholds by calculating elasticities from observed bunching patterns. The package produces publication-ready results for academic research in public economics.","use_cases":"Measuring taxpayer responses to earned income tax credit kinks, Analyzing bunching behavior at corporate tax rate thresholds","audience":"Early-PhD, Senior-DS"},{"id":"package-bnlearn","type":"package","name":"bnlearn","description":"Bayesian network structure learning, parameter estimation, and inference. Implements constraint-based (PC, GS), score-based (HC, TABU), and hybrid algorithms for DAG learning with discrete and continuous data.","category":"Causal Discovery","url":"https://cran.r-project.org/package=bnlearn","difficulty":"intermediate","prerequisites":"directed-acyclic-graphs, conditional-independence, maximum-likelihood-estimation","topic_tags":"bayesian-networks, causal-discovery, probabilistic-graphical-models, structure-learning, R-package","summary":"bnlearn is an R package for learning Bayesian network structures from data and performing probabilistic inference. It provides multiple algorithms for discovering causal relationships and estimating parameters in directed acyclic graphs. The package is widely used by researchers and practitioners for causal discovery and probabilistic modeling tasks.","use_cases":"discovering causal relationships between customer behavior variables from transaction data, building probabilistic models for medical diagnosis by learning dependencies between symptoms and conditions","audience":"Mid-DS, Senior-DS"},{"id":"package-dagitty","type":"package","name":"dagitty","description":"Analysis of structural causal models represented as DAGs. Computes adjustment sets, identifies instrumental variables, tests conditional independencies, and finds minimal sufficient adjustment sets for causal identification.","category":"Causal Discovery","url":"https://cran.r-project.org/package=dagitty","difficulty":"intermediate","prerequisites":"directed-acyclic-graphs, causal-inference-theory, R-programming","topic_tags":"causal-graphs, DAG-analysis, adjustment-sets, causal-identification, d-separation","summary":"dagitty is an R package for analyzing directed acyclic graphs (DAGs) to support causal inference. It helps researchers identify which variables to control for in observational studies by computing adjustment sets and testing causal assumptions. The package is widely used by economists and data scientists working on causal identification problems.","use_cases":"Determining which covariates to include when estimating the causal effect of a treatment on an outcome, Testing whether your causal assumptions are consistent with observed data patterns using conditional independence tests","audience":"Mid-DS, Early-PhD"},{"id":"package-ggdag","type":"package","name":"ggdag","description":"Visualize and analyze causal DAGs using ggplot2. Provides tidy interface to dagitty with publication-quality DAG plots, path highlighting, and adjustment set visualization.","category":"Causal Discovery","url":"https://cran.r-project.org/package=ggdag","difficulty":"beginner","prerequisites":"ggplot2, basic-causal-inference, R-programming","topic_tags":"causal-diagrams, DAG-visualization, ggplot2, causal-inference, R-package","summary":"ggdag is an R package that creates publication-quality causal directed acyclic graphs (DAGs) using ggplot2 syntax. It provides an intuitive interface for drawing causal diagrams, identifying confounders, and visualizing adjustment sets needed for causal identification. The package is especially useful for researchers who need to communicate causal assumptions clearly in papers and presentations.","use_cases":"Drawing causal diagrams to identify which variables to control for in a regression analyzing the effect of user engagement features on retention, Creating publication-ready DAGs to illustrate potential confounders when studying the causal impact of recommendation algorithms on user behavior","audience":"Early-PhD, Junior-DS"},{"id":"package-pcalg","type":"package","name":"pcalg","description":"Causal structure learning from observational data using the PC algorithm and variants. Estimates Markov equivalence class of DAGs from conditional independence tests with intervention support.","category":"Causal Discovery","url":"https://cran.r-project.org/package=pcalg","difficulty":"advanced","prerequisites":"conditional-independence-testing, directed-acyclic-graphs, python-networkx","topic_tags":"causal-discovery, PC-algorithm, structure-learning, observational-data, DAG-estimation","summary":"The pcalg package implements the PC algorithm and its variants for learning causal structure from observational data through conditional independence testing. It estimates the Markov equivalence class of directed acyclic graphs (DAGs) that could have generated the observed data, with support for interventional data. This is a foundational tool for causal discovery when you need to infer causal relationships without experimental manipulation.","use_cases":"Discovering causal relationships in healthcare data where randomized experiments are unethical or impossible, Learning market structure and causal dependencies between economic variables from observational business data","audience":"Senior-DS, Early-PhD"},{"id":"package-ananke","type":"package","name":"Ananke","description":"Causal inference using graphical models (DAGs), including identification theory and effect estimation.","category":"Causal Discovery & Graphical Models","url":"[https://github.com/py-why/Ananke](https://github.com/ghosthamlet/ananke","difficulty":"intermediate","prerequisites":"python-networkx, directed-acyclic-graphs, instrumental-variables","topic_tags":"causal-inference, dag-identification, graphical-models, python-package, effect-estimation","summary":"Ananke is a Python package for causal inference that leverages directed acyclic graphs (DAGs) to identify causal effects and estimate treatment impacts. It implements formal identification theory to determine whether causal effects can be computed from observational data given assumptions encoded in graphical models. The package is particularly useful for researchers who need to move beyond simple correlation analysis to establish causal relationships.","use_cases":"Determining whether a marketing intervention's effect can be identified from observational data given confounding variables, Estimating the causal impact of a product feature on user retention while accounting for selection bias using instrumental variables","audience":"Mid-DS, Senior-DS"},{"id":"package-benchpress","type":"package","name":"Benchpress","description":"Benchmarking 41+ structure learning algorithms for causal discovery. Standardized evaluation framework.","category":"Causal Discovery & Graphical Models","url":"https://github.com/felixleopoldo/benchpress","difficulty":"intermediate","prerequisites":"python-scikit-learn, directed-acyclic-graphs, statistical-hypothesis-testing","topic_tags":"causal-discovery, structure-learning, benchmarking, graph-algorithms, evaluation-framework","summary":"Benchpress is a standardized evaluation framework that benchmarks 41+ algorithms for learning causal graph structures from observational data. It provides consistent comparison metrics and evaluation protocols for causal discovery methods. Researchers and data scientists use it to select the best structure learning algorithm for their specific dataset and problem constraints.","use_cases":"Comparing multiple causal discovery algorithms on your dataset to identify which performs best before committing to one approach, Evaluating a new structure learning method you've developed against established baselines using standardized metrics","audience":"Mid-DS, Senior-DS"},{"id":"package-causal-discovery-toolbox-(cdt)","type":"package","name":"Causal Discovery Toolbox (CDT)","description":"Implements algorithms for causal discovery (recovering causal graph structure) from observational data.","category":"Causal Discovery & Graphical Models","url":"https://github.com/FenTechSolutions/CausalDiscoveryToolbox","difficulty":"advanced","prerequisites":"python-networkx, directed-acyclic-graphs, hypothesis-testing","topic_tags":"causal-discovery, graph-structure, observational-data, causal-graphs, structure-learning","summary":"CDT is a Python package that implements algorithms to automatically discover causal relationships and graph structures from observational data without prior knowledge of the causal model. It's primarily used by researchers and data scientists working on causal inference problems where the underlying causal structure is unknown. The toolkit provides various algorithms like PC, GES, and constraint-based methods to recover directed acyclic graphs representing causal relationships.","use_cases":"Discovering which features causally influence customer churn from historical user behavior data, Identifying causal pathways between genes, proteins, and disease outcomes from genomics datasets","audience":"Senior-DS, Early-PhD"},{"id":"package-causalnex","type":"package","name":"CausalNex","description":"Uses Bayesian Networks for causal reasoning, combining ML with expert knowledge to model relationships.","category":"Causal Discovery & Graphical Models","url":"https://github.com/microsoft/causalnex","difficulty":"intermediate","prerequisites":"python-pandas, directed-acyclic-graphs, bayesian-inference","topic_tags":"causal-discovery, bayesian-networks, structural-causal-models, graph-learning, python-package","summary":"CausalNex is a Python library that combines machine learning with domain expertise to build Bayesian Networks for causal reasoning. It enables practitioners to discover causal relationships from data while incorporating prior knowledge through structural constraints. The package is particularly useful for understanding complex systems where relationships between variables need to be modeled and interpreted causally.","use_cases":"Building a causal model to understand which marketing channels actually drive customer conversions versus just correlate with them, Modeling supply chain relationships to identify which factors causally impact delivery delays for operational improvements","audience":"Mid-DS, Senior-DS"},{"id":"package-lingam","type":"package","name":"LiNGAM","description":"Specialized package for learning non-Gaussian linear causal models, implementing various versions of the LiNGAM algorithm including ICA-based methods.","category":"Causal Discovery & Graphical Models","url":"https://github.com/cdt15/lingam","difficulty":"advanced","prerequisites":"independent-component-analysis, directed-acyclic-graphs, maximum-likelihood-estimation","topic_tags":"lingam, causal-discovery, non-gaussian, structural-equations, ica-based","summary":"LiNGAM (Linear Non-Gaussian Acyclic Model) is a specialized package for discovering causal structure in observational data by exploiting non-Gaussian noise assumptions. It implements various algorithms including ICA-based, DirectLiNGAM, and other variants to learn directed acyclic graphs from linear structural equation models. Primarily used by researchers and advanced practitioners working on causal discovery problems where traditional correlation-based methods fail.","use_cases":"Discovering causal relationships in economic time series data where variables have non-Gaussian distributions, Learning the causal structure of gene regulatory networks from expression data with non-Gaussian noise","audience":"Senior-DS, Early-PhD"},{"id":"package-mcd","type":"package","name":"MCD","description":"Mixture of Causal Graphs discovery for heterogeneous time series (ICML 2024). Finds time-varying causal structures.","category":"Causal Discovery & Graphical Models","url":"https://pypi.org/project/MCD/","difficulty":"advanced","prerequisites":"structural-causal-models, graph-neural-networks, time-series-analysis","topic_tags":"causal-discovery, time-varying-graphs, heterogeneous-time-series, mixture-models, ICML-2024","summary":"MCD discovers time-varying causal structures in heterogeneous time series data using a mixture of causal graphs approach. It identifies different causal regimes that may exist at different time periods or across different entities in the data. This is particularly valuable for understanding how causal relationships evolve over time or differ across subgroups.","use_cases":"Analyzing how causal relationships between economic variables change during different market regimes, Understanding time-varying causal effects in A/B testing when user behavior patterns shift over time","audience":"Senior-DS, Early-PhD"},{"id":"package-sdci","type":"package","name":"SDCI","description":"State-dependent causal inference for conditionally stationary processes (ICML 2025). Handles regime-switching causal graphs.","category":"Causal Discovery & Graphical Models","url":"https://pypi.org/project/SDCI/","difficulty":"advanced","prerequisites":"causal-inference, graphical-models, time-series-analysis","topic_tags":"causal-discovery, time-series, regime-switching, graphical-models, state-dependent","summary":"SDCI implements state-dependent causal inference methods for time series data where causal relationships change across different regimes or states. This advanced package handles conditionally stationary processes where the underlying causal graph structure switches between different configurations over time. Particularly useful for economists and data scientists analyzing structural breaks or regime changes in causal relationships.","use_cases":"Analyzing how monetary policy transmission mechanisms change during different economic regimes (recession vs expansion), Discovering causal relationships in user behavior data that vary across different platform states or market conditions","audience":"Senior-DS, Early-PhD"},{"id":"package-tigramite","type":"package","name":"Tigramite","description":"Specialized package for causal inference in time series data implementing PCMCI, PCMCIplus, LPCMCI algorithms with conditional independence tests.","category":"Causal Discovery & Graphical Models","url":"https://github.com/jakobrunge/tigramite","difficulty":"advanced","prerequisites":"time-series-analysis, directed-acyclic-graphs, conditional-independence-testing","topic_tags":"causal-discovery, time-series, pcmci, granger-causality, python-package","summary":"Tigramite is a Python package for discovering causal relationships in time series data using advanced algorithms like PCMCI and PCMCIplus. It's designed for researchers who need to identify causal structures from temporal data while accounting for confounders and complex dependencies. The package implements state-of-the-art conditional independence tests specifically tailored for time series causal discovery.","use_cases":"Identifying causal relationships between economic indicators over time, Discovering feedback loops in climate variables from observational data","audience":"Senior-DS, Early-PhD"},{"id":"package-causal-learn","type":"package","name":"causal-learn","description":"Comprehensive Python package serving as Python translation and extension of Java-based Tetrad toolkit for causal discovery algorithms.","category":"Causal Discovery & Graphical Models","url":"https://github.com/py-why/causal-learn","difficulty":"intermediate","prerequisites":"python-pandas, directed-acyclic-graphs, hypothesis-testing","topic_tags":"causal-discovery, graphical-models, python-package, structural-learning, tetrad","summary":"Causal-learn is a comprehensive Python package that implements causal discovery algorithms to automatically learn causal relationships from observational data. It serves as the Python version of the established Tetrad toolkit, providing methods to discover causal graphs, estimate causal effects, and validate causal assumptions. The package is widely used by researchers and data scientists who need to move beyond correlational analysis to understand underlying causal mechanisms.","use_cases":"Learning causal structure from observational healthcare data to identify which treatments actually cause improved patient outcomes, Discovering causal relationships in marketing attribution data to understand which touchpoints truly drive conversions versus mere correlation","audience":"Mid-DS, Senior-DS"},{"id":"package-causal-llm-bfs","type":"package","name":"causal-llm-bfs","description":"LLM + BFS hybrid for efficient causal graph discovery. Uses language models to guide structure search.","category":"Causal Discovery & Graphical Models","url":"https://github.com/superkaiba/causal-llm-bfs","difficulty":"advanced","prerequisites":"causal-inference-methods, graph-neural-networks, transformer-architectures","topic_tags":"causal-discovery, large-language-models, graph-search, structure-learning, hybrid-methods","summary":"A novel approach that combines large language models with breadth-first search algorithms to efficiently discover causal graph structures from data. The LLM provides intelligent guidance to the search process, potentially reducing the exponential complexity of traditional causal structure learning. This cutting-edge method is particularly useful for researchers working on automated causal discovery in complex domains.","use_cases":"Discovering causal relationships in high-dimensional observational datasets where domain knowledge can guide structure search, Automating causal graph construction for A/B testing frameworks in tech platforms with hundreds of potential confounders","audience":"Senior-DS, Early-PhD"},{"id":"package-gcastle","type":"package","name":"gCastle","description":"Huawei Noah's Ark Lab end-to-end causal structure learning toolchain emphasizing gradient-based methods with GPU acceleration (NOTEARS, GOLEM).","category":"Causal Discovery & Graphical Models","url":"https://github.com/huawei-noah/trustworthyAI","difficulty":"intermediate","prerequisites":"python-programming, networkx, pytorch-basics","topic_tags":"causal-discovery, directed-acyclic-graphs, gradient-optimization, gpu-computing, python-package","summary":"gCastle is Huawei Noah's Ark Lab's comprehensive Python toolchain for learning causal structure from observational data using gradient-based optimization methods. It provides GPU-accelerated implementations of popular algorithms like NOTEARS and GOLEM for discovering directed acyclic graphs (DAGs) that represent causal relationships. The package offers an end-to-end pipeline from data preprocessing to causal graph visualization and evaluation.","use_cases":"Discovering causal relationships in business metrics to understand which factors drive customer churn or revenue growth, Learning gene regulatory networks from genomics data to identify which genes causally influence disease outcomes","audience":"Mid-DS, Senior-DS"},{"id":"package-py-tetrad","type":"package","name":"py-tetrad","description":"Python interface to Tetrad Java library using JPype, providing direct access to Tetrad's causal discovery algorithms with efficient data translation.","category":"Causal Discovery & Graphical Models","url":"https://github.com/py-why/py-tetrad","difficulty":"intermediate","prerequisites":"python-pandas, directed-acyclic-graphs, java-installation","topic_tags":"causal-discovery, graphical-models, python-wrapper, tetrad-library, causal-inference","summary":"py-tetrad is a Python wrapper that provides access to the comprehensive Tetrad Java library for causal discovery and graphical modeling. It allows researchers to use Tetrad's powerful algorithms like PC, FCI, and GES directly from Python environments with seamless data conversion. The package bridges Python's data science ecosystem with Tetrad's mature causal inference implementations.","use_cases":"Learning causal structure from observational data to identify potential interventions in business processes, Applying constraint-based algorithms to discover causal relationships in experimental datasets","audience":"Mid-DS, Early-PhD"},{"id":"package-catenets","type":"package","name":"CATENets","description":"JAX-accelerated neural network CATE estimators implementing SNet, FlexTENet, TARNet, CFRNet, and DragonNet architectures.","category":"Causal Inference & Matching","url":"https://github.com/AliciaCurth/CATENets","difficulty":"advanced","prerequisites":"causal-inference-fundamentals, neural-networks, JAX-programming","topic_tags":"neural-cate-estimation, treatment-effects, deep-causal-inference, JAX-acceleration","summary":"CATENets provides JAX-accelerated implementations of state-of-the-art neural network architectures for estimating Conditional Average Treatment Effects (CATE). The package includes multiple deep learning approaches like TARNet, DragonNet, and FlexTENet for heterogeneous treatment effect estimation. It's designed for researchers and practitioners who need scalable, GPU-accelerated causal inference methods for complex, high-dimensional data.","use_cases":"Estimating personalized treatment effects in A/B tests with complex user features and interactions, Analyzing heterogeneous policy impacts across different demographic groups using observational data","audience":"Senior-DS, Early-PhD"},{"id":"package-causalinference","type":"package","name":"CausalInference","description":"Implements classical causal inference methods like propensity score matching, inverse probability weighting, stratification.","category":"Causal Inference & Matching","url":"https://github.com/laurencium/causalinference","difficulty":"intermediate","prerequisites":"python-pandas, regression-analysis, observational-studies","topic_tags":"propensity-score-matching, treatment-effects, causal-methods, python-package","summary":"CausalInference is a Python package that implements foundational causal inference methods for estimating treatment effects from observational data. It provides accessible implementations of propensity score matching, inverse probability weighting, and stratification techniques. The package is ideal for data scientists who need to move beyond correlation to establish causal relationships in non-experimental settings.","use_cases":"Measuring the impact of a marketing campaign on customer retention using observational data, Evaluating the effect of a product feature launch on user engagement when randomized experiments weren't possible","audience":"Junior-DS, Mid-DS"},{"id":"package-causallib","type":"package","name":"CausalLib","description":"IBM-developed package that provides a scikit-learn-inspired API for causal inference with meta-algorithms supporting arbitrary machine learning models.","category":"Causal Inference & Matching","url":"https://github.com/IBM/causallib","difficulty":"intermediate","prerequisites":"python-scikit-learn, basic-causal-inference, propensity-score-matching","topic_tags":"causal-inference, python-package, matching-methods, meta-algorithms, sklearn-api","summary":"CausalLib is IBM's Python package that brings causal inference methods into a familiar scikit-learn framework. It provides standardized implementations of matching, weighting, and other causal methods that can work with any machine learning model as the underlying estimator. The package is designed for practitioners who want to apply causal inference techniques without building everything from scratch.","use_cases":"Estimating treatment effects in A/B tests with confounding variables using propensity score matching, Evaluating the causal impact of marketing campaigns by combining machine learning models with causal inference methods","audience":"Junior-DS, Mid-DS"},{"id":"package-causalml","type":"package","name":"CausalML","description":"Focuses on uplift modeling and heterogeneous treatment effect estimation using machine learning techniques.","category":"Causal Inference & Matching","url":"https://github.com/uber/causalml","difficulty":"intermediate","prerequisites":"python-scikit-learn, randomized-controlled-trials, regression-analysis","topic_tags":"uplift-modeling, heterogeneous-treatment-effects, causal-ml, personalization, python-package","summary":"CausalML is a Python package that enables practitioners to estimate heterogeneous treatment effects and perform uplift modeling using machine learning approaches. It provides implementations of meta-learners like T-learner, S-learner, and X-learner to identify which users or segments respond differently to treatments. The package is particularly valuable for personalizing interventions in marketing, product features, and policy decisions.","use_cases":"Determining which customers should receive marketing promotions based on their likelihood to respond positively, Identifying user segments that benefit most from a new product feature to optimize rollout strategy","audience":"Mid-DS, Senior-DS"},{"id":"package-causalmatch","type":"package","name":"CausalMatch","description":"Implements Propensity Score Matching (PSM) and Coarsened Exact Matching (CEM) with ML flexibility for propensity score estimation.","category":"Causal Inference & Matching","url":"https://github.com/bytedance/CausalMatch","difficulty":"intermediate","prerequisites":"python-scikit-learn, logistic-regression, pandas-dataframes","topic_tags":"propensity-score-matching, causal-inference, observational-data, treatment-effects, python-package","summary":"CausalMatch is a Python package that implements propensity score matching and coarsened exact matching methods for causal inference from observational data. It allows data scientists to estimate treatment effects by matching treated and control units with similar characteristics, incorporating machine learning models for flexible propensity score estimation. The package is particularly useful for reducing selection bias when randomized experiments aren't feasible.","use_cases":"Measuring impact of marketing campaigns on customer retention using historical user data, Evaluating effectiveness of new product features by matching users who adopted the feature with similar non-adopters","audience":"Mid-DS, Junior-DS"},{"id":"package-causalplayground","type":"package","name":"CausalPlayground","description":"Python library for causal research that addresses the scarcity of real-world datasets with known causal relations. Provides fine-grained control over structural causal models.","category":"Causal Inference & Matching","url":"https://github.com/causal-playground/causal-playground","difficulty":"intermediate","prerequisites":"python-pandas, causal-diagrams, structural-causal-models","topic_tags":"causal-inference, simulation, synthetic-data, python-package, experimental-design","summary":"CausalPlayground is a Python library that generates synthetic datasets with known causal relationships for causal inference research and education. It allows researchers to create controlled environments for testing causal methods when real-world data with ground truth causal effects is unavailable. The library provides fine-grained control over structural causal models, making it valuable for benchmarking causal inference algorithms.","use_cases":"Testing and comparing different causal inference methods on datasets where true causal effects are known, Teaching causal inference concepts by generating examples with controllable confounding and treatment effects","audience":"Early-PhD, Mid-DS"},{"id":"package-causalpy","type":"package","name":"CausalPy","description":"Developed by PyMC Labs, focuses specifically on causal inference in quasi-experimental settings. Specializes in scenarios where randomization is impossible or expensive.","category":"Causal Inference & Matching","url":"https://github.com/pymc-labs/pymc-marketing","difficulty":"intermediate","prerequisites":"python-pandas, bayesian-statistics, difference-in-differences","topic_tags":"causal-inference, quasi-experimental, bayesian-methods, pymc, econometrics","summary":"CausalPy is a Python package by PyMC Labs designed for causal inference in quasi-experimental settings using Bayesian methods. It's particularly valuable when randomized controlled trials aren't feasible, offering tools for difference-in-differences, interrupted time series, and regression discontinuity designs. The package integrates with PyMC's probabilistic programming framework to provide uncertainty quantification for causal estimates.","use_cases":"Evaluating the impact of a policy change on business metrics using interrupted time series analysis, Measuring treatment effects in observational data where randomization wasn't possible using synthetic control methods","audience":"Mid-DS, Senior-DS"},{"id":"package-dowhy","type":"package","name":"DoWhy","description":"End-to-end framework for causal inference based on causal graphs (DAGs) and potential outcomes. Covers identification, estimation, refutation.","category":"Causal Inference & Matching","url":"https://github.com/py-why/dowhy","difficulty":"intermediate","prerequisites":"python-pandas, directed-acyclic-graphs, regression-analysis","topic_tags":"causal-inference, dag-modeling, treatment-effects, python-package, experimental-design","summary":"DoWhy is a comprehensive Python framework that implements the four-step causal inference process: modeling with DAGs, identification of causal effects, estimation using various methods, and robustness testing through refutation. It provides a unified interface for causal analysis that guides practitioners through proper methodology while supporting multiple estimation techniques from matching to instrumental variables.","use_cases":"Measuring impact of product feature changes on user engagement when randomized experiments aren't feasible, Evaluating effectiveness of marketing campaigns or policy interventions using observational data","audience":"Mid-DS, Senior-DS"},{"id":"package-keceni","type":"package","name":"KECENI","description":"Doubly robust, non-parametric estimation of node-wise counterfactual means under network interference (arXiv 2024).","category":"Causal Inference & Matching","url":"https://pypi.org/project/KECENI/","difficulty":"advanced","prerequisites":"causal-inference, network-analysis, doubly-robust-estimation","topic_tags":"network-interference, counterfactual-estimation, doubly-robust, spillover-effects, non-parametric","summary":"KECENI implements doubly robust estimation for measuring counterfactual outcomes when treatments have spillover effects through network connections. It provides non-parametric methods to estimate what would have happened to each node under different treatment assignments, accounting for both direct effects and indirect effects from connected nodes. This is particularly valuable for economists and data scientists analyzing interventions in networked systems where traditional causal inference methods fail due to interference.","use_cases":"Estimating impact of targeted ads on social media users and their friends, Measuring spillover effects of job training programs in communities with social connections","audience":"Senior-DS, Early-PhD"},{"id":"package-networkcausaltree","type":"package","name":"NetworkCausalTree","description":"Estimates both direct treatment effects and spillover effects under clustered network interference (Bargagli-Stoffi et al. 2025).","category":"Causal Inference & Matching","url":"https://github.com/fbargaglistoffi/NetworkCausalTree","difficulty":"advanced","prerequisites":"causal-forests, graph-theory, clustered-standard-errors","topic_tags":"network-effects, treatment-spillovers, causal-trees, interference-estimation","summary":"NetworkCausalTree extends causal forest methods to estimate both direct treatment effects and network spillover effects when units are connected in clusters or networks. It handles the complex interference patterns that arise when treating one unit affects connected units, which standard causal inference methods cannot capture. This is particularly valuable for economists and data scientists analyzing interventions in networked settings like social media, organizations, or geographic regions.","use_cases":"Measuring how a social media algorithm change affects both treated users and their connected friends, Estimating spillover effects of employee training programs within organizational teams or departments","audience":"Senior-DS, Early-PhD"},{"id":"package-pysensemakr","type":"package","name":"PySensemakr","description":"Implements Cinelli-Hazlett framework for assessing robustness to unobserved confounding. Computes confounder strength needed to invalidate results.","category":"Causal Inference & Matching","url":"https://github.com/carloscinelli/PySensemakr","difficulty":"intermediate","prerequisites":"causal-inference-basics, python-pandas, regression-analysis","topic_tags":"sensitivity-analysis, confounding, causal-inference, robustness-checks","summary":"PySensemakr implements the Cinelli-Hazlett sensitivity analysis framework to assess how robust causal estimates are to unobserved confounding. It calculates how strong an unmeasured confounder would need to be to overturn your causal conclusions. Essential for validating observational studies and strengthening causal arguments.","use_cases":"Testing robustness of A/B test results when you suspect unmeasured confounders like user engagement, Validating causal effects in observational studies by quantifying confounder strength needed to nullify findings","audience":"Mid-DS, Senior-DS"},{"id":"package-aipyw","type":"package","name":"aipyw","description":"Minimal, fast AIPW (Augmented Inverse Probability Weighting) implementation for discrete treatments. Sklearn-compatible with cross-fitting.","category":"Causal Inference & Matching","url":"https://github.com/apoorvalal/aipyw","difficulty":"intermediate","prerequisites":"python-sklearn, propensity-score-matching, cross-validation","topic_tags":"AIPW, treatment-effects, doubly-robust, causal-inference, python-package","summary":"AIPW is a doubly-robust method for estimating treatment effects that combines propensity score weighting with outcome modeling. This package provides a fast, sklearn-compatible implementation with cross-fitting to reduce overfitting bias. It's particularly useful for discrete treatment scenarios where you want robust causal estimates.","use_cases":"Estimating the effect of a marketing campaign on customer purchases using observational data, Measuring impact of a feature rollout on user engagement when randomization wasn't possible","audience":"Mid-DS, Senior-DS"},{"id":"package-causal-curve","type":"package","name":"causal-curve","description":"Continuous treatment dose-response curve estimation. GPS and TMLE methods for continuous treatments.","category":"Causal Inference & Matching","url":"https://github.com/ronikobrosly/causal-curve","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-scikit-learn, TMLE","topic_tags":"dose-response, continuous-treatment, GPS, TMLE, causal-inference","summary":"A Python package for estimating dose-response curves when treatments are continuous rather than binary. Implements Generalized Propensity Score (GPS) and Targeted Maximum Likelihood Estimation (TMLE) methods to estimate causal effects across different treatment intensities. Useful for understanding how varying levels of intervention affect outcomes.","use_cases":"Measuring how different advertising spend levels affect customer acquisition, Estimating optimal drug dosage effects on patient recovery rates","audience":"Mid-DS, Senior-DS"},{"id":"package-fastmatch","type":"package","name":"fastmatch","description":"Fast k-nearest-neighbor matching for large datasets using Facebook's FAISS library.","category":"Causal Inference & Matching","url":"https://github.com/py-econometrics/fastmatch","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-scikit-learn, nearest-neighbors-algorithms","topic_tags":"k-nearest-neighbors, propensity-matching, causal-inference, faiss-library, python-package","summary":"A Python package that accelerates k-nearest-neighbor matching for causal inference by leveraging Facebook's FAISS library for efficient similarity search. It's particularly useful for matching treatment and control units in observational studies when dealing with large datasets that would be computationally expensive with traditional matching methods. The package enables researchers to perform propensity score matching and other distance-based matching at scale.","use_cases":"Matching treated customers to control customers in a large e-commerce dataset for causal impact analysis, Finding similar firms as controls when evaluating the effect of a policy intervention on company outcomes","audience":"Mid-DS, Senior-DS"},{"id":"package-mcf-(modified-causal-forest)","type":"package","name":"mcf (Modified Causal Forest)","description":"Comprehensive Python implementation for heterogeneous treatment effect estimation. Handles binary/multiple discrete treatments with optimal policy learning via Policy Trees.","category":"Causal Inference & Matching","url":"https://github.com/MCFpy/mcf","difficulty":"intermediate","prerequisites":"python-scikit-learn, random-forests, causal-inference-fundamentals","topic_tags":"heterogeneous-treatment-effects, causal-forests, policy-optimization, python-implementation","summary":"MCF is a Python package that extends causal forests to estimate how treatment effects vary across different subgroups in your data. It's designed for data scientists running A/B tests or policy evaluations who need to understand not just average treatment effects, but which users or segments benefit most from interventions. The package includes policy tree functionality to automatically recommend optimal treatment assignment rules.","use_cases":"Personalizing product features by estimating which user segments respond best to different UI changes, Optimizing marketing campaigns by identifying customer characteristics that predict higher response to specific promotional strategies","audience":"Mid-DS, Senior-DS"},{"id":"package-pydtr","type":"package","name":"pydtr","description":"Dynamic treatment regimes using Iterative Q-Learning. Scikit-learn compatible for multi-stage optimal treatment sequencing.","category":"Causal Inference & Matching","url":"https://pypi.org/project/pydtr/","difficulty":"advanced","prerequisites":"scikit-learn, q-learning, causal-inference-methods","topic_tags":"dynamic-treatment, q-learning, multi-stage-treatment, personalized-medicine, python-package","summary":"PyDTR implements dynamic treatment regimes using Iterative Q-Learning to optimize sequential treatment decisions over multiple time periods. It's designed for researchers and data scientists working on personalized treatment strategies where optimal actions depend on patient history and evolving conditions. The package provides scikit-learn compatible tools for learning adaptive treatment policies from observational or experimental data.","use_cases":"Optimizing sequential drug dosing regimens based on patient response history and biomarkers, Designing adaptive mobile health interventions that adjust messaging frequency based on user engagement patterns","audience":"Senior-DS, Early-PhD"},{"id":"package-pyregadj","type":"package","name":"pyregadj","description":"Regression and ML adjustments to treatment effects in RCTs. Implements List et al. (2024) methods.","category":"Causal Inference & Matching","url":"https://github.com/vyasenov/pyregadj","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, python-scikit-learn, linear-regression","topic_tags":"regression-adjustment, RCT-analysis, treatment-effects, variance-reduction, python-package","summary":"A Python package implementing regression and machine learning adjustments for treatment effect estimation in randomized controlled trials, based on List et al. (2024) methods. It helps reduce variance in RCT analysis by incorporating baseline covariates and pre-treatment variables. Particularly useful for improving precision of treatment effect estimates when you have rich baseline data.","use_cases":"Analyzing A/B test results with user demographic and behavioral covariates to get more precise treatment effects, Estimating impact of educational interventions while controlling for student baseline characteristics and school fixed effects","audience":"Mid-DS, Junior-DS"},{"id":"package-scikit-uplift","type":"package","name":"scikit-uplift","description":"Focuses on uplift modeling and estimating heterogeneous treatment effects using various ML-based methods.","category":"Causal Inference & Matching","url":"https://github.com/maks-sh/scikit-uplift","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, python-scikit-learn, causal-inference-basics","topic_tags":"uplift-modeling, heterogeneous-treatment-effects, causal-ml, personalization, python-package","summary":"scikit-uplift is a Python package designed for uplift modeling, which predicts the incremental impact of treatments on individual units rather than just overall treatment effects. It provides machine learning-based methods to identify which customers or users will respond most positively to interventions like marketing campaigns or product changes. The package is particularly valuable for personalization and targeting decisions in business applications.","use_cases":"Identifying which customers to target with promotional offers to maximize incremental revenue, Determining which users should receive a new product feature to optimize engagement lift","audience":"Mid-DS, Senior-DS"},{"id":"package-y0","type":"package","name":"y0","description":"Causal inference framework providing tools for causal graph manipulation and effect identification.","category":"Causal Inference & Matching","url":"https://github.com/y0-causal-inference/y0","difficulty":"intermediate","prerequisites":"python-programming, directed-acyclic-graphs, causal-identification-theory","topic_tags":"causal-inference, graph-manipulation, identification-algorithms, python-package, causal-graphs","summary":"Y0 is a Python framework for causal inference that provides computational tools for manipulating causal graphs and identifying causal effects. It implements algorithms for causal identification, graph operations, and effect estimation from observational data. The package is designed for researchers and practitioners who need to work with causal DAGs and perform formal causal analysis.","use_cases":"Determining if a causal effect is identifiable from observational data given a causal graph, Manipulating and analyzing complex causal graphs with confounders and mediators","audience":"Mid-DS, Senior-DS"},{"id":"package-atbounds","type":"package","name":"ATbounds","description":"Implements modern treatment effect bounds beyond basic Manski worst-case scenarios. Provides tighter bounds using monotonicity, mean independence, and other assumptions following Lee and Weidner (2021).","category":"Causal Inference (Bounds)","url":"https://cran.r-project.org/package=ATbounds","difficulty":"advanced","prerequisites":"causal-inference, manski-bounds, potential-outcomes","topic_tags":"partial-identification, treatment-effects, bounds, causal-inference, monotonicity","summary":"ATbounds implements modern treatment effect bounds that improve upon basic Manski worst-case bounds by incorporating additional assumptions like monotonicity and mean independence. The package follows Lee and Weidner (2021) methodology to provide tighter identification bounds when randomized experiments aren't feasible. It's particularly useful for causal inference researchers working with observational data where point identification is impossible.","use_cases":"Evaluating job training programs where participation is endogenous and randomization isn't possible, Estimating returns to education when ability is unobserved and creates selection bias","audience":"Senior-DS, Early-PhD"},{"id":"package-causalgps","type":"package","name":"CausalGPS","description":"Machine learning-based generalized propensity score estimation for continuous treatments. Uses SuperLearner ensemble methods for flexible estimation of dose-response curves.","category":"Causal Inference (Continuous Treatment)","url":"https://cran.r-project.org/package=CausalGPS","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-scikit-learn, causal-inference-fundamentals","topic_tags":"generalized-propensity-score, continuous-treatment, dose-response, ensemble-methods, causal-inference","summary":"CausalGPS provides machine learning-based estimation of generalized propensity scores for continuous treatment variables, extending traditional binary propensity score methods. It leverages SuperLearner ensemble methods to flexibly model the relationship between covariates and continuous treatment doses. The package enables robust estimation of dose-response curves and causal effects when treatments vary in intensity rather than just presence/absence.","use_cases":"Estimating the causal effect of different advertising spend levels on customer acquisition, Analyzing how varying dosages of a medical intervention affect patient outcomes","audience":"Mid-DS, Senior-DS"},{"id":"package-drdid","type":"package","name":"DRDID","description":"Implements locally efficient doubly robust DiD estimators that combine inverse probability weighting and outcome regression for improved statistical properties. Handles both panel data and repeated cross-sections in the canonical 2x2 DiD setting with covariates, providing robustness against model misspecification.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=DRDID","difficulty":"intermediate","prerequisites":"difference-in-differences, propensity-score-matching, panel-data-analysis","topic_tags":"doubly-robust, difference-in-differences, causal-inference, treatment-effects, R-package","summary":"DRDID is an R package that implements doubly robust difference-in-differences estimators, combining inverse probability weighting with outcome regression for more reliable causal effect estimates. It's designed for researchers who need robust DiD analysis with covariates in 2x2 treatment/control settings. The package provides protection against model misspecification by requiring only one of the two models (propensity score or outcome regression) to be correctly specified.","use_cases":"Evaluating the causal impact of a policy intervention when treatment assignment depends on observable characteristics, Analyzing the effect of a product launch or business intervention when you have pre/post data and want to control for confounding variables","audience":"Mid-DS, Senior-DS"},{"id":"package-honestdid","type":"package","name":"HonestDiD","description":"Constructs robust confidence intervals for DiD and event-study designs under violations of parallel trends. Allows researchers to conduct sensitivity analysis by relaxing the parallel trends assumption using smoothness or relative magnitude restrictions on pre-trend violations.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=HonestDiD","difficulty":"intermediate","prerequisites":"difference-in-differences, event-study-methodology, causal-inference-fundamentals","topic_tags":"sensitivity-analysis, parallel-trends, robust-inference, difference-in-differences, event-study","summary":"HonestDiD is an R package that helps researchers test the robustness of difference-in-differences and event study results when the parallel trends assumption may be violated. It constructs confidence intervals that remain valid under specified violations of parallel trends, allowing for more credible causal inference. The package is particularly valuable for researchers who want to move beyond just testing parallel trends to actually accounting for potential violations in their inference.","use_cases":"Evaluating policy impact on employment outcomes when treated and control groups show different pre-treatment trends, Analyzing the effect of a product launch on user engagement when baseline metrics aren't perfectly parallel across test regions","audience":"Mid-DS, Senior-DS"},{"id":"package-bacondecomp","type":"package","name":"bacondecomp","description":"Performs Goodman-Bacon decomposition showing how two-way fixed effects (TWFE) estimates are weighted averages of all possible 2\u00d72 DiD comparisons. Essential for diagnosing negative weights problems in staggered adoption designs.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=bacondecomp","difficulty":"intermediate","prerequisites":"difference-in-differences, fixed-effects-regression, panel-data-analysis","topic_tags":"goodman-bacon, twfe-decomposition, staggered-adoption, negative-weights, causal-inference","summary":"The bacondecomp package implements the Goodman-Bacon decomposition, which breaks down two-way fixed effects estimates into weighted averages of all possible 2x2 difference-in-differences comparisons. This diagnostic tool is essential for understanding when TWFE estimates may be biased due to negative weights in staggered treatment adoption settings. Researchers use it to evaluate whether their DiD design is compromised by treatment effect heterogeneity.","use_cases":"Diagnosing bias in a staggered rollout study where different states adopted a policy at different times, Evaluating the validity of TWFE estimates in a corporate setting where business units received treatment interventions sequentially","audience":"Mid-DS, Senior-DS"},{"id":"package-did","type":"package","name":"did","description":"Implements group-time average treatment effects (ATT(g,t)) for staggered DiD designs with multiple periods and variation in treatment timing. Provides flexible aggregation into event-study plots or overall treatment effect estimates, addressing the well-documented negative weighting issues with conventional TWFE under staggered adoption.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=did","difficulty":"intermediate","prerequisites":"difference-in-differences, panel-data-analysis, R-programming","topic_tags":"difference-in-differences, staggered-adoption, event-study, causal-inference, panel-data","summary":"The 'did' package implements modern difference-in-differences methods for staggered treatment adoption, solving the negative weighting problems in traditional two-way fixed effects models. It calculates group-time average treatment effects and aggregates them into event-study plots or overall estimates. Ideal for economists and data scientists analyzing policy interventions or product rollouts with varying treatment timing across units.","use_cases":"Evaluating the impact of minimum wage increases rolled out across different states at different times, Measuring the effect of a new product feature launched to different user cohorts in a staggered fashion","audience":"Mid-DS, Early-PhD"},{"id":"package-didimputation","type":"package","name":"didimputation","description":"Implements the imputation-based DiD estimator that first estimates Y(0) counterfactuals from untreated observations using two-way fixed effects, then imputes treatment effects for treated units. Avoids negative weighting problems of conventional TWFE under heterogeneous treatment effects.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=didimputation","difficulty":"intermediate","prerequisites":"difference-in-differences, two-way-fixed-effects, panel-data-analysis","topic_tags":"did-imputation, treatment-effects, causal-inference, heterogeneous-effects, econometrics","summary":"An R package implementing imputation-based difference-in-differences estimation that avoids the negative weighting issues of traditional two-way fixed effects models. It first estimates counterfactual outcomes for untreated units, then imputes treatment effects, making it robust to heterogeneous treatment effects across time and units.","use_cases":"Evaluating staggered policy rollouts where treatment timing varies across states or regions, Measuring impact of corporate interventions implemented at different times across business units","audience":"Mid-DS, Senior-DS"},{"id":"package-fastdid","type":"package","name":"fastdid","description":"High-performance implementation of Callaway & Sant'Anna estimators optimized for large datasets with millions of observations. Reduces computation time from hours to seconds while supporting time-varying covariates and multiple events per unit.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=fastdid","difficulty":"intermediate","prerequisites":"difference-in-differences, python-pandas, callaway-santanna-estimator","topic_tags":"staggered-did, high-performance-computing, causal-inference, large-datasets, econometrics-package","summary":"A high-performance Python package implementing Callaway & Sant'Anna difference-in-differences estimators, specifically optimized for massive datasets with millions of observations. It dramatically reduces computation time from hours to seconds while handling complex scenarios like time-varying covariates and multiple treatment events per unit.","use_cases":"Analyzing the staggered rollout of a product feature across millions of users with varying characteristics, Evaluating policy impacts across thousands of geographic units over multiple time periods with large administrative datasets","audience":"Mid-DS, Senior-DS"},{"id":"package-fect","type":"package","name":"fect","description":"Fixed Effects Counterfactual Estimators (v2.0+) incorporating gsynth functionality. Supports treatment switching on/off with carryover effects, matrix completion methods, and Rambachan & Roth sensitivity analysis for parallel trends violations.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=fect","difficulty":"advanced","prerequisites":"difference-in-differences, panel-data-methods, matrix-completion","topic_tags":"counterfactual-estimation, interactive-fixed-effects, treatment-effects, sensitivity-analysis, panel-data","summary":"Advanced R package for causal inference with panel data that extends traditional difference-in-differences to handle complex treatment patterns and violations of parallel trends. Combines matrix completion methods with interactive fixed effects models to estimate counterfactual outcomes when units can switch treatment status multiple times. Includes modern sensitivity analysis tools to assess robustness to parallel trends assumptions.","use_cases":"Evaluating policy interventions where regions can adopt and abandon policies over time with lasting effects, Measuring impact of product feature rollouts across markets with staggered implementation and potential reversal","audience":"Senior-DS, Early-PhD"},{"id":"package-staggered","type":"package","name":"staggered","description":"Provides the efficient estimator for randomized staggered rollout designs, offering optimal weighting schemes for treatment effect estimation. Also implements Callaway & Sant'Anna and Sun & Abraham estimators with design-based Fisher inference for randomized experiments.","category":"Causal Inference (DiD)","url":"https://cran.r-project.org/package=staggered","difficulty":"intermediate","prerequisites":"difference-in-differences, randomized-controlled-trials, panel-data-analysis","topic_tags":"staggered-rollout, difference-in-differences, treatment-effects, randomized-experiments, causal-inference","summary":"The staggered package implements efficient estimators for randomized staggered rollout experiments, where treatment is rolled out to different units at different times. It provides optimal weighting schemes and includes popular estimators like Callaway & Sant'Anna and Sun & Abraham with design-based inference. This is particularly useful for tech companies running gradual feature rollouts or policy experiments.","use_cases":"Analyzing gradual feature rollouts where different user cohorts receive treatment at staggered time periods, Evaluating policy interventions implemented across different regions or departments at different dates","audience":"Mid-DS, Senior-DS"},{"id":"package-dtrreg","type":"package","name":"DTRreg","description":"Dynamic treatment regime estimation via G-estimation for sequential treatment decisions. Implements methods for finding optimal treatment rules that adapt over time based on patient characteristics.","category":"Causal Inference (Dynamic Treatment)","url":"https://cran.r-project.org/package=DTRreg","difficulty":"advanced","prerequisites":"causal-inference, regression-modeling, longitudinal-data","topic_tags":"dynamic-treatment, g-estimation, sequential-decisions, personalized-medicine, causal-inference","summary":"DTRreg implements G-estimation methods for finding optimal dynamic treatment regimes that adapt treatment decisions over time based on evolving patient characteristics. This package is essential for researchers developing personalized treatment strategies in clinical settings where treatment decisions must be made sequentially. It enables estimation of treatment rules that maximize long-term outcomes by accounting for time-varying confounders and treatment history.","use_cases":"Optimizing multi-stage cancer treatment protocols where drug choice depends on tumor response and patient health status, Designing adaptive educational interventions where teaching methods adjust based on student progress and engagement metrics","audience":"Senior-DS, Early-PhD"},{"id":"package-dyntxregime","type":"package","name":"DynTxRegime","description":"Comprehensive package for dynamic treatment regimes implementing Q-learning, value search, and outcome-weighted learning methods. Accompanies the textbook 'Dynamic Treatment Regimes' (Tsiatis et al., 2020).","category":"Causal Inference (Dynamic Treatment)","url":"https://cran.r-project.org/package=DynTxRegime","difficulty":"advanced","prerequisites":"reinforcement-learning-basics, causal-inference-fundamentals, R-programming","topic_tags":"dynamic-treatment, Q-learning, personalized-medicine, sequential-decision-making, causal-inference","summary":"DynTxRegime is an R package implementing advanced methods for dynamic treatment regimes, including Q-learning and outcome-weighted learning approaches. It's designed for researchers developing personalized treatment strategies where decisions adapt based on patient responses over time. The package accompanies a comprehensive textbook and provides tools for sequential decision-making in medical and behavioral interventions.","use_cases":"Optimizing multi-stage cancer treatment protocols where drug selection depends on tumor response, Designing adaptive educational interventions that adjust based on student performance","audience":"Senior-DS, Early-PhD"},{"id":"package-eventstudyr","type":"package","name":"eventstudyr","description":"Implements event study best practices from Freyaldenhoven et al. (2021) including sup-t confidence bands for uniform inference and formal pre-trend testing. Provides robust methods for dynamic treatment effect estimation.","category":"Causal Inference (Event Study)","url":"https://cran.r-project.org/package=eventstudyr","difficulty":"intermediate","prerequisites":"difference-in-differences, panel-data-methods, statistical-inference","topic_tags":"event-study, causal-inference, dynamic-treatment-effects, pre-trends, uniform-inference","summary":"R package implementing state-of-the-art event study methods with formal pre-trend testing and sup-t confidence bands for uniform inference. Based on Freyaldenhoven et al. (2021) best practices for robust dynamic treatment effect estimation. Essential for researchers conducting rigorous event studies with proper statistical inference.","use_cases":"Evaluating policy impact over time with staggered treatment adoption, Testing for pre-trends and estimating dynamic effects in corporate finance event studies","audience":"Mid-DS, Senior-DS"},{"id":"package-fixes","type":"package","name":"fixes","description":"Streamlined event study workflows with simple run_es() and plot_es() functions built on fixest. New 2025 package providing convenient wrappers for common event study specifications.","category":"Causal Inference (Event Study)","url":"https://cran.r-project.org/package=fixes","difficulty":"beginner","prerequisites":"fixest-package, difference-in-differences, R-programming","topic_tags":"event-study, causal-inference, R-package, difference-in-differences, visualization","summary":"The fixes package provides streamlined R functions for event study analysis, offering simple run_es() and plot_es() wrappers around the fixest package. Released in 2025, it eliminates the complexity of setting up common event study specifications, making causal inference workflows more accessible to practitioners.","use_cases":"Evaluating the impact of a policy change on user engagement metrics across different treatment cohorts, Analyzing the effect of a product launch on sales performance with automated visualization of pre/post-treatment trends","audience":"Junior-DS, Mid-DS"},{"id":"package-inferference","type":"package","name":"inferference","description":"Computes inverse probability weighted (IPW) causal effects under partial interference following Tchetgen Tchetgen and VanderWeele (2012). Handles spillover effects within groups while maintaining independence across groups.","category":"Causal Inference (Interference)","url":"https://cran.r-project.org/package=inferference","difficulty":"advanced","prerequisites":"causal-inference, inverse-probability-weighting, randomized-experiments","topic_tags":"interference, spillover-effects, ipw-estimation, causal-inference, sutva-violations","summary":"The inferference package implements inverse probability weighted estimation for causal effects when units interfere with each other, violating the standard SUTVA assumption. It handles partial interference settings where spillovers occur within predefined groups but independence is maintained across groups. This is essential for experiments where treatment of one unit affects outcomes of nearby units.","use_cases":"Analyzing social media experiments where friends influence each other's behavior, Evaluating educational interventions where student outcomes depend on classroom peers' treatment status","audience":"Senior-DS, Early-PhD"},{"id":"package-latenetwork","type":"package","name":"latenetwork","description":"Handles both noncompliance AND network interference of unknown form following Hoshino and Yanagi (2023 JASA). Provides valid inference when treatment effects spill over through network connections.","category":"Causal Inference (Interference)","url":"https://cran.r-project.org/package=latenetwork","difficulty":"advanced","prerequisites":"instrumental-variables, causal-inference, network-analysis","topic_tags":"network-interference, instrumental-variables, LATE, spillover-effects, causal-inference","summary":"Implements methods from Hoshino and Yanagi (2023) to estimate local average treatment effects when both treatment noncompliance and network spillovers are present. Provides valid statistical inference for randomized experiments where treatment effects propagate through social or economic networks of unknown structure.","use_cases":"A/B testing social media features where user interactions create spillovers between treatment and control groups, Evaluating educational interventions in schools where peer effects contaminate the control group","audience":"Senior-DS, Early-PhD"},{"id":"package-evalue","type":"package","name":"EValue","description":"Conducts sensitivity analyses for unmeasured confounding, selection bias, and measurement error in observational studies and meta-analyses. Computes E-values representing the minimum strength of association unmeasured confounders would need to fully explain away an observed effect.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=EValue","difficulty":"intermediate","prerequisites":"observational-studies, regression-analysis, confounding-variables","topic_tags":"e-value, sensitivity-analysis, causal-inference, observational-studies, unmeasured-confounding","summary":"EValue is a package for conducting sensitivity analyses to assess how robust causal conclusions are to potential unmeasured confounding, selection bias, and measurement error. It computes E-values that quantify the minimum strength of association that unmeasured confounders would need to have to completely explain away an observed treatment effect. This tool is essential for researchers working with observational data who need to evaluate the credibility of their causal claims.","use_cases":"Evaluating whether unmeasured confounders could explain away the observed effect of a medical treatment in an observational study, Assessing robustness of findings in a tech company's analysis of user behavior interventions where randomization wasn't possible","audience":"Mid-DS, Senior-DS"},{"id":"package-superlearner","type":"package","name":"SuperLearner","description":"Implements the Super Learner algorithm for optimal ensemble prediction via cross-validation. Creates weighted combinations of multiple ML algorithms (XGBoost, Random Forest, glmnet, neural networks, SVM, BART) with guaranteed asymptotic optimality.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=SuperLearner","difficulty":"intermediate","prerequisites":"python-scikit-learn, cross-validation, ensemble-methods","topic_tags":"ensemble-learning, super-learner, model-stacking, prediction, causal-inference","summary":"SuperLearner is an ensemble method that optimally combines multiple machine learning algorithms using cross-validation to create weighted predictions with theoretical guarantees. It's widely used in causal inference and prediction tasks where you want to leverage the strengths of different algorithms without manual tuning. The method automatically finds the best combination of base learners like XGBoost, Random Forest, and neural networks.","use_cases":"Estimating treatment effects in randomized trials where you need robust prediction of outcomes, Building high-performance prediction models by combining multiple algorithms without overfitting","audience":"Mid-DS, Senior-DS"},{"id":"package-causaltoolbox","type":"package","name":"causalToolbox","description":"Implements meta-learner algorithms (S-learner, T-learner, X-learner) for heterogeneous treatment effect estimation using flexible base learners including honest Random Forests and BART for personalized CATE estimation.","category":"Causal Inference (ML)","url":"https://github.com/forestry-labs/causalToolbox","difficulty":"intermediate","prerequisites":"random-forests, causal-inference-basics, python-scikit-learn","topic_tags":"heterogeneous-treatment-effects, meta-learners, personalized-medicine, A-B-testing, CATE-estimation","summary":"causalToolbox provides implementations of popular meta-learner algorithms (S-learner, T-learner, X-learner) for estimating heterogeneous treatment effects across different subgroups. It combines flexible machine learning models like Random Forests and BART with causal inference methods to estimate personalized treatment effects (CATE). This package is particularly useful for practitioners who want to move beyond average treatment effects to understand how treatments work differently for different individuals or segments.","use_cases":"Personalizing marketing campaigns by estimating which customer segments respond best to different promotional strategies, Clinical trial analysis to identify patient subgroups who benefit most from a new treatment based on their characteristics","audience":"Mid-DS, Junior-DS"},{"id":"package-causalweight","type":"package","name":"causalweight","description":"Semiparametric causal inference methods based on inverse probability weighting and double machine learning for average treatment effects, causal mediation analysis (direct/indirect effects), and dynamic treatment evaluation. Supports LATE estimation with instrumental variables.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=causalweight","difficulty":"advanced","prerequisites":"propensity-score-matching, instrumental-variables, cross-validation","topic_tags":"causal-inference, treatment-effects, mediation-analysis, double-ml, ipw","summary":"A Python package implementing advanced semiparametric causal inference methods that combine inverse probability weighting with double machine learning techniques. It enables researchers to estimate average treatment effects, decompose causal pathways through mediation analysis, and evaluate dynamic treatment regimes while handling high-dimensional confounders. The package is particularly valuable for economists and data scientists working on complex causal questions where traditional methods may fall short.","use_cases":"Measuring the direct vs indirect effects of a job training program on earnings through skill acquisition, Evaluating the causal impact of personalized marketing campaigns while controlling for selection bias using customer behavioral data","audience":"Senior-DS, Early-PhD"},{"id":"package-ddml","type":"package","name":"ddml","description":"Streamlined double/debiased machine learning estimation with emphasis on (short-)stacking to combine multiple base learners, increasing robustness to unknown data generating processes. Designed as a complement to DoubleML with simpler syntax.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=ddml","difficulty":"intermediate","prerequisites":"python-scikit-learn, causal-inference-basics, cross-validation","topic_tags":"double-machine-learning, causal-inference, model-stacking, treatment-effects, python-package","summary":"ddml is a Python package for double/debiased machine learning that combines multiple base learners through stacking to estimate causal effects robustly. It offers simpler syntax than DoubleML while maintaining statistical rigor for treatment effect estimation. The package is particularly useful when the underlying data generating process is unknown and you want to hedge against model misspecification.","use_cases":"Estimating impact of price changes on demand when functional form is uncertain, Measuring effect of marketing campaigns using ensemble of ML models for robustness","audience":"Mid-DS, Senior-DS"},{"id":"package-grf","type":"package","name":"grf","description":"Forest-based statistical estimation and inference for heterogeneous treatment effects, supporting multiple treatment arms, instrumental variables, survival outcomes, and quantile regression\u2014all with honest estimation and valid confidence intervals. The most widely-used R package for CATE estimation.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=grf","difficulty":"intermediate","prerequisites":"random-forests, treatment-effects, R-programming","topic_tags":"causal-forests, heterogeneous-treatment-effects, CATE-estimation, R-package, honest-inference","summary":"The grf package is the leading R implementation for causal forest estimation, enabling researchers to identify how treatment effects vary across individuals using machine learning. It provides robust statistical inference with confidence intervals for heterogeneous treatment effects, supporting complex scenarios like multiple treatments and instrumental variables. Widely adopted by data scientists and economists for personalized treatment recommendations and policy analysis.","use_cases":"A/B testing platform wants to identify which user segments respond differently to a new feature recommendation, Healthcare researchers analyzing how patient characteristics affect drug treatment effectiveness across subpopulations","audience":"Mid-DS, Senior-DS"},{"id":"package-hdm","type":"package","name":"hdm","description":"High-dimensional statistical methods featuring heteroscedasticity-robust LASSO with theoretically-grounded penalty selection, post-double-selection inference, and treatment effect estimation under sparsity assumptions for high-dimensional controls.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=hdm","difficulty":"advanced","prerequisites":"lasso-regression, instrumental-variables, asymptotic-theory","topic_tags":"high-dimensional-inference, treatment-effects, post-selection, robust-standard-errors, sparsity","summary":"The hdm package implements theoretically rigorous methods for causal inference in high-dimensional settings where the number of potential confounders exceeds sample size. It combines LASSO variable selection with post-double-selection techniques to estimate treatment effects while maintaining valid statistical inference under sparsity assumptions.","use_cases":"Estimating advertising effectiveness when controlling for thousands of user features and behavioral variables, Evaluating policy interventions using administrative data with rich covariate information from multiple linked datasets","audience":"Senior-DS, Early-PhD"},{"id":"package-ltmle","type":"package","name":"ltmle","description":"Targeted maximum likelihood estimation for treatment/censoring-specific mean outcomes with time-varying treatments and confounders. Supports longitudinal settings, marginal structural models, and dynamic treatment regimes alongside IPTW and G-computation.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=ltmle","difficulty":"advanced","prerequisites":"causal-inference, longitudinal-data-analysis, tmle","topic_tags":"tmle, longitudinal-causal-inference, time-varying-treatment, dynamic-treatment-regimes, marginal-structural-models","summary":"ltmle implements Longitudinal Targeted Maximum Likelihood Estimation for causal inference with time-varying treatments and confounders. It enables estimation of treatment effects in complex longitudinal settings where treatments, confounders, and outcomes evolve over time. The package supports dynamic treatment regimes, marginal structural models, and provides alternatives to standard IPTW and G-computation approaches.","use_cases":"Estimating the causal effect of varying medication dosages over time on patient outcomes while accounting for time-varying health status, Analyzing the impact of dynamic marketing interventions on customer behavior when treatment assignment depends on previous responses and changing customer characteristics","audience":"Senior-DS, Early-PhD"},{"id":"package-sensemakr","type":"package","name":"sensemakr","description":"Suite of sensitivity analysis tools extending the traditional omitted variable bias framework, computing robustness values, bias-adjusted estimates, and sensitivity contour plots for OLS regression to assess how strong unmeasured confounders would need to be to overturn conclusions.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=sensemakr","difficulty":"intermediate","prerequisites":"linear-regression, causal-inference-fundamentals, R-programming","topic_tags":"sensitivity-analysis, omitted-variable-bias, causal-inference, regression-diagnostics, robustness-testing","summary":"sensemakr is an R package for sensitivity analysis that helps researchers assess how robust their causal conclusions are to potential unmeasured confounders. It extends traditional omitted variable bias analysis by computing robustness values and creating sensitivity contour plots to quantify how strong hidden confounders would need to be to change your results. Particularly useful for observational studies where you can't randomize treatment assignment.","use_cases":"Testing whether your finding that education increases wages is robust to unmeasured ability or family background, Assessing if your conclusion about a marketing campaign's effectiveness could be overturned by unmeasured customer characteristics","audience":"Mid-DS, Early-PhD"},{"id":"package-tmle","type":"package","name":"tmle","description":"Implements targeted maximum likelihood estimation for point treatment effects with binary or continuous outcomes. Estimates ATE, ATT, ATC, and supports marginal structural models. Integrates SuperLearner for data-adaptive nuisance parameter estimation.","category":"Causal Inference (ML)","url":"https://cran.r-project.org/package=tmle","difficulty":"advanced","prerequisites":"propensity-score-matching, super-learner, double-machine-learning","topic_tags":"tmle, treatment-effects, doubly-robust, causal-ml, ate-estimation","summary":"TMLE is a doubly robust method for estimating causal treatment effects that combines outcome modeling and propensity score estimation. It integrates machine learning methods like SuperLearner for flexible nuisance parameter estimation while maintaining statistical guarantees. Popular for estimating average treatment effects in observational studies with complex confounding.","use_cases":"Estimating effect of mobile app feature on user retention using observational data, Measuring impact of pricing changes on customer churn with high-dimensional covariates","audience":"Senior-DS, Early-PhD"},{"id":"package-tmle3","type":"package","name":"tmle3","description":"A modular, extensible framework for targeted minimum loss-based estimation supporting custom TMLE parameters through a unified interface. Part of the tlverse ecosystem, designed to be as general as the mathematical TMLE framework itself for complex analyses.","category":"Causal Inference (ML)","url":"https://github.com/tlverse/tmle3","difficulty":"advanced","prerequisites":"causal-inference-theory, R-programming, targeted-maximum-likelihood","topic_tags":"TMLE, causal-inference, tlverse, targeted-estimation, R-package","summary":"tmle3 is an advanced R package providing a modular framework for targeted minimum loss-based estimation (TMLE) with support for custom parameters and complex causal analyses. It's part of the tlverse ecosystem and designed for researchers who need flexible, extensible TMLE implementations. The package allows for sophisticated causal inference analyses including stochastic interventions and custom estimands.","use_cases":"Estimating causal effects of continuous treatments with custom intervention distributions, Building custom TMLE estimators for novel causal parameters not available in standard packages","audience":"Senior-DS, Early-PhD"},{"id":"package-cbps","type":"package","name":"CBPS","description":"Implements Covariate Balancing Propensity Score, which estimates propensity scores by jointly optimizing treatment prediction and covariate balance via generalized method of moments (GMM). Supports binary, multi-valued, and continuous treatments, as well as longitudinal settings for marginal structural models.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=CBPS","difficulty":"intermediate","prerequisites":"propensity-score-matching, generalized-method-of-moments, python-sklearn","topic_tags":"propensity-scoring, covariate-balancing, treatment-effects, causal-inference, weighting-methods","summary":"CBPS is a Python package that implements Covariate Balancing Propensity Score methodology for causal inference. It improves upon traditional propensity score methods by simultaneously optimizing for treatment prediction accuracy and covariate balance between treatment groups. The package handles various treatment types (binary, multi-valued, continuous) and supports longitudinal analysis through marginal structural models.","use_cases":"Evaluating impact of marketing campaigns where you need better balance between treatment and control groups than standard propensity scoring, Analyzing effectiveness of policy interventions with multiple treatment levels while ensuring comparable groups across covariates","audience":"Mid-DS, Senior-DS"},{"id":"package-matchit","type":"package","name":"MatchIt","description":"Comprehensive matching package that selects matched samples of treated and control groups with similar covariate distributions. Provides a unified interface to multiple matching methods including nearest neighbor, optimal pair, optimal full, genetic, exact, coarsened exact (CEM), cardinality matching, and subclassification with propensity score estimation via GLM, GAM, random forest, and BART.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=MatchIt","difficulty":"intermediate","prerequisites":"logistic-regression, python-pandas, experimental-design","topic_tags":"propensity-score-matching, causal-inference, treatment-effects, observational-studies, covariate-balance","summary":"MatchIt is a comprehensive R package that implements multiple matching methods to create balanced treatment and control groups from observational data. It provides a unified interface for techniques like nearest neighbor matching, optimal matching, and coarsened exact matching, with built-in propensity score estimation. Data scientists and researchers use it to reduce selection bias when estimating causal effects from non-experimental data.","use_cases":"Estimating the effect of a marketing campaign on customer retention using historical data with matched treatment and control groups, Evaluating the impact of a policy change by matching similar units before and after implementation to control for confounding variables","audience":"Mid-DS, Early-PhD"},{"id":"package-weightit","type":"package","name":"WeightIt","description":"Unified interface for generating balancing weights for causal effect estimation in observational studies. Supports binary, multi-category, and continuous treatments for point and longitudinal/marginal structural models. Methods include inverse probability weighting (IPW), entropy balancing, covariate balancing propensity score (CBPS), energy balancing, stable balancing weights, BART, and SuperLearner.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=WeightIt","difficulty":"intermediate","prerequisites":"propensity-score-matching, regression-analysis, observational-studies","topic_tags":"causal-inference, propensity-scores, treatment-effects, observational-data, r-package","summary":"WeightIt is an R package that provides a unified interface for generating balancing weights to estimate causal effects from observational data. It supports multiple weighting methods including inverse probability weighting, entropy balancing, and covariate balancing propensity scores for various treatment types. The package is particularly useful for researchers who need to compare different weighting approaches or handle complex treatment scenarios like continuous treatments or longitudinal data.","use_cases":"Evaluating the causal effect of a marketing campaign on customer retention using observational data with multiple confounders, Estimating the impact of employee training programs on productivity when randomized experiments are not feasible","audience":"Mid-DS, Senior-DS"},{"id":"package-cobalt","type":"package","name":"cobalt","description":"Generates standardized balance tables and plots for covariates after preprocessing via matching, weighting, or subclassification. Provides unified balance assessment across multiple R packages (MatchIt, WeightIt, twang, Matching, optmatch, CBPS, ebal, cem, sbw, designmatch). Supports multi-category, continuous, and longitudinal treatments with clustered and multiply imputed data.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=cobalt","difficulty":"intermediate","prerequisites":"causal-inference-fundamentals, propensity-score-matching, r-programming","topic_tags":"balance-assessment, matching-diagnostics, causal-inference, love-plots, r-package","summary":"cobalt is an R package that creates standardized balance tables and visualizations to assess covariate balance after causal inference preprocessing steps like matching, weighting, or subclassification. It works with multiple popular R causal inference packages and provides unified diagnostics across different methods. The package is essential for validating that treatment and control groups are comparable before estimating causal effects.","use_cases":"Evaluating whether propensity score matching successfully balanced covariates between treated and control groups in an A/B test analysis, Creating standardized balance diagnostics across multiple weighting methods to choose the best approach for estimating treatment effects","audience":"Mid-DS, Early-PhD"},{"id":"package-ebal","type":"package","name":"ebal","description":"Implements entropy balancing, a reweighting method that finds weights for control units such that specified covariate moment conditions (means, variances) are exactly satisfied while staying as close as possible to uniform weights by minimizing Kullback-Leibler divergence. Primarily designed for ATT estimation.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=ebal","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-pandas, observational-studies","topic_tags":"entropy-balancing, causal-inference, reweighting, covariate-matching, ATT-estimation","summary":"Entropy balancing is a preprocessing method for causal inference that creates weights for control units to exactly match treatment group moments on observed covariates. It improves upon propensity score matching by directly optimizing covariate balance while maintaining interpretable weights. Data scientists and researchers use it to estimate treatment effects from observational data when randomized experiments aren't feasible.","use_cases":"Estimating the impact of a marketing campaign on customer behavior using historical transaction data, Evaluating the effect of a policy intervention by reweighting control regions to match treated regions on demographic characteristics","audience":"Mid-DS, Early-PhD"},{"id":"package-optmatch","type":"package","name":"optmatch","description":"Distance-based bipartite matching using minimum cost network flow algorithms, oriented to matching treatment and control groups in observational studies. Provides optimal full matching and pair matching with support for propensity score distances, Mahalanobis distance, calipers, and exact matching constraints.","category":"Causal Inference (Matching)","url":"https://cran.r-project.org/package=optmatch","difficulty":"intermediate","prerequisites":"propensity-score-matching, causal-inference-basics, r-programming","topic_tags":"optimal-matching, propensity-score, causal-inference, observational-studies, treatment-effects","summary":"R package implementing optimal matching algorithms for creating balanced treatment and control groups in observational studies. Uses minimum cost network flow to find the best possible matches based on propensity scores or other distance metrics. Essential tool for causal inference when randomized experiments aren't feasible.","use_cases":"Matching treated and control patients in medical studies to estimate treatment effects, Creating balanced groups in A/B test analysis when randomization was imperfect or impossible","audience":"Mid-DS, Early-PhD"},{"id":"package-cmaverse","type":"package","name":"CMAverse","description":"Unified interface for six causal mediation approaches including traditional regression, inverse odds weighting, and g-formula. Supports multiple sequential mediators and exposure-mediator interactions.","category":"Causal Inference (Mediation)","url":"https://cran.r-project.org/package=CMAverse","difficulty":"intermediate","prerequisites":"linear-regression, causal-inference-fundamentals, r-programming","topic_tags":"mediation-analysis, causal-mechanisms, g-formula, exposure-mediator-interactions, sequential-mediators","summary":"CMAverse provides a unified R interface for implementing six different causal mediation analysis methods, including traditional regression-based approaches, inverse odds weighting, and g-formula estimation. It's designed for researchers who need to estimate how much of a causal effect operates through intermediate variables (mediators), with support for complex scenarios involving multiple sequential mediators and interactions between exposures and mediators.","use_cases":"Analyzing how much of a digital marketing campaign's effect on sales operates through increased brand awareness versus direct purchase intent, Decomposing the causal effect of a new feature rollout on user retention into pathways through engagement metrics, satisfaction scores, and usage frequency","audience":"Mid-DS, Senior-DS"},{"id":"package-mediation","type":"package","name":"mediation","description":"Estimates Average Causal Mediation Effects (ACME) with sensitivity analysis for unmeasured confounding. Implements Tingley et al. (2014 JSS) methods for understanding causal mechanisms.","category":"Causal Inference (Mediation)","url":"https://cran.r-project.org/package=mediation","difficulty":"intermediate","prerequisites":"causal-inference-basics, regression-analysis, r-programming","topic_tags":"mediation-analysis, causal-mechanisms, sensitivity-analysis, indirect-effects, r-package","summary":"The mediation package provides tools for estimating how much of a treatment effect operates through intermediate variables (mediators). It implements robust methods for calculating Average Causal Mediation Effects (ACME) and includes sensitivity analysis to assess how unmeasured confounding might affect results. Essential for researchers who need to understand not just whether treatments work, but how they work.","use_cases":"Analyzing whether a job training program improves wages directly or through increased skills, Understanding if a marketing campaign affects sales through brand awareness or purchase intent","audience":"Mid-DS, Early-PhD"},{"id":"package-pstrata","type":"package","name":"PStrata","description":"Principal stratification analysis for noncompliance and truncation-by-death using both Bayesian (Stan) and frequentist estimation. Implements Liu and Li (2023) methods for causal inference with post-treatment complications.","category":"Causal Inference (Principal Stratification)","url":"https://cran.r-project.org/package=PStrata","difficulty":"advanced","prerequisites":"causal-inference-fundamentals, Bayesian-statistics, Stan-modeling","topic_tags":"principal-stratification, causal-inference, noncompliance, truncation-by-death, Bayesian-methods","summary":"PStrata implements advanced principal stratification methods for handling two key challenges in causal inference: participant noncompliance and truncation-by-death. The package provides both Bayesian (Stan) and frequentist approaches based on Liu and Li (2023) methods, allowing researchers to estimate causal effects when post-treatment complications arise.","use_cases":"Clinical trial analysis where patients don't adhere to assigned treatments and some experience mortality, Educational intervention studies with student dropout and varying compliance rates","audience":"Senior-DS, Early-PhD"},{"id":"package-rddapp","type":"package","name":"rddapp","description":"Supports multi-assignment RDD with two running variables, power analysis for RDD designs, and includes a Shiny interface for interactive analysis. Handles both sharp and fuzzy designs with bandwidth selection.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rddapp","difficulty":"intermediate","prerequisites":"regression-discontinuity-design, R-programming, ggplot2","topic_tags":"regression-discontinuity, multi-assignment-RDD, power-analysis, causal-inference, R-package","summary":"An R package that extends standard regression discontinuity designs to handle complex scenarios with multiple assignment variables and fuzzy cutoffs. It provides power analysis tools to help researchers determine sample size requirements and includes an interactive Shiny interface for exploratory analysis. Particularly useful for policy evaluation where treatment assignment depends on multiple criteria or has probabilistic elements.","use_cases":"Evaluating education policies where student placement depends on both test scores and geographic location, Analyzing healthcare interventions with fuzzy eligibility rules based on multiple patient characteristics","audience":"Mid-DS, Early-PhD"},{"id":"package-rddensity","type":"package","name":"rddensity","description":"Implements manipulation testing (density discontinuity testing) procedures using local polynomial density estimators to detect perfect self-selection around a cutoff. Provides rddensity() for hypothesis testing, rdbwdensity() for bandwidth selection, and rdplotdensity() for density plots with confidence bands.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rddensity","difficulty":"intermediate","prerequisites":"regression-discontinuity-design, local-polynomial-regression, hypothesis-testing","topic_tags":"manipulation-testing, regression-discontinuity, density-estimation, falsification-tests, causal-inference","summary":"R package for testing whether individuals manipulate their assignment variable around a regression discontinuity cutoff by examining density discontinuities. Essential for validating RDD assumptions before running causal analyses. Provides McCrary-style tests with modern local polynomial methods and visualization tools.","use_cases":"Testing if students can manipulate test scores around scholarship eligibility thresholds, Checking whether firms bunch around regulatory size cutoffs to avoid compliance costs","audience":"Mid-DS, Early-PhD"},{"id":"package-rddtools","type":"package","name":"rddtools","description":"Regression discontinuity design toolkit with clustered inference for geographic discontinuities. Provides bandwidth selection, specification tests, and visualization tools.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rddtools","difficulty":"intermediate","prerequisites":"regression-analysis, causal-inference-basics, R-programming","topic_tags":"regression-discontinuity, causal-inference, geographic-analysis, bandwidth-selection, statistical-toolkit","summary":"rddtools is an R package that provides a comprehensive toolkit for implementing regression discontinuity designs, with specialized features for geographic discontinuities and clustered standard errors. It streamlines the RDD workflow by offering automated bandwidth selection, diagnostic tests, and publication-ready visualizations. The package is particularly useful for researchers analyzing policy changes or natural experiments with geographic boundaries.","use_cases":"Analyzing the causal impact of school district policies by comparing students just across district boundaries, Evaluating the effect of tax policy changes by examining businesses on either side of state or municipal borders","audience":"Mid-DS, Early-PhD"},{"id":"package-rdlocrand","type":"package","name":"rdlocrand","description":"Provides tools for RD analysis under local randomization: rdrandinf() performs hypothesis testing using randomization inference, rdwinselect() selects a window around the cutoff where randomization likely holds, rdsensitivity() assesses sensitivity to different windows, and rdrbounds() constructs Rosenbaum bounds for unobserved confounders.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rdlocrand","difficulty":"intermediate","prerequisites":"regression-discontinuity-design, randomization-inference, R-programming","topic_tags":"regression-discontinuity, local-randomization, randomization-inference, causal-inference, R-package","summary":"R package implementing local randomization methods for regression discontinuity designs as an alternative to conventional parametric approaches. Provides tools for window selection, randomization-based hypothesis testing, and sensitivity analysis when treatment assignment is as-good-as-random near the cutoff. Particularly useful when bandwidth selection and functional form assumptions are problematic in standard RDD.","use_cases":"Evaluating education policy interventions where students are assigned to programs based on test score cutoffs, Analyzing the causal effects of financial aid eligibility based on income thresholds","audience":"Mid-DS, Early-PhD"},{"id":"package-rdmulti","type":"package","name":"rdmulti","description":"Provides tools for RD designs with multiple cutoffs or scores: rdmc() estimates pooled and cutoff-specific effects in multi-cutoff designs, rdmcplot() draws RD plots for multi-cutoff designs, and rdms() estimates effects in cumulative cutoffs or multi-score (geographic/boundary) designs.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rdmulti","difficulty":"intermediate","prerequisites":"regression-discontinuity, causal-inference-fundamentals, R-programming","topic_tags":"regression-discontinuity, multiple-cutoffs, geographic-boundaries, causal-inference, R-package","summary":"rdmulti is an R package that extends regression discontinuity designs to handle multiple cutoffs or scoring dimensions. It's used by researchers analyzing policies with multiple thresholds or geographic boundaries where standard RD methods don't apply. The package enables pooled estimation across cutoffs and handles complex multi-dimensional discontinuities.","use_cases":"Analyzing education policies with different grade-level cutoffs across districts, Estimating effects of zoning laws or electoral boundaries using geographic discontinuities","audience":"Mid-DS, Senior-DS"},{"id":"package-rdpower","type":"package","name":"rdpower","description":"Provides tools for power, sample size, and minimum detectable effects (MDE) calculations in RD designs using robust bias-corrected local polynomial inference: rdpower() calculates power, rdsampsi() calculates required sample size for desired power, and rdmde() computes minimum detectable effects.","category":"Causal Inference (RDD)","url":"https://cran.r-project.org/package=rdpower","difficulty":"intermediate","prerequisites":"regression-discontinuity-design, R-programming, statistical-power-analysis","topic_tags":"power-analysis, regression-discontinuity, sample-size-calculation, experimental-design, R-package","summary":"rdpower is an R package for calculating statistical power, required sample sizes, and minimum detectable effects in regression discontinuity (RD) designs. It uses robust bias-corrected local polynomial methods to provide accurate ex-ante calculations for RD studies. Essential for researchers planning RD experiments who need to determine feasibility and resource requirements.","use_cases":"Planning a policy evaluation study using school admission cutoffs and need to determine minimum sample size for 80% power, Calculating the smallest effect size detectable with existing administrative data around eligibility thresholds","audience":"Mid-DS, Early-PhD"},{"id":"package-sctools","type":"package","name":"SCtools","description":"Automates placebo tests and multi-treated-unit ATT calculations for synthetic control. Provides utilities for generating in-space and in-time placebos with visualization.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=SCtools","difficulty":"intermediate","prerequisites":"synthetic-control-method, python-programming, causal-inference-basics","topic_tags":"synthetic-control, placebo-tests, causal-inference, python-package, policy-evaluation","summary":"SCtools is a Python package that automates synthetic control analysis by handling placebo tests and multi-unit treatment effects. It simplifies the implementation of robustness checks through automated in-space and in-time placebo generation with built-in visualization capabilities. The package is designed for researchers conducting policy evaluation and causal inference studies using synthetic control methods.","use_cases":"Evaluating the impact of a policy intervention across multiple states or regions simultaneously, Conducting robustness checks for synthetic control studies by automating placebo tests and generating diagnostic plots","audience":"Mid-DS, Early-PhD"},{"id":"package-synth","type":"package","name":"Synth","description":"The original synthetic control method implementation for comparative case studies. Constructs a weighted combination of comparison units to create a synthetic counterfactual for estimating effects of interventions on a single treated unit, as used in seminal studies of California tobacco program and German reunification.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=Synth","difficulty":"intermediate","prerequisites":"panel-data-analysis, python-numpy, linear-regression","topic_tags":"synthetic-control, causal-inference, policy-evaluation, counterfactual-estimation, comparative-case-studies","summary":"The original synthetic control method implementation for creating artificial counterfactuals when studying the causal effect of interventions on a single treated unit. Used by researchers and data scientists to evaluate policy impacts by constructing a weighted combination of similar untreated units that mimics the pre-treatment behavior of the treated unit. Essential for comparative case studies where traditional experimental or quasi-experimental designs are not feasible.","use_cases":"evaluating-state-policy-impact-using-other-states-as-controls, measuring-market-entry-effects-by-comparing-treated-geography-to-synthetic-control","audience":"Mid-DS, Early-PhD"},{"id":"package-augsynth","type":"package","name":"augsynth","description":"Implements the Augmented Synthetic Control Method, which uses an outcome model (ridge regression by default) to correct for bias when pre-treatment fit is imperfect. Uniquely supports staggered adoption across multiple treated units via multisynth() function.","category":"Causal Inference (Synthetic Control)","url":"https://github.com/ebenmichael/augsynth","difficulty":"intermediate","prerequisites":"synthetic-control-method, ridge-regression, panel-data-analysis","topic_tags":"synthetic-control, causal-inference, staggered-adoption, bias-correction, policy-evaluation","summary":"The augsynth package implements Augmented Synthetic Control, which improves upon traditional synthetic control by using ridge regression to correct for bias when pre-treatment fit between treated and synthetic units is poor. It's particularly valuable for tech economists evaluating policy interventions or feature rollouts where perfect pre-treatment matching isn't achievable, and uniquely handles staggered adoption scenarios where different units receive treatment at different times.","use_cases":"Evaluating the impact of a new product feature rolled out to different markets at different times, Measuring the effect of a policy change across states when synthetic control fit is imperfect","audience":"Mid-DS, Senior-DS"},{"id":"package-gsynth","type":"package","name":"gsynth","description":"Implements generalized synthetic control with interactive fixed effects, extending SCM to multiple treated units with variable treatment timing. Uses factor models to impute counterfactuals, handling unbalanced panels and complex treatment patterns with latent factor structures.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=gsynth","difficulty":"intermediate","prerequisites":"synthetic-control-method, panel-data-regression, factor-analysis","topic_tags":"generalized-synthetic-control, interactive-fixed-effects, causal-inference, panel-data, factor-models","summary":"gsynth extends the synthetic control method to handle multiple treated units with staggered treatment timing using interactive fixed effects models. It addresses limitations of traditional SCM by incorporating latent factor structures to better model complex treatment patterns in unbalanced panel data. The package is particularly useful for policy evaluation when treatment rollout varies across units and time periods.","use_cases":"evaluating staggered policy rollouts across multiple states or regions, analyzing product feature launches with different timing across user segments","audience":"Mid-DS, Senior-DS"},{"id":"package-microsynth","type":"package","name":"microsynth","description":"Extends synthetic control method to micro-level data with many units. Implements permutation inference and handles high-dimensional settings where traditional SCM struggles.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=microsynth","difficulty":"advanced","prerequisites":"synthetic-control-method, panel-data-analysis, permutation-tests","topic_tags":"synthetic-control, micro-level-data, permutation-inference, causal-inference, high-dimensional","summary":"The microsynth package extends the synthetic control method to handle micro-level data with many units, addressing limitations of traditional SCM in high-dimensional settings. It implements permutation-based inference procedures to provide robust statistical testing for treatment effects. This tool is particularly valuable for researchers working with individual-level or firm-level panel data where creating synthetic controls from a small donor pool is challenging.","use_cases":"Evaluating impact of policy changes on individual households or firms using administrative microdata, Assessing treatment effects in randomized experiments with many units where traditional synthetic control donor pools are insufficient","audience":"Senior-DS, Early-PhD"},{"id":"package-pensynth","type":"package","name":"pensynth","description":"Implements penalized synthetic control method from Abadie & L'Hour (2021). Adds regularization to improve pre-treatment fit and reduce interpolation bias in sparse donor pools.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=pensynth","difficulty":"intermediate","prerequisites":"synthetic-control-method, ridge-regression, python-scikit-learn","topic_tags":"synthetic-control, causal-inference, regularization, policy-evaluation, python-package","summary":"Pensynth implements the penalized synthetic control method that adds L2 regularization to the traditional synthetic control approach. This helps improve pre-treatment fit and reduces interpolation bias when working with sparse donor pools, making synthetic control more robust for policy evaluation studies.","use_cases":"Evaluating policy impact when you have few suitable control units and traditional synthetic control produces poor pre-treatment fit, Analyzing treatment effects in settings with high-dimensional covariates where standard synthetic control suffers from overfitting","audience":"Mid-DS, Senior-DS"},{"id":"package-scpi","type":"package","name":"scpi","description":"Provides rigorous prediction intervals for synthetic control methods following Cattaneo et al. (2021, 2025). Supports staggered adoption designs with valid uncertainty quantification.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=scpi","difficulty":"intermediate","prerequisites":"synthetic-control-method, causal-inference-basics, R-programming","topic_tags":"synthetic-control, prediction-intervals, causal-inference, uncertainty-quantification, staggered-adoption","summary":"The scpi package implements rigorous prediction intervals for synthetic control methods, providing valid uncertainty quantification for treatment effect estimates. It supports both single-unit and staggered adoption designs, addressing a key limitation of traditional synthetic control methods that lack formal statistical inference procedures.","use_cases":"Evaluating policy impact with confidence intervals when a state implements new regulation, Measuring marketing campaign effects across multiple markets with rollout uncertainty","audience":"Mid-DS, Senior-DS"},{"id":"package-synthdid","type":"package","name":"synthdid","description":"Implements synthetic difference-in-differences, a hybrid method combining insights from both DiD and synthetic control that reweights and matches pre-treatment trends. Provides improved robustness properties compared to either method alone by combining their strengths.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=synthdid","difficulty":"intermediate","prerequisites":"difference-in-differences, synthetic-control-method, panel-data-analysis","topic_tags":"synthetic-difference-in-differences, causal-inference, panel-data, hybrid-estimator, treatment-effects","summary":"Synthetic DiD is a causal inference method that combines synthetic control and difference-in-differences approaches to estimate treatment effects in panel data. It improves upon traditional DiD by reweighting control units to better match pre-treatment trends, while maintaining the robustness properties of both parent methods. Data scientists and researchers use it when they need stronger identification assumptions than standard DiD but more flexibility than pure synthetic control.","use_cases":"Evaluating the impact of a new policy rollout across different states or regions when treatment assignment isn't random, Measuring the effect of a product feature launch on user engagement when only some user segments received the feature","audience":"Mid-DS, Senior-DS"},{"id":"package-tidysynth","type":"package","name":"tidysynth","description":"Brings synthetic control method into the tidyverse with cleaner syntax and built-in placebo inference. Provides pipe-friendly workflows for SCM estimation and visualization.","category":"Causal Inference (Synthetic Control)","url":"https://cran.r-project.org/package=tidysynth","difficulty":"intermediate","prerequisites":"synthetic-control-method, R-tidyverse, difference-in-differences","topic_tags":"synthetic-control, causal-inference, policy-evaluation, tidyverse, R-package","summary":"tidysynth is an R package that brings the synthetic control method into the tidyverse ecosystem with cleaner, pipe-friendly syntax. It simplifies the process of creating synthetic controls for causal inference and includes built-in placebo testing functionality. The package is designed for researchers and analysts who need to evaluate policy interventions or treatment effects using synthetic control methodology.","use_cases":"Evaluating the causal impact of a new policy implemented in one state compared to other states, Analyzing the effect of a product launch in one market while using other similar markets as synthetic controls","audience":"Mid-DS, Early-PhD"},{"id":"package-mapie","type":"package","name":"MAPIE","description":"Scikit-learn-contrib library for conformal prediction intervals. Provides model-agnostic uncertainty quantification for regression and classification.","category":"Conformal Prediction & Uncertainty","url":"https://github.com/scikit-learn-contrib/MAPIE","difficulty":"intermediate","prerequisites":"scikit-learn, python-numpy, statistical-inference","topic_tags":"conformal-prediction, uncertainty-quantification, prediction-intervals, model-agnostic, scikit-learn","summary":"MAPIE is a Python library that implements conformal prediction methods to generate prediction intervals with statistical guarantees. It works with any scikit-learn compatible model to quantify uncertainty without making distributional assumptions. The library is particularly useful for practitioners who need reliable uncertainty estimates in production machine learning systems.","use_cases":"Adding confidence intervals to existing regression models in production to flag uncertain predictions, Quantifying prediction uncertainty for medical diagnosis models where knowing confidence levels is critical for decision-making","audience":"Junior-DS, Mid-DS"},{"id":"package-torchcp","type":"package","name":"TorchCP","description":"PyTorch-native conformal prediction for DNNs, GNNs, and LLMs with GPU acceleration.","category":"Conformal Prediction & Uncertainty","url":"https://github.com/ml-stat-Sustech/TorchCP","difficulty":"intermediate","prerequisites":"pytorch-tensors, neural-network-training, python-classes","topic_tags":"conformal-prediction, uncertainty-quantification, pytorch, deep-learning, prediction-intervals","summary":"TorchCP is a PyTorch-native library that implements conformal prediction methods for deep neural networks, graph neural networks, and large language models. It provides GPU-accelerated uncertainty quantification with prediction intervals that have statistical guarantees. The package is designed for practitioners who need to add reliable uncertainty estimates to their existing PyTorch models.","use_cases":"Adding confidence intervals to production deep learning models for risk assessment, Quantifying uncertainty in graph neural network predictions for molecular property prediction","audience":"Mid-DS, Senior-DS"},{"id":"package-crepes","type":"package","name":"crepes","description":"Lightweight library for conformal regressors and predictive systems. Simple API for calibrated prediction intervals.","category":"Conformal Prediction & Uncertainty","url":"https://github.com/henrikbostrom/crepes","difficulty":"intermediate","prerequisites":"scikit-learn, regression-analysis, python-numpy","topic_tags":"conformal-prediction, uncertainty-quantification, prediction-intervals, calibrated-models, regression","summary":"CREPES is a lightweight Python library that implements conformal prediction methods for regression tasks, providing calibrated prediction intervals with statistical guarantees. It offers a simple API to wrap existing regression models and generate reliable uncertainty estimates without making distributional assumptions. The library is particularly useful for practitioners who need trustworthy confidence bounds on their predictions.","use_cases":"Adding uncertainty estimates to production ML models for risk-sensitive decisions, Validating model reliability by checking if prediction intervals contain true values at specified confidence levels","audience":"Mid-DS, Junior-DS"},{"id":"package-fortuna","type":"package","name":"fortuna","description":"AWS library for uncertainty quantification in deep learning. Bayesian and conformal methods.","category":"Conformal Prediction & Uncertainty","url":"https://github.com/awslabs/fortuna","difficulty":"intermediate","prerequisites":"pytorch, bayesian-inference, python-numpy","topic_tags":"uncertainty-quantification, conformal-prediction, bayesian-deep-learning, aws-tools, model-reliability","summary":"Fortuna is AWS's library for quantifying uncertainty in deep learning models using both Bayesian and conformal prediction methods. It helps data scientists build more reliable ML systems by providing confidence intervals and uncertainty estimates for neural network predictions. The library integrates with popular deep learning frameworks and offers production-ready implementations of uncertainty quantification techniques.","use_cases":"Adding confidence intervals to production ML models to flag uncertain predictions, Evaluating model reliability in high-stakes applications like medical diagnosis or autonomous systems","audience":"Mid-DS, Senior-DS"},{"id":"package-puncc","type":"package","name":"puncc","description":"IRT Lab's library for predictive uncertainty with conformal prediction. Supports various conformal methods.","category":"Conformal Prediction & Uncertainty","url":"https://github.com/deel-ai/puncc","difficulty":"intermediate","prerequisites":"scikit-learn, prediction-intervals, python-numpy","topic_tags":"conformal-prediction, uncertainty-quantification, prediction-intervals, model-calibration, python-library","summary":"PUNCC is a Python library that implements conformal prediction methods for quantifying uncertainty in machine learning predictions. It provides various conformal prediction techniques to generate prediction intervals with statistical guarantees. The library is designed for practitioners who need reliable uncertainty estimates alongside their model predictions.","use_cases":"Adding uncertainty bounds to production ML models to flag low-confidence predictions, Validating model reliability by checking if prediction intervals achieve target coverage rates","audience":"Mid-DS, Senior-DS"},{"id":"package-cjoint","type":"package","name":"cjoint","description":"Estimates Average Marginal Component Effects (AMCEs) for conjoint experiments following Hainmueller, Hopkins & Yamamoto (2014). Handles multi-dimensional preferences with clustered standard errors.","category":"Conjoint Analysis","url":"https://cran.r-project.org/package=cjoint","difficulty":"intermediate","prerequisites":"survey-design, linear-regression, R-programming","topic_tags":"conjoint-analysis, experimental-design, survey-experiments, causal-inference, preference-elicitation","summary":"The cjoint package implements the standard method for analyzing conjoint experiments, estimating how individual attributes influence choices or ratings. It's widely used by researchers in political science, marketing, and economics to understand multi-dimensional preferences and trade-offs. The package handles complex survey designs with proper clustering and follows established best practices from Hainmueller et al.","use_cases":"Measuring voter preferences across candidate attributes like experience, party, and policy positions, Testing product features to understand which combinations drive consumer choice in market research","audience":"Early-PhD, Mid-DS"},{"id":"package-cregg","type":"package","name":"cregg","description":"Tidy interface for conjoint analysis with visualization. Provides functions for calculating and plotting marginal means and AMCEs with ggplot2-based output for publication-ready figures.","category":"Conjoint Analysis","url":"https://cran.r-project.org/package=cregg","difficulty":"intermediate","prerequisites":"conjoint-experiments, R-programming, ggplot2","topic_tags":"conjoint-analysis, causal-inference, survey-experiments, data-visualization, R-package","summary":"An R package that provides a streamlined workflow for analyzing conjoint experiments, with built-in functions for calculating Average Marginal Component Effects (AMCEs) and marginal means. It generates publication-ready visualizations using ggplot2, making it easy to interpret and communicate results from choice-based experiments.","use_cases":"Analyzing consumer preferences for product features in market research studies, Measuring voter preferences for candidate attributes in political science research","audience":"Mid-DS, Early-PhD"},{"id":"package-h2o-sparkling-water","type":"package","name":"H2O Sparkling Water","description":"H2O's distributed ML engine on Spark with GLM/GAM that provides p-values, confidence intervals, and Tweedie/Gamma distributions.","category":"Core Libraries & Linear Models","url":"https://github.com/h2oai/sparkling-water","difficulty":"intermediate","prerequisites":"apache-spark, python-pyspark, generalized-linear-models","topic_tags":"distributed-ml, spark-integration, statistical-inference, glm-gam, large-scale-modeling","summary":"H2O Sparkling Water integrates H2O's machine learning capabilities with Apache Spark, enabling distributed GLM and GAM models with statistical inference features like p-values and confidence intervals. It's particularly valuable for data scientists working with large datasets who need both scalability and rigorous statistical testing. The library supports specialized distributions like Tweedie and Gamma for modeling non-normal data at scale.","use_cases":"Building interpretable insurance pricing models on terabytes of claims data with proper statistical significance testing, Running large-scale A/B test analysis with GAM models to capture non-linear effects while maintaining distributed processing","audience":"Mid-DS, Senior-DS"},{"id":"package-linregress","type":"package","name":"Linregress","description":"Simple linear regression for Rust with R-style formula syntax, standard errors, t-stats, and p-values.","category":"Core Libraries & Linear Models","url":"https://crates.io/crates/linregress","difficulty":"beginner","prerequisites":"rust-basics, linear-regression-theory","topic_tags":"rust-statistics, linear-regression, OLS-implementation, statistical-computing","summary":"Linregress is a Rust library that provides simple linear regression functionality with an R-like formula syntax. It outputs standard statistical measures including standard errors, t-statistics, and p-values, making it accessible for users familiar with R who want to implement regression in Rust. The package is ideal for basic econometric analysis and statistical modeling in Rust applications.","use_cases":"Building a Rust application that needs to perform quick linear regressions on data streams, Implementing basic econometric models in a high-performance Rust backend system","audience":"Junior-DS, Mid-DS"},{"id":"package-polars","type":"package","name":"Polars","description":"Blazingly fast DataFrame library for Rust and Python with SQL-like syntax, lazy evaluation, and excellent time series handling.","category":"Core Libraries & Linear Models","url":"https://crates.io/crates/polars","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, dataframe-operations","topic_tags":"data-manipulation, performance-optimization, rust-backend, lazy-evaluation, time-series","summary":"Polars is a high-performance DataFrame library built in Rust with Python bindings that offers pandas-like functionality with significantly faster execution speeds. It features lazy evaluation, memory efficiency, and SQL-like syntax making it ideal for large dataset processing. Tech economists and data scientists use it to accelerate data pipelines and handle computationally intensive analysis workflows.","use_cases":"Processing large financial datasets with millions of transactions for market analysis, Accelerating existing pandas workflows that are hitting memory or speed bottlenecks","audience":"Junior-DS, Mid-DS"},{"id":"package-scikit-learn","type":"package","name":"Scikit-learn","description":"Foundational ML library with regression models (incl. regularized), model selection, cross-validation, evaluation metrics.","category":"Core Libraries & Linear Models","url":"https://github.com/scikit-learn/scikit-learn","difficulty":"beginner","prerequisites":"python-basics, numpy-arrays, pandas-dataframes","topic_tags":"machine-learning, supervised-learning, model-evaluation, cross-validation, feature-selection","summary":"Scikit-learn is Python's most widely-used machine learning library, providing simple and efficient tools for data mining and analysis. It offers comprehensive implementations of classification, regression, and clustering algorithms with consistent APIs. The library is essential for anyone starting in machine learning, offering everything from basic linear regression to advanced ensemble methods with built-in model evaluation tools.","use_cases":"Building predictive models for user conversion rates using logistic regression with cross-validation, Implementing A/B test analysis with regularized regression models to control for multiple features","audience":"Junior-DS, Early-PhD"},{"id":"package-statsmodels","type":"package","name":"Statsmodels","description":"Comprehensive library for estimating statistical models (OLS, GLM, etc.), conducting tests, and data exploration. Core tool.","category":"Core Libraries & Linear Models","url":"https://github.com/statsmodels/statsmodels","difficulty":"beginner","prerequisites":"python-pandas, linear-algebra, hypothesis-testing","topic_tags":"statistical-modeling, regression-analysis, econometrics, hypothesis-testing, python-library","summary":"Statsmodels is Python's go-to library for classical statistical analysis and econometric modeling. It provides comprehensive implementations of regression models (OLS, logistic, Poisson), time series analysis, and statistical tests with detailed output similar to R or Stata. Essential for anyone doing rigorous statistical analysis in Python.","use_cases":"Running OLS regression to estimate treatment effects in an A/B test with proper statistical inference, Fitting logistic regression models to predict user conversion and interpreting coefficients","audience":"Junior-DS, Early-PhD"},{"id":"package-appelpy","type":"package","name":"appelpy","description":"Applied Econometrics Library bridging Stata-like syntax with Python. Built on statsmodels with convenient API.","category":"Core Libraries & Linear Models","url":"https://github.com/mfarragher/appelpy","difficulty":"beginner","prerequisites":"python-pandas, basic-regression, statsmodels","topic_tags":"regression, stata-alternative, econometrics, linear-models, python-package","summary":"Appelpy is a Python package that provides Stata-like syntax for econometric analysis, built on top of statsmodels. It's designed for economists and data scientists transitioning from Stata to Python who want familiar commands and output formats. The library simplifies regression analysis with convenient methods for model specification, diagnostics, and results presentation.","use_cases":"Stata users switching to Python who want familiar regression syntax and output, Running standard econometric models (OLS, fixed effects) with simplified commands","audience":"Junior-DS, Early-PhD"},{"id":"package-collapse","type":"package","name":"collapse","description":"High-performance data transformation package designed by an economist. Provides fast grouped operations, time series functions, and panel data tools with 10-100\u00d7 speedups over dplyr on large data.","category":"Data Workflow","url":"https://cran.r-project.org/package=collapse","difficulty":"intermediate","prerequisites":"python-pandas, R-dplyr, panel-data-concepts","topic_tags":"data-transformation, performance-optimization, panel-data, time-series, grouped-operations","summary":"High-performance data transformation package built specifically for economists working with large datasets. Offers dramatic speed improvements (10-100x) over standard tools like dplyr for grouped operations, time series transformations, and panel data manipulation. Designed to handle the scale and complexity typical in economic research and industry applications.","use_cases":"Processing multi-year firm-level datasets with millions of observations for panel regression analysis, Real-time transformation of high-frequency trading data with complex time-based grouping operations","audience":"Mid-DS, Senior-DS"},{"id":"package-data.table","type":"package","name":"data.table","description":"Extension of data.frame providing fast aggregation of large data (100GB+), ordered joins, and memory-efficient operations. Uses reference semantics for in-place modification with concise syntax [:=, .SD, by=].","category":"Data Workflow","url":"https://cran.r-project.org/package=data.table","difficulty":"intermediate","prerequisites":"R-programming, data-frame-operations, SQL-joins","topic_tags":"data-manipulation, R-package, large-datasets, memory-efficiency, aggregation","summary":"data.table is an R package that extends data.frame functionality for high-performance operations on large datasets (100GB+). It provides fast aggregation, ordered joins, and memory-efficient operations using reference semantics for in-place modifications. The package is essential for data scientists working with large-scale data processing in R environments.","use_cases":"Processing multi-gigabyte transaction logs for fraud detection with fast grouping and aggregation, Joining multiple large customer datasets in memory without copying data","audience":"Junior-DS, Mid-DS"},{"id":"package-haven","type":"package","name":"haven","description":"Import and export Stata, SPSS, and SAS data files preserving variable labels and value labels. Handles .dta, .sav, .sas7bdat, and .xpt formats with labelled vectors for metadata.","category":"Data Workflow","url":"https://cran.r-project.org/package=haven","difficulty":"beginner","prerequisites":"R-basics, data-frame-manipulation","topic_tags":"data-import, statistical-software, metadata-preservation, file-formats","summary":"The haven package provides seamless import and export functionality for proprietary statistical software formats including Stata, SPSS, and SAS files. It preserves valuable metadata like variable labels and value labels that are typically lost during data conversion. Essential for researchers working with datasets from multiple statistical platforms or transitioning between software ecosystems.","use_cases":"Converting legacy SPSS survey data to R while preserving question text and response labels for analysis, Importing Stata panel datasets with documented variable definitions for replication studies","audience":"Junior-DS, Early-PhD"},{"id":"package-tidyverse","type":"package","name":"tidyverse","description":"Meta-package installing core tidyverse packages: ggplot2 (visualization), dplyr (manipulation), tidyr (tidying), readr (import), purrr (functional programming), tibble (data frames), stringr (strings), and forcats (factors).","category":"Data Workflow","url":"https://cran.r-project.org/package=tidyverse","difficulty":"beginner","prerequisites":"r-basics, data-frames","topic_tags":"r-programming, data-manipulation, data-visualization, workflow-tools, exploratory-analysis","summary":"The tidyverse is R's most popular meta-package that installs a coherent collection of data science tools with consistent syntax and philosophy. It provides everything needed for a complete data workflow from import to visualization, making R code more readable and intuitive. Essential for anyone doing data analysis in R, from beginners learning their first data manipulation to experienced analysts building complex pipelines.","use_cases":"cleaning and analyzing customer transaction data for business insights, creating publication-ready visualizations and summary statistics for research papers","audience":"Junior-DS, Early-PhD"},{"id":"package-aer","type":"package","name":"AER","description":"Companion package to 'Applied Econometrics with R' (Kleiber & Zeileis) plus datasets from Stock & Watson. Provides ivreg() for instrumental variables, tobit(), and econometric testing functions.","category":"Datasets","url":"https://cran.r-project.org/package=AER","difficulty":"beginner","prerequisites":"R-programming, linear-regression, basic-econometrics","topic_tags":"instrumental-variables, econometric-datasets, R-package, textbook-companion, applied-econometrics","summary":"The AER package is a comprehensive R companion to the popular 'Applied Econometrics with R' textbook, containing datasets and functions for econometric analysis. It provides easy access to classic datasets from Stock & Watson plus essential econometric functions like ivreg() for instrumental variables and tobit() for censored regression. This makes it ideal for students and practitioners learning foundational econometric methods with real data.","use_cases":"Working through econometrics textbook exercises with pre-loaded datasets and matching functions, Teaching introductory econometrics course using standardized datasets that students can easily access","audience":"Early-PhD, Junior-DS"},{"id":"package-causaldata","type":"package","name":"causaldata","description":"Unified collection of datasets from three major causal inference textbooks: 'The Effect' (Huntington-Klein), 'Causal Inference: The Mixtape' (Cunningham), and 'Causal Inference: What If?' (Hern\u00e1n & Robins).","category":"Datasets","url":"https://cran.r-project.org/package=causaldata","difficulty":"beginner","prerequisites":"basic-statistics, causal-inference-concepts","topic_tags":"causal-inference, datasets, textbook-resources, econometrics, research-data","summary":"A unified R package containing datasets from three foundational causal inference textbooks, providing ready-to-use data for learning and practicing causal methods. Essential for students and practitioners working through these influential texts who need clean, standardized datasets. Eliminates the hassle of data preparation so users can focus on learning causal inference techniques.","use_cases":"Working through problem sets and examples from The Effect, Mixtape, or Causal Inference What If textbooks, Teaching causal inference courses with standardized datasets that students can easily access","audience":"Early-PhD, Junior-DS"},{"id":"package-wooldridge","type":"package","name":"wooldridge","description":"All 115 datasets from Wooldridge's 'Introductory Econometrics: A Modern Approach' (7th edition). Includes wage equations, crime data, housing prices, and classic econometrics teaching examples.","category":"Datasets","url":"https://cran.r-project.org/package=wooldridge","difficulty":"beginner","prerequisites":"python-pandas, R-basics, linear-regression","topic_tags":"econometrics-datasets, textbook-data, teaching-materials, regression-examples, panel-data","summary":"A comprehensive collection of 115 real-world datasets from Wooldridge's widely-used econometrics textbook, covering topics like labor economics, crime, housing, and education. These datasets are specifically curated for learning econometric methods and include classic examples used in thousands of classrooms worldwide. Perfect for practicing regression techniques, causal inference methods, and econometric modeling on clean, well-documented data.","use_cases":"Learning econometrics by replicating textbook examples and homework problems, Teaching econometrics courses with standardized, well-documented datasets","audience":"Early-PhD, Junior-DS"},{"id":"package-factoranalyzer","type":"package","name":"FactorAnalyzer","description":"Specialized library for Exploratory (EFA) and Confirmatory (CFA) Factor Analysis with rotation options for interpretability.","category":"Dimensionality Reduction","url":"https://github.com/EducationalTestingService/factor_analyzer","difficulty":"intermediate","prerequisites":"python-pandas, linear-algebra, principal-component-analysis","topic_tags":"factor-analysis, exploratory-factor-analysis, confirmatory-factor-analysis, dimensionality-reduction, survey-analysis","summary":"FactorAnalyzer is a Python library that implements both Exploratory Factor Analysis (EFA) to discover underlying latent factors in data and Confirmatory Factor Analysis (CFA) to test hypothesized factor structures. It includes various rotation methods like varimax and promax to make factor loadings more interpretable. The package is particularly useful for psychometric analysis, survey research, and identifying latent constructs in high-dimensional data.","use_cases":"Analyzing customer survey responses to identify underlying satisfaction dimensions, Validating psychological questionnaire structure by confirming hypothesized factor models","audience":"Mid-DS, Early-PhD"},{"id":"package-opentsne","type":"package","name":"openTSNE","description":"Optimized, parallel implementation of t-distributed Stochastic Neighbor Embedding (t-SNE) for large datasets.","category":"Dimensionality Reduction","url":"https://github.com/pavlin-policar/openTSNE","difficulty":"intermediate","prerequisites":"python-scikit-learn, matplotlib-plotting, numpy-arrays","topic_tags":"t-sne, dimensionality-reduction, data-visualization, clustering, high-dimensional-data","summary":"openTSNE is an optimized Python implementation of t-SNE that can handle large datasets through parallelization and memory efficiency improvements. Data scientists use it to visualize high-dimensional data by reducing it to 2D or 3D plots while preserving local neighborhood structure. It's particularly valuable when working with datasets too large for standard scikit-learn t-SNE implementations.","use_cases":"Visualizing customer segments from high-dimensional behavioral data with millions of users, Creating 2D embeddings of product features or user preferences for exploratory data analysis","audience":"Mid-DS, Junior-DS"},{"id":"package-umap-learn","type":"package","name":"umap-learn","description":"Fast and scalable implementation of Uniform Manifold Approximation and Projection (UMAP) for non-linear reduction.","category":"Dimensionality Reduction","url":"https://github.com/lmcinnes/umap","difficulty":"intermediate","prerequisites":"python-scikit-learn, numpy-arrays, manifold-learning","topic_tags":"umap, dimensionality-reduction, manifold-learning, visualization, embedding","summary":"UMAP is a fast dimensionality reduction technique that preserves both local and global structure in high-dimensional data. It's particularly popular for creating 2D/3D visualizations of complex datasets and generating embeddings for downstream machine learning tasks. The umap-learn package provides an efficient Python implementation with scikit-learn compatibility.","use_cases":"Visualizing high-dimensional customer behavior data or product features in 2D scatter plots, Creating lower-dimensional embeddings of text documents or genomic data for clustering analysis","audience":"Mid-DS, Junior-DS"},{"id":"package-biogeme","type":"package","name":"Biogeme","description":"Maximum likelihood estimation of parametric models, with strong support for complex discrete choice models.","category":"Discrete Choice Models","url":"https://github.com/michelbierlaire/biogeme","difficulty":"intermediate","prerequisites":"python-pandas, maximum-likelihood-estimation, logistic-regression","topic_tags":"discrete-choice, maximum-likelihood, econometrics, python-package, logit-models","summary":"Biogeme is a Python package for maximum likelihood estimation of parametric models, particularly specialized for discrete choice models like logit, probit, and nested logit. It's widely used by economists and data scientists for modeling consumer choice behavior, transportation decisions, and other scenarios where individuals select from discrete alternatives. The package provides flexible model specification and robust estimation capabilities for complex choice structures.","use_cases":"Modeling consumer preferences between product alternatives in e-commerce recommendation systems, Analyzing transportation mode choice (car vs public transit vs bike) for urban planning decisions","audience":"Mid-DS, Senior-DS"},{"id":"package-pyblp","type":"package","name":"PyBLP","description":"Tools for estimating demand for differentiated products using the Berry-Levinsohn-Pakes (BLP) method.","category":"Discrete Choice Models","url":"https://github.com/jeffgortmaker/pyblp","difficulty":"advanced","prerequisites":"python-pandas, instrumental-variables, maximum-likelihood-estimation","topic_tags":"discrete-choice, demand-estimation, blp-method, product-differentiation, python-package","summary":"PyBLP is a Python implementation of the Berry-Levinsohn-Pakes method for estimating consumer demand in markets with differentiated products. It's primarily used by economists and researchers studying industrial organization, antitrust, and market structure analysis. The package handles complex estimation problems involving endogeneity and unobserved product characteristics through instrumental variables and random coefficients.","use_cases":"Estimating price elasticity and market power in smartphone markets for antitrust analysis, Analyzing consumer preferences for car features to predict demand for new vehicle models","audience":"Senior-DS, Early-PhD"},{"id":"package-pylogit","type":"package","name":"PyLogit","description":"Flexible implementation of conditional/multinomial logit models with utilities for data preparation.","category":"Discrete Choice Models","url":"https://github.com/timothyb0912/pylogit","difficulty":"intermediate","prerequisites":"python-pandas, maximum-likelihood-estimation, logistic-regression","topic_tags":"discrete-choice, multinomial-logit, conditional-logit, choice-modeling, python-package","summary":"PyLogit is a Python package that implements conditional and multinomial logit models for analyzing discrete choice data. It provides flexible utilities for preparing choice datasets and estimating models where individuals select from multiple alternatives. The package is particularly useful for economists and data scientists working with consumer choice, transportation, or other decision-making data.","use_cases":"Modeling consumer product choices in market research studies, Analyzing transportation mode selection for urban planning","audience":"Mid-DS, Early-PhD"},{"id":"package-xlogit","type":"package","name":"XLogit","description":"Fast estimation of Multinomial Logit and Mixed Logit models, optimized for performance.","category":"Discrete Choice Models","url":"https://github.com/arteagac/xlogit","difficulty":"intermediate","prerequisites":"python-pandas, maximum-likelihood-estimation, choice-modeling","topic_tags":"discrete-choice, multinomial-logit, mixed-logit, python-package, choice-modeling","summary":"XLogit is a Python package for fast estimation of Multinomial Logit and Mixed Logit models with performance optimizations. It's primarily used by researchers and analysts working on discrete choice problems where individuals select from multiple alternatives. The package offers speed improvements over traditional estimation methods while maintaining statistical rigor.","use_cases":"Analyzing consumer product choice behavior from survey data, Modeling transportation mode selection for urban planning studies","audience":"Mid-DS, Senior-DS"},{"id":"package-torch-choice","type":"package","name":"torch-choice","description":"PyTorch framework for flexible estimation of complex discrete choice models, leveraging GPU acceleration.","category":"Discrete Choice Models","url":"https://github.com/gsbDBI/torch-choice","difficulty":"intermediate","prerequisites":"python-pytorch, logistic-regression, maximum-likelihood-estimation","topic_tags":"discrete-choice, pytorch, gpu-acceleration, econometrics, python-package","summary":"PyTorch-based framework that enables fast, GPU-accelerated estimation of discrete choice models like multinomial logit, nested logit, and mixed logit. Popular among researchers and data scientists who need to model consumer choices, product adoption, or other categorical decision-making processes. Combines the flexibility of PyTorch with specialized tools for choice modeling.","use_cases":"modeling customer product selection behavior for e-commerce recommendation systems, analyzing transportation mode choice for urban planning and policy evaluation","audience":"Mid-DS, Senior-DS"},{"id":"package-doubleml","type":"package","name":"DoubleML","description":"Implements the double/debiased ML framework (Chernozhukov et al.) for estimating causal parameters (ATE, LATE, POM) with ML nuisances.","category":"Double/Debiased Machine Learning (DML)","url":"https://github.com/DoubleML/doubleml-for-py","difficulty":"intermediate","prerequisites":"scikit-learn, causal-inference-fundamentals, cross-validation","topic_tags":"double-machine-learning, causal-inference, treatment-effects, python-package, econometrics","summary":"DoubleML is a Python package that implements the double/debiased machine learning framework for robust causal inference. It allows researchers to estimate treatment effects while using flexible machine learning models for nuisance parameters, avoiding bias from regularization. The package provides ready-to-use estimators for average treatment effects, local average treatment effects, and potential outcome means.","use_cases":"Estimating the causal effect of a product feature on user engagement while controlling for high-dimensional user characteristics, Measuring the impact of a policy intervention using observational data with many confounding variables","audience":"Mid-DS, Senior-DS"},{"id":"package-doubly-debiased-lasso","type":"package","name":"Doubly-Debiased-Lasso","description":"High-dimensional inference under hidden confounding. Doubly debiased Lasso for valid inference.","category":"Double/Debiased Machine Learning (DML)","url":"https://github.com/zijguo/Doubly-Debiased-Lasso","difficulty":"advanced","prerequisites":"lasso-regression, causal-inference, high-dimensional-statistics","topic_tags":"doubly-debiased, lasso-regularization, confounding-adjustment, high-dimensional-inference, causal-estimation","summary":"Advanced method for conducting valid statistical inference in high-dimensional settings where traditional Lasso estimates are biased due to regularization and hidden confounding. Combines debiasing techniques to correct for both selection bias from Lasso penalization and confounding bias from unobserved variables. Enables researchers to obtain valid confidence intervals and p-values for treatment effects in complex observational data.","use_cases":"Estimating treatment effects in genomics studies with thousands of genetic markers and potential unmeasured confounders, Analyzing digital marketing campaigns with high-dimensional user features where selection bias and confounding threaten causal conclusions","audience":"Senior-DS, Early-PhD"},{"id":"package-econml","type":"package","name":"EconML","description":"Microsoft toolkit for estimating heterogeneous treatment effects using DML, causal forests, meta-learners, and orthogonal ML methods.","category":"Double/Debiased Machine Learning (DML)","url":"https://github.com/py-why/EconML","difficulty":"intermediate","prerequisites":"python-scikit-learn, linear-regression, treatment-effect-estimation","topic_tags":"heterogeneous-treatment-effects, causal-machine-learning, python-package, microsoft-research, orthogonal-learning","summary":"EconML is Microsoft's Python library for estimating heterogeneous treatment effects using advanced causal ML methods. It combines double/debiased machine learning, causal forests, and meta-learners to identify how treatment effects vary across different subgroups. The toolkit is designed for practitioners who need to go beyond average treatment effects to understand personalized causal impacts.","use_cases":"Estimating how price discounts affect different customer segments in e-commerce, Measuring heterogeneous effects of job training programs across demographic groups","audience":"Mid-DS, Senior-DS"},{"id":"package-synapseml","type":"package","name":"SynapseML","description":"Microsoft's distributed ML library with native Double ML (DoubleMLEstimator) for heterogeneous treatment effects at scale.","category":"Double/Debiased Machine Learning (DML)","url":"https://github.com/microsoft/SynapseML","difficulty":"intermediate","prerequisites":"apache-spark, causal-inference-basics, python-scikit-learn","topic_tags":"double-ml, causal-inference, distributed-computing, treatment-effects, spark","summary":"SynapseML is Microsoft's distributed machine learning library that extends Spark with native support for Double ML estimation through DoubleMLEstimator. It enables scalable causal inference and heterogeneous treatment effect estimation on large datasets. The library is particularly valuable for tech economists who need to run causal analysis on big data infrastructure.","use_cases":"Estimating personalized treatment effects from A/B tests across millions of users in a streaming platform, Measuring heterogeneous impacts of policy interventions using large-scale administrative datasets","audience":"Mid-DS, Senior-DS"},{"id":"package-pydoublelasso","type":"package","name":"pydoublelasso","description":"Double\u2011post\u00a0Lasso estimator for high\u2011dimensional treatment effects (Belloni\u2011Chernozhukov\u2011Hansen\u202f2014).","category":"Double/Debiased Machine Learning (DML)","url":"https://pypi.org/project/pydoublelasso/","difficulty":"intermediate","prerequisites":"python-scikit-learn, lasso-regression, causal-inference-fundamentals","topic_tags":"double-lasso, high-dimensional-causal-inference, treatment-effects, regularization, python-package","summary":"PyDoubleLasso implements the Belloni-Chernozhukov-Hansen double-post LASSO method for estimating treatment effects when you have many control variables. It uses LASSO for variable selection in both treatment and outcome models, then applies post-LASSO estimation to get unbiased treatment effect estimates. Essential for causal inference in high-dimensional settings where traditional methods break down.","use_cases":"Estimating impact of marketing campaigns when you have hundreds of customer features and need to control for confounders, Measuring effect of policy interventions using administrative data with many demographic and economic control variables","audience":"Mid-DS, Senior-DS"},{"id":"package-pyhtelasso","type":"package","name":"pyhtelasso","description":"Debiased\u2011Lasso detector of heterogeneous treatment effects in randomized experiments.","category":"Double/Debiased Machine Learning (DML)","url":"https://pypi.org/project/pyhtelasso/","difficulty":"advanced","prerequisites":"python-scikit-learn, causal-inference-fundamentals, randomized-controlled-trials","topic_tags":"heterogeneous-treatment-effects, debiased-lasso, double-machine-learning, causal-inference, python-package","summary":"A Python package implementing debiased Lasso methods to detect and estimate heterogeneous treatment effects in randomized experiments. It combines machine learning regularization techniques with causal inference to identify which subgroups respond differently to treatments. Particularly useful for researchers and data scientists working on personalized interventions or understanding treatment effect variation.","use_cases":"Analyzing A/B test results to identify which user segments respond differently to a new product feature, Evaluating clinical trial data to determine which patient characteristics predict stronger treatment responses","audience":"Senior-DS, Early-PhD"},{"id":"package-declaredesign","type":"package","name":"DeclareDesign","description":"Ex ante experimental design declaration and diagnosis. Enables researchers to formally describe their research design, diagnose statistical properties via simulation, and improve designs before data collection.","category":"Experimental Design","url":"https://cran.r-project.org/package=DeclareDesign","difficulty":"intermediate","prerequisites":"randomized-experiments, statistical-inference, R-programming","topic_tags":"experimental-design, power-analysis, causal-inference, simulation, pre-registration","summary":"DeclareDesign is an R package that helps researchers formally specify their experimental designs before collecting data. It enables simulation-based diagnosis of design properties like power, bias, and coverage to optimize study parameters. The package promotes transparent research by encouraging explicit declaration of assumptions and analysis plans.","use_cases":"A/B testing team wants to determine optimal sample sizes and randomization strategy before launching a new feature experiment, Academic researcher needs to pre-register their field experiment design and demonstrate adequate statistical power for grant applications","audience":"Mid-DS, Early-PhD"},{"id":"package-contextual","type":"package","name":"contextual","description":"Multi-armed bandit algorithms including Thompson Sampling, UCB, and LinUCB. Directly applicable to adaptive A/B testing and recommendation optimization with simulation and evaluation tools.","category":"Experimental Design","url":"https://cran.r-project.org/package=contextual","difficulty":"intermediate","prerequisites":"python-numpy, probability-distributions, A/B-testing","topic_tags":"multi-armed-bandits, adaptive-experimentation, recommendation-systems, online-optimization","summary":"The contextual package implements multi-armed bandit algorithms for adaptive experimentation, allowing dynamic allocation of traffic to better-performing variants during A/B tests. It's essential for data scientists running experiments where you want to minimize regret while learning optimal strategies. Includes simulation tools to evaluate bandit performance before deployment.","use_cases":"Dynamically allocating website traffic between different homepage designs during an A/B test, Optimizing personalized product recommendations by learning which recommendation algorithms work best for different user segments","audience":"Mid-DS, Junior-DS"},{"id":"package-fabricatr","type":"package","name":"fabricatr","description":"Simulates realistic social science data for power analysis and design testing. Creates hierarchical data structures with correlated variables matching real-world patterns.","category":"Experimental Design","url":"https://cran.r-project.org/package=fabricatr","difficulty":"intermediate","prerequisites":"R-programming, experimental-design, statistical-power","topic_tags":"data-simulation, power-analysis, experimental-design, hierarchical-data, A/B-testing","summary":"fabricatr is an R package that generates realistic synthetic datasets with complex hierarchical structures and correlated variables. It's designed for researchers who need to test experimental designs and conduct power analyses before collecting real data. The package specializes in creating social science-style data that mimics real-world patterns and relationships.","use_cases":"Planning sample sizes for a multi-level A/B test across different user segments and geographic regions, Testing whether your analysis pipeline can detect treatment effects in clustered randomized trials before launching","audience":"Mid-DS, Early-PhD"},{"id":"package-randomizr","type":"package","name":"randomizr","description":"Proper randomization procedures for experiments with known assignment probabilities. Implements simple, complete, block, and cluster randomization with exact probability calculations for IPW estimation.","category":"Experimental Design","url":"https://cran.r-project.org/package=randomizr","difficulty":"beginner","prerequisites":"basic-probability, experimental-design-concepts, R-programming","topic_tags":"randomization, experimental-design, causal-inference, IPW-estimation, R-package","summary":"randomizr is an R package that implements proper randomization procedures for experiments, ensuring known assignment probabilities for valid statistical inference. It supports simple, complete, block, and cluster randomization designs with exact probability calculations. The package is essential for researchers who need to implement rigorous randomization schemes and calculate inverse probability weights for unbiased treatment effect estimation.","use_cases":"A/B testing platform needs to implement block randomization to ensure balanced treatment assignment across user segments, Field experiment researcher running a clustered randomized trial in villages needs exact assignment probabilities for IPW estimation","audience":"Junior-DS, Early-PhD"},{"id":"package-nashpy","type":"package","name":"Nashpy","description":"Computation of Nash equilibria for 2-player games. Support enumeration and Lemke-Howson algorithm.","category":"Game Theory & Mechanism Design","url":"https://github.com/drvinceknight/Nashpy","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, basic-optimization","topic_tags":"nash-equilibrium, two-player-games, algorithmic-game-theory, python-package","summary":"Nashpy is a Python library for computing Nash equilibria in 2-player games using enumeration and the Lemke-Howson algorithm. It's particularly useful for researchers and practitioners working on strategic interactions, auction design, and competitive analysis. The package provides clean implementations of classic game theory algorithms with a simple API.","use_cases":"Analyzing bidding strategies in two-sided marketplace auctions, Modeling competitive pricing between two firms in market entry scenarios","audience":"Early-PhD, Mid-DS"},{"id":"package-openspiel","type":"package","name":"OpenSpiel","description":"DeepMind's 70+ game environments with multi-agent RL algorithms including Alpha-Rank, Neural Fictitious Self-Play, and CFR variants.","category":"Game Theory & Mechanism Design","url":"https://github.com/deepmind/open_spiel","difficulty":"intermediate","prerequisites":"python-programming, reinforcement-learning-basics, nash-equilibrium","topic_tags":"multi-agent-rl, game-theory, algorithmic-game-theory, neural-fictitious-self-play, counterfactual-regret-minimization","summary":"OpenSpiel is DeepMind's comprehensive framework providing 70+ game environments for multi-agent reinforcement learning research. It includes implementations of advanced algorithms like Alpha-Rank, Neural Fictitious Self-Play, and CFR variants for studying strategic interactions. Researchers and practitioners use it to experiment with game-theoretic scenarios and develop multi-agent AI systems.","use_cases":"Training AI agents to compete in poker or other strategic games using counterfactual regret minimization, Analyzing market competition dynamics by modeling firms as learning agents in auction environments","audience":"Mid-DS, Senior-DS"},{"id":"package-fairpy","type":"package","name":"fairpy","description":"Fair division algorithms from academic papers. Implements cake-cutting and item allocation procedures.","category":"Game Theory & Mechanism Design","url":"https://github.com/erelsgl/fairpy","difficulty":"intermediate","prerequisites":"python-programming, basic-game-theory, algorithmic-thinking","topic_tags":"fair-division, cake-cutting, item-allocation, mechanism-design, python-package","summary":"A Python package implementing academic fair division algorithms including cake-cutting and item allocation procedures. Provides ready-to-use implementations of classic and modern fairness mechanisms from game theory literature. Useful for researchers and practitioners needing to fairly allocate resources or analyze allocation mechanisms.","use_cases":"Dividing computational resources or budget fairly among team members or departments, Research on auction mechanisms and fair allocation algorithms in economics or computer science","audience":"Early-PhD, Mid-DS"},{"id":"package-fairpyx","type":"package","name":"fairpyx","description":"Course-seat allocation with capacity constraints. Practical fair division for university course assignment.","category":"Game Theory & Mechanism Design","url":"https://github.com/ariel-research/fairpyx","difficulty":"intermediate","prerequisites":"python-programming, linear-programming, algorithmic-game-theory","topic_tags":"fair-division, course-allocation, mechanism-design, capacity-constraints, python-package","summary":"Fairpyx is a Python package that implements fair division algorithms for allocating course seats with capacity constraints. It provides practical solutions for university course assignment problems using game theory and mechanism design principles. The package is particularly useful for educational institutions needing to fairly distribute limited course spots among students.","use_cases":"University registrar allocating popular course seats among students with different preferences, Business school assigning MBA students to elective courses with enrollment caps","audience":"Junior-DS, Mid-DS"},{"id":"package-pygambit","type":"package","name":"pygambit","description":"N-player extensive form games with Alan Turing Institute support. Computes Nash, perfect, and sequential equilibria.","category":"Game Theory & Mechanism Design","url":"https://github.com/gambitproject/gambit","difficulty":"intermediate","prerequisites":"python-basics, nash-equilibrium, game-theory-fundamentals","topic_tags":"game-theory, extensive-form-games, nash-equilibrium, python-package, mechanism-design","summary":"Pygambit is a Python package for analyzing N-player extensive form games, with institutional support from the Alan Turing Institute. It provides computational tools for finding various equilibrium concepts including Nash, perfect, and sequential equilibria. Researchers and practitioners use it to model and solve complex strategic interactions with sequential decision-making.","use_cases":"Modeling auction mechanisms with multiple bidding rounds and computing optimal bidding strategies, Analyzing multi-stage bargaining processes between firms in merger negotiations","audience":"Early-PhD, Senior-DS"},{"id":"package-gamlss","type":"package","name":"gamlss","description":"Distributional regression where all parameters of a response distribution (location, scale, shape) can be modeled as functions of predictors, supporting 100+ distributions including highly skewed and kurtotic continuous and discrete distributions.","category":"Generalized Additive Models","url":"https://cran.r-project.org/package=gamlss","difficulty":"intermediate","prerequisites":"generalized-linear-models, R-programming, maximum-likelihood-estimation","topic_tags":"distributional-regression, generalized-additive-models, flexible-distributions, centile-estimation, R-package","summary":"GAMLSS extends traditional regression by modeling all parameters of a response distribution (location, scale, shape) as functions of predictors, not just the mean. It supports over 100 distributions including highly skewed and heavy-tailed distributions, making it ideal for complex real-world data that violates standard regression assumptions. The package is particularly valuable for centile estimation and analyzing heteroskedastic data with non-normal distributions.","use_cases":"modeling-income-distributions-with-varying-skewness-across-demographics, analyzing-medical-reference-curves-where-variance-changes-with-age","audience":"Mid-DS, Senior-DS"},{"id":"package-mgcv","type":"package","name":"mgcv","description":"The definitive GAM implementation providing generalized additive (mixed) models with automatic smoothness estimation via REML/GCV/ML, supporting thin plate splines, tensor products, multiple distributions, and scalable fitting for large datasets.","category":"Generalized Additive Models","url":"https://cran.r-project.org/package=mgcv","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, smoothing-splines","topic_tags":"generalized-additive-models, nonparametric-regression, spline-smoothing, mixed-effects, R-package","summary":"mgcv is R's premier package for fitting Generalized Additive Models (GAMs), enabling flexible nonparametric regression with automatic smoothness selection. It's widely used by data scientists and researchers who need to model complex nonlinear relationships while maintaining interpretability. The package handles everything from simple smooth curves to complex mixed effects models with multiple smoothing terms.","use_cases":"Modeling nonlinear relationships between customer engagement metrics and time/seasonality, Analyzing dose-response curves in A/B tests where treatment effects vary smoothly across user segments","audience":"Mid-DS, Senior-DS"},{"id":"package-geolift","type":"package","name":"GeoLift","description":"Meta's end-to-end synthetic control for geo experiments with multi-cell testing and power calculations.","category":"Geo-Experiments & Lift Measurement","url":"https://github.com/facebookincubator/GeoLift","difficulty":"intermediate","prerequisites":"causal-inference, python-programming, a-b-testing","topic_tags":"geo-experiments, synthetic-control, causal-inference, incrementality-testing, python-package","summary":"GeoLift is Meta's open-source Python package for running geo-level experiments using synthetic control methods. It enables data scientists to measure incrementality of marketing campaigns or product features across geographic regions with proper statistical power calculations. The package handles multi-cell testing scenarios and provides end-to-end workflow from experiment design to results analysis.","use_cases":"Measuring incremental lift from advertising campaigns across different cities or regions, Testing impact of new product features rolled out to specific geographic markets","audience":"Mid-DS, Senior-DS"},{"id":"package-matched_markets","type":"package","name":"matched_markets","description":"Google's time-based regression with greedy search for optimal geo experiment groups.","category":"Geo-Experiments & Lift Measurement","url":"https://github.com/google/matched_markets","difficulty":"intermediate","prerequisites":"regression-analysis, experimental-design, python-pandas","topic_tags":"geo-experiments, market-matching, causal-inference, google-package, incrementality-testing","summary":"Google's matched_markets package implements time-based regression with greedy search algorithms to find optimal control and treatment groups for geo experiments. It's designed for data scientists running incrementality tests who need to match geographic markets based on historical performance. The package automates the complex process of selecting statistically similar market pairs for reliable causal inference.","use_cases":"Testing impact of marketing campaigns across different cities by matching similar geographic markets, Measuring incremental lift from product feature rollouts by selecting comparable regions as controls","audience":"Mid-DS, Senior-DS"},{"id":"package-trimmed_match","type":"package","name":"trimmed_match","description":"Google's robust analysis for paired geo experiments using trimmed statistics. Handles outliers in geo-level data.","category":"Geo-Experiments & Lift Measurement","url":"https://github.com/google/trimmed_match","difficulty":"intermediate","prerequisites":"a-b-testing, python-pandas, outlier-detection","topic_tags":"geo-experiments, robust-statistics, incrementality, trimmed-estimators, paired-design","summary":"Google's trimmed_match package provides robust statistical methods for analyzing paired geo experiments by using trimmed statistics to handle outliers in geographic data. It's designed for measuring incrementality in scenarios where traditional A/B testing isn't feasible due to network effects or spillovers. The package helps data scientists get reliable causal estimates even when geo-level metrics have extreme values.","use_cases":"Measuring the incremental impact of a new ad campaign across different cities while accounting for outlier markets, Evaluating the effectiveness of a product feature rollout across geographic regions with varying baseline performance","audience":"Mid-DS, Senior-DS"},{"id":"package-awesome-economics","type":"package","name":"Awesome Economics","description":"Curated list of economics resources including datasets, software, courses, and blogs.","category":"Inference & Reporting Tools","url":"https://github.com/antontarasenko/awesome-economics","difficulty":"beginner","prerequisites":"basic-economics, research-methodology","topic_tags":"curated-resources, economics-datasets, learning-materials, research-tools","summary":"A comprehensive curated collection of economics resources including datasets, software packages, online courses, and academic blogs. This repository serves as a starting point for economists and data scientists looking to explore economic research tools and methodologies. It provides organized access to foundational and specialized resources across various economics subfields.","use_cases":"Starting economics research and need to find relevant datasets and analytical tools, Teaching an economics course and looking for comprehensive learning materials and software recommendations","audience":"Early-PhD, Curious-browser"},{"id":"package-computational-methods-for-practitioners","type":"package","name":"Computational Methods for practitioners","description":"Open-source textbook by Richard Evans on computational methods for researchers using Python.","category":"Inference & Reporting Tools","url":"https://opensourceecon.github.io/CompMethods/","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, calculus","topic_tags":"computational-methods, python-programming, textbook, numerical-analysis, open-source","summary":"An open-source textbook by Richard Evans teaching computational methods for researchers using Python. It covers fundamental numerical techniques and programming approaches essential for quantitative research. The book provides practical implementation guidance for computational problems commonly encountered in economics and data science.","use_cases":"Learning how to implement optimization algorithms for economic modeling, Building computational skills for dissertation research involving numerical methods","audience":"Early-PhD, Junior-DS"},{"id":"package-econ-project-templates","type":"package","name":"Econ Project Templates","description":"Cookiecutter templates for reproducible economics research projects. Standardized project structure.","category":"Inference & Reporting Tools","url":"https://github.com/OpenSourceEconomics/econ-project-templates","difficulty":"beginner","prerequisites":"command-line-basics, git-version-control","topic_tags":"project-structure, reproducible-research, cookiecutter, research-workflow, standardization","summary":"Cookiecutter templates that provide standardized folder structures and configuration files for economics research projects. These templates help researchers set up consistent, reproducible project environments with predefined directories for data, code, output, and documentation. They're particularly valuable for ensuring research reproducibility and streamlining collaboration across team members.","use_cases":"Starting a new empirical economics paper and needing organized folders for raw data, cleaned data, analysis scripts, and results, Setting up a research project with multiple collaborators who need consistent file organization and naming conventions","audience":"Early-PhD, Junior-DS"},{"id":"package-first-course-in-causal-inference-(python)","type":"package","name":"First Course in Causal Inference (Python)","description":"Python implementation of Peng Ding's textbook 'A First Course in Causal Inference'. Educational resource with code examples.","category":"Inference & Reporting Tools","url":"https://github.com/apoorvalal/ding_causalInference_python","difficulty":"beginner","prerequisites":"python-basics, linear-regression, randomized-experiments","topic_tags":"causal-inference, educational-materials, python-implementation, textbook-companion, daggers","summary":"Python code companion to Peng Ding's causal inference textbook, providing hands-on implementation of key concepts like DAGs, potential outcomes, and identification strategies. Perfect for students and practitioners learning causal inference fundamentals through practical coding exercises. Bridges theory from the textbook with executable Python examples.","use_cases":"PhD student working through Ding's textbook wants to implement exercises in Python, Data scientist transitioning from correlation to causation needs structured learning path with code","audience":"Early-PhD, Junior-DS"},{"id":"package-python-packages-for-applied-economists","type":"package","name":"Python Packages for Applied Economists","description":"Curated collection of Python packages for applied researchers organized by functionality.","category":"Inference & Reporting Tools","url":"https://github.com/clibassi/python-packages-for-applied-economists","difficulty":"beginner","prerequisites":"python-pandas, python-basics, pip-package-management","topic_tags":"python-packages, applied-economics, econometrics, package-discovery, research-tools","summary":"A curated collection of Python packages specifically selected for applied economists and researchers. This resource organizes packages by functionality to help researchers quickly find the right tools for their economic analysis needs. It serves as a comprehensive starting point for building a Python toolkit for empirical economic research.","use_cases":"Setting up Python environment for new economics research project, Finding specialized packages for causal inference or econometric modeling","audience":"Junior-DS, Early-PhD"},{"id":"package-clusterbootstraps","type":"package","name":"clusterbootstraps","description":"Wild cluster bootstrap and pairs cluster bootstrap implementations for clustered standard errors.","category":"Inference & Reporting Tools","url":"https://pypi.org/project/clusterbootstraps/","difficulty":"intermediate","prerequisites":"regression-analysis, clustered-standard-errors, python-statsmodels","topic_tags":"bootstrap-methods, clustered-standard-errors, statistical-inference, econometrics-tools","summary":"Implementation of wild cluster bootstrap and pairs cluster bootstrap methods for computing robust standard errors when data has clustered structure. These bootstrap techniques provide alternatives to analytical clustered standard errors, especially useful when clusters are few or unbalanced. Commonly used in econometrics and causal inference when traditional asymptotic assumptions may not hold.","use_cases":"A/B testing with few treatment clusters where analytical standard errors may be unreliable, Difference-in-differences analysis with small number of treated units requiring robust inference","audience":"Mid-DS, Senior-DS"},{"id":"package-maketables","type":"package","name":"maketables","description":"Publication-ready regression tables for pyfixest, statsmodels, linearmodels. Outputs HTML (great-tables), LaTeX, Word.","category":"Inference & Reporting Tools","url":"https://github.com/py-econometrics/maketables","difficulty":"beginner","prerequisites":"python-pandas, regression-analysis, statsmodels-or-pyfixest","topic_tags":"regression-tables, publication-ready, latex-output, html-tables, statistical-reporting","summary":"A Python package that creates publication-ready regression tables from popular econometrics libraries like pyfixest, statsmodels, and linearmodels. It outputs professional-looking tables in HTML, LaTeX, and Word formats, making it easy to include results in papers, reports, and presentations. Essential for anyone who needs to present regression results in a clean, standardized format.","use_cases":"Creating regression tables for academic papers that need LaTeX formatting, Generating HTML tables for internal reports and stakeholder presentations","audience":"Early-PhD, Junior-DS"},{"id":"package-shiftsharese","type":"package","name":"ShiftShareSE","description":"Implements correct standard errors for Bartik/shift-share instrumental variables designs following Ad\u00e3o, Koles\u00e1r, and Morales (2019 QJE). Standard clustered SEs are typically incorrect for shift-share\u2014this package provides econometrically valid inference.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=ShiftShareSE","difficulty":"intermediate","prerequisites":"instrumental-variables, regression-clustering, econometric-inference","topic_tags":"shift-share, Bartik-instruments, standard-errors, regional-economics, causal-inference","summary":"ShiftShareSE implements econometrically correct standard errors for Bartik/shift-share instrumental variable designs, addressing the problem that standard clustered standard errors are typically invalid in these settings. The package follows the methodology from Ad\u00e3o, Koles\u00e1r, and Morales (2019 QJE) to provide valid statistical inference for shift-share research designs commonly used in regional economics and labor studies.","use_cases":"Estimating local labor market effects of trade shocks using industry composition as instruments, Analyzing regional economic impacts of immigration using historical settlement patterns","audience":"Early-PhD, Mid-DS"},{"id":"package-gmm","type":"package","name":"gmm","description":"Generalized Method of Moments estimation implementing two-step GMM, iterated GMM, and continuous updated estimator (CUE) with HAC covariance matrices. Supports linear and nonlinear moment conditions.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=gmm","difficulty":"advanced","prerequisites":"instrumental-variables, maximum-likelihood-estimation, econometrics-theory","topic_tags":"generalized-method-of-moments, instrumental-variables, econometric-estimation, endogeneity, two-stage-least-squares","summary":"GMM is a flexible econometric estimation framework that finds parameters by matching sample moments to theoretical moments from an economic model. It's particularly valuable when you have more moment conditions than parameters, allowing for overidentification tests and efficient estimation in the presence of endogeneity.","use_cases":"Estimating demand elasticities when prices are endogenous due to unobserved quality shocks, Analyzing dynamic panel data models where lagged dependent variables create correlation with error terms","audience":"Senior-DS, Early-PhD"},{"id":"package-ivmodel","type":"package","name":"ivmodel","description":"Specialized package for weak instrument diagnostics implementing Anderson-Rubin tests, k-class estimators (LIML, Fuller), and sensitivity analysis following Jiang et al. (2015). Essential when instrument strength is questionable.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=ivmodel","difficulty":"advanced","prerequisites":"two-stage-least-squares, instrumental-variables, econometric-theory","topic_tags":"weak-instruments, Anderson-Rubin, LIML, causal-inference, econometrics","summary":"The ivmodel package provides specialized diagnostics and estimation methods for instrumental variable analysis when instruments may be weak. It implements Anderson-Rubin confidence intervals, k-class estimators like LIML and Fuller, and sensitivity analysis tools that remain valid even with poor instrument strength. Essential for researchers who need robust inference when standard IV assumptions are violated.","use_cases":"Testing impact of education on wages using quarter-of-birth instruments with uncertain strength, Evaluating policy effects with geographic variation instruments that may have limited predictive power","audience":"Senior-DS, Early-PhD"},{"id":"package-ivreg","type":"package","name":"ivreg","description":"Modern implementation of two-stage least squares (2SLS) instrumental variables regression with comprehensive diagnostics including hat values, studentized residuals, and component-plus-residual plots. Successor to AER's ivreg() function with superior diagnostic tools.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=ivreg","difficulty":"intermediate","prerequisites":"ordinary-least-squares, linear-regression, econometric-identification","topic_tags":"instrumental-variables, causal-inference, endogeneity, econometrics, R-package","summary":"Modern R package for two-stage least squares instrumental variables regression with enhanced diagnostic capabilities. Designed for economists and data scientists dealing with endogeneity problems in causal analysis. Provides comprehensive residual analysis and model validation tools beyond standard IV implementations.","use_cases":"Estimating price elasticity when price is correlated with unobserved demand factors, Analyzing treatment effects when assignment is influenced by unobservable characteristics","audience":"Mid-DS, Early-PhD"},{"id":"package-momentfit","type":"package","name":"momentfit","description":"Modern S4-based implementation of Generalized Method of Moments supporting systems of equations, nonlinear moment conditions, and hypothesis testing. Successor to gmm package with object-oriented design.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=momentfit","difficulty":"intermediate","prerequisites":"linear-regression, instrumental-variables, R-programming","topic_tags":"generalized-method-moments, causal-inference, econometrics, systems-estimation, R-package","summary":"Modern R package implementing Generalized Method of Moments (GMM) estimation with object-oriented S4 design. Supports complex econometric models including systems of equations and nonlinear moment conditions with robust hypothesis testing. Essential tool for causal inference when dealing with endogeneity and instrumental variables.","use_cases":"Estimating demand elasticity using price instruments when prices are endogenous, Testing overidentifying restrictions in labor economics models with multiple instruments","audience":"Mid-DS, Senior-DS"},{"id":"package-systemfit","type":"package","name":"systemfit","description":"Simultaneous systems estimation implementing Seemingly Unrelated Regression (SUR), two-stage least squares (2SLS), and three-stage least squares (3SLS). Critical for demand systems and structural macro models.","category":"Instrumental Variables","url":"https://cran.r-project.org/package=systemfit","difficulty":"advanced","prerequisites":"linear-algebra, OLS-regression, instrumental-variables","topic_tags":"systems-estimation, structural-modeling, demand-analysis, econometric-packages, simultaneous-equations","summary":"R package for estimating simultaneous equation systems using advanced econometric methods like SUR, 2SLS, and 3SLS. Essential for structural economic models where multiple equations are interdependent, such as demand systems or macro models. Handles endogeneity and cross-equation correlations that single-equation methods cannot address.","use_cases":"Estimating consumer demand systems where prices and quantities are jointly determined, Building structural macroeconomic models with simultaneous feedback between variables like investment and interest rates","audience":"Early-PhD, Senior-DS"},{"id":"package-py-econometrics-`gmm`","type":"package","name":"py-econometrics `gmm`","description":"Lightweight package for setting up and estimating custom GMM models based on user-defined moment conditions.","category":"Instrumental Variables (IV) & GMM","url":"https://github.com/py-econometrics/gmm","difficulty":"intermediate","prerequisites":"python-pandas, two-stage-least-squares, numpy-linear-algebra","topic_tags":"gmm-estimation, moment-conditions, instrumental-variables, custom-models, python-package","summary":"A lightweight Python package that allows economists to define custom moment conditions and estimate GMM models without being constrained to pre-built specifications. It's designed for researchers who need flexibility in their econometric modeling beyond standard IV approaches. The package handles the optimization and variance estimation while letting users focus on specifying their economic theory through moment conditions.","use_cases":"Estimating demand systems with multiple endogenous variables where standard 2SLS isn't sufficient, Testing overidentifying restrictions in custom structural models with researcher-defined moment conditions","audience":"Mid-DS, Senior-DS"},{"id":"package-causalmotifs","type":"package","name":"CausalMotifs","description":"Meta's library for estimating heterogeneous spillover effects in A/B tests. Handles network interference.","category":"Interference & Spillovers","url":"https://github.com/facebookresearch/CausalMotifs","difficulty":"advanced","prerequisites":"randomized-controlled-trials, graph-theory, python-scipy","topic_tags":"network-interference, spillover-effects, experimental-design, causal-inference, python-package","summary":"CausalMotifs is Meta's specialized library for measuring heterogeneous spillover effects in A/B tests when network interference violates standard experimental assumptions. It provides methods to estimate causal effects when treatment of one user affects outcomes of connected users. The package is designed for large-scale platform experiments where user interactions create complex interference patterns.","use_cases":"Social media platform testing feature rollouts where treated users' behavior affects their friends' engagement, Marketplace experiments where seller incentives impact buyer experience through network effects","audience":"Senior-DS, Early-PhD"},{"id":"package-spilled_t","type":"package","name":"spilled_t","description":"Treatment and spillover effect estimation under network interference. Separates direct and indirect effects.","category":"Interference & Spillovers","url":"https://github.com/mpleung/spilled_t","difficulty":"advanced","prerequisites":"causal-inference, network-analysis, randomized-experiments","topic_tags":"network-interference, spillover-effects, causal-inference, treatment-effects, experimental-design","summary":"spilled_t is a specialized package for estimating treatment effects when units are connected through networks, allowing interference between treated and untreated units. It separates direct effects (impact on treated units) from spillover effects (impact on connected untreated units). This is essential for experiments in social networks, marketplaces, or any setting where treatment of one unit can affect outcomes of connected units.","use_cases":"Measuring how advertising to some users affects purchasing behavior of their social network connections, Evaluating educational interventions where treated students influence classroom peers through social learning","audience":"Senior-DS, Early-PhD"},{"id":"package-testinterference","type":"package","name":"testinterference","description":"Statistical tests for SUTVA violations and spillover hypotheses. Detects network interference in experiments.","category":"Interference & Spillovers","url":"https://github.com/tkhdyanagi/testinterference","difficulty":"intermediate","prerequisites":"randomized-experiments, hypothesis-testing, network-effects","topic_tags":"SUTVA-violations, network-interference, spillover-testing, experimental-design, causal-inference","summary":"A statistical package for detecting violations of the Stable Unit Treatment Value Assumption (SUTVA) in randomized experiments. It provides hypothesis tests to identify when treatment effects spill over between units through network connections or geographic proximity. Essential for validating experimental assumptions in social networks, marketplaces, and spatial settings.","use_cases":"Testing whether a social media feature rollout affects both treated users and their untreated friends, Detecting spillover effects in geo-experiments where treated cities influence nearby untreated cities","audience":"Mid-DS, Senior-DS"},{"id":"package-glmnet","type":"package","name":"glmnet","description":"Efficient procedures for fitting regularized generalized linear models via penalized maximum likelihood. Implements LASSO, ridge regression, and elastic net with extremely fast coordinate descent algorithms. Foundation for high-dimensional regression and causal ML.","category":"Machine Learning","url":"https://cran.r-project.org/package=glmnet","difficulty":"intermediate","prerequisites":"linear-regression, python-scikit-learn, cross-validation","topic_tags":"regularization, feature-selection, high-dimensional-regression, coordinate-descent, penalized-regression","summary":"glmnet is the gold standard package for regularized regression, implementing LASSO, ridge, and elastic net with highly optimized algorithms. It's essential for high-dimensional problems where you have more features than observations or need automatic feature selection. Widely used in both traditional ML and modern causal inference methods.","use_cases":"Feature selection in high-dimensional datasets with thousands of variables, Building sparse predictive models for A/B test analysis with many covariates","audience":"Junior-DS, Mid-DS"},{"id":"package-ranger","type":"package","name":"ranger","description":"Fast implementation of random forests particularly suited for high-dimensional data. Provides survival forests, classification, and regression with efficient memory usage. Core backend for grf's causal forests.","category":"Machine Learning","url":"https://cran.r-project.org/package=ranger","difficulty":"intermediate","prerequisites":"python-scikit-learn, R-programming, ensemble-methods","topic_tags":"random-forests, survival-analysis, causal-inference, high-dimensional-data, R-package","summary":"Ranger is a high-performance R package implementing random forests optimized for datasets with many features and large sample sizes. It supports classification, regression, and survival analysis with significantly faster training times and lower memory usage than standard implementations. The package serves as the computational backend for generalized random forests (grf) used in causal inference.","use_cases":"analyzing customer churn with thousands of behavioral features and censored observation times, running causal forest experiments on high-dimensional user data to estimate heterogeneous treatment effects","audience":"Mid-DS, Senior-DS"},{"id":"package-tidymodels","type":"package","name":"tidymodels","description":"Modern framework for modeling and machine learning using tidyverse principles. Meta-package including parsnip (model specification), recipes (preprocessing), workflows, tune (hyperparameter tuning), and yardstick (metrics). Successor to caret.","category":"Machine Learning","url":"https://cran.r-project.org/package=tidymodels","difficulty":"intermediate","prerequisites":"r-programming, dplyr-tidyverse, basic-regression","topic_tags":"r-package, ml-workflow, model-tuning, data-preprocessing, predictive-modeling","summary":"Tidymodels is a comprehensive R framework that streamlines the entire machine learning workflow using consistent tidyverse syntax. It provides unified interfaces for model specification, data preprocessing, hyperparameter tuning, and performance evaluation. The framework is designed to replace caret with a more modular and principled approach to predictive modeling.","use_cases":"Building and comparing multiple ML models for customer churn prediction with automated hyperparameter tuning, Creating reproducible preprocessing pipelines for A/B test outcome prediction models","audience":"Junior-DS, Mid-DS"},{"id":"package-xgboost","type":"package","name":"xgboost","description":"Extreme Gradient Boosting implementing state-of-the-art gradient boosted decision trees. Highly efficient, scalable, and portable with interfaces to R, Python, and other languages. Essential for prediction in double ML workflows.","category":"Machine Learning","url":"https://cran.r-project.org/package=xgboost","difficulty":"intermediate","prerequisites":"python-scikit-learn, gradient-descent, decision-trees","topic_tags":"gradient-boosting, ensemble-methods, prediction, double-ml, causal-inference","summary":"XGBoost is an optimized gradient boosting framework that builds ensembles of decision trees for superior predictive performance. It's the go-to choice for prediction tasks in causal inference workflows, particularly in double machine learning where you need high-quality nuisance parameter estimates. The package offers exceptional speed, memory efficiency, and handles missing values automatically.","use_cases":"Building first-stage prediction models in double ML for treatment effect estimation, Creating high-performance predictors for A/B test variance reduction using CUPED","audience":"Junior-DS, Mid-DS"},{"id":"package-emmeans","type":"package","name":"emmeans","description":"Estimated Marginal Means (least-squares means) for factorial designs. Computes adjusted means and contrasts for balanced and unbalanced designs, with support for mixed models and Bayesian models.","category":"Marginal Effects","url":"https://cran.r-project.org/package=emmeans","difficulty":"intermediate","prerequisites":"linear-regression, ANOVA, R-programming","topic_tags":"marginal-effects, experimental-design, statistical-inference, post-hoc-analysis, R-package","summary":"R package for computing estimated marginal means (EMMs) and contrasts from statistical models, especially useful for factorial experiments and complex designs. Provides adjusted means that account for covariates and unbalanced data, with built-in support for pairwise comparisons and custom contrasts. Essential tool for interpreting results from ANOVA, mixed models, and other factorial designs in experimental settings.","use_cases":"A/B testing with multiple treatment groups where you need to compare adjusted means while controlling for user demographics, Agricultural experiment analyzing crop yields across different fertilizer types and irrigation levels with unbalanced sample sizes","audience":"Mid-DS, Senior-DS"},{"id":"package-marginaleffects","type":"package","name":"marginaleffects","description":"Modern standard for interpreting regression results\u2014up to 1000\u00d7 faster than margins. Computes marginal effects, predictions, contrasts, and slopes for 100+ model classes. Published in JSS 2024.","category":"Marginal Effects","url":"https://cran.r-project.org/package=marginaleffects","difficulty":"intermediate","prerequisites":"regression-modeling, python-statsmodels, statistical-inference","topic_tags":"marginal-effects, causal-inference, regression-interpretation, python-package, econometrics","summary":"A high-performance Python package for computing marginal effects, predictions, and contrasts from regression models. It provides a unified interface for interpreting results across 100+ model types, making it essential for economists and data scientists who need to understand how variables affect outcomes. The package is significantly faster than traditional tools and follows modern best practices for statistical interpretation.","use_cases":"Computing average marginal effects of policy variables in difference-in-differences studies, Generating model predictions with confidence intervals for A/B test result interpretation","audience":"Mid-DS, Senior-DS"},{"id":"package-lifetimes","type":"package","name":"Lifetimes","description":"Analyze customer lifetime value (CLV) using probabilistic models (BG/NBD, Pareto/NBD) to predict purchases.","category":"Marketing Mix Models (MMM) & Business Analytics","url":"https://github.com/CamDavidsonPilon/lifetimes","difficulty":"intermediate","prerequisites":"python-pandas, maximum-likelihood-estimation, cohort-analysis","topic_tags":"customer-lifetime-value, probabilistic-modeling, retention-analysis, marketing-analytics, python-package","summary":"Lifetimes is a Python package that implements probabilistic models like BG/NBD and Pareto/NBD to predict customer behavior and calculate lifetime value. It's widely used by data scientists at subscription companies, e-commerce platforms, and SaaS businesses to forecast customer purchases and retention. The package provides ready-to-use implementations of complex statistical models that would otherwise require significant mathematical expertise to build from scratch.","use_cases":"Predicting monthly recurring revenue and churn for a SaaS platform by modeling subscriber behavior patterns, Optimizing marketing spend allocation by calculating CLV for different customer segments in e-commerce","audience":"Junior-DS, Mid-DS"},{"id":"package-mamimo","type":"package","name":"MaMiMo","description":"Lightweight Python library focused specifically on Marketing Mix Modeling implementation.","category":"Marketing Mix Models (MMM) & Business Analytics","url":"https://github.com/Garve/mamimo","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, media-attribution-basics","topic_tags":"marketing-mix-modeling, media-attribution, python-package, business-analytics, advertising-optimization","summary":"MaMiMo is a lightweight Python library designed specifically for implementing Marketing Mix Models to measure the effectiveness of different marketing channels. It provides tools for data scientists and marketing analysts to build MMM models that quantify the incremental impact of advertising spend across channels like TV, digital, and print. The library focuses on practical implementation with minimal overhead for teams looking to get started with marketing attribution analysis.","use_cases":"Measuring incremental lift from TV advertising campaigns versus digital channels for budget optimization, Building attribution models to understand how different marketing touchpoints contribute to sales for quarterly planning","audience":"Junior-DS, Mid-DS"},{"id":"package-pymc-marketing","type":"package","name":"PyMC Marketing","description":"Collection of Bayesian marketing models built with PyMC, including MMM, CLV, and attribution.","category":"Marketing Mix Models (MMM) & Business Analytics","url":"https://github.com/pymc-labs/pymc-marketing","difficulty":"intermediate","prerequisites":"python-pandas, bayesian-statistics, pymc-basics","topic_tags":"marketing-mix-modeling, customer-lifetime-value, attribution-modeling, bayesian-inference, python-package","summary":"PyMC Marketing is a Python package that implements Bayesian marketing models including Marketing Mix Models (MMM), Customer Lifetime Value (CLV), and attribution analysis. It provides pre-built statistical models for marketing analysts and data scientists to measure campaign effectiveness and customer value. The package leverages PyMC's probabilistic programming framework to handle uncertainty quantification in marketing measurements.","use_cases":"Measuring the incremental impact of different marketing channels (TV, digital, social) on sales revenue, Estimating customer lifetime value and churn probability for subscription businesses","audience":"Mid-DS, Junior-DS"},{"id":"package-mmm_stan","type":"package","name":"mmm_stan","description":"Python/STAN implementation of Bayesian Marketing Mix Models.","category":"Marketing Mix Models (MMM) & Business Analytics","url":"https://github.com/sibylhe/mmm_stan","difficulty":"intermediate","prerequisites":"python-pandas, bayesian-inference, STAN-modeling","topic_tags":"marketing-mix-modeling, bayesian-marketing, attribution-analysis, media-effectiveness, python-package","summary":"A Python implementation using STAN for Bayesian Marketing Mix Models that helps marketers measure the incremental impact of different marketing channels. This package provides tools for attribution analysis, media saturation curves, and adstock modeling to optimize marketing spend allocation. It's commonly used by data scientists in marketing analytics teams to quantify ROI across channels like TV, digital, and print advertising.","use_cases":"Measuring incremental lift from TV advertising campaigns while accounting for base sales and seasonality, Optimizing budget allocation across digital channels (search, social, display) based on diminishing returns curves","audience":"Mid-DS, Senior-DS"},{"id":"package-ziln_cltv","type":"package","name":"ziln_cltv","description":"Google's Zero-Inflated Lognormal loss for heavily-tailed LTV distributions. Outputs both predicted LTV and churn probability.","category":"Marketing Mix Models (MMM) & Business Analytics","url":"https://github.com/google/lifetime_value","difficulty":"intermediate","prerequisites":"python-sklearn, maximum-likelihood-estimation, survival-analysis","topic_tags":"customer-lifetime-value, zero-inflated-models, churn-prediction, python-package, google-research","summary":"Google's Zero-Inflated Lognormal loss function designed for customer lifetime value prediction in scenarios with high churn rates and heavily-tailed revenue distributions. The model simultaneously predicts both customer lifetime value and churn probability, making it ideal for businesses with significant customer dropout. Particularly useful for subscription services, gaming, and e-commerce where many customers generate zero long-term value.","use_cases":"Predicting customer lifetime value for a mobile game where many users churn immediately but some become high-value spenders, Estimating subscription service CLV where a large portion of trial users never convert to paid plans","audience":"Mid-DS, Senior-DS"},{"id":"package-algmatch","type":"package","name":"algmatch","description":"Student-Project Allocation with lecturer preferences. Extends matching to three-sided markets.","category":"Matching & Market Design","url":"https://pypi.org/project/algmatch/","difficulty":"intermediate","prerequisites":"python-programming, linear-programming, game-theory-basics","topic_tags":"three-sided-matching, allocation-algorithms, market-design, optimization, python-package","summary":"Algmatch is a Python package that solves student-project allocation problems where both students and lecturers have preferences, extending traditional two-sided matching to three-sided markets. It's designed for academic institutions and organizations that need to optimally assign people to projects while considering multiple stakeholders' preferences. The package implements algorithms that find stable allocations in complex matching scenarios.","use_cases":"Assigning MBA students to consulting projects based on student preferences, company needs, and faculty supervisor availability, Matching research assistants to lab projects considering student interests, PI preferences, and project requirements","audience":"Mid-DS, Senior-DS"},{"id":"package-deep-opt-auctions","type":"package","name":"deep-opt-auctions","description":"Neural network optimal auction design. Implements RegretNet, RochetNet for mechanism design.","category":"Matching & Market Design","url":"https://github.com/saisrivatsan/deep-opt-auctions","difficulty":"advanced","prerequisites":"pytorch-neural-networks, game-theory-mechanism-design, gradient-descent-optimization","topic_tags":"neural-auctions, regretnet, rochetnet, mechanism-design, deep-learning","summary":"Deep-opt-auctions implements neural network approaches to optimal auction design, featuring RegretNet and RochetNet architectures. These tools allow researchers and practitioners to design complex auction mechanisms that maximize revenue while satisfying incentive compatibility constraints. The package is particularly valuable for mechanism designers working on multi-item auctions or settings where analytical solutions are intractable.","use_cases":"Designing revenue-optimal auctions for online advertising platforms with multiple ad slots, Creating procurement mechanisms for government contracts with complex bidder preferences","audience":"Senior-DS, Early-PhD"},{"id":"package-kep_solver","type":"package","name":"kep_solver","description":"Kidney exchange optimization with hierarchical objectives. Production-ready for kidney paired donation.","category":"Matching & Market Design","url":"https://pypi.org/project/kep_solver/","difficulty":"intermediate","prerequisites":"linear-programming, graph-theory, python-networkx","topic_tags":"kidney-exchange, matching-algorithms, optimization, healthcare-economics, production-package","summary":"A specialized optimization package for kidney paired donation programs that handles complex matching constraints and hierarchical objectives. Designed for production use in real kidney exchange programs where patients with incompatible donors can swap kidneys. Implements state-of-the-art algorithms for finding optimal exchanges while respecting medical, geographic, and fairness constraints.","use_cases":"Implementing kidney exchange matching system for hospital network, Research on market design mechanisms for organ allocation","audience":"Mid-DS, Senior-DS"},{"id":"package-matching","type":"package","name":"matching","description":"Implements Stable Marriage, Hospital-Resident, Student-Allocation, and Stable Roommates using Gale-Shapley (JOSS paper).","category":"Matching & Market Design","url":"https://github.com/daffidwilde/matching","difficulty":"beginner","prerequisites":"python-basics, graph-theory-concepts","topic_tags":"stable-matching, market-design, gale-shapley, two-sided-markets, python-package","summary":"A Python package implementing classic matching algorithms including Stable Marriage and Hospital-Resident problems using the Gale-Shapley algorithm. These algorithms solve two-sided matching problems where participants have preferences and the goal is to find stable pairings. Useful for economists studying market design and data scientists working on assignment problems.","use_cases":"Modeling medical residency matching systems where doctors and hospitals rank each other, Analyzing school choice mechanisms where students and schools have mutual preferences","audience":"Early-PhD, Junior-DS"},{"id":"package-scarfmatch","type":"package","name":"scarfmatch","description":"Matching with couples using Scarf's algorithm. Essential for NRMP-style medical residency matching.","category":"Matching & Market Design","url":"https://pypi.org/project/scarfmatch/","difficulty":"intermediate","prerequisites":"python-networkx, game-theory, linear-programming","topic_tags":"matching-algorithms, two-sided-markets, medical-residency, couples-matching, scarf-algorithm","summary":"Implementation of Scarf's algorithm for matching problems involving couples, where partners have preferences over joint outcomes. Primarily used in medical residency matching (NRMP) where married couples need to be placed together. Handles the complex constraint that couple members must coordinate their matches while maintaining market stability.","use_cases":"Medical residency programs matching married doctor couples to nearby hospitals, Academic job market matching dual-career academic couples to universities in same geographic area","audience":"Mid-DS, Senior-DS"},{"id":"package-glmmtmb","type":"package","name":"glmmTMB","description":"Fit generalized linear mixed models with extensions including zero-inflation, hurdle models, heteroscedasticity, and autocorrelation using Template Model Builder (TMB) with automatic differentiation and Laplace approximation.","category":"Mixed Effects","url":"https://cran.r-project.org/package=glmmTMB","difficulty":"intermediate","prerequisites":"generalized-linear-models, mixed-effects-models, R-programming","topic_tags":"mixed-effects, zero-inflation, overdispersion, hierarchical-models, bayesian-approximation","summary":"glmmTMB is an R package for fitting generalized linear mixed models with advanced extensions like zero-inflation and overdispersion modeling. It uses Template Model Builder for fast automatic differentiation and Laplace approximation, making it particularly useful for complex hierarchical data with excess zeros or variance issues. The package is popular among researchers analyzing clustered or longitudinal data in ecology, economics, and social sciences.","use_cases":"Modeling customer purchase counts with store-level random effects and excess zeros, Analyzing patient treatment outcomes across hospitals with overdispersed count data","audience":"Mid-DS, Senior-DS"},{"id":"package-lme4","type":"package","name":"lme4","description":"Fit linear and generalized linear mixed-effects models using S4 classes with Eigen C++ library for efficient computation, supporting arbitrarily nested and crossed random effects structures for hierarchical and longitudinal data.","category":"Mixed Effects","url":"https://cran.r-project.org/package=lme4","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, random-effects-concepts","topic_tags":"mixed-effects-models, hierarchical-data, longitudinal-analysis, R-package, random-effects","summary":"lme4 is the standard R package for fitting linear and generalized linear mixed-effects models with complex random effect structures. It's widely used by researchers and data scientists working with hierarchical, grouped, or repeated measures data where observations are not independent. The package provides efficient computation through C++ optimization and supports nested and crossed random effects.","use_cases":"Analyzing student test scores clustered within schools and districts, Modeling user behavior over time with random intercepts per user","audience":"Mid-DS, Early-PhD"},{"id":"package-lmertest","type":"package","name":"lmerTest","description":"Provides p-values for lme4 model fits via Satterthwaite's or Kenward-Roger degrees of freedom methods, with Type I/II/III ANOVA tables, model selection tools (step, drop1), and least-squares means calculations.","category":"Mixed Effects","url":"https://cran.r-project.org/package=lmerTest","difficulty":"intermediate","prerequisites":"lme4-package, linear-mixed-models, R-programming","topic_tags":"mixed-effects, hypothesis-testing, p-values, ANOVA, R-package","summary":"lmerTest extends the lme4 package by adding statistical significance testing capabilities to linear mixed-effects models. It provides p-values using sophisticated degrees of freedom approximation methods and supports comprehensive model comparison workflows. Essential for researchers who need to perform hypothesis testing on hierarchical data structures.","use_cases":"Testing significance of treatment effects in randomized controlled trials with clustered data, Evaluating feature importance in A/B tests with user-level random effects","audience":"Junior-DS, Mid-DS"},{"id":"package-nlme","type":"package","name":"nlme","description":"Fit Gaussian linear and nonlinear mixed-effects models with flexible correlation structures, variance functions for heteroscedasticity, and nested random effects. Ships with base R and offers more variance-covariance flexibility than lme4.","category":"Mixed Effects","url":"https://cran.r-project.org/package=nlme","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, panel-data","topic_tags":"mixed-effects-models, longitudinal-analysis, variance-modeling, econometrics, R-package","summary":"nlme is R's built-in package for fitting linear and nonlinear mixed-effects models with sophisticated error structures. It excels at handling complex variance-covariance patterns, autocorrelated errors, and heteroscedasticity in longitudinal data. Popular among economists and researchers who need more flexible modeling of within-group correlations than standard approaches allow.","use_cases":"Modeling treatment effects in panel data where errors are correlated within individuals over time, Analyzing firm performance data with heteroscedastic errors that vary by company size or industry","audience":"Mid-DS, Early-PhD"},{"id":"package-car","type":"package","name":"car","description":"Functions accompanying 'An R Companion to Applied Regression.' Provides advanced regression diagnostics including variance inflation factors (VIF), Type II/III ANOVA, influence measures, linear hypothesis testing, power transformations (Box-Cox), and comprehensive diagnostic plots.","category":"Model Diagnostics","url":"https://cran.r-project.org/package=car","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, statistical-hypothesis-testing","topic_tags":"regression-diagnostics, model-validation, R-package, ANOVA, hypothesis-testing","summary":"The car package is a comprehensive R toolkit for regression model diagnostics and validation, accompanying the popular 'Applied Regression' textbook. It provides essential diagnostic tools like variance inflation factors, influence measures, and hypothesis testing that are standard practice in econometric analysis. The package is widely used by researchers and analysts who need to validate regression assumptions and assess model quality.","use_cases":"Checking multicollinearity in wage regression models using VIF before publication, Testing linear restrictions on coefficients in demand estimation models","audience":"Junior-DS, Early-PhD"},{"id":"package-performance","type":"package","name":"performance","description":"Utilities for computing indices of model quality and goodness of fit, including R\u00b2, RMSE, ICC, AIC/BIC. Provides functions to check models for overdispersion, zero-inflation, multicollinearity (VIF), convergence, and singularity. Supports mixed effects and Bayesian models.","category":"Model Diagnostics","url":"https://cran.r-project.org/package=performance","difficulty":"intermediate","prerequisites":"regression-modeling, statistical-inference, R-programming","topic_tags":"model-diagnostics, goodness-of-fit, mixed-effects, bayesian-models, multicollinearity","summary":"The performance package provides comprehensive utilities for evaluating statistical models, including standard metrics like R\u00b2 and RMSE alongside diagnostic tests for common modeling issues. It supports both frequentist and Bayesian frameworks, with specialized functions for mixed effects models. Essential for practitioners who need to validate model assumptions and communicate model quality effectively.","use_cases":"Evaluating whether a customer churn prediction model meets performance thresholds before deployment, Diagnosing multicollinearity and convergence issues in a hierarchical model analyzing treatment effects across multiple sites","audience":"Junior-DS, Mid-DS"},{"id":"package-see","type":"package","name":"see","description":"Visualization toolbox for the easystats ecosystem built on ggplot2. Provides publication-ready plotting methods for model parameters, predictions, and performance diagnostics from all easystats packages via simple plot() calls.","category":"Model Diagnostics","url":"https://cran.r-project.org/package=see","difficulty":"beginner","prerequisites":"R-programming, ggplot2, statistical-modeling","topic_tags":"model-diagnostics, data-visualization, statistical-plotting, r-packages, publication-graphics","summary":"The 'see' package provides a unified visualization interface for the easystats ecosystem in R, automatically generating publication-ready diagnostic plots and model summaries. It simplifies the process of creating consistent, professional visualizations for statistical models by extending ggplot2 with specialized plotting methods. The package is designed for researchers and analysts who need quick, high-quality visual outputs from their statistical analyses.","use_cases":"Creating diagnostic plots for regression models to check assumptions and identify outliers, Generating publication-ready visualizations of model parameters and confidence intervals for research papers","audience":"Junior-DS, Early-PhD"},{"id":"package-causalnlp","type":"package","name":"CausalNLP","description":"Causal inference for text data. Estimate treatment effects from unstructured text using NLP.","category":"Natural Language Processing for Economics","url":"https://github.com/amaiya/causalnlp","difficulty":"advanced","prerequisites":"python-pandas, scikit-learn, propensity-score-matching","topic_tags":"causal-inference, natural-language-processing, treatment-effects, text-analysis, econometrics","summary":"CausalNLP combines natural language processing with causal inference methods to estimate treatment effects from unstructured text data. It enables researchers to extract causal insights from textual information like reviews, social media posts, or documents where traditional structured data approaches fall short. The package is particularly valuable for economists and data scientists working with large-scale text datasets where experimental data is unavailable.","use_cases":"Measuring the causal effect of product features mentioned in customer reviews on purchase behavior, Estimating treatment effects of policy announcements by analyzing news articles and social media sentiment","audience":"Senior-DS, Early-PhD"},{"id":"package-gensim","type":"package","name":"Gensim","description":"Library focused on topic modeling (LDA, LSI) and document similarity analysis.","category":"Natural Language Processing for Economics","url":"https://github.com/RaRe-Technologies/gensim","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, numpy-arrays","topic_tags":"topic-modeling, document-similarity, text-mining, unsupervised-learning, NLP","summary":"Gensim is a Python library specialized for topic modeling and document similarity analysis, implementing algorithms like Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI). It's widely used by economists and data scientists to discover hidden thematic structures in large text corpora such as research papers, policy documents, or customer reviews. The library excels at memory-efficient processing of large document collections and provides tools for semantic similarity analysis.","use_cases":"Analyzing central bank meeting minutes to identify emerging policy themes and track their evolution over time, Clustering academic economics papers by topic to identify research trends and measure knowledge spillovers between fields","audience":"Mid-DS, Senior-DS"},{"id":"package-transformers","type":"package","name":"Transformers","description":"Access to thousands of pre-trained models for NLP tasks like text classification, summarization, embeddings, etc.","category":"Natural Language Processing for Economics","url":"https://github.com/huggingface/transformers","difficulty":"intermediate","prerequisites":"python-basics, pytorch-tensors, neural-network-fundamentals","topic_tags":"transformers, pre-trained-models, text-classification, language-models, huggingface","summary":"Transformers is a Python library providing access to thousands of pre-trained language models for various NLP tasks. It's widely used by data scientists and researchers to quickly implement state-of-the-art text analysis without training models from scratch. The library supports tasks like sentiment analysis, text summarization, and embedding generation with minimal code.","use_cases":"Analyzing customer feedback sentiment for product development decisions, Extracting key insights from earnings call transcripts for investment research","audience":"Junior-DS, Mid-DS"},{"id":"package-spacy","type":"package","name":"spaCy","description":"Industrial-strength NLP library for efficient text processing pipelines (NER, POS tagging, etc.).","category":"Natural Language Processing for Economics","url":"https://github.com/explosion/spaCy","difficulty":"intermediate","prerequisites":"python-pandas, regular-expressions, basic-linguistics","topic_tags":"natural-language-processing, text-mining, named-entity-recognition, python-library, sentiment-analysis","summary":"spaCy is a production-ready Python library for advanced natural language processing tasks including named entity recognition, part-of-speech tagging, and dependency parsing. It's designed for speed and efficiency in processing large volumes of text data. Tech economists use it to extract structured information from unstructured text sources like earnings calls, patent filings, and regulatory documents.","use_cases":"Extracting company names and financial metrics from SEC filings to build datasets for corporate finance research, Processing job postings to identify skill requirements and wage premiums for labor economics analysis","audience":"Junior-DS, Mid-DS"},{"id":"package-ggraph","type":"package","name":"ggraph","description":"Grammar of graphics for network data built on ggplot2. Provides layouts, geometries, and faceting specifically designed for network visualization with publication-quality output.","category":"Network Analysis","url":"https://cran.r-project.org/package=ggraph","difficulty":"intermediate","prerequisites":"R-ggplot2, network-data-structures, graph-theory-basics","topic_tags":"network-visualization, ggplot2-extension, graph-layouts, social-networks, R-package","summary":"ggraph extends ggplot2's grammar of graphics to network data, enabling sophisticated network visualizations with consistent syntax. It provides specialized layouts, node and edge geometries, and faceting capabilities for creating publication-ready network plots. The package is particularly valuable for researchers and analysts who need to visualize complex relationships in social, biological, or technical networks.","use_cases":"Visualizing social media influence networks to identify key opinion leaders and information flow patterns, Creating publication-ready plots of protein interaction networks showing different types of molecular relationships","audience":"Mid-DS, Senior-DS"},{"id":"package-igraph","type":"package","name":"igraph","description":"Comprehensive network analysis library with efficient algorithms for network creation, manipulation, and analysis. Provides centrality measures, community detection, graph visualization, and network statistics.","category":"Network Analysis","url":"https://cran.r-project.org/package=igraph","difficulty":"intermediate","prerequisites":"python-basics, graph-theory-fundamentals, numpy-arrays","topic_tags":"network-analysis, graph-algorithms, social-networks, community-detection, centrality-measures","summary":"igraph is a powerful network analysis library that provides comprehensive tools for creating, analyzing, and visualizing complex networks. It's widely used by data scientists and researchers for studying social networks, biological systems, and infrastructure networks. The library offers efficient implementations of graph algorithms, centrality measures, and community detection methods.","use_cases":"Analyzing social media networks to identify influential users and community structures, Studying protein interaction networks in computational biology to understand cellular processes","audience":"Junior-DS, Mid-DS"},{"id":"package-sna","type":"package","name":"sna","description":"Social network analysis tools including network visualization, centrality measures, and statistical models for network data. Part of the statnet suite for network regression and exponential random graph models.","category":"Network Analysis","url":"https://cran.r-project.org/package=sna","difficulty":"intermediate","prerequisites":"R-programming, graph-theory, statistical-modeling","topic_tags":"social-networks, network-analysis, ERGM, centrality-measures, R-package","summary":"The sna package provides comprehensive tools for analyzing social networks in R, including network visualization, centrality calculations, and statistical modeling. It's part of the statnet suite and enables researchers to fit exponential random graph models (ERGMs) to understand network formation processes. The package is widely used in sociology, economics, and organizational research for studying relationships and influence patterns.","use_cases":"Analyzing employee collaboration networks to identify key influencers and communication bottlenecks in organizations, Modeling friendship networks in schools to understand how social ties form and influence academic outcomes","audience":"Early-PhD, Mid-DS"},{"id":"package-tidygraph","type":"package","name":"tidygraph","description":"Tidy data interface for network/graph data. Extends dplyr verbs to work with nodes and edges, enabling pipe-friendly network manipulation that integrates seamlessly with ggraph for visualization.","category":"Network Analysis","url":"https://cran.r-project.org/package=tidygraph","difficulty":"beginner","prerequisites":"r-dplyr, ggplot2, basic-graph-theory","topic_tags":"network-analysis, tidyverse, graph-manipulation, data-wrangling, r-package","summary":"tidygraph brings the familiar dplyr grammar to network analysis, making it easy to manipulate nodes and edges using pipes and standard tidyverse verbs. It's designed for R users who want to analyze networks without learning specialized graph packages from scratch. The package integrates seamlessly with ggraph for creating publication-ready network visualizations.","use_cases":"Analyzing social network data to identify influential users and community structures, Studying organizational hierarchies and communication patterns in corporate datasets","audience":"Junior-DS, Mid-DS"},{"id":"package-faer","type":"package","name":"Faer","description":"State-of-the-art linear algebra for Rust with Cholesky, QR, SVD decompositions and multithreaded solvers for large systems.","category":"Numerical Optimization & Computational Tools","url":"https://crates.io/crates/faer","difficulty":"intermediate","prerequisites":"rust-programming, linear-algebra-fundamentals, matrix-decomposition","topic_tags":"rust-linear-algebra, matrix-decomposition, high-performance-computing, numerical-methods, optimization-solvers","summary":"Faer is a high-performance linear algebra library for Rust that provides state-of-the-art implementations of matrix decompositions like Cholesky, QR, and SVD. It features multithreaded solvers optimized for large-scale systems, making it ideal for computationally intensive applications requiring maximum performance. The library is designed for Rust developers who need fast, memory-safe linear algebra operations without sacrificing speed.","use_cases":"Building high-frequency trading systems that require ultra-fast matrix operations for portfolio optimization, Developing machine learning inference engines in Rust that need efficient linear algebra for real-time predictions","audience":"Mid-DS, Senior-DS"},{"id":"package-jax","type":"package","name":"JAX","description":"High-performance numerical computing with autograd and XLA compilation on CPU/GPU/TPU.","category":"Numerical Optimization & Computational Tools","url":"https://github.com/google/jax","difficulty":"intermediate","prerequisites":"python-numpy, automatic-differentiation, linear-algebra","topic_tags":"automatic-differentiation, neural-networks, gpu-computing, scientific-computing, jit-compilation","summary":"JAX is a NumPy-compatible library for high-performance machine learning research that combines automatic differentiation with XLA compilation for CPUs, GPUs, and TPUs. It enables functional programming patterns for neural networks and scientific computing with just-in-time compilation for speed. Popular in research settings for implementing custom models and optimization algorithms that need to scale across accelerators.","use_cases":"Training custom neural network architectures with automatic gradient computation, Implementing scientific computing simulations that need GPU acceleration","audience":"Mid-DS, Senior-DS"},{"id":"package-nalgebra","type":"package","name":"Nalgebra","description":"General-purpose linear algebra library for Rust with dense and sparse matrices, widely used in graphics and physics.","category":"Numerical Optimization & Computational Tools","url":"https://crates.io/crates/nalgebra","difficulty":"intermediate","prerequisites":"rust-programming, matrix-operations, linear-algebra-fundamentals","topic_tags":"linear-algebra, rust-libraries, matrix-computation, numerical-methods, sparse-matrices","summary":"Nalgebra is a comprehensive linear algebra library for Rust that provides efficient implementations of dense and sparse matrix operations. It's particularly popular in graphics programming, physics simulations, and scientific computing applications where performance and memory safety are critical. The library offers a clean API for vector spaces, transformations, and decompositions commonly needed in computational work.","use_cases":"Building 3D graphics engines requiring fast matrix transformations and geometric operations, Implementing physics simulations with large sparse systems for finite element analysis","audience":"Mid-DS, Senior-DS"},{"id":"package-ndarray","type":"package","name":"Ndarray","description":"N-dimensional array library for Rust\u2014the NumPy equivalent with slicing, broadcasting, and BLAS/LAPACK integration.","category":"Numerical Optimization & Computational Tools","url":"https://crates.io/crates/ndarray","difficulty":"intermediate","prerequisites":"rust-programming, numpy-arrays, linear-algebra-basics","topic_tags":"rust, numerical-computing, arrays, scientific-computing, performance","summary":"Ndarray is Rust's equivalent to NumPy, providing efficient n-dimensional arrays with slicing, broadcasting, and mathematical operations. It enables high-performance scientific computing in Rust with BLAS/LAPACK integration for linear algebra operations. This library is essential for data scientists and researchers who need NumPy-like functionality but want Rust's memory safety and performance guarantees.","use_cases":"Building high-performance machine learning algorithms in Rust that require matrix operations and array manipulations, Developing numerical simulation systems where memory safety and speed are critical requirements","audience":"Mid-DS, Senior-DS"},{"id":"package-pytorch","type":"package","name":"PyTorch","description":"Popular deep learning framework with flexible automatic differentiation.","category":"Numerical Optimization & Computational Tools","url":"https://github.com/pytorch/pytorch","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, numpy-arrays","topic_tags":"deep-learning, neural-networks, automatic-differentiation, gpu-computing, python-framework","summary":"PyTorch is a flexible deep learning framework that provides automatic differentiation and dynamic computation graphs. It's widely used by researchers and practitioners for building and training neural networks, from simple models to complex architectures. The framework offers intuitive Python APIs and strong GPU acceleration for efficient model development.","use_cases":"Building and training recommendation systems for user behavior prediction, Developing computer vision models for image classification or object detection","audience":"Junior-DS, Mid-DS"},{"id":"package-jaxonometrics","type":"package","name":"jaxonometrics","description":"JAX-ecosystem implementations of standard econometrics routines for GPU computation.","category":"Numerical Optimization & Computational Tools","url":"https://github.com/py-econometrics/jaxonometrics","difficulty":"intermediate","prerequisites":"econometrics-fundamentals, python-numpy, linear-regression","topic_tags":"econometrics, gpu-computing, jax, numerical-methods, computational-economics","summary":"JAX-based econometrics package that accelerates standard econometric computations using GPU parallelization. Provides drop-in replacements for common econometric estimators with automatic differentiation and vectorization capabilities. Particularly useful for researchers running large-scale economic analyses or Monte Carlo simulations.","use_cases":"Running IV regression on millions of observations with GPU acceleration, Performing bootstrap inference for difference-in-differences with thousands of replications","audience":"Mid-DS, Senior-DS"},{"id":"package-torchonometrics","type":"package","name":"torchonometrics","description":"Econometrics implementations in PyTorch. Leverages autodiff and GPU acceleration for econometric methods.","category":"Numerical Optimization & Computational Tools","url":"https://github.com/apoorvalal/torchonometrics","difficulty":"intermediate","prerequisites":"pytorch-tensors, linear-regression, maximum-likelihood-estimation","topic_tags":"econometrics, pytorch, gpu-acceleration, autodiff, causal-inference","summary":"Torchonometrics brings classical econometric methods into the PyTorch ecosystem, enabling GPU acceleration and automatic differentiation for econometric estimation. It's particularly valuable for researchers and practitioners who need to scale econometric models to large datasets or integrate them with deep learning workflows. The package maintains econometric rigor while leveraging modern computational tools.","use_cases":"Estimating instrumental variables models on million-row datasets with GPU acceleration, Building hybrid models that combine econometric identification strategies with neural network components","audience":"Mid-DS, Senior-DS"},{"id":"package-argmin","type":"package","name":"Argmin","description":"Numerical optimization framework for Rust with Newton, BFGS, L-BFGS, trust region, and derivative-free methods for MLE/GMM.","category":"Optimization","url":"https://crates.io/crates/argmin","difficulty":"intermediate","prerequisites":"rust-programming, numerical-optimization, maximum-likelihood-estimation","topic_tags":"numerical-optimization, rust-library, BFGS, trust-region, maximum-likelihood","summary":"Argmin is a comprehensive numerical optimization framework for Rust that implements classical algorithms like BFGS, L-BFGS, Newton methods, and trust region approaches. It's designed for researchers and engineers who need efficient optimization routines for maximum likelihood estimation and generalized method of moments in Rust applications. The library provides both gradient-based and derivative-free optimization methods with a unified interface.","use_cases":"Estimating parameters in econometric models using maximum likelihood estimation in Rust applications, Optimizing objective functions in high-performance computational economics research where Rust's speed is critical","audience":"Mid-DS, Senior-DS"},{"id":"package-cvxpy","type":"package","name":"cvxpy","description":"Domain-specific language for convex optimization problems. Write math as code \u2014 the standard for convex problems.","category":"Optimization","url":"https://www.cvxpy.org/","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, mathematical-optimization","topic_tags":"convex-optimization, linear-programming, quadratic-programming, mathematical-modeling, python-package","summary":"CVXPY is a Python library that lets you write convex optimization problems using intuitive mathematical syntax that closely mirrors how you'd write them on paper. It's the go-to tool for data scientists and researchers who need to solve portfolio optimization, resource allocation, or machine learning problems with constraints. The library automatically transforms your problem formulation into the appropriate solver format and handles the computational details.","use_cases":"Portfolio optimization with risk constraints and transaction costs, Machine learning model training with regularization and fairness constraints","audience":"Mid-DS, Senior-DS"},{"id":"package-gurobipy","type":"package","name":"gurobipy","description":"Python interface for Gurobi, the best-in-class commercial solver. LP, QP, MIP, and MIQP.","category":"Optimization","url":"https://www.gurobi.com/","difficulty":"intermediate","prerequisites":"linear-programming, python-optimization, mixed-integer-programming","topic_tags":"commercial-solver, linear-programming, mixed-integer-programming, operations-research, python-optimization","summary":"Gurobipy is the Python interface for Gurobi Optimizer, a premium commercial solver for mathematical optimization problems. It's widely regarded as the fastest and most reliable solver for linear programming (LP), quadratic programming (QP), and mixed-integer programming (MIP) problems. Tech economists and data scientists use it for complex optimization tasks where performance and solution quality are critical.","use_cases":"Solving large-scale supply chain optimization problems with thousands of constraints and variables, Implementing auction mechanisms and market design algorithms that require exact optimal solutions","audience":"Mid-DS, Senior-DS"},{"id":"package-ortools","type":"package","name":"ortools","description":"Google's operations research toolkit. Constraint programming, routing, linear/integer programming, and scheduling.","category":"Optimization","url":"https://developers.google.com/optimization","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, mathematical-optimization","topic_tags":"operations-research, constraint-programming, vehicle-routing, linear-programming, scheduling-optimization","summary":"Google's OR-Tools is a comprehensive optimization library that provides solvers for constraint programming, routing problems, and linear/integer programming. It's widely used by data scientists and operations researchers to solve complex scheduling, routing, and resource allocation problems. The toolkit offers both high-level APIs and low-level solver access for various optimization challenges.","use_cases":"Optimizing delivery routes for logistics companies with constraints like vehicle capacity and time windows, Scheduling employees or resources across shifts while satisfying coverage requirements and work regulations","audience":"Mid-DS, Senior-DS"},{"id":"package-scipy.optimize","type":"package","name":"scipy.optimize","description":"Optimization algorithms built into SciPy. Minimization, root finding, curve fitting, and linear programming.","category":"Optimization","url":"https://docs.scipy.org/doc/scipy/reference/optimize.html","difficulty":"beginner","prerequisites":"python-numpy, calculus-derivatives, linear-algebra","topic_tags":"optimization, scipy, numerical-methods, curve-fitting, linear-programming","summary":"SciPy's optimization module provides a comprehensive suite of algorithms for finding optimal solutions to mathematical problems. It's widely used by data scientists and researchers for parameter estimation, model fitting, and solving constrained optimization problems. The package offers user-friendly interfaces to powerful numerical methods without requiring deep mathematical expertise.","use_cases":"Fitting machine learning model hyperparameters using grid search or gradient-based methods, Estimating parameters for econometric models by minimizing loss functions","audience":"Junior-DS, Mid-DS"},{"id":"package-fixedeffectmodel","type":"package","name":"FixedEffectModel","description":"Panel data modeling with IV tests (weak IV, over-identification, endogeneity) and 2-step GMM estimation.","category":"Panel Data & Fixed Effects","url":"https://github.com/ksecology/FixedEffectModel","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, instrumental-variables","topic_tags":"panel-data, fixed-effects, instrumental-variables, gmm-estimation, causal-inference","summary":"A Python package for panel data analysis with fixed effects modeling and comprehensive IV diagnostics. Provides econometric tools for handling endogeneity through instrumental variables and two-step GMM estimation. Essential for economists and data scientists working with longitudinal data where unobserved heterogeneity is a concern.","use_cases":"Analyzing the effect of policy changes on firm outcomes using company panel data with time-invariant unobserved characteristics, Estimating causal effects of education on wages using individual longitudinal data with endogenous schooling decisions","audience":"Mid-DS, Early-PhD"},{"id":"package-fixedeffectmodelpyhdfe","type":"package","name":"FixedEffectModelPyHDFE","description":"Solves linear models with high-dimensional fixed effects, supporting robust variance calculation and IV.","category":"Panel Data & Fixed Effects","url":"https://pypi.org/project/FixedEffectModelPyHDFE/","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, econometric-theory","topic_tags":"fixed-effects, panel-data, high-dimensional, instrumental-variables, econometrics","summary":"FixedEffectModelPyHDFE is a Python implementation for estimating linear models with high-dimensional fixed effects, commonly used in econometric analysis. It handles large categorical variables efficiently and supports robust standard errors and instrumental variable estimation. This package is essential for economists and data scientists working with panel data where controlling for unobserved heterogeneity is critical.","use_cases":"Estimating causal effects in worker-firm matched data with both worker and firm fixed effects, Analyzing product pricing across markets while controlling for time-varying product and market characteristics","audience":"Mid-DS, Early-PhD"},{"id":"package-linearmodels","type":"package","name":"Linearmodels","description":"Estimation of fixed, random, pooled OLS models for panel data. Also Fama-MacBeth and between/first-difference estimators.","category":"Panel Data & Fixed Effects","url":"https://github.com/bashtage/linearmodels","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, econometrics-basics","topic_tags":"panel-data, fixed-effects, fama-macbeth, econometrics, causal-inference","summary":"Linearmodels is a Python package for econometric analysis of panel data, offering comprehensive tools for fixed effects, random effects, and pooled OLS estimation. It includes specialized estimators like Fama-MacBeth for finance applications and between/first-difference methods for causal inference. The package is designed for economists and data scientists working with longitudinal data who need robust statistical methods beyond basic regression.","use_cases":"Analyzing employee productivity across companies over time while controlling for unobserved firm characteristics, Estimating price elasticity effects in A/B tests across different user segments and time periods","audience":"Mid-DS, Early-PhD"},{"id":"package-pyfixest","type":"package","name":"PyFixest","description":"Fast estimation of linear models with multiple high-dimensional fixed effects (like R's `fixest`). Supports OLS, IV, Poisson, robust/cluster SEs.","category":"Panel Data & Fixed Effects","url":"https://github.com/py-econometrics/pyfixest","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, econometric-modeling","topic_tags":"fixed-effects, panel-data, econometrics, causal-inference, python-package","summary":"PyFixest is a Python package for fast estimation of linear models with high-dimensional fixed effects, porting R's popular fixest functionality. It enables economists and data scientists to efficiently run OLS, IV, and Poisson regressions with multiple fixed effects and robust standard errors. The package is particularly valuable for causal inference work requiring control for unobserved heterogeneity across entities or time periods.","use_cases":"Estimating treatment effects in difference-in-differences studies with firm and time fixed effects, Running wage regressions controlling for worker and employer fixed effects in matched employer-employee data","audience":"Mid-DS, Early-PhD"},{"id":"package-alpaca","type":"package","name":"alpaca","description":"Fits generalized linear models (Poisson, negative binomial, logit, probit, Gamma) with high-dimensional k-way fixed effects. Partials out factors during log-likelihood optimization and provides robust/multi-way clustered standard errors, fixed effects recovery, and analytical bias corrections for binary choice models.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=alpaca","difficulty":"intermediate","prerequisites":"generalized-linear-models, panel-data-methods, econometric-clustering","topic_tags":"fixed-effects, high-dimensional-econometrics, gravity-models, bias-correction, clustered-standard-errors","summary":"Alpaca is a specialized package for fitting generalized linear models with high-dimensional fixed effects, particularly useful for gravity models and panel data with many categorical variables. It efficiently handles computational challenges by partialing out fixed effects during optimization and provides robust inference tools. The package is designed for econometric applications requiring both flexible modeling and reliable standard error estimation.","use_cases":"Estimating gravity models for international trade with country-pair and time fixed effects, Analyzing firm-level productivity with multi-way fixed effects for industry, location, and year","audience":"Early-PhD, Mid-DS"},{"id":"package-bife","type":"package","name":"bife","description":"Estimates fixed effects binary choice models (logit and probit) with potentially many individual fixed effects using a pseudo-demeaning algorithm. Addresses the incidental parameters problem through analytical bias correction based on Fern\u00e1ndez-Val (2009) and computes average partial effects.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=bife","difficulty":"intermediate","prerequisites":"panel-data-methods, logistic-regression, R-programming","topic_tags":"binary-choice-models, fixed-effects-estimation, bias-correction, panel-econometrics","summary":"The bife package estimates binary choice models (logit/probit) with individual fixed effects using a pseudo-demeaning algorithm that handles many fixed effects efficiently. It addresses the incidental parameters problem through analytical bias correction and computes average partial effects. This is essential for researchers working with panel data where individual heterogeneity needs to be controlled for in binary outcome models.","use_cases":"Analyzing employee promotion decisions across firms while controlling for unobserved worker characteristics, Studying customer purchase behavior over time while accounting for individual preferences and habits","audience":"Mid-DS, Early-PhD"},{"id":"package-duckreg","type":"package","name":"duckreg","description":"Out-of-core regression (OLS/IV) for very large datasets using DuckDB aggregation. Handles data that doesn't fit in memory.","category":"Panel Data & Fixed Effects","url":"https://github.com/py-econometrics/duckreg","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, linear-regression","topic_tags":"out-of-core-computing, large-datasets, regression-analysis, duckdb, memory-optimization","summary":"Duckreg enables regression analysis on datasets too large to fit in memory by leveraging DuckDB's efficient aggregation capabilities. It supports both OLS and instrumental variables estimation through out-of-core computation, making big data econometrics accessible without requiring distributed computing infrastructure. The package is particularly valuable for researchers working with administrative datasets or large-scale observational data.","use_cases":"Analyzing multi-year administrative datasets with millions of observations for causal inference studies, Running fixed effects regressions on large transaction or user behavior datasets that exceed RAM capacity","audience":"Mid-DS, Senior-DS"},{"id":"package-fixest","type":"package","name":"fixest","description":"Fast and comprehensive package for estimating econometric models with multiple high-dimensional fixed effects, including OLS, GLM, Poisson, and negative binomial models. Features native support for clustered standard errors (up to four-way), instrumental variables, and modern difference-in-differences estimators including Sun-Abraham for staggered treatments.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=fixest","difficulty":"intermediate","prerequisites":"regression-analysis, panel-data-concepts, difference-in-differences","topic_tags":"fixed-effects, panel-data, clustered-standard-errors, difference-in-differences, R-package","summary":"fixest is a high-performance R package for estimating econometric models with multiple high-dimensional fixed effects, supporting OLS, GLM, Poisson, and negative binomial models. It provides native support for clustered standard errors, instrumental variables, and modern difference-in-differences estimators including Sun-Abraham for staggered treatments. The package is optimized for speed and handles large datasets efficiently while offering comprehensive econometric functionality.","use_cases":"Analyzing the impact of policy changes across different states and time periods using difference-in-differences with staggered treatment timing, Estimating demand elasticity from transaction data with customer and product fixed effects while clustering standard errors at the market level","audience":"Mid-DS, Senior-DS"},{"id":"package-lfe","type":"package","name":"lfe","description":"Efficiently estimates linear models with multiple high-dimensional fixed effects using the Method of Alternating Projections. Designed for datasets with factors having thousands of levels (hundreds of thousands of dummy variables), with full support for 2SLS instrumental variables and multi-way clustered standard errors.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=lfe","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, panel-data-structure","topic_tags":"fixed-effects, high-dimensional-data, panel-econometrics, R-package, instrumental-variables","summary":"The lfe package provides memory-efficient estimation of linear models with multiple high-dimensional fixed effects using alternating projections. It's designed for econometric analysis with datasets containing factors with thousands of levels, such as worker-firm matched data or multi-dimensional panel studies. The package supports instrumental variables and multi-way clustered standard errors for robust inference.","use_cases":"analyzing wage effects in worker-firm matched datasets with thousands of companies and workers, estimating treatment effects in multi-dimensional panel data with firm, time, and industry fixed effects","audience":"Mid-DS, Early-PhD"},{"id":"package-panelhetero","type":"package","name":"panelhetero","description":"Heterogeneity analysis across units in panel data. Detects and characterizes unit-level variation.","category":"Panel Data & Fixed Effects","url":"https://github.com/tkhdyanagi/panelhetero","difficulty":"intermediate","prerequisites":"python-pandas, fixed-effects-regression, panel-data-structure","topic_tags":"panel-data, heterogeneity-analysis, unit-effects, econometrics, python-package","summary":"A Python package for analyzing heterogeneity across units in panel datasets, helping researchers detect and characterize unit-level variation beyond standard fixed effects. It provides tools to identify subgroups of units with similar behavior patterns and quantify the extent of heterogeneous treatment effects or parameter variation across panel units.","use_cases":"Analyzing whether a marketing campaign has different effects across geographic regions using sales panel data, Detecting heterogeneous responses to policy changes across firms in longitudinal business datasets","audience":"Mid-DS, Early-PhD"},{"id":"package-panelr","type":"package","name":"panelr","description":"Automates within-between (hybrid) model specification for panel/longitudinal data, combining fixed effects robustness to time-invariant confounding with random effects ability to estimate time-invariant coefficients. Uses lme4 for multilevel estimation with optional Bayesian (brms) and GEE (geepack) backends.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=panelr","difficulty":"intermediate","prerequisites":"panel-data-concepts, lme4-package, fixed-effects-models","topic_tags":"hybrid-models, within-between, panel-data, longitudinal-analysis, multilevel-modeling","summary":"panelr automates the specification of within-between (hybrid) models for panel data analysis, combining the benefits of fixed effects and random effects approaches. It handles the complex data transformations needed to estimate both time-varying and time-invariant effects simultaneously. The package supports multiple estimation backends including lme4, brms, and geepack for different modeling needs.","use_cases":"Analyzing employee productivity over time while controlling for unobserved worker characteristics and estimating effects of education, Studying firm performance across quarters while accounting for industry fixed effects and measuring impact of CEO characteristics","audience":"Mid-DS, Senior-DS"},{"id":"package-plm","type":"package","name":"plm","description":"Comprehensive econometrics package for linear panel models providing fixed effects (within), random effects, between, first-difference, Hausman-Taylor, and nested random effects estimators. Includes GMM, FGLS, and extensive diagnostic tests for serial correlation, cross-sectional dependence, and panel unit roots.","category":"Panel Data & Fixed Effects","url":"https://cran.r-project.org/package=plm","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, hypothesis-testing","topic_tags":"panel-data, fixed-effects, econometrics, causal-inference, python-package","summary":"The plm package is a comprehensive Python library for estimating linear panel data models with multiple econometric estimators. It provides tools for fixed effects, random effects, and advanced methods like Hausman-Taylor and GMM estimation. Essential for economists and data scientists working with longitudinal data who need to control for unobserved heterogeneity and perform rigorous causal inference.","use_cases":"Analyzing the effect of policy changes across states over time while controlling for state-specific unobserved factors, Estimating the impact of company characteristics on firm performance using multi-year corporate panel data","audience":"Mid-DS, Early-PhD"},{"id":"package-pydynpd","type":"package","name":"pydynpd","description":"Estimation of dynamic panel data models using Arellano-Bond (Difference GMM) and Blundell-Bond (System GMM). Includes Windmeijer correction & tests.","category":"Panel Data & Fixed Effects","url":"https://github.com/dazhwu/pydynpd","difficulty":"advanced","prerequisites":"python-pandas, panel-data-econometrics, instrumental-variables","topic_tags":"dynamic-panel-data, GMM-estimation, arellano-bond, econometric-methods, python-package","summary":"A Python package for estimating dynamic panel data models using advanced econometric methods including Arellano-Bond (Difference GMM) and Blundell-Bond (System GMM) estimators. It addresses endogeneity issues in panel data where lagged dependent variables are included as regressors. The package includes the Windmeijer finite-sample correction and diagnostic tests for model specification.","use_cases":"Estimating firm productivity dynamics where current performance depends on past performance and unobserved firm characteristics, Analyzing how past government spending affects current economic growth across countries while controlling for country-specific factors","audience":"Early-PhD, Senior-DS"},{"id":"package-webpower","type":"package","name":"WebPower","description":"Comprehensive collection of tools for basic and advanced statistical power analysis including correlation, t-test, ANOVA, regression, mediation analysis, structural equation modeling (SEM), and multilevel models. Features both R package and web interface.","category":"Power Analysis","url":"https://cran.r-project.org/package=WebPower","difficulty":"intermediate","prerequisites":"statistical-hypothesis-testing, R-programming, experimental-design","topic_tags":"power-analysis, experimental-design, SEM, mediation-analysis, statistical-software","summary":"WebPower is a comprehensive R package and web application for statistical power analysis across various experimental designs and statistical models. It enables researchers to calculate sample sizes, detect effect sizes, and plan studies for everything from basic t-tests to complex structural equation models and multilevel designs. The tool is essential for proper experimental planning and ensuring studies have adequate statistical power to detect meaningful effects.","use_cases":"Planning sample size for a randomized controlled trial testing the effect of a new product feature on user engagement, Determining statistical power for a mediation analysis examining how workplace training affects performance through employee motivation","audience":"Mid-DS, Early-PhD"},{"id":"package-pwr","type":"package","name":"pwr","description":"Provides basic power calculations using effect sizes and notation from Cohen (1988). Supports t-tests, chi-squared tests, one-way ANOVA, correlation tests, proportion tests, and general linear models with analytical (closed-form) solutions.","category":"Power Analysis","url":"https://cran.r-project.org/package=pwr","difficulty":"beginner","prerequisites":"hypothesis-testing, t-tests, basic-statistics","topic_tags":"power-analysis, sample-size, effect-size, experimental-design, Cohen-d","summary":"The pwr package provides essential power calculations for common statistical tests using Cohen's standardized effect sizes. It helps researchers determine appropriate sample sizes before running experiments and assess the power of completed studies. The package covers fundamental tests like t-tests, chi-squared, ANOVA, and correlation analysis with easy-to-use analytical solutions.","use_cases":"Planning sample size for an A/B test to detect a meaningful conversion rate difference, Determining if a completed experiment had sufficient power to detect small effect sizes","audience":"Early-PhD, Junior-DS"},{"id":"package-simr","type":"package","name":"simr","description":"Calculates power for generalized linear mixed models (GLMMs) using Monte Carlo simulation. Designed to work with lme4 models; supports LMMs and GLMMs with crossed random effects, non-normal responses, and complex variance structures where analytical solutions are unavailable.","category":"Power Analysis","url":"https://cran.r-project.org/package=simr","difficulty":"intermediate","prerequisites":"linear-mixed-models, R-lme4, hypothesis-testing","topic_tags":"power-analysis, mixed-models, monte-carlo-simulation, experimental-design, R-package","summary":"simr is an R package that calculates statistical power for generalized linear mixed models through Monte Carlo simulation. It's particularly valuable for researchers designing experiments with complex hierarchical data structures where traditional power calculation methods fall short. The package integrates seamlessly with lme4 models and handles non-normal responses and crossed random effects.","use_cases":"Planning sample sizes for A/B tests with user clustering and multiple treatment levels, Determining power for educational interventions with students nested within schools and teachers","audience":"Mid-DS, Senior-DS"},{"id":"package-adopy","type":"package","name":"ADOpy","description":"Bayesian Adaptive Design Optimization (ADO) for tuning experiments in real-time, with models for psychometric tasks.","category":"Power Simulation & Design of Experiments","url":"https://github.com/adopy/adopy","difficulty":"intermediate","prerequisites":"bayesian-inference, python-scipy, experimental-design","topic_tags":"adaptive-design, bayesian-optimization, psychometrics, real-time-experiments","summary":"ADOpy is a Python package that implements Bayesian Adaptive Design Optimization for running experiments that adapt in real-time based on incoming data. It's particularly useful for psychometric experiments where you want to optimize stimulus selection to maximize information gain. The package includes pre-built models for common psychological tasks and allows researchers to design more efficient experiments.","use_cases":"Optimizing A/B test allocation in real-time based on early results to minimize sample size needed, Running psychophysical experiments that adaptively select stimuli to efficiently estimate perceptual thresholds","audience":"Mid-DS, Senior-DS"},{"id":"package-adaptive","type":"package","name":"Adaptive","description":"Parallel active learning library for adaptive function sampling/evaluation, with live plotting for monitoring.","category":"Power Simulation & Design of Experiments","url":"https://github.com/python-adaptive/adaptive","difficulty":"intermediate","prerequisites":"python-scipy, bayesian-optimization, parallel-computing","topic_tags":"adaptive-sampling, active-learning, function-evaluation, parallel-optimization, experimental-design","summary":"Adaptive is a Python library for intelligent sampling and evaluation of functions using active learning techniques. It enables parallel computation to efficiently explore parameter spaces by adaptively choosing which points to evaluate next. The library includes live plotting capabilities to monitor the learning progress in real-time.","use_cases":"Hyperparameter tuning for machine learning models where function evaluations are expensive, Optimizing simulation parameters in A/B testing frameworks with costly experimental runs","audience":"Mid-DS, Senior-DS"},{"id":"package-ambrosia","type":"package","name":"Ambrosia","description":"End-to-end A/B testing from MobileTeleSystems with PySpark support. Covers experiment design, multi-group splitting, matching, and inference.","category":"Power Simulation & Design of Experiments","url":"https://github.com/MobileTeleSystems/Ambrosia","difficulty":"intermediate","prerequisites":"python-pandas, pyspark, hypothesis-testing","topic_tags":"a-b-testing, experimental-design, pyspark, causal-inference, python-package","summary":"Ambrosia is a comprehensive A/B testing framework from MobileTeleSystems that handles the full experimental workflow from design to analysis using PySpark for scalability. It provides tools for multi-group randomization, matching methods, and statistical inference on large datasets. The package is particularly valuable for data scientists working with big data experimentation pipelines in production environments.","use_cases":"Running large-scale product feature tests across millions of mobile users with proper randomization and statistical analysis, Designing and analyzing multi-arm experiments for marketing campaigns with matched treatment and control groups","audience":"Mid-DS, Senior-DS"},{"id":"package-doegen","type":"package","name":"DoEgen","description":"Automates generation and optimization of designs, especially for mixed factor-level experiments; computes efficiency metrics.","category":"Power Simulation & Design of Experiments","url":"https://github.com/sebhaan/DoEgen","difficulty":"intermediate","prerequisites":"experimental-design-theory, python-scipy, statistical-power-analysis","topic_tags":"experimental-design, design-optimization, mixed-factors, power-analysis, automation","summary":"DoEgen is a package that automatically generates and optimizes experimental designs, particularly for complex experiments with mixed factor levels (continuous and categorical variables). It computes key efficiency metrics like D-optimality and power to help researchers create statistically robust experimental setups. The tool is especially valuable for practitioners who need to balance multiple constraints while maximizing statistical power.","use_cases":"Optimizing A/B test designs with both continuous variables (price, timeout) and categorical factors (UI themes, algorithms), Planning manufacturing experiments with mixed quantitative process parameters and qualitative material choices","audience":"Mid-DS, Senior-DS"},{"id":"package-pydoe2","type":"package","name":"pyDOE2","description":"Implements classical Design of Experiments: factorial (full/fractional), response surface (Box-Behnken, CCD), Latin Hypercube.","category":"Power Simulation & Design of Experiments","url":"https://github.com/clicumu/pyDOE2","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, factorial-analysis","topic_tags":"design-of-experiments, factorial-design, latin-hypercube, response-surface, experimental-design","summary":"pyDOE2 is a Python package that implements classical Design of Experiments methods for efficiently planning experiments and parameter studies. It provides tools for creating factorial designs, response surface methodologies, and space-filling designs like Latin Hypercube sampling. Data scientists and researchers use it to systematically explore parameter spaces with minimal experimental runs while maximizing information gain.","use_cases":"Planning A/B tests with multiple factors to understand interaction effects between UI changes, pricing, and user segments, Optimizing machine learning hyperparameters using response surface methodology to find optimal configurations with fewer training runs","audience":"Mid-DS, Junior-DS"},{"id":"package-tea-tasting","type":"package","name":"tea-tasting","description":"Calculate A/B test statistics directly within data warehouses (BigQuery, ClickHouse, Snowflake, Spark) via Ibis interface. Supports CUPED/CUPAC.","category":"Power Simulation & Design of Experiments","url":"https://github.com/e10v/tea-tasting","difficulty":"intermediate","prerequisites":"SQL-queries, python-pandas, hypothesis-testing","topic_tags":"A-B-testing, data-warehouses, experimentation-platform, CUPED, statistical-inference","summary":"Tea-tasting enables data scientists to run A/B test statistical analysis directly in cloud data warehouses without moving data locally. It provides a unified Python interface via Ibis to calculate test statistics across BigQuery, Snowflake, ClickHouse, and Spark, with built-in support for variance reduction techniques like CUPED and CUPAC.","use_cases":"Running experiment analysis on petabyte-scale user behavior data stored in BigQuery without data export, Implementing CUPED variance reduction for subscription conversion tests using historical user metrics as covariates","audience":"Junior-DS, Mid-DS"},{"id":"package-causalimpact","type":"package","name":"CausalImpact","description":"Python port of Google's R package for estimating causal effects of interventions on time series using Bayesian structural time-series models.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/tcassou/causal_impact","difficulty":"intermediate","prerequisites":"bayesian-statistics, time-series-analysis, python-pandas","topic_tags":"causal-inference, time-series, bayesian-methods, intervention-analysis, python-package","summary":"CausalImpact is a Python implementation of Google's Bayesian structural time-series package for measuring the causal effect of interventions on time series data. It's widely used by data scientists and researchers to evaluate the impact of marketing campaigns, policy changes, or product launches by comparing observed outcomes to counterfactual predictions. The package automatically handles seasonality, trends, and external covariates while providing uncertainty quantification.","use_cases":"Measuring the impact of a new feature launch on user engagement metrics, Evaluating the effectiveness of a marketing campaign on sales revenue","audience":"Mid-DS, Senior-DS"},{"id":"package-differences","type":"package","name":"Differences","description":"Implements modern difference-in-differences methods for staggered adoption designs (e.g., Callaway & Sant'Anna).","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/bernardodionisi/differences","difficulty":"intermediate","prerequisites":"difference-in-differences, panel-data-analysis, python-statsmodels","topic_tags":"difference-in-differences, staggered-adoption, causal-inference, program-evaluation, python-package","summary":"A Python package implementing state-of-the-art difference-in-differences estimators for staggered adoption designs, including Callaway & Sant'Anna's methods. Addresses common issues with two-way fixed effects models when treatment timing varies across units. Essential for practitioners working with modern DiD techniques in policy evaluation and A/B testing contexts.","use_cases":"Evaluating the impact of a policy rollout where different states adopt at different times, Measuring the effect of a product feature launched across different markets on different dates","audience":"Mid-DS, Senior-DS"},{"id":"package-syntheticcontrolmethods","type":"package","name":"SyntheticControlMethods","description":"Implementation of synthetic control methods for comparative case studies when panel data is available.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/OscarEngelbrektson/SyntheticControlMethods","difficulty":"intermediate","prerequisites":"difference-in-differences, python-pandas, linear-regression","topic_tags":"synthetic-control, causal-inference, panel-data, comparative-case-studies","summary":"SyntheticControlMethods implements synthetic control methodology for causal inference when you have one treated unit and multiple control units over time. It creates a synthetic version of the treated unit using weighted combinations of control units to estimate counterfactual outcomes. This is particularly useful for policy evaluation and comparative case studies where traditional randomized experiments aren't feasible.","use_cases":"Evaluating the impact of a new product launch in one market by comparing against a synthetic control made from similar untreated markets, Measuring the effect of a policy change in one state/country by constructing a synthetic version from other unaffected regions","audience":"Mid-DS, Senior-DS"},{"id":"package-tfp-causalimpact","type":"package","name":"TFP CausalImpact","description":"TensorFlow Probability port of Google's CausalImpact. Bayesian structural time-series for intervention effects.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/google/tfp-causalimpact","difficulty":"intermediate","prerequisites":"python-tensorflow, time-series-analysis, bayesian-inference","topic_tags":"causal-impact, bayesian-time-series, intervention-analysis, structural-time-series, tensorflow-probability","summary":"TensorFlow Probability implementation of Google's CausalImpact package for measuring causal effects of interventions in time series data. Uses Bayesian structural time-series models to estimate what would have happened in the absence of an intervention. Particularly useful for A/B testing scenarios where randomization isn't feasible.","use_cases":"Measuring the impact of a marketing campaign on website traffic using control markets, Evaluating the effect of a product feature launch on user engagement metrics","audience":"Mid-DS, Senior-DS"},{"id":"package-csdid","type":"package","name":"csdid","description":"Python adaptation of the R `did` package. Implements multi-period DiD with staggered treatment timing (Callaway & Sant\u2019Anna).","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/d2cml-ai/csdid","difficulty":"intermediate","prerequisites":"python-pandas, difference-in-differences, causal-inference","topic_tags":"difference-in-differences, staggered-treatment, causal-inference, python-package, callaway-santanna","summary":"Python implementation of the Callaway & Sant'Anna difference-in-differences estimator for settings with staggered treatment adoption across multiple time periods. This package handles the complexities of varying treatment timing and provides robust causal effect estimates. Essential tool for economists and data scientists conducting policy evaluation with panel data.","use_cases":"Evaluating the impact of minimum wage increases rolled out across different states at different times, Measuring the effect of a product feature launched to different user cohorts in staggered phases","audience":"Mid-DS, Senior-DS"},{"id":"package-didet","type":"package","name":"didet","description":"DiD with general treatment patterns. Handles effective treatment timing beyond simple staggered adoption.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/tkhdyanagi/didet","difficulty":"intermediate","prerequisites":"difference-in-differences, panel-data-analysis, python-pandas","topic_tags":"difference-in-differences, treatment-timing, causal-inference, python-package, panel-data","summary":"DiDet is a Python package for difference-in-differences analysis that handles complex treatment timing patterns beyond the standard staggered adoption setup. It allows researchers to analyze scenarios with varying treatment intensities, multiple treatment periods, and non-monotonic treatment patterns. The package is particularly useful for tech economists studying interventions with nuanced rollout strategies.","use_cases":"Analyzing the impact of a feature rollout that was turned on and off multiple times across different user segments, Evaluating policy interventions where treatment intensity varied over time and across regions","audience":"Mid-DS, Senior-DS"},{"id":"package-didhetero","type":"package","name":"didhetero","description":"Doubly robust estimation for group-time conditional average treatment effects. UCB for heterogeneous DiD.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/tkhdyanagi/didhetero","difficulty":"advanced","prerequisites":"difference-in-differences, causal-inference, doubly-robust-estimation","topic_tags":"heterogeneous-effects, difference-in-differences, causal-inference, treatment-heterogeneity, doubly-robust","summary":"This package implements doubly robust estimation methods for identifying heterogeneous treatment effects in difference-in-differences designs. It allows researchers to estimate group-time conditional average treatment effects when treatment impacts vary across different subgroups or time periods. The methods provide robust inference by combining outcome regression and propensity score weighting approaches.","use_cases":"Evaluating how a policy rollout affects different demographic groups differently over time, Measuring heterogeneous impacts of a product feature launch across user segments and time periods","audience":"Senior-DS, Early-PhD"},{"id":"package-mlsynth","type":"package","name":"mlsynth","description":"Implements advanced synthetic control methods: forward DiD, cluster SC, factor models, and proximal SC. Designed for single-treated-unit settings.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/jaredjgreathouse/mlsynth","difficulty":"advanced","prerequisites":"difference-in-differences, python-pandas, causal-inference-methods","topic_tags":"synthetic-control, difference-in-differences, causal-inference, policy-evaluation, python-package","summary":"Advanced Python package implementing cutting-edge synthetic control methods including forward DiD, cluster synthetic control, factor models, and proximal synthetic control. Designed specifically for rigorous causal inference in single-treated-unit scenarios where traditional methods may fail. Used by researchers and data scientists conducting policy evaluations and natural experiments.","use_cases":"Evaluating the impact of a new policy implemented in one state/city using other regions as synthetic controls, Analyzing the causal effect of a product launch in a single market by constructing synthetic comparison units","audience":"Senior-DS, Early-PhD"},{"id":"package-pycinc","type":"package","name":"pycinc","description":"Changes\u2011in\u2011Changes (CiC) estimator for distributional treatment effects (Athey\u00a0&\u00a0Imbens\u202f2006).","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://pypi.org/project/pycinc/","difficulty":"advanced","prerequisites":"difference-in-differences, quantile-regression, panel-data-analysis","topic_tags":"changes-in-changes, distributional-effects, causal-inference, treatment-effects, python-package","summary":"PycinC implements the Changes-in-Changes estimator from Athey & Imbens (2006) for measuring treatment effects across the entire outcome distribution, not just the mean. This method extends difference-in-differences to account for distributional changes and is particularly useful when treatment effects vary across quantiles. Researchers use it to understand heterogeneous treatment impacts and policy effects on inequality.","use_cases":"Evaluating how minimum wage increases affect wage distributions at different percentiles, Analyzing distributional impacts of education interventions on test score distributions across student ability levels","audience":"Senior-DS, Early-PhD"},{"id":"package-pyleebounds","type":"package","name":"pyleebounds","description":"Lee\u00a0(2009) sample\u2011selection bounds for treatment effects; trims treated distribution to match selection rates.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://pypi.org/project/pyleebounds/","difficulty":"advanced","prerequisites":"difference-in-differences, propensity-score-matching, python-scipy","topic_tags":"sample-selection-bias, treatment-effects, causal-inference, lee-bounds, python-package","summary":"PyLeeBounds implements Lee (2009) bounds for estimating treatment effects when treatment assignment affects sample selection. The method addresses selection bias by trimming the treated group distribution to match control group selection rates, providing bounds on the true treatment effect. It's essential for researchers dealing with endogenous sample selection in randomized or quasi-experimental settings.","use_cases":"Evaluating job training programs where treatment affects labor force participation rates, Measuring educational intervention effects when treatment influences school dropout decisions","audience":"Senior-DS, Early-PhD"},{"id":"package-pysyncon","type":"package","name":"pysyncon","description":"Synthetic control method implementation compatible with R's Synth and augsynth packages.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/sdfordham/pysyncon","difficulty":"intermediate","prerequisites":"python-pandas, difference-in-differences, panel-data-analysis","topic_tags":"synthetic-control, causal-inference, panel-data, treatment-effects, python-package","summary":"Python implementation of the synthetic control method for causal inference with panel data, providing R Synth package compatibility. Used by researchers and data scientists to estimate treatment effects when randomized experiments aren't feasible. Constructs synthetic control units from donor pool to compare against treated units.","use_cases":"Evaluating impact of policy intervention on a specific region using other regions as controls, Measuring effect of product launch in test market by creating synthetic control from similar markets","audience":"Mid-DS, Senior-DS"},{"id":"package-rdd","type":"package","name":"rdd","description":"Toolkit for sharp RDD analysis, including bandwidth calculation and estimation, integrating with pandas.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/evan-magnusson/rdd","difficulty":"intermediate","prerequisites":"python-pandas, regression-discontinuity-design, causal-inference","topic_tags":"regression-discontinuity, causal-inference, program-evaluation, bandwidth-selection, python-package","summary":"A Python toolkit specifically designed for sharp regression discontinuity design (RDD) analysis with integrated pandas support. It provides automated bandwidth calculation and estimation methods for identifying causal effects at treatment thresholds. The package streamlines the technical implementation of RDD while maintaining statistical rigor.","use_cases":"Evaluating the impact of a scholarship program on student outcomes using GPA cutoffs, Measuring the effect of credit score thresholds on loan approval and subsequent financial behavior","audience":"Mid-DS, Early-PhD"},{"id":"package-rdrobust","type":"package","name":"rdrobust","description":"Comprehensive tools for Regression Discontinuity Designs (RDD), including optimal bandwidth selection, estimation, inference.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/rdpackages/rdrobust","difficulty":"intermediate","prerequisites":"regression-analysis, causal-inference-fundamentals, R-programming","topic_tags":"regression-discontinuity, causal-inference, program-evaluation, R-package, treatment-effects","summary":"rdrobust is an R package that implements state-of-the-art methods for regression discontinuity designs, providing tools for bandwidth selection, robust estimation, and statistical inference. It's widely used by economists and data scientists to estimate causal effects when treatment assignment has a discontinuous cutoff rule. The package handles both sharp and fuzzy RDD designs with modern bias-correction and inference procedures.","use_cases":"Evaluating the impact of a scholarship program that awards aid to students scoring above a specific test threshold, Measuring the effect of a policy change that applies to companies above a certain size cutoff","audience":"Mid-DS, Early-PhD"},{"id":"package-synthlearners","type":"package","name":"synthlearners","description":"Fast synthetic control estimators for panel data problems. Optimized ATT estimation with multiple SC algorithms.","category":"Program Evaluation Methods (DiD, SC, RDD)","url":"https://github.com/apoorvalal/synthlearners","difficulty":"intermediate","prerequisites":"python-pandas, difference-in-differences, causal-inference-fundamentals","topic_tags":"synthetic-control, causal-inference, panel-data, treatment-effects, python-package","summary":"synthlearners is a Python package providing optimized implementations of synthetic control methods for causal inference in panel data settings. It offers multiple algorithms for estimating average treatment effects (ATT) when units are treated at different times. The package is designed for speed and ease of use, making synthetic control methods accessible for practitioners working with observational data.","use_cases":"Evaluating the impact of a policy change on treated states/regions compared to untreated control units, Measuring the causal effect of a product launch or marketing campaign across different markets using historical panel data","audience":"Mid-DS, Junior-DS"},{"id":"package-pyqreg","type":"package","name":"pyqreg","description":"Fast quantile regression solver using interior point methods, supporting robust and clustered standard errors.","category":"Quantile Regression & Distributional Methods","url":"https://github.com/mozjay0619/pyqreg","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, scipy-optimization","topic_tags":"quantile-regression, robust-statistics, interior-point, clustered-errors, distributional-analysis","summary":"pyqreg is a Python package for fast quantile regression using interior point optimization methods. It provides robust alternatives to ordinary least squares by modeling conditional quantiles of the outcome distribution, with support for clustered and robust standard errors. The package is particularly useful for economists and data scientists analyzing heterogeneous treatment effects or non-normal error distributions.","use_cases":"Analyzing wage gaps across income distribution quantiles where effects vary by earnings level, Estimating treatment effects on health outcomes when impacts differ across patient risk profiles","audience":"Mid-DS, Early-PhD"},{"id":"package-pyrifreg","type":"package","name":"pyrifreg","description":"Recentered Influence\u2011Function (RIF) regression for unconditional quantile & distributional effects (Firpo\u202fet\u202fal.,\u202f2008).","category":"Quantile Regression & Distributional Methods","url":"https://github.com/vyasenov/pyrifreg","difficulty":"advanced","prerequisites":"quantile-regression, causal-inference, python-scipy","topic_tags":"quantile-regression, distributional-effects, unconditional-quantile, rif-regression, causal-analysis","summary":"PyRIFReg implements Recentered Influence Function (RIF) regression to estimate unconditional quantile effects and distributional impacts beyond the mean. This advanced econometric method allows researchers to understand how treatments or policies affect different parts of the outcome distribution, not just average effects. Particularly valuable for policy evaluation where distributional consequences matter as much as average impacts.","use_cases":"Analyzing how minimum wage increases affect different parts of the wage distribution rather than just average wages, Evaluating educational interventions' impact on test score inequality by examining effects at various quantiles","audience":"Senior-DS, Early-PhD"},{"id":"package-quantile-forest","type":"package","name":"quantile-forest","description":"Scikit-learn compatible implementation of Quantile Regression Forests for non-parametric estimation.","category":"Quantile Regression & Distributional Methods","url":"https://github.com/zillow/quantile-forest","difficulty":"intermediate","prerequisites":"scikit-learn, random-forests, quantile-regression","topic_tags":"quantile-regression, random-forests, uncertainty-quantification, scikit-learn, python-package","summary":"Quantile-forest is a scikit-learn compatible Python package that implements Quantile Regression Forests, extending random forests to estimate conditional quantiles instead of just point predictions. It enables non-parametric estimation of prediction intervals and full conditional distributions without distributional assumptions. The package is particularly useful for uncertainty quantification and risk assessment in machine learning applications.","use_cases":"Estimating confidence intervals for house price predictions to understand pricing uncertainty, Risk management in financial forecasting by modeling tail quantiles of portfolio returns","audience":"Mid-DS, Junior-DS"},{"id":"package-broom","type":"package","name":"broom","description":"Converts messy output from 100+ statistical model types into consistent tidy tibbles using three verbs: tidy() for coefficient-level statistics, glance() for model-level summaries (R\u00b2, AIC), and augment() for fitted values and residuals.","category":"Regression Output","url":"https://cran.r-project.org/package=broom","difficulty":"beginner","prerequisites":"R-programming, linear-regression, tidyverse-dplyr","topic_tags":"model-output, data-cleaning, statistical-reporting, tidyverse, regression-analysis","summary":"The broom package standardizes the messy, inconsistent output from R's statistical models into clean, analysis-ready data frames. It's essential for data scientists who need to extract coefficients, model statistics, or predictions from models in a consistent format. The package works with over 100 model types, making it a go-to tool for anyone doing statistical modeling in R.","use_cases":"Extracting regression coefficients from multiple models to create comparison tables, Getting fitted values and residuals from various model types for diagnostic plotting","audience":"Junior-DS, Mid-DS"},{"id":"package-gt","type":"package","name":"gt","description":"Build display tables from tabular data using a cohesive grammar of table parts (header, stub, body, footer). Enables progressive construction of publication-quality tables with extensive formatting, footnotes, and cell styling. Outputs to HTML, LaTeX, and RTF.","category":"Regression Output","url":"https://cran.r-project.org/package=gt","difficulty":"beginner","prerequisites":"R-basics, data-frames","topic_tags":"table-formatting, publication-ready, HTML-output, data-presentation, R-visualization","summary":"The gt package provides a grammar of tables approach for creating publication-quality display tables in R. It allows progressive table construction with extensive formatting options, footnotes, and styling capabilities. Outputs can be generated for HTML, LaTeX, and RTF formats, making it ideal for reports, presentations, and academic publications.","use_cases":"Creating formatted regression output tables for academic papers with proper styling and footnotes, Building executive summary tables with custom formatting for business reports and dashboards","audience":"Junior-DS, Mid-DS"},{"id":"package-gtsummary","type":"package","name":"gtsummary","description":"Creates publication-ready analytical and summary tables (Table 1 demographics, regression results, survival analyses) with one line of code. Auto-detects variable types, calculates appropriate statistics, and formats regression models with reference rows and appropriate headers.","category":"Regression Output","url":"https://cran.r-project.org/package=gtsummary","difficulty":"beginner","prerequisites":"R-programming, regression-analysis, data-manipulation","topic_tags":"summary-tables, regression-output, publication-ready, clinical-research, reproducible-research","summary":"An R package that automatically generates publication-ready summary tables and regression output with minimal code. Popular in clinical research and academic settings for creating standardized Table 1 demographics and formatted regression results. Handles variable type detection and statistical formatting automatically.","use_cases":"Creating Table 1 demographics for a clinical trial publication, Formatting logistic regression results for an A/B test report","audience":"Junior-DS, Early-PhD"},{"id":"package-modelsummary","type":"package","name":"modelsummary","description":"Creates publication-quality tables summarizing multiple statistical models side-by-side, plus coefficient plots, data summaries, and correlation matrices. Supports 100+ model types via broom/parameters with output to HTML, LaTeX, Word, PDF, PNG, and Excel.","category":"Regression Output","url":"https://cran.r-project.org/package=modelsummary","difficulty":"beginner","prerequisites":"r-programming, linear-regression, ggplot2","topic_tags":"regression-tables, model-comparison, publication-ready, statistical-output, r-package","summary":"An R package that creates professional-looking tables comparing multiple statistical models side-by-side, perfect for academic papers and reports. It automatically formats regression coefficients, standard errors, and model statistics across 100+ model types. The package also generates coefficient plots and exports to multiple formats including LaTeX, HTML, and Word.","use_cases":"PhD student comparing different regression specifications in their dissertation chapter, Data scientist presenting A/B test results with multiple model variations to stakeholders","audience":"Junior-DS, Early-PhD"},{"id":"package-stargazer","type":"package","name":"stargazer","description":"Produces well-formatted LaTeX, HTML/CSS, and ASCII regression tables with multiple models side-by-side, plus summary statistics tables. Widely used in economics with journal-specific formatting styles (AER, QJE, ASR).","category":"Regression Output","url":"https://cran.r-project.org/package=stargazer","difficulty":"beginner","prerequisites":"R-programming, linear-regression, LaTeX-basics","topic_tags":"regression-tables, academic-publishing, LaTeX-output, R-packages, statistical-reporting","summary":"stargazer is an R package that creates publication-ready regression tables and summary statistics in LaTeX, HTML, and ASCII formats. It's the go-to tool for economics researchers who need to present multiple regression models side-by-side with professional formatting. The package supports journal-specific styles and handles complex table layouts automatically.","use_cases":"Creating regression tables for economics papers with multiple model specifications to show robustness checks, Generating formatted summary statistics tables for dataset descriptions in academic publications","audience":"Early-PhD, Junior-DS"},{"id":"package-texreg","type":"package","name":"texreg","description":"Converts coefficients, standard errors, significance stars, and fit statistics from statistical models into LaTeX, HTML, Word, or console output. Highly extensible with support for custom model types and confidence intervals.","category":"Regression Output","url":"https://cran.r-project.org/package=texreg","difficulty":"beginner","prerequisites":"R-regression-models, LaTeX-basics","topic_tags":"regression-tables, LaTeX-output, model-comparison, academic-publishing, R-package","summary":"R package that automatically formats regression model outputs into publication-ready tables for LaTeX, HTML, Word, or console display. Essential tool for academics and data scientists who need to present multiple models side-by-side with proper formatting. Saves hours of manual table creation and ensures consistent, professional presentation of statistical results.","use_cases":"Creating comparison tables of multiple regression models for academic paper submission, Generating HTML tables of A/B test results for stakeholder presentation","audience":"Early-PhD, Junior-DS"},{"id":"package-here","type":"package","name":"here","description":"Simple path construction from project root. Uses heuristics to find project root (RStudio, .git, .here) enabling portable paths that work across different machines and working directories.","category":"Reproducibility","url":"https://cran.r-project.org/package=here","difficulty":"beginner","prerequisites":"R-basics, file-systems","topic_tags":"file-paths, project-structure, R-package, reproducible-research","summary":"The 'here' package provides a simple solution for constructing file paths relative to your project root in R. It automatically detects project boundaries using common markers like .git folders or RStudio project files, eliminating hardcoded paths that break when code is shared or moved. Essential for creating reproducible analyses that work seamlessly across different machines and environments.","use_cases":"Loading data files in R scripts that need to work for collaborators with different folder structures, Building reproducible research projects where analysis scripts reference data and output folders consistently","audience":"Junior-DS, Early-PhD"},{"id":"package-renv","type":"package","name":"renv","description":"Project-local R dependency management. Creates reproducible environments by recording package versions in a lockfile, isolating project libraries, and enabling version restore.","category":"Reproducibility","url":"https://cran.r-project.org/package=renv","difficulty":"beginner","prerequisites":"R-programming, package-installation, version-control","topic_tags":"dependency-management, reproducible-research, R-environment, project-isolation","summary":"renv is an R package that creates isolated, reproducible project environments by managing package dependencies locally. It records exact package versions in a lockfile and allows teams to restore identical environments across different machines. Essential for ensuring research and analysis projects remain reproducible over time.","use_cases":"Sharing R analysis projects with collaborators while ensuring everyone uses identical package versions, Maintaining multiple R projects with different package version requirements without conflicts","audience":"Junior-DS, Mid-DS"},{"id":"package-rmarkdown","type":"package","name":"rmarkdown","description":"Dynamic documents combining R code with Markdown text. Generates reproducible reports in HTML, PDF, Word, and slides. Foundation for literate programming and reproducible research in R.","category":"Reproducibility","url":"https://cran.r-project.org/package=rmarkdown","difficulty":"beginner","prerequisites":"R-programming, markdown-syntax","topic_tags":"reproducible-research, report-generation, literate-programming, data-visualization, scientific-writing","summary":"R Markdown is a framework that combines R code with plain text to create dynamic, reproducible documents. It allows analysts to embed code, results, and visualizations directly into reports that can be exported to multiple formats. This makes it essential for creating transparent, updatable analysis reports in academic and industry settings.","use_cases":"Creating automated quarterly business reports that update with new data, Writing reproducible research papers with embedded statistical analysis and plots","audience":"Early-PhD, Junior-DS"},{"id":"package-targets","type":"package","name":"targets","description":"Make-like pipeline toolkit for R. Declares dependencies between pipeline steps, skips up-to-date targets, and supports parallel execution. Standard for reproducible research workflows.","category":"Reproducibility","url":"https://cran.r-project.org/package=targets","difficulty":"intermediate","prerequisites":"R-programming, command-line-basics, data-analysis-workflows","topic_tags":"workflow-management, reproducible-research, pipeline-automation, R-package, dependency-tracking","summary":"targets is R's premier pipeline management system that automatically tracks dependencies between analysis steps and only re-runs outdated components. It's become the gold standard for reproducible research workflows in R, replacing manual script orchestration with intelligent automation. Data scientists and researchers use it to build robust, scalable analysis pipelines that save time and prevent errors.","use_cases":"Managing a multi-step machine learning pipeline where data preprocessing, model training, and evaluation depend on each other, Coordinating a research project with multiple data sources, statistical analyses, and report generation that need to update when underlying data changes","audience":"Mid-DS, Early-PhD"},{"id":"package-clubsandwich","type":"package","name":"clubSandwich","description":"Provides cluster-robust variance estimators with small-sample corrections, including bias-reduced linearization (BRL/CR2). Includes functions for hypothesis testing with Satterthwaite degrees of freedom and Hotelling's T\u00b2 approximation\u2014essential when the number of clusters is small.","category":"Robust Standard Errors","url":"https://cran.r-project.org/package=clubSandwich","difficulty":"intermediate","prerequisites":"linear-regression, fixed-effects-models, clustered-data","topic_tags":"cluster-robust-standard-errors, small-sample-corrections, econometrics, causal-inference, r-package","summary":"clubSandwich is an R package that provides cluster-robust variance estimators with small-sample corrections, particularly useful when you have few clusters. It implements advanced methods like bias-reduced linearization (CR2) and provides proper hypothesis testing procedures when standard asymptotic assumptions break down due to small cluster counts.","use_cases":"A/B testing analysis with only 8-12 treatment markets where standard cluster-robust SEs are unreliable, Policy evaluation study with state-level treatment but only 20 states in the dataset","audience":"Mid-DS, Senior-DS"},{"id":"package-lmtest","type":"package","name":"lmtest","description":"Collection of tests for diagnostic checking in linear regression models. Provides the essential coeftest() function for testing coefficients with alternative variance-covariance matrices (pairs with sandwich), plus Breusch-Pagan, Durbin-Watson, and RESET tests.","category":"Robust Standard Errors","url":"https://cran.r-project.org/package=lmtest","difficulty":"beginner","prerequisites":"linear-regression, R-programming, sandwich-package","topic_tags":"regression-diagnostics, robust-standard-errors, heteroskedasticity, econometrics, R-package","summary":"Essential R package for testing assumptions in linear regression models. Provides coeftest() for robust standard errors and diagnostic tests like Breusch-Pagan for heteroskedasticity and Durbin-Watson for serial correlation. Standard tool for econometric analysis and ensuring regression validity.","use_cases":"Testing whether your regression residuals have constant variance before trusting coefficient estimates, Checking for serial correlation in time series regressions to validate model assumptions","audience":"Junior-DS, Early-PhD"},{"id":"package-sandwich","type":"package","name":"sandwich","description":"Object-oriented software for model-robust covariance matrix estimators including heteroscedasticity-consistent (HC0-HC5), heteroscedasticity- and autocorrelation-consistent (HAC/Newey-West), clustered, panel, and bootstrap covariances. Works with lm, glm, fixest, survival models, and many others.","category":"Robust Standard Errors","url":"https://cran.r-project.org/package=sandwich","difficulty":"intermediate","prerequisites":"linear-regression, R-programming, statistical-inference","topic_tags":"robust-standard-errors, heteroskedasticity, clustered-standard-errors, econometrics, R-package","summary":"The sandwich package provides robust covariance matrix estimators for regression models in R, addressing violations of standard assumptions like heteroskedasticity and autocorrelation. It's essential for econometric analysis where you need reliable standard errors and confidence intervals despite model misspecification. The package integrates seamlessly with popular modeling functions and offers various robust estimators including HC, HAC, and clustered variants.","use_cases":"Analyzing panel data with firm-level clustering to account for within-firm correlation in financial performance regressions, Correcting for heteroskedasticity in cross-sectional wage equations where variance increases with education level","audience":"Early-PhD, Mid-DS"},{"id":"package-(pysal-core)","type":"package","name":"(PySAL Core)","description":"The broader PySAL ecosystem contains many tools for spatial data handling, weights, visualization, and analysis.","category":"Spatial Econometrics","url":"https://github.com/pysal/pysal","difficulty":"intermediate","prerequisites":"python-pandas, geopandas, spatial-autocorrelation","topic_tags":"spatial-analysis, econometrics, python-package, geographic-data, spatial-weights","summary":"PySAL is Python's comprehensive spatial analysis library providing tools for exploratory spatial data analysis, spatial econometrics, and geographic modeling. It offers functionality for creating spatial weights matrices, testing for spatial autocorrelation, and running spatial regression models. The library is widely used by economists, geographers, and data scientists working with location-based data.","use_cases":"Analyzing housing price spillovers across neighborhoods using spatial lag models, Testing for geographic clustering in economic outcomes like unemployment rates","audience":"Mid-DS, Early-PhD"},{"id":"package-apache-sedona","type":"package","name":"Apache Sedona","description":"Distributed spatial analytics engine (formerly GeoSpark) with spatial SQL, K-NN joins, and range queries for spatial econometrics.","category":"Spatial Econometrics","url":"https://github.com/apache/sedona","difficulty":"intermediate","prerequisites":"apache-spark, SQL-queries, spatial-data-formats","topic_tags":"distributed-computing, spatial-analysis, geospatial-econometrics, big-data, spark-ecosystem","summary":"Apache Sedona is a distributed spatial analytics engine built on Apache Spark that enables large-scale geospatial analysis through spatial SQL operations. It provides efficient spatial joins, range queries, and K-nearest neighbor operations for processing massive spatial datasets. Tech economists use it to analyze location-based economic phenomena like market concentration, urban development patterns, and regional economic spillovers.","use_cases":"Analyzing ride-sharing market competition by calculating spatial proximity between drivers and demand hotspots across metropolitan areas, Measuring economic spillover effects by performing spatial joins between business locations and demographic data for regional policy research","audience":"Mid-DS, Senior-DS"},{"id":"package-pysal-(spreg)","type":"package","name":"PySAL (spreg)","description":"The spatial regression `spreg` module of PySAL. Implements spatial lag, error, IV models, and diagnostics.","category":"Spatial Econometrics","url":"https://github.com/pysal/spreg","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, geospatial-data","topic_tags":"spatial-regression, econometrics, geospatial-analysis, python-package, spatial-autocorrelation","summary":"PySAL's spreg module provides Python implementations of spatial regression models that account for geographic relationships in data. It handles spatial lag models (where nearby observations influence each other), spatial error models (where errors are spatially correlated), and instrumental variable approaches. Essential for economists and data scientists analyzing location-based phenomena like housing prices, regional economic development, or disease spread.","use_cases":"Analyzing how housing prices in one neighborhood affect prices in adjacent areas, Modeling regional unemployment rates while accounting for spillover effects between neighboring counties","audience":"Mid-DS, Early-PhD"},{"id":"package-sf","type":"package","name":"sf","description":"The modern standard for spatial vector data in R, implementing Simple Features access (ISO 19125). Represents spatial data as data frames with geometry list-columns, enabling seamless tidyverse integration. Interfaces with GDAL (I/O), GEOS (geometry operations), PROJ (projections), and s2 (spherical geometry).","category":"Spatial Econometrics","url":"https://cran.r-project.org/package=sf","difficulty":"beginner","prerequisites":"R-data-frames, basic-GIS-concepts, tidyverse-dplyr","topic_tags":"spatial-analysis, GIS-data, R-package, vector-geometry, geospatial","summary":"The sf package is the modern R standard for working with spatial vector data like points, lines, and polygons. It integrates seamlessly with tidyverse workflows by storing spatial geometries as special columns in regular data frames. This makes spatial data manipulation as intuitive as working with regular tabular data while providing access to powerful geospatial operations.","use_cases":"Analyzing retail store locations and customer demographics within geographic boundaries, Processing transportation networks and calculating route distances for logistics optimization","audience":"Junior-DS, Mid-DS"},{"id":"package-spatialreg","type":"package","name":"spatialreg","description":"Comprehensive package for spatial regression model estimation, split from spdep in 2019. Provides maximum likelihood, two-stage least squares, and GMM estimation for spatial lag (SAR), spatial error (SEM), and combined (SARAR/SAC) models, plus Spatial Durbin and SLX variants with impact calculations.","category":"Spatial Econometrics","url":"https://cran.r-project.org/package=spatialreg","difficulty":"intermediate","prerequisites":"spatial-autocorrelation, linear-regression, R-programming","topic_tags":"spatial-regression, spatial-econometrics, maximum-likelihood, spatial-autocorrelation, R-package","summary":"The spatialreg package provides comprehensive tools for estimating spatial regression models in R, handling spatial dependencies in cross-sectional data. It offers multiple estimation methods including maximum likelihood and GMM for spatial lag, spatial error, and combined models. Essential for economists and data scientists working with geographically clustered data where standard regression assumptions fail.","use_cases":"analyzing house prices with neighborhood spillover effects, studying regional economic growth with spatial interdependencies","audience":"Mid-DS, Early-PhD"},{"id":"package-spdep","type":"package","name":"spdep","description":"The foundational R package for spatial weights matrix creation and spatial autocorrelation testing. Provides functions for creating spatial weights from polygon contiguities and point patterns, computing global statistics (Moran's I, Geary's C), local indicators (LISA), and Lagrange multiplier tests.","category":"Spatial Econometrics","url":"https://cran.r-project.org/package=spdep","difficulty":"intermediate","prerequisites":"R-programming, spatial-data-structures, regression-analysis","topic_tags":"spatial-weights, spatial-autocorrelation, morans-i, neighborhood-analysis, R-package","summary":"The foundational R package for spatial econometrics that enables creation of spatial weights matrices and testing for spatial autocorrelation. Provides essential functions for defining neighborhood structures, computing Moran's I and Geary's C statistics, and running diagnostic tests for spatial dependence. Essential toolkit for any spatial analysis workflow in economics or regional science.","use_cases":"Testing whether house prices show spatial clustering patterns across neighborhoods, Analyzing regional unemployment spillovers and economic contagion effects","audience":"Early-PhD, Mid-DS"},{"id":"package-splm","type":"package","name":"splm","description":"Maximum likelihood and GMM estimation for spatial panel data models. Implements fixed and random effects specifications with spatial lag and/or spatial error components, including the Kapoor-Kelejian-Prucha (2007) GM estimator. Provides diagnostic tests for spatial autocorrelation in panel settings.","category":"Spatial Econometrics","url":"https://cran.r-project.org/package=splm","difficulty":"advanced","prerequisites":"panel-data-methods, spatial-econometrics, maximum-likelihood-estimation","topic_tags":"spatial-panel, econometric-methods, maximum-likelihood, GMM-estimation, spatial-autocorrelation","summary":"The splm package provides maximum likelihood and GMM estimation methods specifically designed for spatial panel data models. It handles complex econometric specifications including fixed and random effects with spatial lag and error components, implementing advanced estimators like Kapoor-Kelejian-Prucha. Essential for researchers analyzing panel data where observations exhibit spatial dependence across geographic units over time.","use_cases":"Analyzing regional economic growth patterns across states/countries over multiple years with spatial spillover effects, Estimating housing price dynamics across metropolitan areas accounting for neighborhood spatial correlation in panel data","audience":"Senior-DS, Early-PhD"},{"id":"package-awesome-quant","type":"package","name":"Awesome Quant","description":"Curated list of quantitative finance libraries and resources (many statistical/TS tools overlap with econometrics).","category":"Standard Errors, Bootstrapping & Reporting","url":"https://wilsonfreitas.github.io/awesome-quant/","difficulty":"beginner","prerequisites":"python-basics, statistical-inference, pandas-dataframes","topic_tags":"quantitative-finance, time-series, statistical-libraries, bootstrap, econometrics","summary":"A comprehensive collection of Python, R, and other libraries for quantitative finance, including tools for time series analysis, statistical modeling, and bootstrapping methods. Many of these libraries provide robust standard error calculations and resampling techniques that are directly applicable to econometric analysis. This curated list serves as a discovery tool for finding specialized packages for financial econometrics and statistical inference.","use_cases":"Finding Python libraries for calculating robust standard errors in financial time series models, Discovering R packages for bootstrap methods when analyzing market microstructure data","audience":"Junior-DS, Curious-browser"},{"id":"package-beyond-jupyter-(transferlab)","type":"package","name":"Beyond Jupyter (TransferLab)","description":"Teaches software design principles for ML\u2014modularity, abstraction, and reproducibility\u2014going beyond ad hoc Jupyter workflows. Focus on maintainable, production-quality ML code.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://transferlab.ai/trainings/beyond-jupyter/","difficulty":"intermediate","prerequisites":"jupyter-notebooks, python-scikit-learn, git-version-control","topic_tags":"software-engineering, ml-production, code-organization, reproducible-research, python-packaging","summary":"A comprehensive guide to transforming messy Jupyter notebook workflows into well-structured, maintainable ML codebases. Covers essential software engineering practices like modular design, abstraction layers, and automated testing for machine learning projects. Essential for data scientists transitioning from exploratory analysis to production-ready ML systems.","use_cases":"Refactoring a prototype ML model from notebooks into a deployable package, Setting up reproducible experiment tracking and model versioning for a research team","audience":"Junior-DS, Mid-DS"},{"id":"package-causal-inference-for-the-brave-and-true","type":"package","name":"Causal Inference for the Brave and True","description":"Modern introduction to causal inference methods (DiD, IV, RDD, Synth, ML-based) with Python code examples.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://matheusfacure.github.io/python-causality-handbook/","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, hypothesis-testing","topic_tags":"causal-inference, difference-in-differences, instrumental-variables, regression-discontinuity, python-implementation","summary":"A comprehensive guide to modern causal inference methods including Difference-in-Differences, Instrumental Variables, Regression Discontinuity Design, and Synthetic Controls with hands-on Python implementations. Designed for practitioners who want to move beyond correlational analysis to establish causal relationships in observational data. Combines theoretical foundations with practical coding examples for real-world applications.","use_cases":"Evaluating the causal impact of a product feature launch on user engagement using natural experiments, Measuring the effectiveness of a marketing campaign while controlling for selection bias and confounding factors","audience":"Junior-DS, Mid-DS"},{"id":"package-coding-for-economists","type":"package","name":"Coding for Economists","description":"Practical guide by A. Turrell on using Python for modern econometric research, data analysis, and workflows.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://aeturrell.github.io/coding-for-economists/","difficulty":"beginner","prerequisites":"python-basics, econometric-fundamentals","topic_tags":"python-econometrics, bootstrap-methods, standard-errors, econometric-workflows, data-analysis","summary":"A comprehensive guide by Arthur Turrell that teaches economists how to use Python for econometric analysis, focusing on practical implementation of standard error calculations and bootstrap methods. The resource bridges the gap between theoretical econometrics and modern programming practices, making it ideal for researchers transitioning from Stata or R to Python workflows.","use_cases":"Implementing robust standard errors in Python for regression analysis when transitioning from Stata, Setting up bootstrap confidence intervals for non-standard econometric estimators in research projects","audience":"Early-PhD, Junior-DS"},{"id":"package-deep-learning-specialization-(coursera)","type":"package","name":"Deep Learning Specialization (Coursera)","description":"Intermediate 5-course series by Andrew Ng covering deep neural networks, CNNs, RNNs, transformers, and real-world DL applications using TensorFlow.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://www.coursera.org/specializations/deep-learning","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, calculus","topic_tags":"deep-learning, neural-networks, tensorflow, computer-vision, nlp","summary":"Comprehensive 5-course specialization by Andrew Ng covering foundational and advanced deep learning concepts including CNNs, RNNs, and transformers. Provides hands-on experience with TensorFlow for building real-world deep learning applications. Ideal for practitioners transitioning from traditional ML to deep learning methods.","use_cases":"Building image classification models for product recommendation systems, Implementing sequence-to-sequence models for natural language processing tasks","audience":"Junior-DS, Mid-DS"},{"id":"package-machine-learning-specialization-(coursera)","type":"package","name":"Machine Learning Specialization (Coursera)","description":"Beginner-friendly 3-course series by Andrew Ng covering core ML methods (regression, classification, clustering, trees, NN) with hands-on projects.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://www.coursera.org/specializations/machine-learning-introduction/","difficulty":"beginner","prerequisites":"python-basics, linear-algebra","topic_tags":"machine-learning, supervised-learning, neural-networks, coursera, andrew-ng","summary":"Andrew Ng's comprehensive 3-course Machine Learning Specialization on Coursera provides a beginner-friendly introduction to core ML concepts including regression, classification, clustering, and neural networks. The program combines theoretical foundations with hands-on Python projects using popular libraries. Ideal for those starting their ML journey who want structured learning with practical implementation experience.","use_cases":"Building first predictive model for business metrics, Transitioning from traditional analytics to machine learning methods","audience":"Junior-DS, Curious-browser"},{"id":"package-python-for-econometrics","type":"package","name":"Python for Econometrics","description":"Comprehensive intro notes by Kevin Sheppard covering Python basics, core libraries, and econometrics applications.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://www.kevinsheppard.com/files/teaching/python/notes/python_introduction_2023.pdf","difficulty":"beginner","prerequisites":"basic-python-syntax, linear-regression","topic_tags":"python-econometrics, bootstrap-methods, standard-errors, intro-tutorial, kevin-sheppard","summary":"Kevin Sheppard's comprehensive introduction to using Python for econometric analysis, covering essential libraries like NumPy, Pandas, and statsmodels. The notes bridge basic Python programming with econometric applications, focusing on practical implementation of standard error calculations and bootstrapping techniques. Ideal for economists transitioning from R/Stata to Python or data scientists learning econometric methods.","use_cases":"Learning to implement robust standard errors and clustered standard errors in Python instead of Stata, Building bootstrap confidence intervals for econometric models using Python libraries","audience":"Early-PhD, Junior-DS"},{"id":"package-quantecon-lectures","type":"package","name":"QuantEcon Lectures","description":"High-quality lecture series on quantitative economic modeling, computational tools, and economics using Python/Julia.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://quantecon.org/lectures/","difficulty":"intermediate","prerequisites":"python-programming, basic-statistics, linear-regression","topic_tags":"bootstrap, standard-errors, quantitative-economics, computational-methods, python-lectures","summary":"Comprehensive lecture series covering quantitative economic modeling with focus on computational methods for statistical inference. Teaches bootstrap methods and standard error calculation techniques using Python and Julia for economic analysis. Designed for economists and data scientists who need rigorous statistical foundations for empirical work.","use_cases":"Calculating confidence intervals for regression coefficients in economic models, Implementing bootstrap procedures to assess uncertainty in policy impact estimates","audience":"Early-PhD, Mid-DS"},{"id":"package-scipy-bootstrap","type":"package","name":"SciPy Bootstrap","description":"(`scipy.stats.bootstrap`) Computes bootstrap confidence intervals for various statistics using percentile, BCa methods.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://github.com/scipy/scipy","difficulty":"beginner","prerequisites":"python-scipy, numpy-arrays, confidence-intervals","topic_tags":"bootstrap, confidence-intervals, statistical-inference, scipy, uncertainty-quantification","summary":"SciPy's bootstrap function provides a simple interface for computing bootstrap confidence intervals using resampling methods. It supports multiple confidence interval types including percentile and bias-corrected accelerated (BCa) methods. This is essential for quantifying uncertainty when analytical standard errors are difficult to derive.","use_cases":"Computing confidence intervals for complex statistics like median or correlation coefficients where analytical formulas are unavailable, Estimating uncertainty in A/B test metrics when sample distributions are non-normal or when dealing with ratio metrics","audience":"Junior-DS, Mid-DS"},{"id":"package-stargazer-1","type":"package","name":"Stargazer","description":"Python port of R's stargazer for creating publication-quality regression tables (HTML, LaTeX) from `statsmodels` & `linearmodels` results.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://github.com/StatsReporting/stargazer","difficulty":"beginner","prerequisites":"python-statsmodels, regression-analysis, latex-basics","topic_tags":"regression-tables, publication-formatting, statsmodels, latex-output, research-reporting","summary":"Stargazer is a Python package that creates professional, publication-ready regression tables from statsmodels and linearmodels results. It formats output for HTML and LaTeX, making it easy to include statistical results in academic papers and reports. The package is particularly valuable for researchers who need clean, standardized table formatting without manual work.","use_cases":"Creating formatted regression tables for academic paper submission with multiple model comparisons, Generating HTML tables of econometric results for internal research reports and presentations","audience":"Early-PhD, Junior-DS"},{"id":"package-the-missing-semester-of-your-cs-education-(mit)","type":"package","name":"The Missing Semester of Your CS Education (MIT)","description":"Teaches essential developer tools often skipped in formal education\u2014command line, Git, Vim, scripting, debugging, etc.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://missing.csail.mit.edu/","difficulty":"beginner","prerequisites":"basic-programming, command-line-basics","topic_tags":"developer-tools, command-line, git, vim, debugging","summary":"MIT's comprehensive course covering essential developer tools and workflows that are typically missing from computer science curricula. Teaches practical skills like shell scripting, version control, text editors, and debugging that are crucial for day-to-day programming work. Perfect foundation for anyone entering tech roles who needs to master the development environment.","use_cases":"New data scientist needs to learn Git for collaboration and version control of analysis code, PhD student wants to improve productivity with command-line tools and automated workflows for research","audience":"Junior-DS, Early-PhD"},{"id":"package-wildboottest","type":"package","name":"wildboottest","description":"Fast implementation of various wild cluster bootstrap algorithms (WCR, WCU) for robust inference, especially with few clusters.","category":"Standard Errors, Bootstrapping & Reporting","url":"https://github.com/py-econometrics/wildboottest","difficulty":"intermediate","prerequisites":"clustered-standard-errors, bootstrap-methods, python-regression","topic_tags":"wild-bootstrap, clustered-inference, robust-standard-errors, few-clusters, python-package","summary":"A Python package implementing fast wild cluster bootstrap algorithms for robust statistical inference when you have few clusters. It's particularly useful for economists and data scientists who need reliable confidence intervals and p-values in clustered data settings where traditional asymptotic methods fail. The package offers both restricted (WCR) and unrestricted (WCU) wild bootstrap variants with computational optimizations.","use_cases":"A/B testing with few treatment groups where you need robust confidence intervals for treatment effects, Evaluating policy interventions across states/regions when you have limited geographic clusters","audience":"Mid-DS, Senior-DS"},{"id":"package-filterpy","type":"package","name":"FilterPy","description":"Focuses on Kalman filters (standard, EKF, UKF) and smoothers with a clear, pedagogical implementation style.","category":"State Space & Volatility Models","url":"https://github.com/rlabbe/filterpy","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, bayesian-inference","topic_tags":"kalman-filter, time-series, state-estimation, python-package, signal-processing","summary":"FilterPy is a Python library that provides clear, educational implementations of Kalman filters and related state estimation algorithms. It's designed with a pedagogical approach, making complex filtering concepts accessible through well-documented code and examples. The library covers standard Kalman filters, Extended Kalman Filters (EKF), Unscented Kalman Filters (UKF), and various smoothing algorithms.","use_cases":"tracking user engagement states over time in product analytics, estimating hidden volatility regimes in financial time series data","audience":"Junior-DS, Mid-DS"},{"id":"package-metran","type":"package","name":"Metran","description":"Specialized package for estimating Dynamic Factor Models (DFM) using state-space methods and Kalman filtering.","category":"State Space & Volatility Models","url":"https://github.com/pastas/metran","difficulty":"advanced","prerequisites":"kalman-filtering, time-series-analysis, maximum-likelihood-estimation","topic_tags":"dynamic-factor-models, kalman-filtering, state-space-models, time-series, econometrics","summary":"Metran is a specialized package for estimating Dynamic Factor Models (DFM) that capture common trends across multiple time series using state-space representation and Kalman filtering. It's primarily used by econometricians and quantitative researchers working with high-dimensional time series data. The package enables decomposition of observed variables into common factors and idiosyncratic components for forecasting and dimensionality reduction.","use_cases":"Nowcasting GDP using mixed-frequency economic indicators, Risk factor modeling in finance with multiple asset return series","audience":"Senior-DS, Early-PhD"},{"id":"package-pykalman","type":"package","name":"PyKalman","description":"Implements Kalman filter, smoother, and EM algorithm for parameter estimation, including support for missing values and UKF.","category":"State Space & Volatility Models","url":"https://github.com/pykalman/pykalman","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, time-series-analysis","topic_tags":"kalman-filter, state-space-models, time-series, parameter-estimation, python-package","summary":"PyKalman is a Python implementation of Kalman filtering algorithms for state space modeling and time series analysis. It provides tools for filtering, smoothing, and parameter estimation using the EM algorithm, with robust handling of missing data. The package is particularly useful for economists and data scientists working with dynamic models and noisy time series data.","use_cases":"Tracking dynamic pricing models with noisy market data and missing observations, Estimating hidden economic indicators like consumer sentiment from observable market variables","audience":"Mid-DS, Senior-DS"},{"id":"package-pymc-statespace","type":"package","name":"PyMC Statespace","description":"(See Bayesian) Bayesian state-space modeling using PyMC, integrating Kalman filtering within MCMC for parameter estimation.","category":"State Space & Volatility Models","url":"https://github.com/pymc-devs/pymc-statespace","difficulty":"advanced","prerequisites":"PyMC-basics, Kalman-filtering, MCMC-methods","topic_tags":"state-space-models, Bayesian-inference, time-series, volatility-modeling, MCMC","summary":"PyMC Statespace combines Bayesian inference with state-space modeling by integrating Kalman filtering within MCMC parameter estimation. It enables researchers to model latent states and time-varying parameters with full uncertainty quantification. This package is particularly valuable for economists and data scientists working with dynamic systems where traditional frequentist approaches fall short.","use_cases":"Modeling time-varying volatility in financial returns with parameter uncertainty, Estimating latent economic states like business cycle phases with Bayesian credible intervals","audience":"Senior-DS, Early-PhD"},{"id":"package-stochvol","type":"package","name":"stochvol","description":"Efficient Bayesian estimation of stochastic volatility (SV) models using MCMC.","category":"State Space & Volatility Models","url":"https://github.com/rektory/stochvol","difficulty":"advanced","prerequisites":"MCMC-methods, bayesian-inference, time-series-analysis","topic_tags":"stochastic-volatility, bayesian-estimation, financial-econometrics, time-series, MCMC","summary":"The stochvol package provides efficient Bayesian estimation of stochastic volatility models using Markov Chain Monte Carlo methods. It's designed for researchers and practitioners working with financial time series who need to model time-varying volatility patterns. The package offers fast implementation of various SV model specifications with comprehensive diagnostic tools.","use_cases":"Modeling volatility clustering in stock returns for risk management applications, Estimating time-varying volatility parameters for option pricing and derivative valuation","audience":"Senior-DS, Early-PhD"},{"id":"package-hypors","type":"package","name":"HypoRS","description":"Hypothesis testing library for Rust with T-tests, Z-tests, ANOVA, Chi-square, designed to work seamlessly with Polars DataFrames.","category":"Statistical Inference & Hypothesis Testing","url":"https://crates.io/crates/hypors","difficulty":"intermediate","prerequisites":"rust-programming, statistical-hypothesis-testing, polars-dataframes","topic_tags":"hypothesis-testing, rust-statistics, statistical-inference, polars-integration, t-tests","summary":"HypoRS is a comprehensive hypothesis testing library for Rust that implements classical statistical tests including T-tests, Z-tests, ANOVA, and Chi-square tests. It's designed with seamless Polars DataFrame integration, making it ideal for data scientists working in the Rust ecosystem. The library provides a modern, performant alternative to Python's scipy.stats for statistical inference tasks.","use_cases":"A/B testing analysis on user engagement metrics stored in Polars DataFrames, Quality control testing in manufacturing data pipelines built with Rust","audience":"Mid-DS, Senior-DS"},{"id":"package-pingouin","type":"package","name":"Pingouin","description":"User-friendly interface for common statistical tests (ANOVA, ANCOVA, t-tests, correlations, chi\u00b2, reliability) built on pandas & scipy.","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/raphaelvallat/pingouin","difficulty":"beginner","prerequisites":"python-pandas, scipy-stats, statistical-hypothesis-testing","topic_tags":"statistical-testing, python-package, anova, correlation-analysis, t-tests","summary":"Pingouin is a beginner-friendly Python package that simplifies running common statistical tests like ANOVA, t-tests, and correlations with pandas-style syntax. It provides clean, interpretable outputs for hypothesis testing without requiring deep statistical programming knowledge. Perfect for data scientists who need reliable statistical inference tools with minimal setup complexity.","use_cases":"A/B testing conversion rates between different website variants using t-tests and effect size calculations, Analyzing survey data to test correlations between user satisfaction scores and product features","audience":"Junior-DS, Mid-DS"},{"id":"package-pywhy-stats","type":"package","name":"PyWhy-Stats","description":"Part of the PyWhy ecosystem providing statistical methods specifically for causal applications, including various independence tests and power-divergence methods.","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/py-why/pywhy-stats","difficulty":"intermediate","prerequisites":"python-pandas, scipy-stats, causal-inference-basics","topic_tags":"independence-tests, causal-inference, statistical-testing, python-package, hypothesis-testing","summary":"PyWhy-Stats is a specialized statistical package within the PyWhy ecosystem that provides independence tests and statistical methods tailored for causal inference applications. It offers implementations of various hypothesis tests and power-divergence methods specifically designed to support causal analysis workflows. Data scientists and researchers use it to test assumptions and validate statistical relationships in causal modeling pipelines.","use_cases":"Testing conditional independence assumptions before running a causal inference model, Validating instrumental variable assumptions by testing independence between instruments and confounders","audience":"Mid-DS, Senior-DS"},{"id":"package-scipy.stats","type":"package","name":"Scipy.stats","description":"Foundational module within SciPy for a wide range of statistical functions, distributions, and hypothesis tests (t-tests, ANOVA, chi\u00b2, KS, etc.).","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/scipy/scipy","difficulty":"beginner","prerequisites":"python-basics, numpy-arrays, descriptive-statistics","topic_tags":"statistical-testing, probability-distributions, python-statistics, hypothesis-testing, significance-testing","summary":"Scipy.stats is the go-to Python module for statistical analysis, providing implementations of dozens of probability distributions and essential hypothesis tests. It's the foundational toolkit for data scientists and researchers who need to perform statistical inference, from basic t-tests to complex goodness-of-fit tests. The module handles both the computational heavy-lifting and provides intuitive interfaces for common statistical workflows.","use_cases":"A/B testing analyst comparing conversion rates between two app versions using t-tests or chi-square tests, Research scientist validating that their experimental data follows a normal distribution before applying parametric methods","audience":"Junior-DS, Early-PhD"},{"id":"package-statrs","type":"package","name":"Statrs","description":"Comprehensive statistical distributions for Rust (Normal, T, Gamma, etc.) with PDF, CDF, quantile functions\u2014the scipy.stats equivalent.","category":"Statistical Inference & Hypothesis Testing","url":"https://crates.io/crates/statrs","difficulty":"intermediate","prerequisites":"rust-programming, probability-distributions, scipy-stats","topic_tags":"statistical-distributions, rust-statistics, probability-functions, quantile-methods","summary":"Statrs is a Rust library providing comprehensive statistical distributions with PDF, CDF, and quantile functions, serving as the Rust equivalent to Python's scipy.stats. It's designed for data scientists and researchers who need high-performance statistical computations in Rust applications. The library supports major distributions like Normal, T, Gamma, and others with reliable numerical implementations.","use_cases":"Building high-performance statistical applications in Rust that require probability calculations, Implementing Monte Carlo simulations or statistical models where Python's performance is insufficient","audience":"Mid-DS, Senior-DS"},{"id":"package-expectation","type":"package","name":"expectation","description":"E-values and game-theoretic probability for sequential testing. Enables early signal detection with proper error control.","category":"Statistical Inference & Hypothesis Testing","url":"https://pypi.org/project/expectation/","difficulty":"intermediate","prerequisites":"python-scipy, hypothesis-testing, sequential-analysis","topic_tags":"e-values, sequential-testing, game-theoretic-probability, early-stopping, statistical-inference","summary":"E-values provide a game-theoretic approach to hypothesis testing that enables continuous monitoring and early stopping with guaranteed error control. This package implements sequential testing methods that can detect signals as soon as they emerge, without the multiple testing penalties of traditional p-values. It's particularly valuable for A/B testing and clinical trials where early decision-making is critical.","use_cases":"A/B testing with early stopping when treatment effect is detected, Clinical trial monitoring for safety signals with continuous data collection","audience":"Mid-DS, Senior-DS"},{"id":"package-gcimpute","type":"package","name":"gcimpute","description":"Gaussian copula imputation for mixed variable types with streaming capability (Journal of Statistical Software 2024).","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/udellgroup/gcimpute","difficulty":"intermediate","prerequisites":"python-pandas, missing-data-theory, copula-models","topic_tags":"gaussian-copula, missing-data, imputation, mixed-data-types, streaming-data","summary":"A Python package implementing Gaussian copula-based imputation for datasets with mixed variable types (continuous, categorical, ordinal). It handles missing data by modeling the dependence structure between variables using copulas, with streaming capability for large datasets that don't fit in memory.","use_cases":"Imputing missing values in customer datasets with mixed demographics and behavioral features, Preprocessing large streaming datasets with missing entries for real-time ML pipelines","audience":"Mid-DS, Senior-DS"},{"id":"package-hypothetical","type":"package","name":"hypothetical","description":"Library focused on hypothesis testing: ANOVA/MANOVA, t-tests, chi-square, Fisher's exact, nonparametric tests (Mann-Whitney, Kruskal-Wallis, etc.).","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/aschleg/hypothetical","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, p-values","topic_tags":"hypothesis-testing, statistical-tests, anova, t-tests, nonparametric","summary":"A Python library providing comprehensive hypothesis testing tools including parametric tests (t-tests, ANOVA) and nonparametric alternatives (Mann-Whitney, Kruskal-Wallis). Essential for data scientists and researchers who need to validate statistical claims and compare groups in their analyses. Offers both classical and robust testing methods with clear result interpretation.","use_cases":"Testing whether a new feature significantly improves user engagement metrics across different user segments, Comparing treatment effectiveness across multiple groups in a clinical trial or A/B test experiment","audience":"Junior-DS, Early-PhD"},{"id":"package-lifelines","type":"package","name":"lifelines","description":"Comprehensive library for survival analysis: Kaplan-Meier, Nelson-Aalen, Cox regression, AFT models, handling censored data.","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/CamDavidsonPilon/lifelines","difficulty":"intermediate","prerequisites":"python-pandas, scipy-stats, regression-analysis","topic_tags":"survival-analysis, kaplan-meier, cox-regression, censored-data, python-library","summary":"Lifelines is a Python library for survival analysis that handles time-to-event data with censoring. It provides implementations of key survival models including Kaplan-Meier curves, Cox proportional hazards, and accelerated failure time models. Data scientists and researchers use it to analyze customer churn, equipment failure, clinical trials, and other duration-based phenomena.","use_cases":"Analyzing customer subscription lifetimes and churn patterns for retention modeling, Studying user engagement duration and feature adoption survival curves in product analytics","audience":"Mid-DS, Senior-DS"},{"id":"package-miceforest","type":"package","name":"miceforest","description":"LightGBM-accelerated multiple imputation by chained equations. Fast MICE for large datasets.","category":"Statistical Inference & Hypothesis Testing","url":"https://github.com/AnotherSamWilson/miceforest","difficulty":"intermediate","prerequisites":"python-pandas, missing-data-mechanisms, gradient-boosting","topic_tags":"multiple-imputation, missing-data, lightgbm, mice, data-preprocessing","summary":"miceforest is a Python package that implements Multiple Imputation by Chained Equations (MICE) using LightGBM as the underlying model. It provides a fast, scalable solution for handling missing data in large datasets by leveraging gradient boosting instead of traditional linear models. The package is particularly useful for data scientists working with complex datasets where missing data patterns are non-linear.","use_cases":"Imputing missing values in customer datasets with mixed data types before running machine learning models, Handling missing survey responses in social science research with complex interaction patterns","audience":"Mid-DS, Junior-DS"},{"id":"package-savvi","type":"package","name":"savvi","description":"Safe Anytime Valid Inference using e-processes and confidence sequences (Ramdas et al. 2023). Valid inference at any stopping time.","category":"Statistical Inference & Hypothesis Testing","url":"https://pypi.org/project/savvi/","difficulty":"advanced","prerequisites":"hypothesis-testing, sequential-analysis, martingale-theory","topic_tags":"sequential-testing, anytime-valid-inference, e-processes, confidence-sequences, optional-stopping","summary":"SAVVI implements e-processes and confidence sequences for statistically valid inference at any stopping time, solving the optional stopping problem in sequential testing. It enables researchers to peek at results and stop experiments early while maintaining statistical validity. Particularly valuable for A/B testing and adaptive trial designs where traditional p-values break down under sequential monitoring.","use_cases":"Running A/B tests where you need to monitor results continuously and stop early if significant effects are detected, Clinical trials or expensive experiments where you want valid statistical inference even when stopping rules depend on observed data","audience":"Senior-DS, Early-PhD"},{"id":"package-dolo","type":"package","name":"Dolo","description":"Framework for describing and solving economic models (DSGE, OLG, etc.) using a declarative YAML-based format.","category":"Structural Econometrics & Estimation","url":"https://github.com/EconForge/dolo","difficulty":"advanced","prerequisites":"python-programming, dynamic-programming, macroeconomic-theory","topic_tags":"dsge-models, economic-modeling, yaml-configuration, dynamic-programming, macroeconomics","summary":"Dolo is a Python framework that allows economists to specify and solve complex dynamic economic models using human-readable YAML configuration files. It handles DSGE models, overlapping generations models, and other structural economic frameworks with built-in solution algorithms. The declarative approach separates model specification from solution methods, making economic models more reproducible and easier to modify.","use_cases":"Building and solving DSGE models for monetary policy analysis without writing low-level numerical code, Comparing solution methods across different overlapping generations models using consistent YAML specifications","audience":"Early-PhD, Senior-DS"},{"id":"package-greeners","type":"package","name":"Greeners","description":"Comprehensive Rust econometrics library with OLS, IV, panel data estimators, fixed effects, DiD, and heteroskedasticity-robust standard errors (HC0-HC3).","category":"Structural Econometrics & Estimation","url":"https://crates.io/crates/greeners","difficulty":"intermediate","prerequisites":"rust-programming, linear-regression, instrumental-variables","topic_tags":"rust-econometrics, panel-data, difference-in-differences, robust-standard-errors, instrumental-variables","summary":"Greeners is a comprehensive Rust econometrics library offering core estimation methods including OLS, instrumental variables, and panel data models. It provides robust standard error corrections and implements difference-in-differences estimators with fixed effects capabilities. The library is designed for economists and data scientists who need high-performance econometric analysis in Rust environments.","use_cases":"Estimating causal effects of policy interventions using difference-in-differences with panel data, Running instrumental variables regressions with heteroskedasticity-robust standard errors for program evaluation","audience":"Mid-DS, Senior-DS"},{"id":"package-hark","type":"package","name":"HARK","description":"Toolkit for solving, simulating, and estimating models with heterogeneous agents (e.g., consumption-saving).","category":"Structural Econometrics & Estimation","url":"https://github.com/econ-ark/HARK","difficulty":"advanced","prerequisites":"dynamic-programming, maximum-likelihood-estimation, numerical-optimization","topic_tags":"heterogeneous-agents, consumption-saving, structural-models, lifecycle-models, behavioral-economics","summary":"HARK is a Python toolkit for building and estimating structural economic models with heterogeneous agents, particularly focused on consumption-saving problems. It provides pre-built model classes and numerical methods for solving dynamic optimization problems commonly found in macroeconomics and household finance research. Researchers use it to estimate parameters, run policy simulations, and test theoretical predictions against empirical data.","use_cases":"Estimating how different types of households respond to changes in interest rates or income uncertainty, Simulating the distributional effects of tax policy changes on consumption and savings behavior","audience":"Early-PhD, Senior-DS"},{"id":"package-quantecon.py","type":"package","name":"QuantEcon.py","description":"Core library for quantitative economics: dynamic programming, Markov chains, game theory, numerical methods.","category":"Structural Econometrics & Estimation","url":"https://github.com/QuantEcon/QuantEcon.py","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, dynamic-programming","topic_tags":"dynamic-programming, markov-chains, game-theory, numerical-methods, python-library","summary":"QuantEcon.py is a comprehensive Python library providing computational tools for quantitative economics research and analysis. It implements core methods including dynamic programming solvers, Markov chain analysis, game theory algorithms, and numerical optimization routines. The library is widely used by economists and data scientists for structural modeling, policy analysis, and theoretical research.","use_cases":"Solving dynamic economic models like optimal consumption-savings problems with value function iteration, Analyzing market competition using Nash equilibrium computation and evolutionary game dynamics","audience":"Early-PhD, Mid-DS"},{"id":"package-dcegm","type":"package","name":"dcegm","description":"JAX-compatible DC-EGM algorithm for discrete-continuous dynamic programming (Iskhakov et al. 2017).","category":"Structural Econometrics & Estimation","url":"https://github.com/OpenSourceEconomics/dcegm","difficulty":"advanced","prerequisites":"dynamic-programming, JAX, structural-models","topic_tags":"discrete-continuous-choice, endogenous-grid-method, computational-economics, JAX-implementation, dynamic-programming","summary":"JAX implementation of the DC-EGM (Discrete-Continuous Endogenous Grid Method) algorithm for solving dynamic programming problems with both discrete and continuous choices. This method efficiently handles complex structural models where agents make simultaneous decisions across different choice dimensions. Essential for researchers working on lifecycle models, consumption-saving problems, or any structural model combining discrete and continuous optimization.","use_cases":"Estimating lifecycle consumption-saving models with discrete labor supply choices, Solving dynamic investment problems with both portfolio allocation and participation decisions","audience":"Senior-DS, Early-PhD"},{"id":"package-econpizza","type":"package","name":"econpizza","description":"Solve nonlinear heterogeneous agent models (HANK) with perfect foresight. Efficient perturbation and projection methods.","category":"Structural Econometrics & Estimation","url":"https://github.com/gboehl/econpizza","difficulty":"advanced","prerequisites":"python-programming, dynamic-programming, DSGE-modeling","topic_tags":"heterogeneous-agents, DSGE, macroeconomics, nonlinear-models, python-package","summary":"Econpizza is a Python package for solving complex heterogeneous agent New Keynesian (HANK) models with nonlinear dynamics and perfect foresight. It implements efficient perturbation and projection methods for macroeconomic models where agents have different characteristics. Primarily used by macroeconomists and central bank researchers working on monetary policy analysis.","use_cases":"Analyzing monetary policy transmission through heterogeneous household responses to interest rate changes, Studying fiscal policy effects when agents have different income levels and borrowing constraints","audience":"Senior-DS, Early-PhD"},{"id":"package-geconpy","type":"package","name":"gEconpy","description":"DSGE modeling tools inspired by R's gEcon. Automatic first-order condition derivation with Dynare export.","category":"Structural Econometrics & Estimation","url":"https://github.com/jessegrabowski/gEconpy","difficulty":"advanced","prerequisites":"python-sympy, DSGE-modeling, maximum-likelihood-estimation","topic_tags":"DSGE, structural-modeling, macroeconomics, dynare, python-package","summary":"gEconpy is a Python package for building and estimating Dynamic Stochastic General Equilibrium (DSGE) models, inspired by R's gEcon package. It automatically derives first-order conditions from economic models and exports them to Dynare for numerical solution. The tool is primarily used by macroeconomists and researchers working on structural economic models.","use_cases":"Building a New Keynesian DSGE model to analyze monetary policy transmission mechanisms, Estimating parameters of a real business cycle model using Bayesian methods via Dynare integration","audience":"Early-PhD, Senior-DS"},{"id":"package-gegravity","type":"package","name":"gegravity","description":"General equilibrium structural gravity modeling for trade policy analysis. Only Python package for Anderson-van Wincoop GE gravity.","category":"Structural Econometrics & Estimation","url":"https://pypi.org/project/gegravity/","difficulty":"advanced","prerequisites":"trade-economics, structural-econometrics, python-pandas","topic_tags":"gravity-models, trade-policy, general-equilibrium, structural-econometrics, python-package","summary":"gegravity is a specialized Python package for structural gravity modeling in international trade, implementing the Anderson-van Wincoop general equilibrium framework. It's designed for trade economists and policy analysts who need to estimate how trade costs, tariffs, and other policies affect bilateral trade flows. The package is unique as the only Python implementation of GE gravity models, making advanced trade policy analysis more accessible.","use_cases":"Estimating the trade effects of Brexit or other trade policy changes using structural gravity models, Analyzing how transportation infrastructure investments affect bilateral trade patterns through reduced trade costs","audience":"Early-PhD, Senior-DS"},{"id":"package-pydsge","type":"package","name":"pydsge","description":"DSGE model simulation, filtering, and Bayesian estimation. Handles occasionally binding constraints.","category":"Structural Econometrics & Estimation","url":"https://github.com/gboehl/pydsge","difficulty":"advanced","prerequisites":"python-scipy, bayesian-mcmc, macroeconomic-theory","topic_tags":"DSGE-models, bayesian-estimation, macroeconomic-modeling, structural-econometrics, kalman-filtering","summary":"Python package for Dynamic Stochastic General Equilibrium (DSGE) model simulation, filtering, and Bayesian estimation with support for occasionally binding constraints like zero lower bound. Primarily used by macroeconomists and central bank researchers for structural macroeconomic modeling and policy analysis. Enables full Bayesian estimation workflow from model specification to posterior inference.","use_cases":"Central bank economist estimating a New Keynesian DSGE model with zero lower bound constraints for monetary policy analysis, Academic researcher conducting Bayesian estimation of medium-scale DSGE model to study business cycle dynamics","audience":"Senior-DS, Early-PhD"},{"id":"package-pynare","type":"package","name":"pynare","description":"Python wrapper/interface to Dynare for DSGE model solving. Bridge between Python workflows and Dynare.","category":"Structural Econometrics & Estimation","url":"https://github.com/gboehl/pynare","difficulty":"intermediate","prerequisites":"python-basics, DSGE-modeling, Dynare-syntax","topic_tags":"DSGE, macroeconomic-modeling, python-wrapper, structural-estimation, dynare","summary":"Pynare is a Python wrapper that provides an interface to Dynare, allowing economists to solve Dynamic Stochastic General Equilibrium (DSGE) models within Python workflows. It bridges the gap between Python's data science ecosystem and Dynare's specialized DSGE modeling capabilities. This tool is particularly useful for researchers who want to integrate macroeconomic modeling with Python-based analysis pipelines.","use_cases":"Running DSGE model simulations and parameter estimation within Jupyter notebooks alongside other economic analysis, Building automated pipelines that combine DSGE model results with Python data processing and visualization tools","audience":"Early-PhD, Senior-DS"},{"id":"package-respy","type":"package","name":"respy","description":"Simulation and estimation of finite-horizon dynamic discrete choice (DDC) models (e.g., labor/education choice).","category":"Structural Econometrics & Estimation","url":"https://github.com/OpenSourceEconomics/respy","difficulty":"advanced","prerequisites":"maximum-likelihood-estimation, dynamic-programming, python-numpy","topic_tags":"dynamic-discrete-choice, structural-models, labor-economics, simulation, estimation","summary":"respy is a Python package for simulating and estimating finite-horizon dynamic discrete choice models, commonly used in labor and education economics. It allows researchers to model sequential decision-making processes where agents make discrete choices (like work vs. education) over time. The package handles the computational complexity of solving and estimating these structural models using methods like maximum likelihood.","use_cases":"Modeling career decisions where individuals choose between working, attending school, or staying home over their lifetime, Estimating the returns to education by modeling how people decide when to enter/exit schooling based on expected future earnings","audience":"Senior-DS, Early-PhD"},{"id":"package-upper-envelope","type":"package","name":"upper-envelope","description":"Fast upper envelope scan for discrete-continuous dynamic programming. JAX and numba implementations.","category":"Structural Econometrics & Estimation","url":"https://github.com/OpenSourceEconomics/upper-envelope","difficulty":"advanced","prerequisites":"dynamic-programming, JAX-optimization, structural-models","topic_tags":"upper-envelope, dynamic-programming, structural-estimation, JAX, numba","summary":"Fast upper envelope scan implementation for discrete-continuous dynamic programming problems in structural econometrics. Provides optimized JAX and numba backends for computing upper envelopes efficiently in complex optimization routines. Essential for researchers solving high-dimensional structural models where computational speed is critical.","use_cases":"Estimating dynamic labor supply models with discrete job choices and continuous hours decisions, Solving firm investment problems with discrete capacity expansion and continuous investment levels","audience":"Senior-DS, Early-PhD"},{"id":"package-openmx","type":"package","name":"OpenMx","description":"Extended SEM software with programmatic model specification via paths (RAM) or matrix algebra, supporting mixture distributions, item factor analysis, state space models, and behavior genetics twin studies.","category":"Structural Equation Modeling","url":"https://cran.r-project.org/package=OpenMx","difficulty":"advanced","prerequisites":"structural-equation-modeling, matrix-algebra, R-programming","topic_tags":"SEM, latent-variables, behavior-genetics, twin-studies, matrix-specification","summary":"OpenMx is an advanced R package for structural equation modeling that allows programmatic model specification through path diagrams or matrix algebra. It extends beyond basic SEM to support complex models including mixture distributions, item factor analysis, state space models, and specialized behavior genetics applications like twin studies.","use_cases":"Modeling genetic and environmental influences on traits using twin study data, Building custom latent variable models with non-standard distributions or constraints","audience":"Senior-DS, Early-PhD"},{"id":"package-blavaan","type":"package","name":"blavaan","description":"Bayesian latent variable analysis extending lavaan with MCMC estimation via Stan or JAGS, supporting Bayesian CFA, SEM, growth models, and model comparison with WAIC, LOO, and Bayes factors.","category":"Structural Equation Modeling","url":"https://cran.r-project.org/package=blavaan","difficulty":"advanced","prerequisites":"lavaan-SEM, Stan-MCMC, Bayesian-statistics","topic_tags":"Bayesian-SEM, latent-variable-modeling, MCMC-estimation, structural-equation-modeling, Stan","summary":"blavaan extends the popular lavaan package to perform Bayesian structural equation modeling using MCMC estimation via Stan or JAGS. It enables researchers to incorporate prior knowledge, quantify uncertainty through posterior distributions, and perform robust model comparison using Bayesian information criteria. This package is essential for psychometricians and social scientists who need principled uncertainty quantification in their latent variable models.","use_cases":"Testing measurement invariance across groups while incorporating prior knowledge about factor loadings, Building confirmatory factor analysis models with informative priors when sample sizes are small","audience":"Senior-DS, Early-PhD"},{"id":"package-lavaan","type":"package","name":"lavaan","description":"Free, open-source latent variable analysis providing commercial-quality functionality for path analysis, confirmatory factor analysis, structural equation modeling, and growth curve models with intuitive model syntax.","category":"Structural Equation Modeling","url":"https://cran.r-project.org/package=lavaan","difficulty":"intermediate","prerequisites":"R-programming, linear-regression, factor-analysis","topic_tags":"structural-equation-modeling, confirmatory-factor-analysis, latent-variables, psychometrics, R-package","summary":"lavaan is an R package for structural equation modeling that provides an intuitive syntax for specifying complex latent variable models. It's widely used by researchers in psychology, marketing, and social sciences for testing theoretical frameworks and measurement models. The package offers comprehensive functionality for path analysis, confirmatory factor analysis, and growth curve modeling with robust statistical output.","use_cases":"Testing whether customer satisfaction mediates the relationship between product quality and purchase intention, Validating a multi-factor survey instrument by confirming the underlying latent construct structure","audience":"Early-PhD, Mid-DS"},{"id":"package-sdv-(synthetic-data-vault)","type":"package","name":"SDV (Synthetic Data Vault)","description":"Comprehensive library for generating synthetic tabular, relational, and time series data using various models.","category":"Synthetic Data Generation","url":"https://github.com/sdv-dev/SDV","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, statistical-distributions","topic_tags":"synthetic-data, privacy-preserving, tabular-data, data-simulation, generative-models","summary":"SDV is a comprehensive Python library for generating synthetic data that maintains statistical properties of original datasets. It supports tabular, relational, and time series data using various generative models including GANs and statistical approaches. Data scientists and researchers use it for privacy-preserving analytics, testing pipelines, and data augmentation.","use_cases":"Creating synthetic customer data for model testing when production data contains PII, Generating additional training samples for machine learning models with limited data","audience":"Junior-DS, Mid-DS"},{"id":"package-synthpop","type":"package","name":"Synthpop","description":"Port of the R package for generating synthetic populations based on sample survey data.","category":"Synthetic Data Generation","url":"https://github.com/alan-turing-institute/synthpop","difficulty":"intermediate","prerequisites":"python-pandas, survey-sampling, data-privacy-techniques","topic_tags":"synthetic-data, survey-simulation, privacy-preserving, population-modeling, r-package-port","summary":"Synthpop is a Python port of the popular R package that generates synthetic datasets mimicking the statistical properties of original survey data while preserving privacy. It's widely used by researchers and data scientists who need realistic fake data for testing, sharing, or publication. The package implements multiple synthesis methods to create populations that maintain the relationships and distributions found in sensitive source data.","use_cases":"Creating shareable datasets for academic research when original survey data contains PII, Generating realistic test data for validating analysis pipelines before accessing production survey data","audience":"Mid-DS, Senior-DS"},{"id":"package-quanteda","type":"package","name":"quanteda","description":"Comprehensive framework for quantitative text analysis. Provides fast text preprocessing, document-feature matrices, dictionary analysis, and integration with topic models. Standard for political science text analysis.","category":"Text Analysis","url":"https://cran.r-project.org/package=quanteda","difficulty":"intermediate","prerequisites":"R-programming, document-term-matrices, text-tokenization","topic_tags":"text-analysis, R-package, document-feature-matrix, political-text-analysis, NLP-preprocessing","summary":"Quanteda is R's leading package for quantitative text analysis, offering efficient text preprocessing, document-feature matrix creation, and dictionary-based analysis. Widely adopted in political science and social science research for analyzing large text corpora. Provides seamless integration with topic modeling and other advanced text mining techniques.","use_cases":"analyzing political speeches and manifestos to identify policy positions across parties, processing social media data to measure public sentiment toward policy changes","audience":"Early-PhD, Mid-DS"},{"id":"package-stm","type":"package","name":"stm","description":"Structural Topic Models incorporating document-level metadata as covariates affecting topic prevalence and content. Enables studying how topics vary across groups or time with uncertainty quantification.","category":"Text Analysis","url":"https://cran.r-project.org/package=stm","difficulty":"intermediate","prerequisites":"topic-modeling-LDA, R-programming, bayesian-inference","topic_tags":"structural-topic-models, document-covariates, text-mining, bayesian-nlp, metadata-analysis","summary":"STM extends traditional topic modeling by incorporating document-level metadata (like author, time, or group) as covariates that can influence both topic prevalence and content. Unlike standard LDA, it allows researchers to study how topics systematically vary across different conditions while providing proper uncertainty quantification. Popular among social scientists and applied researchers analyzing textual data with rich metadata.","use_cases":"Analyzing how political speech topics change over time periods or across party affiliations, Studying how product review themes vary by customer demographics or product categories","audience":"Mid-DS, Senior-DS"},{"id":"package-text2vec","type":"package","name":"text2vec","description":"Efficient text vectorization with word embeddings (GloVe), topic models (LDA), and document similarity. Memory-efficient streaming API for large corpora with C++ backend.","category":"Text Analysis","url":"https://cran.r-project.org/package=text2vec","difficulty":"intermediate","prerequisites":"python-programming, natural-language-processing, matrix-operations","topic_tags":"text-vectorization, word-embeddings, topic-modeling, document-similarity, R-package","summary":"text2vec is an R package for efficient text analysis providing word embeddings (GloVe), topic modeling (LDA), and document similarity calculations. It features a memory-efficient streaming API with C++ backend for processing large text corpora. Popular among data scientists for feature engineering and text preprocessing in machine learning pipelines.","use_cases":"Building recommendation systems by computing document similarity between user profiles and product descriptions, Creating word embeddings for sentiment analysis or text classification models in production","audience":"Junior-DS, Mid-DS"},{"id":"package-tidytext","type":"package","name":"tidytext","description":"Tidy data principles for text mining. Converts text to tidy format (one-token-per-row), enabling analysis with dplyr, ggplot2, and other tidyverse tools. Accompanies the book 'Text Mining with R'.","category":"Text Analysis","url":"https://cran.r-project.org/package=tidytext","difficulty":"beginner","prerequisites":"R-dplyr, basic-text-preprocessing, ggplot2","topic_tags":"text-mining, tidyverse, tokenization, sentiment-analysis, R-package","summary":"tidytext is an R package that applies tidy data principles to text analysis by converting text into one-token-per-row format. It integrates seamlessly with tidyverse tools like dplyr and ggplot2, making text mining accessible to users familiar with tidy data workflows. The package is designed around the companion book 'Text Mining with R' and provides intuitive functions for tokenization, sentiment analysis, and text visualization.","use_cases":"Analyzing customer reviews or survey responses to extract sentiment and key themes, Processing social media posts or news articles to identify trending topics and perform word frequency analysis","audience":"Junior-DS, Curious-browser"},{"id":"package-arch","type":"package","name":"ARCH","description":"Specialized library for modeling and forecasting conditional volatility using ARCH, GARCH, EGARCH, and related models.","category":"Time Series Econometrics","url":"https://github.com/bashtage/arch","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, maximum-likelihood-estimation","topic_tags":"volatility-modeling, GARCH, financial-econometrics, heteroskedasticity, python-package","summary":"ARCH is a Python library for modeling time-varying volatility in financial and economic time series using ARCH, GARCH, and related models. It's widely used by quantitative analysts and researchers to forecast conditional variance and analyze volatility clustering. The package provides easy-to-use implementations of various volatility models with diagnostic tools and forecasting capabilities.","use_cases":"Modeling and forecasting stock return volatility for risk management, Analyzing volatility clustering in cryptocurrency prices for trading strategies","audience":"Mid-DS, Senior-DS"},{"id":"package-kfas","type":"package","name":"KFAS","description":"State space modeling framework for exponential family time series with computationally efficient Kalman filtering, smoothing, forecasting, and simulation. Supports observations from Gaussian, Poisson, binomial, negative binomial, and gamma distributions.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=KFAS","difficulty":"intermediate","prerequisites":"kalman-filters, maximum-likelihood-estimation, R-programming","topic_tags":"state-space-models, kalman-filtering, time-series-forecasting, exponential-family, R-package","summary":"KFAS is an R package for state space modeling with exponential family distributions, providing efficient Kalman filter implementations for non-Gaussian time series. It enables researchers and practitioners to handle complex time series with count data, binary outcomes, or other non-normal distributions while maintaining computational efficiency. The package is particularly valuable for econometric modeling where traditional Gaussian assumptions are violated.","use_cases":"modeling-weekly-retail-sales-with-poisson-distributed-counts, forecasting-binary-market-events-with-time-varying-probabilities","audience":"Mid-DS, Senior-DS"},{"id":"package-kats","type":"package","name":"Kats","description":"Broad toolkit for time series analysis, including multivariate analysis, detection (outliers, change points, trends), feature extraction.","category":"Time Series Econometrics","url":"https://github.com/facebookresearch/Kats","difficulty":"intermediate","prerequisites":"python-pandas, statsmodels, time-series-basics","topic_tags":"time-series-analysis, anomaly-detection, changepoint-detection, forecasting, multivariate-analysis","summary":"Kats is a comprehensive Python toolkit developed by Facebook for time series analysis and forecasting. It provides unified APIs for detection tasks like outlier identification, changepoint analysis, and trend detection, along with feature extraction capabilities. The package is designed for practitioners who need robust time series tools beyond basic forecasting.","use_cases":"Detecting anomalies in user engagement metrics for A/B test validity, Identifying structural breaks in revenue time series during product launches","audience":"Mid-DS, Senior-DS"},{"id":"package-localprojections","type":"package","name":"LocalProjections","description":"Community implementations of Jord\u00e0 (2005) Local Projections for estimating impulse responses without VAR assumptions.","category":"Time Series Econometrics","url":"https://github.com/elenev/localprojections","difficulty":"intermediate","prerequisites":"time-series-analysis, linear-regression, impulse-response-functions","topic_tags":"local-projections, impulse-response, time-series, causal-inference, econometrics","summary":"Local Projections is a method for estimating impulse response functions that avoids the restrictive assumptions of Vector Autoregressions (VARs). It directly estimates the response of variables to shocks at different horizons using separate regressions, making it more robust to model misspecification. Popular in macroeconomics and finance for analyzing policy effects and market dynamics.","use_cases":"Estimating how GDP responds to monetary policy shocks over multiple quarters, Analyzing stock market reactions to earnings announcements across different time horizons","audience":"Mid-DS, Early-PhD"},{"id":"package-ts-flint","type":"package","name":"TS-Flint","description":"Two Sigma's time-series library for Spark with optimized temporal joins, as-of joins, and distributed OLS for high-frequency data.","category":"Time Series Econometrics","url":"https://github.com/twosigma/flint","difficulty":"intermediate","prerequisites":"apache-spark, python-pandas, SQL-joins","topic_tags":"time-series, spark-distributed, temporal-joins, financial-data, econometrics","summary":"TS-Flint is Two Sigma's open-source time series library built on Apache Spark for handling large-scale temporal data. It provides optimized temporal joins, as-of joins, and distributed statistical methods like OLS regression specifically designed for high-frequency financial and economic data. The library enables efficient analysis of time series data that's too large for single-machine processing.","use_cases":"Analyzing high-frequency trading data by joining price feeds with news events using as-of joins to avoid look-ahead bias, Running distributed OLS regressions on large panels of stock returns with market factors across multiple time periods","audience":"Mid-DS, Senior-DS"},{"id":"package-dlm","type":"package","name":"dlm","description":"Maximum likelihood and Bayesian analysis of Normal linear state space models (Dynamic Linear Models). Features numerically stable SVD-based algorithms for Kalman filtering and smoothing, plus tools for MCMC-based Bayesian inference including forward filtering backward sampling (FFBS).","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=dlm","difficulty":"intermediate","prerequisites":"linear-algebra, maximum-likelihood-estimation, time-series-basics","topic_tags":"state-space-models, kalman-filtering, bayesian-inference, time-series-econometrics, r-package","summary":"The dlm package provides robust implementations of Dynamic Linear Models for time series analysis with unobserved state variables. It offers both classical maximum likelihood estimation via numerically stable Kalman filtering and Bayesian MCMC methods including forward filtering backward sampling. Economists and data scientists use it for modeling time-varying parameters, forecasting with uncertainty quantification, and analyzing structural breaks in economic data.","use_cases":"modeling-time-varying-coefficients-in-regression, forecasting-macroeconomic-variables-with-uncertainty","audience":"Mid-DS, Early-PhD"},{"id":"package-dynlm","type":"package","name":"dynlm","description":"Provides an interface for fitting dynamic linear regression models with extended formula syntax. Supports convenient lag operators L(), differencing d(), trend(), season(), and harmonic components while preserving time series attributes.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=dynlm","difficulty":"intermediate","prerequisites":"linear-regression, time-series-analysis, R-programming","topic_tags":"dynamic-regression, lag-operators, time-series-modeling, econometric-packages, R-package","summary":"dynlm is an R package that simplifies fitting dynamic linear regression models by extending standard formula syntax with lag operators, differencing, and seasonal components. It's particularly useful for econometricians and data scientists working with time series data who need to model relationships with lagged variables. The package maintains time series properties while providing intuitive syntax for complex temporal modeling.","use_cases":"modeling-sales-with-lagged-advertising-effects, estimating-distributed-lag-models-for-policy-impact-analysis","audience":"Mid-DS, Early-PhD"},{"id":"package-mfilter","type":"package","name":"mFilter","description":"Implements time series filters for extracting trend and cyclical components. Includes Hodrick-Prescott, Baxter-King, Christiano-Fitzgerald, Butterworth, and trigonometric regression filters commonly used in macroeconomics and business cycle analysis.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=mFilter","difficulty":"intermediate","prerequisites":"time-series-analysis, python-pandas, macroeconomic-indicators","topic_tags":"time-series-filtering, business-cycle-analysis, trend-extraction, macroeconometrics, detrending-methods","summary":"mFilter is a Python package that implements classic econometric filters for decomposing time series into trend and cyclical components. It provides ready-to-use implementations of Hodrick-Prescott, Baxter-King, and other filters commonly used in macroeconomic research and business cycle analysis. Essential for economists and data scientists working with economic time series data.","use_cases":"Extracting business cycle fluctuations from GDP data to study economic recessions and expansions, Detrending financial time series to isolate short-term volatility from long-term growth patterns","audience":"Early-PhD, Mid-DS"},{"id":"package-strucchange","type":"package","name":"strucchange","description":"Testing, monitoring, and dating structural changes in linear regression models. Implements the generalized fluctuation test framework (CUSUM, MOSUM, recursive estimates) and F-test framework (Chow test, supF, aveF, expF) with breakpoint estimation and confidence intervals.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=strucchange","difficulty":"intermediate","prerequisites":"linear-regression, time-series-analysis, R-programming","topic_tags":"structural-breaks, econometric-testing, time-series, regression-diagnostics, R-package","summary":"The strucchange package provides comprehensive tools for detecting when coefficients in linear regression models change over time. It implements multiple testing frameworks including CUSUM tests and Chow tests to identify structural breaks and estimate breakpoint dates with confidence intervals. Essential for economists and data scientists analyzing policy changes, market shifts, or other regime changes in time series data.","use_cases":"Testing whether a marketing campaign caused a structural break in customer conversion rates, Identifying when economic policy changes affected the relationship between unemployment and inflation","audience":"Mid-DS, Early-PhD"},{"id":"package-tsdyn","type":"package","name":"tsDyn","description":"Implements nonlinear autoregressive time series models including threshold AR (TAR/SETAR), smooth transition AR (STAR, LSTAR), and multivariate extensions (TVAR, TVECM). Enables regime-switching dynamics analysis with parametric and non-parametric approaches.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=tsDyn","difficulty":"intermediate","prerequisites":"time-series-analysis, autoregressive-models, R-programming","topic_tags":"nonlinear-time-series, regime-switching, threshold-models, econometrics, R-package","summary":"tsDyn is an R package for fitting nonlinear autoregressive time series models that can switch between different regimes based on threshold values or smooth transitions. It's particularly valuable for economists and data scientists analyzing financial markets, macroeconomic indicators, or any time series where relationships change over time. The package supports both univariate models (TAR, SETAR, STAR) and multivariate extensions (TVAR, TVECM) for complex economic systems.","use_cases":"Modeling stock market volatility that behaves differently during bull vs bear markets, Analyzing central bank policy transmission effects that vary across economic cycles","audience":"Mid-DS, Senior-DS"},{"id":"package-urca","type":"package","name":"urca","description":"Implements unit root and cointegration tests commonly used in applied econometric analysis. Includes Augmented Dickey-Fuller, Phillips-Perron, KPSS, Elliott-Rothenberg-Stock, and Zivot-Andrews tests, plus Johansen's cointegration procedure for multivariate series.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=urca","difficulty":"intermediate","prerequisites":"time-series-analysis, linear-regression, R-programming","topic_tags":"unit-root-testing, cointegration, time-series, stationarity, econometrics","summary":"The urca package provides essential statistical tests for analyzing time series stationarity and long-run relationships between variables. It implements standard econometric tests like ADF and KPSS for unit roots, plus Johansen's method for testing cointegration between multiple series. These tools are fundamental for proper time series modeling and avoiding spurious regression results.","use_cases":"Testing whether stock prices or economic indicators are stationary before building forecasting models, Analyzing long-run equilibrium relationships between related financial variables like interest rates and exchange rates","audience":"Mid-DS, Early-PhD"},{"id":"package-vars","type":"package","name":"vars","description":"Comprehensive package for Vector Autoregression (VAR), Structural VAR (SVAR), and Structural Vector Error Correction (SVEC) models. Provides estimation, lag selection, diagnostic testing, forecasting, Granger causality analysis, impulse response functions, and forecast error variance decomposition.","category":"Time Series Econometrics","url":"https://cran.r-project.org/package=vars","difficulty":"intermediate","prerequisites":"multivariate-statistics, R-programming, time-series-analysis","topic_tags":"VAR-models, impulse-response, Granger-causality, structural-econometrics, R-package","summary":"The vars package is R's comprehensive toolkit for Vector Autoregression analysis, enabling economists to model relationships between multiple time series variables simultaneously. It provides end-to-end functionality from model estimation and diagnostic testing to advanced techniques like impulse response functions and forecast error variance decomposition. Essential for researchers studying macroeconomic dynamics, policy transmission mechanisms, and causal relationships in multivariate time series data.","use_cases":"Analyzing how monetary policy shocks propagate through macroeconomic variables like GDP, inflation, and unemployment, Studying dynamic relationships between tech company metrics like user growth, revenue, and engagement over time","audience":"Mid-DS, Early-PhD"},{"id":"package-augurs","type":"package","name":"Augurs","description":"Time series forecasting and analysis for Rust with ETS, MSTL decomposition, seasonality detection, outlier detection, and Prophet-style models.","category":"Time Series Forecasting","url":"https://crates.io/crates/augurs","difficulty":"intermediate","prerequisites":"rust-programming, time-series-basics, statistical-forecasting","topic_tags":"time-series-forecasting, rust-programming, seasonality-detection, outlier-detection, exponential-smoothing","summary":"Augurs is a Rust library for time series forecasting that implements classical methods like ETS (Exponential Smoothing) and MSTL decomposition alongside modern approaches like Prophet-style models. It provides a high-performance toolkit for seasonality detection, outlier identification, and production-ready forecasting workflows. The library is designed for developers who need fast, reliable time series analysis in Rust environments.","use_cases":"Building high-performance demand forecasting systems for e-commerce inventory management, Implementing real-time anomaly detection in IoT sensor data streams","audience":"Mid-DS, Senior-DS"},{"id":"package-mlforecast","type":"package","name":"MLForecast","description":"Scalable time series forecasting using machine learning models (e.g., LightGBM, XGBoost) as regressors.","category":"Time Series Forecasting","url":"https://github.com/Nixtla/mlforecast","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, lightgbm-xgboost","topic_tags":"time-series, machine-learning, forecasting, scalable-ml, python-package","summary":"MLForecast is a Python package that applies machine learning models like LightGBM and XGBoost to time series forecasting problems. It provides a scalable framework for converting time series data into supervised learning problems with engineered features. The package is designed for practitioners who want to leverage gradient boosting methods for forecasting at scale.","use_cases":"Forecasting daily sales across thousands of retail SKUs using historical patterns and external features, Predicting server resource usage across multiple data centers using machine learning regressors","audience":"Junior-DS, Mid-DS"},{"id":"package-neuralforecast","type":"package","name":"NeuralForecast","description":"Deep learning models (N-BEATS, N-HiTS, Transformers, RNNs) for time series forecasting, built on PyTorch Lightning.","category":"Time Series Forecasting","url":"https://github.com/Nixtla/neuralforecast","difficulty":"intermediate","prerequisites":"python-pytorch, time-series-analysis, neural-networks","topic_tags":"neural-forecasting, deep-learning, time-series, pytorch-lightning","summary":"NeuralForecast is a PyTorch Lightning-based library that implements state-of-the-art deep learning models for time series forecasting, including N-BEATS, N-HiTS, and Transformer architectures. It's designed for data scientists and researchers who need to apply advanced neural network methods to forecasting problems. The package provides production-ready implementations with built-in training workflows and model evaluation capabilities.","use_cases":"Forecasting daily sales for retail chains with complex seasonal patterns, Predicting server resource usage for capacity planning in cloud infrastructure","audience":"Mid-DS, Senior-DS"},{"id":"package-prophet","type":"package","name":"Prophet","description":"Forecasting procedure for time series with strong seasonality and trend components, developed by Facebook.","category":"Time Series Forecasting","url":"https://github.com/facebook/prophet","difficulty":"beginner","prerequisites":"python-pandas, time-series-concepts, basic-regression","topic_tags":"time-series-forecasting, seasonality-modeling, trend-analysis, facebook-prophet, business-forecasting","summary":"Prophet is an automated forecasting tool designed for business time series with daily observations that display patterns on different time scales. It handles seasonality, holidays, and trend changes automatically with minimal parameter tuning. The package is particularly effective for forecasting problems where you have historical data with strong seasonal effects.","use_cases":"Forecasting daily active users or revenue for a tech product with weekly and yearly seasonality, Predicting demand for e-commerce items accounting for holidays and promotional events","audience":"Junior-DS, Mid-DS"},{"id":"package-statsforecast","type":"package","name":"StatsForecast","description":"Fast, scalable implementations of popular statistical forecasting models (ETS, ARIMA, Theta, etc.) optimized for performance.","category":"Time Series Forecasting","url":"https://github.com/Nixtla/statsforecast","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, statistical-models","topic_tags":"statistical-forecasting, time-series, arima, exponential-smoothing, python-package","summary":"StatsForecast is a high-performance Python package that implements classical statistical forecasting methods like ARIMA, ETS, and Theta models with optimized speed and scalability. It's designed for practitioners who need reliable, fast implementations of established forecasting techniques rather than cutting-edge ML approaches. The package is particularly useful for production forecasting workflows where interpretability and computational efficiency matter.","use_cases":"Forecasting daily sales across thousands of SKUs in retail, Predicting server resource usage for capacity planning","audience":"Junior-DS, Mid-DS"},{"id":"package-fable","type":"package","name":"fable","description":"A tidyverse-native forecasting framework providing ETS, ARIMA, and other models for tidy time series (tsibble objects). Enables fitting multiple models across many time series simultaneously with a consistent formula-based interface.","category":"Time Series Forecasting","url":"https://cran.r-project.org/package=fable","difficulty":"intermediate","prerequisites":"R-dplyr, time-series-decomposition, tsibble-objects","topic_tags":"forecasting, tidyverse, time-series, R-package, ARIMA","summary":"fable is an R package that brings forecasting models like ARIMA and ETS into the tidyverse ecosystem, working seamlessly with tsibble time series objects. It allows analysts to fit multiple forecasting models across hundreds of time series simultaneously using familiar dplyr-style syntax. The package is particularly valuable for scaling forecasting workflows while maintaining code readability and reproducibility.","use_cases":"Forecasting demand across thousands of product SKUs in retail analytics, Generating revenue predictions for multiple business units or geographic regions","audience":"Junior-DS, Mid-DS"},{"id":"package-forecast","type":"package","name":"forecast","description":"The foundational R package for univariate time series forecasting. Provides methods for exponential smoothing via state space models (ETS), automatic ARIMA modeling with auto.arima(), TBATS for complex seasonality, and comprehensive model evaluation tools.","category":"Time Series Forecasting","url":"https://cran.r-project.org/package=forecast","difficulty":"beginner","prerequisites":"basic-R, univariate-time-series, descriptive-statistics","topic_tags":"time-series, ARIMA, exponential-smoothing, forecasting, R-package","summary":"The forecast package is R's go-to tool for univariate time series forecasting, offering automated model selection and forecasting methods. It's widely used by analysts and researchers for its user-friendly interface to complex forecasting techniques like ARIMA and exponential smoothing. The package excels at handling seasonal patterns and provides comprehensive diagnostic tools for model evaluation.","use_cases":"forecasting monthly sales revenue for business planning, predicting daily website traffic for capacity planning","audience":"Junior-DS, Mid-DS"},{"id":"package-pmdarima","type":"package","name":"pmdarima","description":"ARIMA modeling with automatic parameter selection (auto-ARIMA), similar to R's `forecast::auto.arima`.","category":"Time Series Forecasting","url":"https://github.com/alkaline-ml/pmdarima","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, statsmodels","topic_tags":"auto-arima, time-series-forecasting, parameter-tuning, python-package","summary":"pmdarima is a Python package that automatically selects optimal ARIMA model parameters for time series forecasting, eliminating manual hyperparameter tuning. It provides a user-friendly interface similar to R's auto.arima function, making ARIMA modeling accessible to practitioners without deep statistical expertise. The package handles data preprocessing, model selection, and forecast generation in a streamlined workflow.","use_cases":"Forecasting monthly sales revenue with automatic model selection, Predicting daily website traffic without manual ARIMA parameter tuning","audience":"Junior-DS, Mid-DS"},{"id":"package-prophet-1","type":"package","name":"prophet","description":"Automatic forecasting procedure based on an additive decomposable model with non-linear trends, yearly/weekly/daily seasonality, and holiday effects. Robust to missing data, trend shifts, and outliers; designed for business time series with strong seasonal patterns.","category":"Time Series Forecasting","url":"https://cran.r-project.org/package=prophet","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, matplotlib","topic_tags":"time-series-forecasting, business-analytics, seasonality, trend-analysis, automated-forecasting","summary":"Prophet is Facebook's open-source forecasting tool that automatically generates predictions for business time series data with minimal configuration. It handles seasonal patterns, holidays, and missing data out-of-the-box, making it accessible to analysts without deep forecasting expertise. The tool excels at business metrics like daily active users, revenue, or inventory demand that show strong seasonal patterns.","use_cases":"Forecasting daily website traffic for capacity planning, Predicting monthly sales revenue accounting for seasonal trends and holidays","audience":"Junior-DS, Mid-DS"},{"id":"package-sktime","type":"package","name":"sktime","description":"Unified framework for various time series tasks, including forecasting with classical, ML, and deep learning models.","category":"Time Series Forecasting","url":"https://github.com/sktime/sktime","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, time-series-decomposition","topic_tags":"time-series-forecasting, scikit-learn-compatible, python-package, machine-learning, classical-forecasting","summary":"sktime is a scikit-learn compatible Python package that provides a unified interface for time series forecasting, classification, and regression. It combines classical statistical methods (ARIMA, exponential smoothing) with modern machine learning and deep learning approaches in a single framework. The package is designed to make time series analysis more accessible while maintaining the flexibility needed for advanced modeling.","use_cases":"Forecasting product demand across multiple SKUs with different seasonal patterns, Predicting server resource usage to optimize cloud infrastructure scaling","audience":"Junior-DS, Mid-DS"},{"id":"package-catboost","type":"package","name":"CatBoost","description":"Gradient boosting library excelling with categorical features (minimal preprocessing needed). Robust against overfitting.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/catboost/catboost","difficulty":"intermediate","prerequisites":"python-scikit-learn, gradient-boosting, cross-validation","topic_tags":"gradient-boosting, categorical-features, ensemble-methods, overfitting-prevention","summary":"CatBoost is a gradient boosting library that handles categorical features natively without requiring extensive preprocessing like one-hot encoding. It's particularly popular among data scientists for its robustness against overfitting and competitive performance in machine learning competitions and production systems.","use_cases":"E-commerce recommendation systems with mixed categorical and numerical user/product features, Customer churn prediction using demographic categories and behavioral metrics","audience":"Junior-DS, Mid-DS"},{"id":"package-lightgbm","type":"package","name":"LightGBM","description":"Fast, distributed gradient boosting (also supports RF). Known for speed, low memory usage, and handling large datasets.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/microsoft/LightGBM","difficulty":"intermediate","prerequisites":"python-scikit-learn, gradient-boosting, pandas-dataframes","topic_tags":"gradient-boosting, ensemble-methods, high-performance-ml, large-datasets, python-package","summary":"LightGBM is a high-performance gradient boosting framework that excels at handling large datasets with minimal memory usage. It's widely adopted by data scientists and ML engineers for its speed and efficiency compared to other boosting methods like XGBoost. The package supports both gradient boosting and random forests, making it versatile for various prediction tasks.","use_cases":"Predicting user conversion rates on large e-commerce datasets with millions of records, Building real-time recommendation systems that need fast inference on high-dimensional feature sets","audience":"Junior-DS, Mid-DS"},{"id":"package-linfa","type":"package","name":"Linfa","description":"Rust ML toolkit inspired by scikit-learn with GLMs, clustering (K-Means), PCA, SVM, and regularization (Lasso/Ridge).","category":"Tree & Ensemble Methods for Prediction","url":"https://crates.io/crates/linfa","difficulty":"intermediate","prerequisites":"rust-programming, scikit-learn, linear-regression","topic_tags":"rust-ml, scikit-learn-alternative, systems-programming, performance-optimization, ml-toolkit","summary":"Linfa is a Rust-based machine learning toolkit that provides scikit-learn-inspired APIs for common ML algorithms including GLMs, clustering, and dimensionality reduction. It offers memory-safe, high-performance implementations suitable for production systems where speed and reliability are critical. The library is ideal for developers building ML pipelines in Rust or those seeking alternatives to Python-based ML stacks.","use_cases":"Building high-performance ML microservices in Rust where Python's GIL creates bottlenecks, Implementing ML algorithms in embedded systems or edge computing environments requiring memory safety","audience":"Mid-DS, Senior-DS"},{"id":"package-ngboost","type":"package","name":"NGBoost","description":"Extends gradient boosting to probabilistic prediction, providing uncertainty estimates alongside point predictions. Built on scikit-learn.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/stanfordmlgroup/ngboost","difficulty":"intermediate","prerequisites":"scikit-learn, gradient-boosting, probability-distributions","topic_tags":"uncertainty-quantification, probabilistic-prediction, gradient-boosting, ensemble-methods","summary":"NGBoost extends traditional gradient boosting to output full probability distributions instead of just point predictions, enabling uncertainty quantification in machine learning models. It's particularly valuable for data scientists who need to understand prediction confidence and risk assessment. Built on scikit-learn, it maintains familiar APIs while adding probabilistic capabilities.","use_cases":"Predicting customer lifetime value with confidence intervals for business planning, Medical diagnosis predictions where uncertainty bounds are critical for clinical decisions","audience":"Mid-DS, Senior-DS"},{"id":"package-scikit-learn-ens.","type":"package","name":"Scikit-learn Ens.","description":"(`RandomForestClassifier`/`Regressor`) Widely-used, versatile implementation of Random Forests. Easy API and parallel processing support.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/scikit-learn/scikit-learn","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn-basics, train-test-split","topic_tags":"random-forest, ensemble-methods, classification, regression, feature-importance","summary":"Scikit-learn's Random Forest implementation provides an easy-to-use interface for building ensemble models that combine multiple decision trees. It's one of the most popular machine learning algorithms for both classification and regression tasks, offering built-in feature importance scores and robust performance across diverse datasets. The implementation includes automatic parallelization and handles mixed data types well.","use_cases":"Predicting customer churn using mixed categorical and numerical features, Estimating house prices with feature importance ranking for real estate analysis","audience":"Junior-DS, Mid-DS"},{"id":"package-smartcore","type":"package","name":"SmartCore","description":"Rust ML library with regression, classification, clustering, matrix decomposition (SVD, PCA), and model selection tools.","category":"Tree & Ensemble Methods for Prediction","url":"https://crates.io/crates/smartcore","difficulty":"intermediate","prerequisites":"rust-programming, linear-algebra, supervised-learning","topic_tags":"rust-ml, systems-programming, performance-optimization, cross-platform-ml, native-compilation","summary":"SmartCore is a comprehensive machine learning library built in Rust, offering high-performance implementations of regression, classification, clustering, and dimensionality reduction algorithms. It's designed for developers who need fast, memory-safe ML computations with native performance. The library provides a full suite of model selection and evaluation tools alongside core algorithms.","use_cases":"Building high-performance ML pipelines in production systems where speed and memory safety are critical, Developing cross-platform ML applications that need to compile to native binaries without runtime dependencies","audience":"Mid-DS, Senior-DS"},{"id":"package-xgboost-1","type":"package","name":"XGBoost","description":"High-performance, optimized gradient boosting library (also supports RF). Known for speed, efficiency, and winning competitions.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/dmlc/xgboost","difficulty":"intermediate","prerequisites":"python-sklearn, decision-trees, cross-validation","topic_tags":"gradient-boosting, ensemble-methods, competition-ml, tree-models, feature-importance","summary":"XGBoost is a highly optimized gradient boosting framework that combines multiple weak learners (typically decision trees) to create powerful predictive models. It's widely adopted in industry and competitive machine learning for its exceptional performance, built-in regularization, and efficient handling of missing values. The library provides both regression and classification capabilities with extensive hyperparameter tuning options.","use_cases":"Predicting customer churn with mixed categorical and numerical features, Building recommendation system ranking models for e-commerce platforms","audience":"Junior-DS, Mid-DS"},{"id":"package-cuml-(rapids)","type":"package","name":"cuML (RAPIDS)","description":"GPU-accelerated implementation of Random Forests for significant speedups on large datasets. Scikit-learn compatible API.","category":"Tree & Ensemble Methods for Prediction","url":"https://github.com/rapidsai/cuml","difficulty":"intermediate","prerequisites":"scikit-learn, python-pandas, CUDA-programming","topic_tags":"random-forest, GPU-acceleration, scikit-learn-compatible, large-scale-ml, RAPIDS","summary":"cuML is NVIDIA's GPU-accelerated machine learning library that provides scikit-learn compatible implementations of popular algorithms like Random Forests. It delivers significant performance speedups on large datasets by leveraging GPU parallelization while maintaining familiar APIs. Data scientists can drop it in as a replacement for scikit-learn models when working with datasets that benefit from GPU acceleration.","use_cases":"Training Random Forest models on millions of e-commerce transactions for fraud detection, Running large-scale feature selection experiments on genomics datasets with thousands of features","audience":"Mid-DS, Senior-DS"},{"id":"package-causallift","type":"package","name":"CausalLift","description":"Uplift modeling for observational (non-RCT) data using inverse probability weighting.","category":"Uplift Modeling","url":"https://github.com/Minyus/causallift","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-scikit-learn, randomized-controlled-trials","topic_tags":"uplift-modeling, causal-inference, treatment-effects, observational-data, python-package","summary":"CausalLift is a Python package for uplift modeling that estimates treatment effects from observational data using inverse probability weighting. It helps data scientists identify which individuals are most likely to respond positively to treatments when randomized experiments aren't feasible. The package is particularly useful for marketing campaigns and policy interventions where you need to estimate causal effects from non-experimental data.","use_cases":"Estimating which customers would increase purchases if targeted with a marketing campaign using historical transaction data, Evaluating the effectiveness of a new feature rollout on user engagement when A/B testing wasn't initially implemented","audience":"Mid-DS, Senior-DS"},{"id":"package-upliftml","type":"package","name":"UpliftML","description":"Booking.com's enterprise uplift modeling via PySpark and H2O. Six meta-learners plus Uplift Random Forest with ROI-constrained optimization.","category":"Uplift Modeling","url":"https://github.com/bookingcom/upliftml","difficulty":"intermediate","prerequisites":"pyspark-ml, causal-inference, scikit-learn","topic_tags":"uplift-modeling, treatment-effects, marketing-optimization, causal-ml, pyspark","summary":"UpliftML is Booking.com's production-ready uplift modeling library that combines six meta-learners with Uplift Random Forest for measuring treatment effects. Built on PySpark and H2O for enterprise scale, it includes ROI-constrained optimization to maximize business impact. Data scientists use it to optimize marketing campaigns and personalization strategies by identifying which customers will respond positively to treatments.","use_cases":"Optimizing email marketing campaigns by identifying customers most likely to convert when contacted, Personalizing discount offers by finding users who need incentives versus those who would purchase anyway","audience":"Mid-DS, Senior-DS"},{"id":"package-pylift","type":"package","name":"pylift","description":"Wayfair's uplift modeling wrapping sklearn for speed with rigorous Qini curve evaluation.","category":"Uplift Modeling","url":"https://github.com/wayfair/pylift","difficulty":"intermediate","prerequisites":"python-sklearn, causal-inference, A-B-testing","topic_tags":"uplift-modeling, treatment-effects, marketing-attribution, qini-curves, causal-ml","summary":"pylift is Wayfair's Python package that extends scikit-learn for uplift modeling, enabling practitioners to identify which customers will respond positively to treatments. It provides fast implementations with rigorous evaluation through Qini curves, making it practical for marketing and product experimentation at scale.","use_cases":"Identifying which customers to target with promotional campaigns based on predicted treatment response, Optimizing product recommendation strategies by modeling individual-level causal effects","audience":"Mid-DS, Senior-DS"},{"id":"package-cowplot","type":"package","name":"cowplot","description":"Publication-ready ggplot2 themes and plot arrangement utilities. Provides clean themes, plot annotations, and functions for combining plots with shared axes.","category":"Visualization","url":"https://cran.r-project.org/package=cowplot","difficulty":"beginner","prerequisites":"R-ggplot2, data-visualization, R-programming","topic_tags":"data-visualization, publication-graphics, plot-themes, R-package","summary":"Cowplot is an R package that extends ggplot2 with publication-ready themes and utilities for combining multiple plots. It provides clean, minimalist themes and functions to arrange plots with shared legends and aligned axes. Popular among researchers and analysts who need to create professional figures for papers, reports, and presentations.","use_cases":"Creating multi-panel figures for academic papers with consistent formatting, Building dashboard-style layouts combining different chart types with shared legends","audience":"Junior-DS, Early-PhD"},{"id":"package-patchwork","type":"package","name":"patchwork","description":"Compose multiple ggplot2 plots into publication-ready multi-panel figures. Uses intuitive operators (+, |, /) for arrangement with automatic alignment and shared legends.","category":"Visualization","url":"https://cran.r-project.org/package=patchwork","difficulty":"beginner","prerequisites":"ggplot2-basics, R-programming","topic_tags":"data-visualization, publication-figures, multi-panel-plots, ggplot2-extension","summary":"Patchwork is an R package that simplifies combining multiple ggplot2 plots into cohesive multi-panel figures using intuitive operators. It automatically handles plot alignment, shared legends, and spacing, making it easy to create publication-quality composite visualizations. The package is essential for researchers and analysts who need to present multiple related plots in a single figure.","use_cases":"Creating multi-panel figures for academic papers showing results across different conditions or datasets, Building dashboards with multiple related visualizations that need consistent alignment and shared aesthetics","audience":"Junior-DS, Mid-DS"},{"id":"dataset-lmsys-chat-1m","type":"dataset","name":"LMSYS-Chat-1M","description":"1M real-world conversations with 25 state-of-the-art LLMs spanning 154 languages","category":"AI & LLM","url":"https://huggingface.co/datasets/lmsys/lmsys-chat-1m","difficulty":"intermediate","prerequisites":"python-pandas, huggingface-transformers, text-preprocessing","topic_tags":"conversational-ai, llm-evaluation, multilingual-data, chatbot-analysis, natural-language","summary":"A comprehensive dataset containing 1 million real conversations between users and 25 different state-of-the-art language models across 154 languages. This resource enables researchers and practitioners to analyze conversational patterns, evaluate LLM performance, and study multilingual chatbot interactions at scale.","use_cases":"Benchmarking chatbot performance across different languages and comparing response quality between LLM models, Training conversation classifiers or building datasets for fine-tuning conversational AI systems","audience":"Mid-DS, Senior-DS"},{"id":"dataset-diqad","type":"dataset","name":"DiQAD","description":"100K real-world user dialogues with comprehensive 6-dimension quality assessment","category":"AI & LLM","url":"https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation","difficulty":"intermediate","prerequisites":"python-pandas, natural-language-processing, data-preprocessing","topic_tags":"dialogue-systems, quality-metrics, conversational-ai, evaluation-datasets, human-computer-interaction","summary":"DiQAD is a large-scale dataset containing 100,000 real-world user dialogues with systematic quality ratings across six dimensions. It provides researchers and practitioners with ground truth data for training and evaluating dialogue quality assessment models. The dataset is particularly valuable for developing automated conversation evaluation systems and benchmarking chatbot performance.","use_cases":"Training automated dialogue quality scoring models for chatbot evaluation, Benchmarking conversational AI systems against human-annotated quality standards","audience":"Mid-DS, Senior-DS"},{"id":"dataset-uss-(user-satisfaction-simulation)","type":"dataset","name":"USS (User Satisfaction Simulation)","description":"6,800 dialogues with 5-level satisfaction scale labels across multiple domains","category":"AI & LLM","url":"https://github.com/sunnweiwei/user-satisfaction-simulation","difficulty":"beginner","prerequisites":"python-pandas, classification-metrics, dialogue-systems","topic_tags":"user-satisfaction, dialogue-evaluation, conversational-ai, labeled-dataset","summary":"A simulation dataset containing 6,800 dialogues labeled with user satisfaction scores on a 5-point scale across multiple domains. This dataset enables researchers and practitioners to train models for predicting user satisfaction in conversational AI systems. It's particularly valuable for evaluating chatbot performance and understanding factors that drive user engagement.","use_cases":"Training ML models to predict user satisfaction scores for chatbot interactions, Benchmarking conversational AI systems against standardized satisfaction metrics","audience":"Junior-DS, Mid-DS"},{"id":"dataset-convai-dataset","type":"dataset","name":"ConvAI Dataset","description":"4,750 human-to-bot dialogues with thumbs up/down feedback plus quality scores","category":"AI & LLM","url":"http://convai.io/2017/data/dataset_description.pdf","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-NLP","topic_tags":"dialogue-systems, human-feedback, conversational-AI, quality-assessment, training-data","summary":"The ConvAI Dataset contains 4,750 human-to-bot conversations with quality ratings and thumbs up/down feedback from users. This dataset is commonly used for training and evaluating conversational AI systems, providing both dialogue examples and human preference signals. It's particularly valuable for researchers working on chatbot improvement and dialogue quality assessment.","use_cases":"Training a chatbot to generate more human-preferred responses using the feedback scores, Benchmarking dialogue quality metrics against human ratings","audience":"Junior-DS, Mid-DS"},{"id":"dataset-arena-human-preference-(55k)","type":"dataset","name":"Arena Human Preference (55K)","description":"55K+ real-world conversations with human preference labels from Chatbot Arena","category":"AI & LLM","url":"https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k","difficulty":"intermediate","prerequisites":"python-pandas, pytorch-transformers, statistical-hypothesis-testing","topic_tags":"human-preference, llm-evaluation, chatbot-arena, conversation-data, preference-learning","summary":"A large-scale dataset containing over 55,000 real-world conversations between users and chatbots, each labeled with human preference judgments from Chatbot Arena. This dataset provides ground truth for training preference models and evaluating conversational AI systems against human judgment. It's particularly valuable for researchers and practitioners working on LLM alignment and evaluation metrics.","use_cases":"Training reward models for RLHF to align language models with human preferences, Benchmarking new LLM evaluation metrics against human judgment data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-brazilian-ecommerce","type":"dataset","name":"Brazilian eCommerce","description":"100,000 orders (2016-2018) structured in 9 relational tables from Olist","category":"E-Commerce","url":"https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce","difficulty":"beginner","prerequisites":"python-pandas, SQL-joins, data-visualization","topic_tags":"ecommerce-data, relational-database, customer-analytics, order-analysis, kaggle-dataset","summary":"A comprehensive dataset containing 100,000 Brazilian eCommerce orders from Olist marketplace spanning 2016-2018, organized across 9 interconnected tables. This real-world relational dataset includes order details, customer information, product data, seller metrics, and payment information. Ideal for learning SQL joins, customer analytics, and eCommerce business intelligence practices.","use_cases":"Learning relational database analysis and SQL joins with realistic eCommerce schema, Building customer segmentation and order analysis dashboards for portfolio projects","audience":"Early-PhD, Junior-DS"},{"id":"dataset-open-cdp","type":"dataset","name":"Open CDP","description":"Omnichannel interaction tracking with AI-driven identity resolution","category":"E-Commerce","url":"https://rees46.com/en/datasets","difficulty":"intermediate","prerequisites":"SQL-joins, python-pandas, customer-segmentation","topic_tags":"customer-data-platform, omnichannel-analytics, identity-resolution, e-commerce, dataset","summary":"Open CDP is a dataset containing omnichannel customer interaction data with AI-powered identity resolution capabilities. It enables analysts to track customer journeys across multiple touchpoints and channels. The dataset is particularly valuable for understanding cross-platform customer behavior and building unified customer profiles.","use_cases":"Building a unified customer journey analysis across web, mobile, and in-store touchpoints, Training machine learning models to predict customer lifetime value using cross-channel behavioral data","audience":"Mid-DS, Junior-DS"},{"id":"dataset-jd.com-2020-(msom-20)","type":"dataset","name":"JD.com 2020 (MSOM-20)","description":"2.5M customers (457k purchasers) and 31,868 SKUs from JD.com","category":"E-Commerce","url":"https://connect.informs.org/msom/events/datadriven2020","difficulty":"intermediate","prerequisites":"python-pandas, descriptive-statistics, retail-analytics","topic_tags":"customer-segmentation, e-commerce-data, retail-operations, purchase-behavior, SKU-analysis","summary":"A comprehensive e-commerce dataset from JD.com containing transaction and customer data for 2.5 million customers and over 31,000 products. This dataset enables analysis of customer purchasing patterns, product performance, and operational metrics in one of China's largest online retail platforms. Originally featured in Management Science & Operations Management research, it's ideal for studying consumer behavior and retail operations at scale.","use_cases":"Analyzing customer lifetime value and segmentation patterns across different product categories, Building demand forecasting models for inventory management using historical purchase data","audience":"Mid-DS, Early-PhD"},{"id":"dataset-alibaba-ads-(ijcai-18)","type":"dataset","name":"Alibaba Ads (IJCAI-18)","description":"6 billion display ad/click logs over 8 days from 100M users","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/147588","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, logistic-regression","topic_tags":"display-advertising, click-prediction, large-scale-data, behavioral-modeling, e-commerce-analytics","summary":"This dataset contains 6 billion display advertisement impression and click records from Alibaba's platform, spanning 8 days and covering 100 million users. It's commonly used for developing and benchmarking click-through rate prediction models and studying large-scale user behavior in e-commerce advertising. The dataset provides real-world scale for testing recommendation systems and ad optimization algorithms.","use_cases":"Building click-through rate prediction models for display advertising campaigns, Analyzing user engagement patterns across different product categories and ad formats","audience":"Mid-DS, Senior-DS"},{"id":"dataset-coveo-shopping-(sigir-21)","type":"dataset","name":"Coveo Shopping (SIGIR-21)","description":"30M+ browsing events with query and image vectors for e-commerce search","category":"E-Commerce","url":"https://github.com/coveooss/SIGIR-ecom-data-challenge","difficulty":"intermediate","prerequisites":"python-pandas, vector-embeddings, collaborative-filtering","topic_tags":"e-commerce-search, query-embeddings, browsing-behavior, recommendation-systems, SIGIR-dataset","summary":"A large-scale dataset containing 30+ million browsing events from Coveo's e-commerce platform, featuring both textual queries and image embeddings. Published at SIGIR 2021, it provides real-world data for training and evaluating search ranking and recommendation models. The dataset is particularly valuable for researchers working on multimodal e-commerce search systems.","use_cases":"Training neural ranking models that combine text queries with product image features, Benchmarking recommendation algorithms against real e-commerce browsing patterns","audience":"Mid-DS, Senior-DS"},{"id":"dataset-retail-rocket","type":"dataset","name":"Retail Rocket","description":"2.76M events (views, carts, purchases) from 1.4M visitors","category":"E-Commerce","url":"https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, basic-SQL","topic_tags":"event-tracking, funnel-analysis, e-commerce, behavioral-data, conversion-rates","summary":"A large-scale e-commerce dataset containing 2.76M user interaction events (page views, add-to-cart, purchases) from 1.4M website visitors. This Kaggle dataset is ideal for learning user behavior analysis, conversion funnel optimization, and recommendation systems. The rich event sequence data makes it perfect for practicing data manipulation and exploring customer journey patterns.","use_cases":"Building a recommendation system to suggest products based on user browsing and purchase history, Analyzing conversion funnels to identify drop-off points between viewing, adding to cart, and purchasing","audience":"Junior-DS, Curious-browser"},{"id":"dataset-google-merchandise","type":"dataset","name":"Google Merchandise","description":"3 months obfuscated GA4 e-commerce data (Nov 2020-Jan 2021)","category":"E-Commerce","url":"https://www.kaggle.com/datasets/bigquery/google-analytics-sample","difficulty":"beginner","prerequisites":"SQL-basics, python-pandas, web-analytics-concepts","topic_tags":"google-analytics, ecommerce-data, web-analytics, customer-behavior, conversion-funnel","summary":"This dataset contains 3 months of obfuscated Google Analytics 4 e-commerce data from November 2020 to January 2021. It provides real-world web analytics data for learning customer behavior analysis, conversion tracking, and e-commerce metrics without privacy concerns. The dataset is ideal for practicing GA4 data structure understanding and building analytics dashboards.","use_cases":"Learning to analyze e-commerce conversion funnels and customer journey patterns, Building practice dashboards for web analytics and testing GA4 data visualization techniques","audience":"Junior-DS, Curious-browser"},{"id":"dataset-shopee","type":"dataset","name":"Shopee","description":"Dataset from Shopee's 2020 Code League competition","category":"E-Commerce","url":"https://www.kaggle.com/c/shopee-code-league-2021","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, exploratory-data-analysis","topic_tags":"e-commerce-data, competition-dataset, southeast-asia, shopee, retail-analytics","summary":"Dataset from Shopee's 2020 Code League programming competition featuring real e-commerce data from Southeast Asia's largest shopping platform. Contains product listings, user interactions, and transaction data typical of online marketplace operations. Ideal for practicing data analysis skills on realistic e-commerce scenarios without dealing with data collection complexities.","use_cases":"Learning e-commerce analytics by exploring product categorization and user behavior patterns, Building portfolio projects demonstrating skills in retail data analysis and Southeast Asian market insights","audience":"Junior-DS, Curious-browser"},{"id":"dataset-flipkart","type":"dataset","name":"Flipkart","description":"Sales dataset from Indian e-commerce platform Flipkart","category":"E-Commerce","url":"https://www.kaggle.com/datasets/iyumrahul/flipkartsalesdataset","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-visualization","topic_tags":"e-commerce-data, sales-analysis, indian-market, retail-dataset","summary":"Sales dataset from Flipkart, one of India's largest e-commerce platforms, containing transaction and product information. This dataset is ideal for learning e-commerce analytics fundamentals and understanding Indian online retail patterns. Perfect for practicing data manipulation, exploratory analysis, and basic business intelligence techniques.","use_cases":"Learning e-commerce metrics like conversion rates, average order value, and customer segmentation, Building predictive models for product demand forecasting in emerging markets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-pakistan-e-commerce","type":"dataset","name":"Pakistan e-commerce","description":"500k+ transactions (Mar 2016 - Aug 2018) from Pakistan's largest e-commerce","category":"E-Commerce","url":"https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"e-commerce-analytics, transaction-data, emerging-markets, customer-behavior, dataset","summary":"A comprehensive dataset of 500,000+ e-commerce transactions from Pakistan's largest online retailer spanning March 2016 to August 2018. This dataset provides rich transaction-level data including customer information, product categories, pricing, and temporal patterns from a major South Asian market. Ideal for learning e-commerce analytics fundamentals and exploring customer behavior patterns in emerging markets.","use_cases":"Analyzing customer purchasing patterns and seasonal trends in South Asian e-commerce markets, Building customer segmentation models to understand buying behavior in emerging economies","audience":"Junior-DS, Curious-browser"},{"id":"dataset-instacart","type":"dataset","name":"Instacart","description":"3.4M orders, 206k+ users, 49k+ products with reorder behavior","category":"Food & Delivery","url":"https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis","difficulty":"beginner","prerequisites":"python-pandas, basic-sql, logistic-regression","topic_tags":"market-basket-analysis, customer-segmentation, reorder-prediction, e-commerce-analytics, consumer-behavior","summary":"The Instacart dataset contains 3.4 million grocery orders from over 206,000 users, including detailed product information and reorder patterns. It's widely used by data scientists learning recommendation systems and market basket analysis. The dataset is perfect for practicing customer segmentation, demand forecasting, and building reorder prediction models.","use_cases":"Building recommendation engines for grocery e-commerce platforms, Analyzing customer purchase patterns to optimize inventory and marketing strategies","audience":"Junior-DS, Curious-browser"},{"id":"dataset-open-e-commerce-1.0-(mit)","type":"dataset","name":"Open E-Commerce 1.0 (MIT)","description":"1.8M Amazon purchases with demographics (age, gender, location). Real household e-commerce behavior at scale","category":"E-Commerce","url":"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGAVK9","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, descriptive-statistics","topic_tags":"consumer-behavior, purchase-data, demographic-analysis, amazon-data, household-economics","summary":"Large-scale dataset containing 1.8 million Amazon purchase records linked to household demographics including age, gender, and location. This MIT-licensed dataset provides researchers and analysts with real consumer behavior data at unprecedented scale. Perfect for studying purchasing patterns, demographic segmentation, and e-commerce trends.","use_cases":"Analyzing how age and gender influence product category preferences and spending patterns, Building customer segmentation models to understand regional differences in e-commerce behavior","audience":"Junior-DS, Mid-DS"},{"id":"dataset-upworthy-news-headlines","type":"dataset","name":"Upworthy News Headlines","description":"32,487 headline/image experiments on 538M assignments","category":"Advertising","url":"https://upworthy.natematias.com/","difficulty":"intermediate","prerequisites":"hypothesis-testing, python-pandas, statistical-significance","topic_tags":"ab-testing, experimentation, media-optimization, headline-testing, dataset","summary":"A large-scale dataset containing 32,487 headline and image A/B test experiments from Upworthy, covering 538 million user assignments. This dataset provides real-world examples of digital media experimentation and is valuable for understanding how content optimization works in practice. Researchers and practitioners can use it to study A/B testing methodologies, effect sizes, and content performance patterns.","use_cases":"Analyzing A/B test effect sizes and statistical power in media experiments, Training machine learning models to predict headline performance and engagement","audience":"Mid-DS, Junior-DS"},{"id":"dataset-assistments-dataset","type":"dataset","name":"ASSISTments Dataset","description":"Data from online tutoring platform for educational data mining","category":"Education","url":"https://sites.google.com/site/las2016data/home","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, data-visualization","topic_tags":"educational-data-mining, learning-analytics, student-behavior, tutoring-systems, longitudinal-data","summary":"The ASSISTments dataset contains student interaction data from an online tutoring platform, including problem-solving attempts, hints requested, and learning outcomes. It's widely used by education researchers and data scientists to study learning patterns, predict student performance, and evaluate tutoring effectiveness. The dataset provides rich longitudinal data perfect for understanding how students learn mathematics through digital platforms.","use_cases":"Predicting which students are at risk of failing based on their tutoring session patterns, A/B testing different hint strategies to see which helps students learn more effectively","audience":"Junior-DS, Curious-browser"},{"id":"dataset-gamified-learning","type":"dataset","name":"Gamified Learning","description":"Experiments on gamification in learning environments","category":"Education","url":"https://data.mendeley.com/datasets/7kgpn39m8w/1","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, python-pandas, statistical-hypothesis-testing","topic_tags":"gamification, education-technology, experimental-design, learning-outcomes, behavioral-interventions","summary":"This dataset contains experimental results from studies testing gamification elements (points, badges, leaderboards) in educational settings. It's commonly used by education researchers and product teams to understand how game mechanics affect student engagement and learning outcomes. The data enables analysis of treatment effects across different gamification strategies and learner populations.","use_cases":"Designing A/B tests for an educational app to determine which gamification features improve course completion rates, Academic research on the effectiveness of different reward systems in online learning platforms","audience":"Mid-DS, Curious-browser"},{"id":"dataset-stanford-gsb-experiment-collection","type":"dataset","name":"Stanford GSB Experiment Collection","description":"Datasets for experimentation analysis from Stanford Graduate School of Business","category":"Education","url":"https://github.com/gsbDBI/ExperimentData","difficulty":"intermediate","prerequisites":"python-pandas, randomization-inference, hypothesis-testing","topic_tags":"experimental-data, randomized-trials, academic-datasets, causal-inference, stanford","summary":"A curated collection of real experimental datasets from Stanford Graduate School of Business research projects. These datasets include randomized controlled trials and quasi-experimental studies with clean documentation for learning causal inference methods. Ideal for practitioners wanting to practice experimental analysis techniques on high-quality academic data.","use_cases":"Learning experimental design by replicating published Stanford studies, Testing causal inference packages on clean randomized trial data","audience":"Early-PhD, Junior-DS"},{"id":"dataset-athey's-course-datasets","type":"dataset","name":"Athey's Course Datasets","description":"Datasets related to causal inference and experimental design from Susan Athey","category":"Education","url":"https://github.com/itamarcaspi/experimentdatar","difficulty":"intermediate","prerequisites":"python-pandas, difference-in-differences, regression-analysis","topic_tags":"causal-inference, experimental-design, athey-datasets, academic-research, educational-materials","summary":"Educational datasets curated by Susan Athey for teaching causal inference and experimental design methods. These datasets are commonly used in academic courses and workshops to demonstrate key concepts like randomized controlled trials, natural experiments, and treatment effect estimation. They provide clean, well-documented examples perfect for learning and practicing causal inference techniques.","use_cases":"Learning causal inference methods through hands-on practice with real experimental data, Teaching econometrics courses with standardized datasets that illustrate key concepts","audience":"Early-PhD, Junior-DS"},{"id":"dataset-pep-experimental-research","type":"dataset","name":"PEP Experimental Research","description":"Experimental research datasets from Partnership for Economic Policy","category":"Education","url":"https://www.pep-net.org/publications/datasets/experimental-research-datasets","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, experiment-design","topic_tags":"randomized-controlled-trials, development-economics, policy-evaluation, experimental-data, dataset","summary":"A collection of experimental research datasets from Partnership for Economic Policy focusing on randomized controlled trials in developing countries. These datasets are primarily used by researchers and analysts studying the impact of various policy interventions on economic and social outcomes. The data provides real-world examples of experimental design and implementation in development economics contexts.","use_cases":"Learning how to analyze RCT data by replicating published development economics studies, Teaching experimental methods using real policy intervention datasets from developing countries","audience":"Early-PhD, Curious-browser"},{"id":"dataset-computational-neuroscience","type":"dataset","name":"Computational Neuroscience","description":"Experimental data from neural recordings and behavior","category":"Education","url":"https://crcns.org/","difficulty":"intermediate","prerequisites":"python-pandas, signal-processing, matplotlib","topic_tags":"neural-recordings, behavioral-data, neuroscience, experimental-data, spike-trains","summary":"Collection of experimental datasets containing neural activity recordings (spike trains, LFP, etc.) paired with behavioral measurements from various neuroscience experiments. Used by researchers studying brain-behavior relationships and computational neuroscientists developing analysis methods. Includes data from different brain regions, species, and experimental paradigms.","use_cases":"Training machine learning models to decode motor intentions from neural signals, Analyzing neural population dynamics during decision-making tasks","audience":"Early-PhD, Curious-browser"},{"id":"dataset-asos-experiments","type":"dataset","name":"ASOS Experiments","description":"99 real e-commerce experiments with daily checkpoints from ASOS","category":"Fashion & Apparel","url":"https://www.kaggle.com/datasets/marinazmieva/asos-digital-experiments-dataset","difficulty":"beginner","prerequisites":"python-pandas, statistical-hypothesis-testing, data-visualization","topic_tags":"ab-testing, ecommerce-experiments, fashion-retail, kaggle-dataset, experimental-design","summary":"A collection of 99 real A/B testing experiments from ASOS with daily performance metrics and outcomes. This dataset provides hands-on experience with real e-commerce experimentation data, including control/treatment groups, daily checkpoints, and business metrics. Perfect for learning experimental analysis techniques and understanding how fashion retailers optimize their platforms.","use_cases":"Learning A/B test analysis by practicing on real e-commerce experiments with known outcomes, Building experimentation dashboards and monitoring systems using actual daily checkpoint data","audience":"Junior-DS, Early-PhD"},{"id":"dataset-amazon-sessions-(kdd-cup-23)","type":"dataset","name":"Amazon Sessions (KDD Cup 23)","description":"Sessions from 6 locales with 40k-500k products per locale","category":"E-Commerce","url":"https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge","difficulty":"beginner","prerequisites":"python-pandas, data-preprocessing, exploratory-data-analysis","topic_tags":"e-commerce, session-data, multilingual, recommender-systems, user-behavior","summary":"A large-scale dataset from Amazon containing user session data across 6 different locales, with each locale featuring 40k-500k products. This KDD Cup 2023 competition dataset is ideal for learning e-commerce analytics and building recommender systems. The multilingual nature makes it valuable for understanding cross-cultural shopping patterns and international e-commerce behavior.","use_cases":"Building product recommendation systems using session-based collaborative filtering, Analyzing cross-locale differences in user shopping behavior and conversion patterns","audience":"Junior-DS, Mid-DS"},{"id":"dataset-jd.com-search","type":"dataset","name":"JD.com Search","description":"170,000 users' real search queries (2021-2022) from JD.com","category":"E-Commerce","url":"https://github.com/rucliujn/JDsearch","difficulty":"beginner","prerequisites":"python-pandas, basic-chinese, exploratory-data-analysis","topic_tags":"search-behavior, e-commerce-analytics, user-queries, chinese-market, dataset","summary":"A dataset containing 170,000 real user search queries from JD.com, China's second-largest e-commerce platform, collected between 2021-2022. This data provides insights into Chinese consumer search behavior and e-commerce patterns. Perfect for researchers studying search intent, query analysis, or Chinese market dynamics.","use_cases":"Analyzing search query patterns to understand Chinese consumer preferences and seasonal trends, Building search recommendation systems or query suggestion models for e-commerce platforms","audience":"Junior-DS, Curious-browser"},{"id":"dataset-jd-pretrain-data","type":"dataset","name":"JD-pretrain-data","description":"Encoded search queries and item data for intent detection","category":"E-Commerce","url":"https://github.com/jdcomsearch/jd-pretrain-data","difficulty":"intermediate","prerequisites":"python-pandas, text-embeddings, classification-models","topic_tags":"search-intent, query-embeddings, e-commerce-data, behavioral-analytics","summary":"A dataset containing encoded search queries and corresponding item data designed for training intent detection models in e-commerce contexts. The data includes pre-processed embeddings that can be used to classify user search behavior and predict purchase intent. This resource is valuable for data scientists working on search optimization and recommendation systems.","use_cases":"Training machine learning models to classify whether a search query indicates browsing vs purchase intent, Building recommendation systems that surface relevant products based on encoded search patterns","audience":"Junior-DS, Mid-DS"},{"id":"dataset-bestbuy","type":"dataset","name":"BestBuy","description":"Mobile website clicks (~42k) for Xbox games from BestBuy","category":"E-Commerce","url":"https://www.kaggle.com/competitions/acm-sf-chapter-hackathon-big","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-statistics","topic_tags":"clickstream-analysis, mobile-commerce, gaming-industry, user-behavior, e-commerce-data","summary":"A dataset containing approximately 42,000 mobile website click events for Xbox games on BestBuy's platform. This dataset provides real-world e-commerce clickstream data ideal for learning web analytics and user behavior analysis techniques. It's commonly used in hackathons and educational settings to practice conversion funnel analysis and mobile user experience optimization.","use_cases":"Analyzing mobile conversion funnels for Xbox game purchases to identify drop-off points, Building click-through rate models to optimize product page layouts for gaming products","audience":"Junior-DS, Curious-browser"},{"id":"dataset-rakuten-sigir","type":"dataset","name":"Rakuten SIGIR","description":"E-commerce dataset for SIGIR workshop from Rakuten","category":"E-Commerce","url":"https://sigir-ecom.github.io/ecom2018/data-task.html","difficulty":"intermediate","prerequisites":"python-pandas, information-retrieval-basics, A-B-testing","topic_tags":"e-commerce-search, information-retrieval, ranking-algorithms, user-behavior, dataset","summary":"This is an e-commerce dataset from Rakuten created for the SIGIR workshop, containing search and user interaction data from their platform. It's designed for researchers and practitioners working on information retrieval problems in e-commerce contexts. The dataset enables experimentation with search ranking algorithms, user behavior analysis, and recommendation systems in retail settings.","use_cases":"Developing and benchmarking search ranking algorithms for e-commerce platforms, Analyzing user search behavior patterns to improve product discovery and conversion rates","audience":"Mid-DS, Senior-DS"},{"id":"dataset-wayfair-search-(wands)","type":"dataset","name":"Wayfair Search (WANDS)","description":"233k human-annotated query-product judgments, 43k products","category":"E-Commerce","url":"https://github.com/wayfair/WANDS","difficulty":"beginner","prerequisites":"python-pandas, information-retrieval-basics, data-preprocessing","topic_tags":"search-relevance, e-commerce, annotations, furniture, dataset","summary":"WANDS is a large-scale dataset containing 233,000 human-annotated query-product judgments from Wayfair's search system, covering 43,000 furniture and home goods products. It provides ground truth relevance labels for search queries, making it valuable for training and evaluating search ranking algorithms. The dataset is particularly useful for researchers and practitioners working on e-commerce search relevance problems.","use_cases":"Training machine learning models to predict search result relevance for e-commerce platforms, Benchmarking different search ranking algorithms against human-labeled ground truth data","audience":"Junior-DS, Mid-DS"},{"id":"dataset-criteo-display-advertising","type":"dataset","name":"Criteo Display Advertising","description":"342GB total with 13 integer features, 26 hashed categorical features","category":"Advertising","url":"https://ailab.criteo.com/ressources/","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, logistic-regression","topic_tags":"CTR-prediction, advertising, large-scale, categorical-features, dataset","summary":"The Criteo Display Advertising dataset is a 342GB collection containing click-through rate data with 13 integer features and 26 hashed categorical features. It's widely used by data scientists and researchers for benchmarking CTR prediction models at scale. The dataset provides real-world advertising data for training and evaluating machine learning algorithms in computational advertising.","use_cases":"Benchmarking CTR prediction models for display advertising campaigns, Training large-scale machine learning systems for real-time bid optimization","audience":"Mid-DS, Senior-DS"},{"id":"dataset-avazu","type":"dataset","name":"Avazu","description":"Dataset for click-through rate prediction on mobile ads","category":"Advertising","url":"https://www.kaggle.com/competitions/avazu-ctr-prediction","difficulty":"beginner","prerequisites":"python-pandas, logistic-regression, binary-classification","topic_tags":"click-through-rate, mobile-advertising, kaggle-dataset, binary-classification, ad-tech","summary":"The Avazu dataset contains mobile ad click data from a popular Kaggle competition focused on predicting click-through rates. It includes anonymized features about users, devices, and ad placements with binary click outcomes. This dataset is widely used for learning CTR prediction techniques and benchmarking classification models in digital advertising contexts.","use_cases":"Learning CTR prediction modeling techniques for digital advertising applications, Benchmarking binary classification algorithms on real-world mobile ad click data","audience":"Junior-DS, Early-PhD"},{"id":"dataset-yoyi","type":"dataset","name":"Yoyi","description":"Computational advertising dataset from Chinese ad platform","category":"Advertising","url":"https://apex.sjtu.edu.cn/datasets/7","difficulty":"intermediate","prerequisites":"python-pandas, click-through-rate-modeling, A-B-testing","topic_tags":"computational-advertising, click-through-rate, chinese-market, ad-platform, dataset","summary":"Yoyi is a computational advertising dataset from a Chinese advertising platform containing user interactions, ad features, and campaign performance metrics. It provides real-world data for researchers and practitioners working on ad targeting, bidding strategies, and campaign optimization. The dataset is particularly valuable for understanding advertising dynamics in the Chinese market context.","use_cases":"Training click-through-rate prediction models for ad platforms, Benchmarking bidding algorithms against real Chinese market data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-ele.me-search","type":"dataset","name":"Ele.me Search","description":"Search log dataset from Ele.me (Chinese food delivery)","category":"Food & Delivery","url":"https://tianchi.aliyun.com/dataset/120281","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, exploratory-data-analysis","topic_tags":"search-logs, food-delivery, user-behavior, dataset, china-market","summary":"Search log dataset from Ele.me, one of China's largest food delivery platforms, containing user search queries and interactions. This dataset provides insights into Chinese consumer food preferences and search behavior patterns. It's valuable for understanding search optimization, recommendation systems, and market analysis in the food delivery domain.","use_cases":"Analyzing search query patterns to improve food delivery app search algorithms, Understanding regional food preferences and dietary trends in Chinese markets","audience":"Junior-DS, Mid-DS"},{"id":"dataset-ele.me-clickstream","type":"dataset","name":"Ele.me Clickstream","description":"Clickstream data from Ele.me food delivery platform","category":"Food & Delivery","url":"https://tianchi.aliyun.com/dataset/131047","difficulty":"intermediate","prerequisites":"python-pandas, web-analytics, survival-analysis","topic_tags":"clickstream-analysis, food-delivery, user-behavior, conversion-funnels, session-data","summary":"Clickstream dataset from Ele.me, a major Chinese food delivery platform, containing user navigation and interaction patterns. The data captures user journeys from browsing to ordering, making it valuable for understanding customer behavior in food delivery apps. Researchers and data scientists use this for conversion analysis, recommendation system evaluation, and user experience optimization.","use_cases":"Analyzing conversion funnels to identify drop-off points in the food ordering process, Building recommendation systems for restaurants and dishes based on user browsing patterns","audience":"Mid-DS, Junior-DS"},{"id":"dataset-alibaba-industrial-dump-(150gb)","type":"dataset","name":"Alibaba Industrial Dump (150GB)","description":"Large-scale industrial dataset from Alibaba (150GB)","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/81505","difficulty":"intermediate","prerequisites":"python-pandas, distributed-computing, SQL-joins","topic_tags":"alibaba-dataset, e-commerce-data, large-scale-dataset, industrial-data, recommendation-systems","summary":"A massive 150GB industrial dataset from Alibaba containing real-world e-commerce transaction and user behavior data. This dataset provides researchers and practitioners with access to large-scale commercial data for developing and testing algorithms at industrial scale. It's particularly valuable for understanding user patterns, recommendation systems, and marketplace dynamics in one of the world's largest e-commerce platforms.","use_cases":"Training recommendation algorithms on real e-commerce user behavior and transaction data, Benchmarking distributed computing frameworks and big data processing pipelines","audience":"Mid-DS, Senior-DS"},{"id":"dataset-alibaba-fashion-combo","type":"dataset","name":"Alibaba Fashion Combo","description":"Fashion item combinations from Alibaba for outfit recommendation","category":"Fashion & Apparel","url":"https://tianchi.aliyun.com/dataset/131519","difficulty":"beginner","prerequisites":"python-pandas, collaborative-filtering, data-preprocessing","topic_tags":"fashion-recommendation, outfit-matching, e-commerce-data, recommendation-systems, retail-analytics","summary":"A dataset containing fashion item combinations from Alibaba's platform, designed for building outfit recommendation systems. This resource is valuable for data scientists working in retail and e-commerce who want to understand how customers combine different fashion items. The dataset enables experimentation with recommendation algorithms and fashion compatibility modeling.","use_cases":"Building a 'complete the look' feature for an e-commerce fashion website, Training models to suggest complementary items when customers view a specific clothing piece","audience":"Junior-DS, Mid-DS"},{"id":"dataset-alibaba-brick-and-mortar-(ijcai-16)","type":"dataset","name":"Alibaba Brick and Mortar (IJCAI-16)","description":"Online and offline check-ins/purchases from 1,000+ stores","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/53","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, SQL-basics","topic_tags":"o2o-commerce, retail-analytics, customer-behavior, location-data, chinese-ecommerce","summary":"A dataset containing online and offline customer check-ins and purchase behaviors from over 1,000 Alibaba-affiliated brick-and-mortar stores. This O2O (online-to-offline) commerce dataset enables analysis of omnichannel customer journeys and retail optimization strategies. It's particularly valuable for understanding how digital platforms integrate with physical retail experiences.","use_cases":"Analyzing customer conversion patterns between online browsing and offline purchases, Building recommendation systems that bridge digital and physical shopping experiences","audience":"Junior-DS, Mid-DS"},{"id":"dataset-alibaba-mobile-2021","type":"dataset","name":"Alibaba Mobile 2021","description":"Mobile user behavior data from Alibaba (2021)","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/109858","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, behavioral-analytics","topic_tags":"mobile-analytics, user-behavior, e-commerce, alibaba, dataset","summary":"Mobile user behavior dataset from Alibaba's 2021 platform activity, capturing user interactions, sessions, and engagement patterns. This dataset is valuable for data scientists working on mobile commerce optimization and user experience research. It provides real-world e-commerce behavioral data for building recommendation systems and conducting user journey analysis.","use_cases":"Building mobile app recommendation engines for e-commerce platforms, Analyzing user session patterns to optimize mobile checkout flows","audience":"Junior-DS, Mid-DS"},{"id":"dataset-alibaba-clickstream-2018","type":"dataset","name":"Alibaba Clickstream 2018","description":"Clickstream data from Alibaba platforms (2018)","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/56","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-visualization","topic_tags":"clickstream-data, e-commerce-analytics, user-behavior, alibaba-dataset","summary":"Large-scale clickstream dataset from Alibaba's e-commerce platforms capturing user browsing and interaction patterns from 2018. This dataset provides real-world examples of user behavior data commonly found in tech companies. It's ideal for learning web analytics techniques and understanding how users navigate e-commerce sites.","use_cases":"Analyzing user journey patterns to optimize website conversion funnels, Building recommendation systems based on historical browsing behavior","audience":"Junior-DS, Curious-browser"},{"id":"dataset-alibaba-cloud-theme","type":"dataset","name":"Alibaba Cloud Theme","description":"Themed dataset related to Alibaba Cloud services","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/9716","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, data-visualization","topic_tags":"cloud-computing, e-commerce-data, alibaba, dataset, business-analytics","summary":"A themed dataset containing information about Alibaba Cloud services and their usage patterns. This dataset is suitable for learning cloud service analytics and exploring e-commerce infrastructure data. It provides real-world examples for practicing data analysis on cloud computing metrics.","use_cases":"Analyzing cloud service adoption patterns for market research, Building dashboards to visualize cloud infrastructure usage trends","audience":"Junior-DS, Curious-browser"},{"id":"dataset-alibaba-ads-dataset","type":"dataset","name":"Alibaba Ads Dataset","description":"Advertising dataset from Alibaba for ad targeting and prediction","category":"Advertising","url":"https://tianchi.aliyun.com/dataset/148347","difficulty":"intermediate","prerequisites":"python-pandas, click-through-rate-modeling, feature-engineering","topic_tags":"advertising-data, click-prediction, user-behavior, dataset, alibaba","summary":"Large-scale advertising dataset from Alibaba containing user interactions, ad features, and click/conversion data for training recommendation and targeting models. The dataset is commonly used for benchmarking click-through rate prediction algorithms and studying user behavior patterns in e-commerce advertising. It provides real-world scale and complexity typical of modern ad platforms.","use_cases":"Training CTR prediction models for ad targeting optimization, Benchmarking recommendation algorithms against industry-scale data","audience":"Junior-DS, Mid-DS"},{"id":"dataset-alibaba-user-behavior-2018","type":"dataset","name":"Alibaba User Behavior 2018","description":"649M user interactions (clicks, carts, buys) on 25M items","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/649","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-preprocessing","topic_tags":"user-behavior, e-commerce, clickstream, large-scale-data, recommendation-systems","summary":"Large-scale dataset containing 649 million user interactions across clicks, cart additions, and purchases on 25 million items from Alibaba's e-commerce platform. This comprehensive behavioral data captures real user journeys and purchasing patterns at massive scale. Ideal for learning recommendation systems, user segmentation, and conversion funnel analysis on realistic industry data.","use_cases":"Building recommendation algorithms to predict user purchase behavior based on browsing and cart patterns, Analyzing conversion funnels to identify drop-off points between clicks, cart additions, and final purchases","audience":"Junior-DS, Mid-DS"},{"id":"dataset-alibaba-personalized-re-ranking","type":"dataset","name":"Alibaba Personalized Re-Ranking","description":"Mobile shopping user click data on recommended items","category":"E-Commerce","url":"http://yongfeng.me/dataset/","difficulty":"intermediate","prerequisites":"python-pandas, recommender-systems, click-through-rate-modeling","topic_tags":"re-ranking, personalization, e-commerce, click-data, alibaba","summary":"Real-world dataset from Alibaba's mobile shopping platform containing user click behavior on recommended items. Used for developing and evaluating personalized re-ranking algorithms that optimize recommendation order based on individual user preferences. Particularly valuable for studying how to improve recommendation systems beyond initial item selection.","use_cases":"Training personalized re-ranking models to optimize recommendation order for individual users, Benchmarking recommendation algorithms against real e-commerce click data","audience":"Mid-DS, Junior-DS"},{"id":"dataset-online-shopping-intention","type":"dataset","name":"Online Shopping Intention","description":"12,330 user sessions with numerical and categorical features for purchase prediction","category":"E-Commerce","url":"https://www.kaggle.com/datasets/henrysue/online-shoppers-intention","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, logistic-regression","topic_tags":"purchase-prediction, session-data, classification, e-commerce, customer-behavior","summary":"A dataset of 12,330 online shopping sessions with features like page views, bounce rates, and visitor types to predict purchase intention. Popular for learning classification techniques and understanding e-commerce customer behavior. Contains both numerical features (session duration, page values) and categorical features (visitor type, month, browser) making it ideal for feature engineering practice.","use_cases":"Building a model to identify high-intent visitors for targeted marketing campaigns, Learning binary classification techniques with a realistic business dataset","audience":"Junior-DS, Early-PhD"},{"id":"dataset-microlens","type":"dataset","name":"MicroLens","description":"1 billion interactions from 34 million users on 1 million micro-videos","category":"Entertainment & Media","url":"https://github.com/westlake-repl/MicroLens","difficulty":"intermediate","prerequisites":"python-pandas, collaborative-filtering, spark-dataframes","topic_tags":"micro-video, user-interactions, recommendation-systems, large-scale-data, entertainment","summary":"MicroLens is a massive dataset containing 1 billion user interactions across 34 million users and 1 million micro-videos, designed for recommendation system research and development. This large-scale entertainment dataset enables researchers and data scientists to build and evaluate video recommendation algorithms at realistic scale. The dataset captures user engagement patterns on short-form video content, making it ideal for studying modern social media consumption behaviors.","use_cases":"Training and benchmarking recommendation algorithms for short-form video platforms like TikTok or Instagram Reels, Analyzing user engagement patterns and content virality in micro-video ecosystems","audience":"Mid-DS, Senior-DS"},{"id":"dataset-kuaisar","type":"dataset","name":"KuaiSAR","description":"5M search actions, 14.6M recommendation events from 25k users","category":"Entertainment & Media","url":"https://kuaisar.github.io/","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"search-behavior, recommendation-systems, user-interactions, video-platform, dataset","summary":"KuaiSAR is a large-scale dataset containing 5 million search actions and 14.6 million recommendation events from 25,000 users on the Kuaishou video platform. This dataset provides real-world user behavior data for studying search and recommendation system interactions. It's valuable for researchers and practitioners working on understanding user engagement patterns in video streaming platforms.","use_cases":"Analyzing how users transition between search and recommendation behaviors on video platforms, Building baseline models to predict user engagement with recommended vs searched content","audience":"Junior-DS, Mid-DS"},{"id":"dataset-amazon-reviews-(2023)","type":"dataset","name":"Amazon Reviews (2023)","description":"571M reviews (1996-2023), 33 categories, 48M items - comprehensive Amazon review dataset","category":"E-Commerce","url":"https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, JSON-parsing","topic_tags":"amazon-reviews, sentiment-analysis, e-commerce-data, natural-language-processing, consumer-behavior","summary":"Massive collection of 571 million Amazon customer reviews spanning 27 years across 33 product categories. This comprehensive dataset enables large-scale analysis of consumer sentiment, product performance, and purchasing patterns. Essential resource for researchers studying e-commerce dynamics, recommendation systems, and natural language processing applications.","use_cases":"Building recommendation systems by analyzing review patterns and user preferences across product categories, Training sentiment analysis models to classify customer satisfaction and predict product success","audience":"Junior-DS, Mid-DS"},{"id":"dataset-m5product","type":"dataset","name":"M5Product","description":"5 modalities (image, text, table, video, audio), 6M+ samples for multimodal learning","category":"E-Commerce","url":"https://xiaodongsuper.github.io/M5Product_dataset/index.html","difficulty":"intermediate","prerequisites":"pytorch-dataloaders, computer-vision-basics, pandas-dataframes","topic_tags":"multimodal-learning, e-commerce-data, product-datasets, computer-vision, cross-modal","summary":"M5Product is a large-scale multimodal dataset containing 6M+ product samples across 5 modalities: images, text descriptions, structured tables, videos, and audio. It's designed for researchers and practitioners working on multimodal machine learning in e-commerce contexts. The dataset enables training and evaluation of models that can understand and reason across different types of product information simultaneously.","use_cases":"Training multimodal product recommendation systems that combine visual features with textual descriptions, Building cross-modal search engines where users can find products using text queries matched against images and videos","audience":"Mid-DS, Senior-DS"},{"id":"dataset-tmall-reviews","type":"dataset","name":"Tmall Reviews","description":"Product reviews from Tmall (Alibaba's B2C platform)","category":"E-Commerce","url":"https://tianchi.aliyun.com/dataset/140281","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, chinese-language-basics","topic_tags":"product-reviews, chinese-ecommerce, sentiment-analysis, consumer-behavior, text-data","summary":"A dataset containing product reviews from Tmall, Alibaba's business-to-consumer e-commerce platform in China. This dataset provides insights into Chinese consumer behavior, product sentiment, and purchasing patterns. It's valuable for researchers studying e-commerce dynamics, cross-cultural consumer preferences, and Chinese market analysis.","use_cases":"Analyzing sentiment patterns of Chinese consumers across different product categories, Training recommendation systems for Chinese e-commerce platforms","audience":"Junior-DS, Curious-browser"},{"id":"dataset-home-depot-product-search","type":"dataset","name":"Home Depot Product Search","description":"Human-rated relevance scores (1-3) for search terms and products","category":"E-Commerce","url":"https://www.kaggle.com/datasets/thedevastator/the-home-depot-products-dataset","difficulty":"beginner","prerequisites":"python-pandas, basic-ML-evaluation, data-cleaning","topic_tags":"search-relevance, e-commerce, ranking-metrics, retail-data, kaggle-dataset","summary":"This dataset contains human-annotated relevance scores (1-3) for search query-product pairs from Home Depot's e-commerce platform. It's commonly used for learning search ranking and information retrieval concepts in retail contexts. The dataset provides a practical foundation for understanding how search relevance is measured and optimized in real e-commerce systems.","use_cases":"Training a learning-to-rank model for product search results, Evaluating search algorithm performance using NDCG and other ranking metrics","audience":"Junior-DS, Curious-browser"},{"id":"dataset-innerwear-data","type":"dataset","name":"Innerwear Data","description":"Data scraped from Victoria's Secret and other innerwear retailers","category":"Fashion & Apparel","url":"https://www.kaggle.com/datasets/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others","difficulty":"beginner","prerequisites":"python-pandas, web-scraping-basics, data-cleaning","topic_tags":"fashion-retail, scraped-data, product-catalog, e-commerce, apparel","summary":"A dataset containing product information scraped from Victoria's Secret and other innerwear retailers. The data likely includes product names, prices, descriptions, sizes, and other catalog details useful for retail analytics. This type of scraped retail data is commonly used for competitive analysis and market research in the fashion industry.","use_cases":"Analyzing pricing strategies across innerwear brands and competitors, Building recommendation systems for fashion e-commerce platforms","audience":"Junior-DS, Curious-browser"},{"id":"dataset-flipkart-products","type":"dataset","name":"Flipkart Products","description":"Product information scraped from Flipkart e-commerce platform","category":"E-Commerce","url":"https://www.kaggle.com/datasets/PromptCloudHQ/flipkart-products","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, data-cleaning","topic_tags":"e-commerce-data, product-catalog, indian-market, web-scraping, retail-analytics","summary":"Product information dataset scraped from Flipkart, one of India's largest e-commerce platforms. Contains product details like prices, ratings, categories, and descriptions. Useful for market research, pricing analysis, and understanding Indian e-commerce trends.","use_cases":"Analyzing pricing strategies and competitive positioning across product categories in Indian e-commerce, Building recommendation systems or price prediction models using product features and customer ratings","audience":"Junior-DS, Curious-browser"},{"id":"dataset-stanford-amazon-beer","type":"dataset","name":"Stanford Amazon/Beer","description":"Amazon product data and BeerAdvocate reviews from Stanford SNAP","category":"Entertainment & Media","url":"https://snap.stanford.edu/data/#amazon","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, data-cleaning","topic_tags":"product-reviews, sentiment-analysis, recommendation-systems, e-commerce, text-data","summary":"Large-scale dataset containing Amazon product metadata and BeerAdvocate user reviews, curated by Stanford's SNAP research group. The dataset includes product information, user ratings, review text, and temporal data spanning multiple years. It's commonly used for learning recommendation systems, sentiment analysis, and exploring consumer behavior patterns in e-commerce settings.","use_cases":"Building a product recommendation system using collaborative filtering on beer ratings, Analyzing sentiment trends in product reviews to understand consumer preferences over time","audience":"Junior-DS, Curious-browser"},{"id":"dataset-metacritic-video-games","type":"dataset","name":"Metacritic Video Games","description":"Video game reviews and metadata from Metacritic","category":"Entertainment & Media","url":"https://tianchi.aliyun.com/dataset/144719","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"gaming-data, review-analysis, metacritic, entertainment-analytics, ratings-data","summary":"A comprehensive dataset containing video game reviews, ratings, and metadata scraped from Metacritic. This dataset includes critic scores, user ratings, game metadata, and review text, making it ideal for learning data analysis fundamentals in an engaging entertainment context. Perfect for beginners to practice exploratory data analysis, visualization, and basic statistical analysis on real-world review data.","use_cases":"Analyzing factors that influence game ratings and commercial success, Building recommendation systems based on user preferences and critic scores","audience":"Junior-DS, Curious-browser"},{"id":"dataset-goodreads","type":"dataset","name":"Goodreads","description":"Book information and user reviews from Goodreads platform","category":"Entertainment & Media","url":"https://mengtingwan.github.io/data/goodreads.html#datasets","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, data-visualization","topic_tags":"book-data, recommendation-systems, user-ratings, text-analysis, social-networks","summary":"A comprehensive dataset containing book metadata, user ratings, and reviews from the Goodreads social reading platform. This dataset is commonly used for building recommendation systems, analyzing reading patterns, and studying user behavior in social media contexts. It provides rich text data alongside numerical ratings, making it ideal for both collaborative filtering and content-based recommendation approaches.","use_cases":"Building a book recommendation engine using collaborative filtering on user ratings, Analyzing sentiment patterns in book reviews to predict commercial success","audience":"Junior-DS, Curious-browser"},{"id":"dataset-walmart-(m5)","type":"dataset","name":"Walmart (M5)","description":"Hierarchical sales data for 3,049 products across 10 stores","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/competitions/m5-forecasting-accuracy","difficulty":"intermediate","prerequisites":"time-series-forecasting, python-pandas, hierarchical-modeling","topic_tags":"time-series, retail-forecasting, hierarchical-data, competition-dataset, walmart","summary":"The Walmart M5 dataset contains daily sales data for 3,049 products across 10 stores, organized in a hierarchical structure by state, store, category, and item. This dataset was featured in the M5 forecasting competition and is widely used for benchmarking hierarchical time series forecasting methods. It includes both sales quantities and pricing information, making it ideal for demand forecasting research and retail analytics applications.","use_cases":"Developing hierarchical forecasting models that predict sales at multiple aggregation levels (store, category, item), Benchmarking time series forecasting algorithms against competition baselines for retail demand prediction","audience":"Mid-DS, Senior-DS"},{"id":"dataset-ecuador-grocery-(favorita)","type":"dataset","name":"Ecuador Grocery (Favorita)","description":"Unit sales data with store/item metadata and oil prices from Ecuador","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, data-visualization","topic_tags":"time-series-forecasting, retail-analytics, kaggle-dataset, sales-prediction, grocery-data","summary":"Complete grocery sales dataset from Ecuador's Favorita chain with daily unit sales across multiple stores and product categories, plus external factors like oil prices. Popular Kaggle competition dataset that's ideal for learning time series forecasting and retail analytics. Includes rich metadata on stores, items, promotions, and holidays making it perfect for feature engineering practice.","use_cases":"Learning time series forecasting techniques on real retail data with multiple stores and products, Building demand forecasting models that incorporate external economic indicators and promotional effects","audience":"Junior-DS, Curious-browser"},{"id":"dataset-ukraine-ecommerce-(fozzy)","type":"dataset","name":"Ukraine eCommerce (Fozzy)","description":"E-commerce sales data from Fozzy Group retail chain in Ukraine","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-visualization","topic_tags":"ecommerce-data, retail-analytics, sales-forecasting, customer-behavior, ukraine-economy","summary":"E-commerce sales data from Fozzy Group, one of Ukraine's largest retail chains, providing transaction-level records from their grocery and supermarket operations. This dataset offers insights into Ukrainian consumer behavior, seasonal patterns, and retail performance metrics. Ideal for learning retail analytics fundamentals and exploring Eastern European market dynamics.","use_cases":"Analyzing seasonal demand patterns for grocery products in Ukrainian markets, Building customer segmentation models for Eastern European retail chains","audience":"Junior-DS, Curious-browser"},{"id":"dataset-office-supplies-(dmda-2023)","type":"dataset","name":"Office Supplies (DMDA 2023)","description":"Office supply sales for DMDA 2023 workshop challenge","category":"Grocery & Supermarkets","url":"https://sites.google.com/view/dmdaworkshop2023/data-challenge","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, data-visualization","topic_tags":"time-series-forecasting, retail-data, workshop-dataset, sales-prediction, demand-planning","summary":"A workshop dataset containing office supply sales data designed for the DMDA 2023 forecasting challenge. This beginner-friendly dataset provides clean sales transactions that are ideal for learning time series forecasting techniques and demand prediction methods. Perfect for practicing forecasting workflows and comparing different prediction models.","use_cases":"Learning time series forecasting methods on clean retail data, Benchmarking forecasting algorithms in a workshop or classroom setting","audience":"Junior-DS, Early-PhD"},{"id":"dataset-brazilian-drugs-(anvisa)","type":"dataset","name":"Brazilian Drugs (ANVISA)","description":"Sales data for controlled substances reported by ANVISA","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/tiagoacardoso/venda-medicamentos-controlados-anvisa","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, SQL-basics","topic_tags":"pharmaceuticals, Brazil, regulatory-data, sales-data, controlled-substances","summary":"Sales data for controlled substances regulated by Brazil's National Health Surveillance Agency (ANVISA). This dataset provides transaction-level information on pharmaceutical sales, useful for studying drug market dynamics, regulatory compliance, and public health patterns. Researchers and analysts can examine prescription trends, market concentration, and regional distribution patterns.","use_cases":"Analyzing prescription drug market concentration and pricing patterns in Brazil, Studying regional variations in controlled substance usage for public health research","audience":"Junior-DS, Curious-browser"},{"id":"dataset-indian-sales","type":"dataset","name":"Indian Sales","description":"Sales forecasting dataset for small basket items in India","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/girishvutukuri/sales-forecasting-for-small-basket","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, scikit-learn","topic_tags":"sales-forecasting, retail-analytics, indian-market, time-series, grocery-data","summary":"A sales forecasting dataset containing transaction data for small basket grocery items in the Indian retail market. This dataset is ideal for learning time series forecasting techniques and understanding retail patterns in emerging markets. Perfect for practicing demand prediction models and seasonal trend analysis.","use_cases":"Building demand forecasting models for grocery retailers to optimize inventory management, Analyzing seasonal purchasing patterns and consumer behavior in Indian retail markets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-walmart-sales","type":"dataset","name":"Walmart Sales","description":"General sales data including CPI and unemployment rate","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/yasserh/walmart-dataset","difficulty":"beginner","prerequisites":"python-pandas, basic-regression, time-series-basics","topic_tags":"retail-analytics, macroeconomic-data, time-series, walmart, sales-forecasting","summary":"Historical sales data from Walmart stores combined with macroeconomic indicators like Consumer Price Index and unemployment rates. This dataset is commonly used for retail analytics and understanding how economic conditions impact consumer spending patterns. It provides a clean foundation for learning time series analysis and econometric modeling in a retail context.","use_cases":"Analyzing how unemployment rates correlate with grocery sales patterns, Building sales forecasting models that incorporate macroeconomic variables","audience":"Junior-DS, Early-PhD"},{"id":"dataset-montgomery-liquor","type":"dataset","name":"Montgomery Liquor","description":"Warehouse and retail liquor sales from Montgomery County, Maryland","category":"Grocery & Supermarkets","url":"https://data.montgomerycountymd.gov/Community-Recreation/Warehouse-and-Retail-Sales/v76h-r7br","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"retail-analytics, government-data, sales-forecasting, inventory-management, alcohol-industry","summary":"Government-collected sales data from liquor stores and warehouses in Montgomery County, Maryland. This clean, structured dataset is ideal for learning retail analytics fundamentals and understanding consumer purchasing patterns. Perfect for practicing time series analysis, seasonal trend identification, and basic forecasting techniques.","use_cases":"Analyzing seasonal alcohol sales patterns to optimize inventory management, Building demand forecasting models for retail liquor store chains","audience":"Junior-DS, Curious-browser"},{"id":"dataset-iowa-liquor","type":"dataset","name":"Iowa Liquor","description":"Monthly Class E liquor sales data with volume and pricing from Iowa","category":"Grocery & Supermarkets","url":"https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-visualization","topic_tags":"retail-analytics, government-data, time-series, pricing-data, consumer-goods","summary":"Monthly liquor sales dataset from Iowa containing transaction-level data with volume, pricing, and retailer information for Class E liquor licenses. This government dataset is commonly used for retail analytics, pricing studies, and demand forecasting exercises. The clean structure and comprehensive coverage make it ideal for learning data analysis techniques on real commercial data.","use_cases":"Analyzing seasonal demand patterns and price elasticity for alcoholic beverages, Building predictive models for retail inventory management and sales forecasting","audience":"Junior-DS, Curious-browser"},{"id":"dataset-brazil-medical","type":"dataset","name":"Brazil Medical","description":"Medicine sales data in Brazil","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/tgomesjuliana/brazil-medicine-sales","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, exploratory-data-analysis","topic_tags":"pharmaceuticals, brazil-market, sales-data, healthcare-economics, retail-analytics","summary":"A dataset containing pharmaceutical sales transactions from Brazilian pharmacies and medical retailers. This data provides insights into medicine purchasing patterns, regional healthcare demand, and pharmaceutical market dynamics in Brazil. It's suitable for market analysis, demand forecasting, and understanding healthcare access patterns across Brazilian regions.","use_cases":"Analyzing regional differences in pharmaceutical demand to inform market entry strategies, Building demand forecasting models for medicine inventory management in Brazilian retail chains","audience":"Junior-DS, Curious-browser"},{"id":"dataset-store-item-demand","type":"dataset","name":"Store Item Demand","description":"50 items across 10 different stores over 5 years","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/competitions/demand-forecasting-kernels-only","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, data-visualization","topic_tags":"demand-forecasting, time-series, retail-analytics, kaggle-dataset","summary":"A clean dataset containing daily sales data for 50 products across 10 stores over 5 years, originally from a Kaggle forecasting competition. Perfect for learning time series forecasting techniques and understanding retail demand patterns. The dataset's structure makes it ideal for comparing different forecasting methods and understanding seasonality in grocery sales.","use_cases":"Learning to build ARIMA or Prophet models for demand forecasting, Comparing forecasting accuracy across different product categories and stores","audience":"Junior-DS, Early-PhD"},{"id":"dataset-italian-grocers","type":"dataset","name":"Italian Grocers","description":"Receipt-level sales data from Italian grocery stores","category":"Grocery & Supermarkets","url":"https://data.mendeley.com/datasets/s8dgbs3rng/1","difficulty":"beginner","prerequisites":"python-pandas, retail-metrics, time-series-analysis","topic_tags":"grocery-retail, consumer-behavior, sales-data, receipts, italy","summary":"Receipt-level transaction data from Italian grocery stores containing detailed purchase information. This dataset is valuable for retail analysts and researchers studying consumer purchasing patterns in European grocery markets. The granular receipt data enables analysis of basket composition, shopping frequency, and seasonal trends.","use_cases":"Analyzing market basket composition and cross-selling opportunities for Italian grocery retailers, Building demand forecasting models for specific product categories in European grocery chains","audience":"Junior-DS, Mid-DS"},{"id":"dataset-tesco-grocery-1.0","type":"dataset","name":"Tesco Grocery 1.0","description":"Grocery purchases from Tesco stores via loyalty cards","category":"Grocery & Supermarkets","url":"https://figshare.com/collections/Tesco_Grocery_1_0/4769354","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, descriptive-statistics","topic_tags":"grocery-data, loyalty-cards, consumer-behavior, retail-analytics, UK-market","summary":"This dataset contains grocery purchase transactions from Tesco stores collected through their loyalty card program. It provides rich consumer behavior data including product choices, spending patterns, and shopping frequency across UK locations. The dataset is ideal for learning retail analytics, customer segmentation, and market basket analysis techniques.","use_cases":"Analyzing customer purchase patterns to identify high-value segments for targeted marketing campaigns, Building recommendation systems to suggest complementary products based on shopping basket analysis","audience":"Junior-DS, Curious-browser"},{"id":"dataset-rossmann-store-sales","type":"dataset","name":"Rossmann Store Sales","description":"1,115 Rossmann drug stores historical sales data","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/competitions/rossmann-store-sales","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, linear-regression","topic_tags":"retail-analytics, sales-forecasting, time-series, kaggle-dataset, germany","summary":"Historical daily sales data from 1,115 Rossmann drugstore locations in Germany, including store features, promotions, and external factors like holidays. This popular Kaggle competition dataset is widely used for learning sales forecasting and retail analytics. Contains rich contextual information making it ideal for exploring how promotions, seasonality, and store characteristics impact sales performance.","use_cases":"Learning time series forecasting techniques on retail sales data, Building promotional impact analysis models for drugstore chains","audience":"Junior-DS, Early-PhD"},{"id":"dataset-polish-grocery","type":"dataset","name":"Polish Grocery","description":"Yearly sales data (2018) from Polish grocery shop","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/agatii/total-sale-2018-yearly-data-of-grocery-shop","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"grocery-retail, sales-data, poland, time-series, retail-analytics","summary":"A complete year of sales transactions from a Polish grocery store in 2018, providing real-world retail data for analysis. This dataset is ideal for learning fundamental data analysis techniques on authentic business data. Perfect for practicing exploratory data analysis, sales forecasting, and understanding retail patterns.","use_cases":"Learning retail analytics fundamentals with real transaction data, Building sales forecasting models for small grocery businesses","audience":"Junior-DS, Curious-browser"},{"id":"dataset-uk-gift-shop-(online-retail)","type":"dataset","name":"UK Gift Shop (Online Retail)","description":"Online retail transactions (2010-2011) from UK gift retailer","category":"Grocery & Supermarkets","url":"http://archive.ics.uci.edu/dataset/352/online+retail","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, basic-SQL","topic_tags":"retail-analytics, customer-segmentation, transaction-data, e-commerce, RFM-analysis","summary":"Classic dataset of online retail transactions from a UK gift shop covering 2010-2011, containing customer purchases, product details, and transaction timestamps. Widely used for learning customer analytics, market basket analysis, and retail forecasting techniques. Perfect for practicing data cleaning and exploratory analysis on real-world e-commerce data.","use_cases":"Learning customer segmentation and RFM analysis techniques, Building recommendation systems for retail products","audience":"Junior-DS, Early-PhD"},{"id":"dataset-turkish-drugs","type":"dataset","name":"Turkish Drugs","description":"Drug sales data from Turkey","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/emrahaydemr/drug-sales-data","difficulty":"beginner","prerequisites":"python-pandas, time-series-analysis, data-visualization","topic_tags":"pharmaceutical-sales, turkey-market, retail-data, time-series, healthcare","summary":"This dataset contains drug sales data from the Turkish pharmaceutical market. It provides insights into medication purchasing patterns and market dynamics in Turkey's healthcare sector. Researchers and analysts can use this data to study pharmaceutical market trends, seasonal patterns, and consumer behavior in the Turkish healthcare system.","use_cases":"Analyzing seasonal patterns in pharmaceutical sales to optimize inventory management, Studying market penetration of different drug categories across Turkish regions","audience":"Junior-DS, Curious-browser"},{"id":"dataset-nyc-shopping","type":"dataset","name":"NYC Shopping","description":"Large sales dataset from New York City retail","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/pigment/big-sales-data","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, descriptive-statistics","topic_tags":"retail-data, sales-analysis, consumer-behavior, NYC-data, tabular-data","summary":"A comprehensive sales dataset from New York City retail establishments, focusing on grocery and supermarket transactions. This dataset provides rich transactional data ideal for learning retail analytics fundamentals and consumer behavior patterns. Perfect for beginners to practice data manipulation, visualization, and basic statistical analysis on real-world retail data.","use_cases":"Learning retail sales forecasting by analyzing seasonal patterns in NYC grocery purchases, Building customer segmentation models to understand shopping behavior across different NYC neighborhoods","audience":"Junior-DS, Curious-browser"},{"id":"dataset-mexican-grocery","type":"dataset","name":"Mexican Grocery","description":"Data from a Mexican grocery store","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/martinezjosegpe/grocery-store","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, descriptive-statistics","topic_tags":"grocery-data, retail-analytics, mexico, consumer-behavior, sales-data","summary":"This dataset contains transactional and operational data from a Mexican grocery store, providing insights into consumer purchasing patterns, product performance, and retail operations. It's ideal for learning retail analytics fundamentals and exploring cross-cultural consumer behavior. The data can be used to practice basic data analysis techniques on real-world retail scenarios.","use_cases":"Analyzing seasonal purchasing patterns and product demand forecasting for a Mexican retail chain, Comparing consumer behavior between Mexican and US grocery markets for market entry strategy","audience":"Junior-DS, Curious-browser"},{"id":"dataset-vietnam-supermarket","type":"dataset","name":"Vietnam Supermarket","description":"Sales and inventory snapshot data from Vietnamese supermarket","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/tienanh2003/sales-and-inventory-snapshot-data","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, descriptive-statistics","topic_tags":"retail-data, inventory-management, sales-analysis, emerging-markets, tabular-data","summary":"Point-in-time sales and inventory data from a Vietnamese supermarket chain, providing insights into Southeast Asian retail patterns. Ideal for learning retail analytics fundamentals and exploring inventory turnover metrics. Contains product-level sales volumes, stock levels, and basic category information across multiple store locations.","use_cases":"Learning retail KPIs like inventory turnover and stockout analysis for portfolio projects, Comparing product performance across different store locations to understand regional preferences","audience":"Junior-DS, Curious-browser"},{"id":"dataset-indian-grocery-(flipkart-supermart)","type":"dataset","name":"Indian Grocery (Flipkart Supermart)","description":"Flipkart Supermart transaction and product details","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/aryansingh95/flipkart-grocery-transaction-and-product-details","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-cleaning","topic_tags":"grocery-retail, transaction-data, india-ecommerce, flipkart, consumer-behavior","summary":"Transaction and product data from Flipkart Supermart's grocery operations in India. This dataset provides real-world e-commerce grocery data for analyzing consumer purchasing patterns, product performance, and market dynamics in the Indian online grocery sector.","use_cases":"Analyzing seasonal demand patterns for grocery products in Indian e-commerce, Building recommendation systems for online grocery shopping platforms","audience":"Junior-DS, Curious-browser"},{"id":"dataset-israeli-grocery","type":"dataset","name":"Israeli Grocery","description":"Grocery purchase data from Israel","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/arielpazsawicki/kimonaim","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, data-visualization","topic_tags":"grocery-data, consumer-behavior, retail-analytics, israel, purchase-patterns","summary":"This dataset contains grocery purchase transaction data from Israeli consumers, providing insights into shopping behaviors and consumption patterns. It's commonly used by retail analysts and economists studying consumer choice and market dynamics. The data can help understand seasonal trends, basket composition, and regional purchasing preferences in the Israeli grocery market.","use_cases":"Analyzing seasonal shopping patterns and holiday effects on grocery purchases, Building market basket analysis models to understand product associations and cross-selling opportunities","audience":"Junior-DS, Curious-browser"},{"id":"dataset-brazilian-store-chain","type":"dataset","name":"Brazilian Store Chain","description":"Sales data from Brazilian retail chain","category":"Grocery & Supermarkets","url":"https://www.kaggle.com/datasets/marcio486/sales-data-for-a-chain-of-brazilian-stores","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, SQL-basics","topic_tags":"retail-analytics, sales-forecasting, consumer-behavior, geographic-analysis, time-series","summary":"This dataset contains transactional sales data from a Brazilian retail chain, including product categories, store locations, and temporal patterns. It's ideal for learning retail analytics fundamentals and exploring consumer purchasing behavior across different regions. The data enables analysis of seasonality, regional preferences, and store performance metrics.","use_cases":"Analyzing seasonal demand patterns to optimize inventory management across different store locations, Building customer segmentation models to understand regional purchasing behaviors and preferences","audience":"Junior-DS, Curious-browser"},{"id":"dataset-dominicks-soft-drinks","type":"dataset","name":"Dominicks Soft Drinks","description":"Weekly scanner data on soft drink purchases from Dominick's Finer Foods","category":"Grocery & Supermarkets","url":"https://www.chicagobooth.edu/research/kilts/research-data/dominicks","difficulty":"beginner","prerequisites":"python-pandas, basic-econometrics, data-visualization","topic_tags":"scanner-data, consumer-behavior, pricing-analysis, retail-data, grocery","summary":"Weekly scanner data capturing soft drink purchases from Dominick's Finer Foods, a Chicago-area grocery chain. This classic dataset is widely used in marketing and economics research to study consumer purchasing behavior, price elasticity, and promotional effects. The data includes product-level sales, prices, and promotional information across multiple store locations.","use_cases":"Analyzing price elasticity of demand for different soft drink brands, Studying the effectiveness of promotional campaigns on consumer purchasing patterns","audience":"Early-PhD, Junior-DS"},{"id":"dataset-hashed-multimodal-banking","type":"dataset","name":"Hashed Multimodal Banking","description":"Banking transactions and product purchases with hashed identifiers","category":"Financial Services","url":"https://github.com/dzhambo/mbd","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, data-hashing","topic_tags":"banking-data, privacy-preserving, transaction-analysis, multimodal-data","summary":"A banking dataset containing transaction records and product purchase data with privacy-preserving hashed customer and merchant identifiers. The multimodal nature combines structured transaction data with product information, making it suitable for financial analytics while protecting sensitive customer information. Commonly used by data scientists in fintech and researchers studying consumer banking behavior.","use_cases":"Building fraud detection models without exposing customer identities, Analyzing customer purchase patterns across different banking products","audience":"Junior-DS, Mid-DS"},{"id":"dataset-sec-edgar-filings","type":"dataset","name":"SEC EDGAR Filings","description":"21M+ public company filings since 1994. 10-Ks, 8-Ks, proxy statements. Full text + structured XBRL data","category":"Financial Services","url":"https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, text-processing","topic_tags":"SEC-filings, financial-data, corporate-disclosure, text-mining, regulatory-data","summary":"Comprehensive database of SEC corporate filings containing 21+ million documents from public companies since 1994. Includes annual reports (10-Ks), quarterly reports (10-Qs), current reports (8-Ks), and proxy statements in both full text and structured XBRL format. Essential resource for financial analysis, corporate research, and regulatory compliance studies.","use_cases":"Analyzing executive compensation trends across industries using proxy statement data, Building models to predict stock price movements based on 10-K risk factor disclosures","audience":"Mid-DS, Senior-DS"},{"id":"dataset-indonesian-fashion","type":"dataset","name":"Indonesian Fashion","description":"Fashion items for image classification tasks from Indonesia","category":"Fashion & Apparel","url":"https://www.kaggle.com/datasets/latifahhukma/fashion-campus","difficulty":"beginner","prerequisites":"python-opencv, convolutional-neural-networks, image-preprocessing","topic_tags":"image-classification, fashion-dataset, indonesia, computer-vision, apparel-recognition","summary":"A curated dataset of Indonesian fashion items designed for image classification machine learning tasks. The dataset provides labeled images of traditional and contemporary clothing items from Indonesia, making it valuable for computer vision practitioners working on fashion recognition systems. It serves as both a learning resource for beginners and a practical dataset for building fashion recommendation or categorization applications.","use_cases":"Building an e-commerce clothing categorization system for Southeast Asian markets, Training a fashion recommendation engine that understands regional clothing preferences","audience":"Junior-DS, Curious-browser"},{"id":"dataset-diginetica-fashion","type":"dataset","name":"Diginetica Fashion","description":"Clickstream and purchase data for fashion e-commerce","category":"Fashion & Apparel","url":"https://competitions.codalab.org/competitions/11161","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, session-analysis","topic_tags":"clickstream-data, e-commerce-analytics, fashion-retail, user-behavior, session-data","summary":"Diginetica Fashion is a clickstream and purchase dataset from fashion e-commerce containing user interactions, product views, and transaction data. It's commonly used in data science competitions and educational projects for learning e-commerce analytics. The dataset provides real-world examples of user behavior patterns in online fashion retail.","use_cases":"Building recommendation systems for fashion e-commerce platforms, Analyzing user journey patterns from browsing to purchase conversion","audience":"Junior-DS, Curious-browser"},{"id":"dataset-dressipi-fashion-(recsys-2022)","type":"dataset","name":"Dressipi Fashion (RecSys 2022)","description":"Session interactions and item features from styling service","category":"Fashion & Apparel","url":"http://www.recsyschallenge.com/2022/dataset.html","difficulty":"intermediate","prerequisites":"python-pandas, collaborative-filtering, session-based-recommendation","topic_tags":"fashion-recommendation, session-data, RecSys-dataset, styling-interactions, sequential-modeling","summary":"A dataset from Dressipi's fashion styling service containing user session interactions and detailed item features, released for the RecSys 2022 conference. It captures real-world fashion recommendation scenarios with temporal dynamics and styling context. The dataset is valuable for researchers developing session-based and sequential recommendation algorithms in the fashion domain.","use_cases":"Developing session-based recommendation models for fashion e-commerce platforms, Benchmarking sequential recommendation algorithms on real styling service data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-fashion-mnist","type":"dataset","name":"Fashion-MNIST","description":"70,000 28x28 grayscale images of 10 fashion categories from Zalando","category":"Fashion & Apparel","url":"https://github.com/zalandoresearch/fashion-mnist","difficulty":"beginner","prerequisites":"python-numpy, convolutional-neural-networks, image-preprocessing","topic_tags":"image-classification, benchmark-dataset, computer-vision, fashion-retail, deep-learning","summary":"Fashion-MNIST is a dataset of 70,000 grayscale images showing clothing and accessories across 10 categories, designed as a more challenging replacement for the classic MNIST digit dataset. It's widely used by researchers and practitioners to benchmark image classification algorithms and test computer vision models. The dataset maintains the same format as MNIST but provides more realistic complexity for fashion item recognition tasks.","use_cases":"Testing and comparing different deep learning architectures for image classification before deploying on production fashion datasets, Teaching computer vision concepts to students with a more engaging alternative to handwritten digits","audience":"Junior-DS, Early-PhD"},{"id":"dataset-blp-us-car-data","type":"dataset","name":"BLP US Car Data","description":"Classic dataset (1971-1990) for demand model estimation","category":"Automotive","url":"https://pyblp.readthedocs.io/en/stable/_notebooks/tutorial/blp.html","difficulty":"advanced","prerequisites":"structural-modeling, GMM-estimation, IV-regression","topic_tags":"demand-estimation, BLP-model, automotive-data, structural-econometrics, dataset","summary":"The foundational dataset used in Berry, Levinsohn, and Pakes' seminal 1995 paper on demand estimation for differentiated products. Contains US automobile market data from 1971-1990 including prices, quantities, and product characteristics. Essential for learning and implementing BLP demand models in industrial organization research.","use_cases":"Learning to implement BLP demand estimation methods for PhD coursework or research, Benchmarking new demand estimation algorithms against established results","audience":"Early-PhD, Senior-DS"},{"id":"dataset-european-car-market","type":"dataset","name":"European Car Market","description":"Car information including prices and attributes (1970-1999)","category":"Automotive","url":"https://sites.google.com/site/frankverbo/data-and-software/data-set-on-the-european-car-market","difficulty":"beginner","prerequisites":"python-pandas, basic-regression, data-visualization","topic_tags":"automotive-data, price-analysis, industrial-organization, european-markets, panel-data","summary":"A comprehensive dataset of European car sales containing vehicle characteristics, pricing, and market information from 1970-1999. This clean, structured dataset is ideal for learning econometric methods and exploring industrial organization concepts. Perfect for analyzing market dynamics, price elasticity, and consumer choice in the automotive sector.","use_cases":"Learning demand estimation and discrete choice modeling with real market data, Analyzing how car features affect pricing and market share over three decades","audience":"Early-PhD, Junior-DS"},{"id":"dataset-russian-car-market","type":"dataset","name":"Russian Car Market","description":"Car sales information in Russia","category":"Automotive","url":"https://www.kaggle.com/datasets/ekibee/car-sales-information","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-econometrics","topic_tags":"automotive-data, market-analysis, russia, sales-data, tabular-dataset","summary":"A dataset containing car sales information from the Russian automotive market. This dataset is useful for economists and data scientists studying consumer behavior, market dynamics, and pricing patterns in emerging markets. The data can be used to analyze demand patterns, brand preferences, and seasonal trends in car purchases.","use_cases":"Analyzing price elasticity and demand patterns for different car brands in the Russian market, Building predictive models for car sales forecasting based on seasonal and economic factors","audience":"Junior-DS, Curious-browser"},{"id":"dataset-german-used-cars","type":"dataset","name":"German Used Cars","description":"Used car listings or sales in Germany","category":"Automotive","url":"https://www.kaggle.com/datasets/gogotchuri/myautogecardetails","difficulty":"beginner","prerequisites":"python-pandas, basic-regression, data-cleaning","topic_tags":"automotive-data, pricing-models, german-market, used-cars, consumer-behavior","summary":"A dataset containing used car listings and sales data from the German automotive market. This dataset is commonly used by data scientists learning pricing models and market analysis techniques. It provides real-world examples of consumer behavior, vehicle depreciation patterns, and market dynamics in one of Europe's largest car markets.","use_cases":"Building price prediction models for used vehicles based on features like mileage, age, and brand, Analyzing depreciation curves and market trends for different car manufacturers in the German market","audience":"Junior-DS, Curious-browser"},{"id":"dataset-indian-automobiles-(telangana)","type":"dataset","name":"Indian Automobiles (Telangana)","description":"Vehicle sales data for Telangana, India (2023)","category":"Automotive","url":"https://www.kaggle.com/datasets/zubairatha/revving-up-telangana-vehicle-sales-2023","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"automotive-data, regional-sales, india-market, vehicle-analytics, sales-dataset","summary":"Vehicle sales dataset from Telangana state, India covering 2023 transactions and registrations. Useful for analysts studying regional automotive markets, consumer preferences, and sales patterns in emerging economies. Contains structured data suitable for exploratory analysis and visualization projects.","use_cases":"Market research analyst studying regional vehicle preferences and brand performance in Indian states, Junior data scientist practicing exploratory data analysis on real-world sales data","audience":"Junior-DS, Curious-browser"},{"id":"dataset-fliggy-travel","type":"dataset","name":"Fliggy Travel","description":"Travel-related data from Alibaba's online travel platform","category":"Travel & Hospitality","url":"https://tianchi.aliyun.com/dataset/113649","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, exploratory-data-analysis","topic_tags":"travel-data, e-commerce, user-behavior, booking-patterns, alibaba","summary":"Travel-related dataset from Fliggy, Alibaba's online travel platform containing booking and user interaction data. This dataset provides insights into travel booking patterns, user preferences, and seasonal trends in the Chinese travel market. It's valuable for understanding e-commerce travel platforms and consumer behavior analysis.","use_cases":"Analyzing seasonal travel booking patterns and peak demand periods, Building recommendation systems for hotels and destinations based on user preferences","audience":"Junior-DS, Curious-browser"},{"id":"dataset-fliggy-transfers","type":"dataset","name":"Fliggy Transfers","description":"Transfer-related data (flights, ground transport) from Fliggy","category":"Travel & Hospitality","url":"https://tianchi.aliyun.com/dataset/140721","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-visualization","topic_tags":"travel-data, transportation-analytics, booking-patterns, mobility-data, hospitality-dataset","summary":"Fliggy Transfers is a dataset containing transfer-related booking and usage data from Alibaba's travel platform, covering flights and ground transportation services. This dataset is valuable for travel industry analysts and data scientists studying booking patterns, transfer preferences, and transportation network optimization. The data provides insights into customer behavior in the travel and hospitality sector.","use_cases":"Analyzing peak travel seasons and transfer demand patterns for transportation companies, Building recommendation systems for optimal flight-to-ground transport connections","audience":"Junior-DS, Mid-DS"},{"id":"dataset-expedia-hotel","type":"dataset","name":"Expedia Hotel","description":"Hotel booking and search data from Expedia","category":"Travel & Hospitality","url":"https://www.kaggle.com/datasets/vijeetnigam26/expedia-hotel","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, SQL-basics","topic_tags":"hotel-bookings, search-behavior, travel-data, conversion-rates, user-sessions","summary":"Hotel booking and search data from Expedia containing user search sessions, hotel attributes, and booking outcomes. This dataset is commonly used for learning predictive modeling and understanding customer behavior in the travel industry. It provides a rich foundation for exploring conversion optimization and recommendation systems.","use_cases":"Building hotel recommendation systems based on user search patterns, Analyzing conversion rates and identifying factors that drive bookings","audience":"Junior-DS, Curious-browser"},{"id":"dataset-airline-delay","type":"dataset","name":"Airline Delay","description":"Airline flight delays and carrier information","category":"Transportation & Mobility","url":"https://www.kaggle.com/datasets/sriharshaeedala/airline-delay","difficulty":"beginner","prerequisites":"python-pandas, basic-sql, descriptive-statistics","topic_tags":"airline-operations, delay-analysis, transportation-data, operational-metrics, time-series","summary":"A comprehensive dataset containing flight delay information and carrier details for analyzing airline operational performance. This dataset is commonly used by transportation analysts, operations researchers, and data scientists to study patterns in flight delays, carrier efficiency, and seasonal travel trends. It provides rich ground truth data for predictive modeling and operational optimization in the aviation industry.","use_cases":"Building predictive models to forecast flight delays based on carrier, route, and seasonal factors, Conducting comparative analysis of airline carrier performance and operational efficiency metrics","audience":"Junior-DS, Curious-browser"},{"id":"dataset-netease-music-(informs)","type":"dataset","name":"NetEase Music (INFORMS)","description":"Data from NetEase Cloud Music for INFORMS competition","category":"Entertainment & Media","url":"https://connect.informs.org/rmp/awards/data-competition","difficulty":"beginner","prerequisites":"python-pandas, exploratory-data-analysis, basic-statistics","topic_tags":"music-streaming, user-behavior, competition-dataset, chinese-market, entertainment-analytics","summary":"NetEase Cloud Music dataset from an INFORMS competition containing user listening behavior and music metadata from one of China's largest music streaming platforms. The dataset provides insights into music consumption patterns, user preferences, and streaming dynamics in the Chinese market. It's ideal for learning recommendation systems, user segmentation, and music analytics techniques.","use_cases":"Building music recommendation algorithms to predict user listening preferences, Analyzing user engagement patterns to optimize playlist curation strategies","audience":"Junior-DS, Curious-browser"},{"id":"dataset-bandcamp-music-sales","type":"dataset","name":"Bandcamp Music Sales","description":"Music sales data (digital/physical) from Bandcamp platform","category":"Entertainment & Media","url":"https://components.one/datasets/bandcamp-sales","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, data-visualization","topic_tags":"music-industry, sales-analytics, independent-artists, digital-commerce, creative-economy","summary":"This dataset contains music sales data from Bandcamp, covering both digital and physical purchases from independent artists on the platform. It provides insights into consumer behavior, pricing strategies, and sales patterns in the independent music ecosystem. The data is valuable for understanding how artists monetize their work outside traditional record label structures.","use_cases":"Analyzing pricing strategies for independent musicians to optimize revenue, Understanding seasonal trends and fan purchasing behavior in digital music markets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-spotify-music-streaming-sessions-(mssd)","type":"dataset","name":"Spotify Music Streaming Sessions (MSSD)","description":"150M+ listening sessions with skips, track features, and playlist context. The largest public music streaming behavior dataset","category":"Entertainment & Media","url":"https://paperswithcode.com/dataset/mssd","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, basic-statistics","topic_tags":"music-streaming, user-behavior, large-scale-dataset, spotify-data, session-analysis","summary":"The Spotify Music Streaming Sessions Dataset contains over 150 million listening sessions with detailed information about user skips, track audio features, and playlist context. This is the largest publicly available dataset for analyzing music streaming behavior and user preferences. Researchers and data scientists use it to study recommendation systems, user engagement patterns, and music consumption trends.","use_cases":"Building recommendation algorithms by analyzing skip patterns and track features, Measuring user engagement and churn prediction based on listening session behavior","audience":"Junior-DS, Mid-DS"},{"id":"dataset-online-auctions-collection","type":"dataset","name":"Online Auctions Collection","description":"Collection of datasets from eBay and experimental auctions","category":"Auctions & Marketplaces","url":"https://www.modelingonlineauctions.com/datasets","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-visualization","topic_tags":"auction-data, ebay-bidding, marketplace-analysis, experimental-auctions, bidding-behavior","summary":"Collection of real eBay auction data and controlled experimental auction datasets for studying bidding behavior and marketplace dynamics. These datasets are commonly used by researchers and practitioners to analyze auction mechanisms, price discovery, and strategic bidding patterns. The data includes bid histories, final prices, item characteristics, and participant behavior across different auction formats.","use_cases":"Analyzing bidding patterns and reserve price effects in online marketplaces, Comparing auction formats and their impact on revenue and participant behavior","audience":"Junior-DS, Early-PhD"},{"id":"dataset-crypto-art-(superrare)","type":"dataset","name":"Crypto Art (SuperRare)","description":"Bids and transactions from SuperRare NFT platform","category":"Auctions & Marketplaces","url":"https://www.kaggle.com/datasets/franceschet/superrare","difficulty":"intermediate","prerequisites":"python-pandas, auction-theory, web3-blockchain-concepts","topic_tags":"NFT-markets, digital-auctions, crypto-economics, art-valuation, blockchain-data","summary":"This dataset contains bidding and transaction data from SuperRare, a prominent NFT marketplace focused on digital art. It provides researchers with real-world auction data to study pricing mechanisms, bidder behavior, and market dynamics in the emerging crypto art economy. The data enables analysis of digital collectibles markets and blockchain-based auction systems.","use_cases":"Analyzing bidding patterns and price discovery mechanisms in NFT auctions, Studying the relationship between artist reputation, artwork characteristics, and final sale prices","audience":"Junior-DS, Mid-DS"},{"id":"dataset-ukraine-procurement-(prozorro)","type":"dataset","name":"Ukraine Procurement (ProZorro)","description":"Public procurement data from ProZorro system","category":"Auctions & Marketplaces","url":"https://www.kaggle.com/datasets/oleksastepaniuk/prozorro-public-procurement-dataset","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, data-visualization","topic_tags":"public-procurement, government-data, auction-analysis, transparency, ukraine","summary":"Public procurement data from Ukraine's ProZorro electronic procurement system, containing bidding information, contract awards, and supplier details. This dataset is valuable for economists and data scientists studying government spending patterns, market competition, and procurement transparency. The data includes auction mechanics, bid amounts, winner selection, and contract performance metrics.","use_cases":"Analyzing bid competition and collusion patterns in government contracts, Studying the impact of transparency reforms on procurement outcomes and pricing","audience":"Mid-DS, Senior-DS"},{"id":"dataset-romania-tenders","type":"dataset","name":"Romania Tenders","description":"Public tender data (2007-2016) from Romania","category":"Auctions & Marketplaces","url":"https://www.kaggle.com/datasets/gpreda/public-tenders-romania-20072016","difficulty":"intermediate","prerequisites":"python-pandas, procurement-economics, data-cleaning","topic_tags":"public-procurement, government-data, auction-analysis, Romania, tender-data","summary":"A comprehensive dataset of Romanian public procurement tenders from 2007-2016, containing bidding information, contract values, and supplier details. This dataset enables researchers and analysts to study government spending patterns, market competition, and procurement efficiency. It's particularly valuable for understanding public sector purchasing behavior and analyzing bidder participation in emerging European markets.","use_cases":"Analyzing corruption risks in public procurement by examining bid patterns and supplier concentration, Studying the impact of EU procurement regulations on bidding competition and contract awards","audience":"Mid-DS, Early-PhD"},{"id":"dataset-art-auction-(artists-for-lahaina)","type":"dataset","name":"Art Auction (Artists for Lahaina)","description":"Artists for Lahaina benefit art auction data (2023)","category":"Auctions & Marketplaces","url":"https://www.kaggle.com/datasets/flkuhm/art-price-dataset","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-visualization","topic_tags":"art-markets, auction-data, charity-fundraising, bidding-behavior, dataset","summary":"This dataset contains bidding and sales data from a 2023 charity art auction organized to benefit Lahaina fire victims. It provides real-world auction data suitable for analyzing bidding patterns, price determinants, and charitable giving behavior in art markets. The dataset is ideal for learning auction analysis techniques and understanding how charitable context affects market outcomes.","use_cases":"Analyzing factors that drive higher bids in charity auctions versus regular art sales, Building models to predict final sale prices based on artist characteristics and auction dynamics","audience":"Junior-DS, Curious-browser"},{"id":"dataset-used-car-auction-(pakwheels)","type":"dataset","name":"Used Car Auction (PakWheels)","description":"Listings from PakWheels Pakistani automobile marketplace","category":"Auctions & Marketplaces","url":"https://www.kaggle.com/datasets/asimzahid/pakistans-largest-pakwheels-automobiles-listings","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, exploratory-data-analysis","topic_tags":"automobile-pricing, marketplace-data, Pakistan-market, used-cars, auction-data","summary":"A dataset of car listings from PakWheels, Pakistan's largest automobile marketplace, containing information about used car sales and pricing. This data is ideal for learning basic data analysis techniques and understanding marketplace dynamics. Researchers and analysts can use it to study pricing patterns, market trends, and consumer behavior in the Pakistani automotive sector.","use_cases":"Building a price prediction model for used cars in Pakistan, Analyzing market trends and popular vehicle types in South Asian automotive markets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-ipinyou-rtb","type":"dataset","name":"Ipinyou RTB","description":"Real-time bidding (RTB) dataset for CTR prediction","category":"Advertising","url":"https://github.com/wnzhang/make-ipinyou-data","difficulty":"intermediate","prerequisites":"python-pandas, logistic-regression, feature-engineering","topic_tags":"real-time-bidding, click-through-rate, programmatic-advertising, conversion-prediction, dataset","summary":"The Ipinyou RTB dataset contains real-world data from programmatic advertising auctions, specifically designed for predicting click-through rates in real-time bidding scenarios. This dataset is widely used by researchers and practitioners to develop and benchmark CTR prediction models in computational advertising. It includes features like user demographics, ad characteristics, and contextual information from actual RTB campaigns.","use_cases":"Building machine learning models to predict which ads users are likely to click in programmatic auctions, Benchmarking different CTR prediction algorithms against industry-standard data for ad tech research","audience":"Mid-DS, Senior-DS"},{"id":"dataset-adform-display","type":"dataset","name":"Adform Display","description":"Display advertising dataset with impressions and clicks","category":"Advertising","url":"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/TADBY7","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, data-visualization","topic_tags":"display-advertising, click-through-rates, impressions, advertising-data, conversion-analysis","summary":"A display advertising dataset containing impression and click data from Adform's advertising platform. This dataset is ideal for learning digital advertising metrics and analyzing campaign performance. Researchers and practitioners use it to understand click-through rates, impression patterns, and basic advertising effectiveness.","use_cases":"calculating click-through rates and conversion metrics for advertising campaigns, building predictive models to estimate ad performance based on impression data","audience":"Junior-DS, Curious-browser"},{"id":"dataset-tencent-social-ads","type":"dataset","name":"Tencent Social Ads","description":"Social ad CTR prediction dataset from Tencent","category":"Advertising","url":"https://algo.qq.com/index.html","difficulty":"intermediate","prerequisites":"python-pandas, machine-learning-classification, feature-engineering","topic_tags":"CTR-prediction, social-advertising, dataset, Tencent, Chinese-market","summary":"A click-through rate prediction dataset from Tencent's social advertising platform, containing user interactions and ad features from the Chinese market. This dataset is commonly used for benchmarking CTR prediction models and understanding social ad performance patterns. It provides real-world advertising data for developing and testing recommendation systems and predictive models.","use_cases":"Benchmarking CTR prediction algorithms against industry-standard dataset, Training machine learning models for social media advertising optimization","audience":"Junior-DS, Mid-DS"},{"id":"dataset-outbrain-click-prediction","type":"dataset","name":"Outbrain Click Prediction","description":"Click prediction based on browsing history from Outbrain","category":"Advertising","url":"https://www.kaggle.com/competitions/outbrain-click-prediction","difficulty":"intermediate","prerequisites":"python-pandas, logistic-regression, feature-engineering","topic_tags":"click-prediction, advertising, kaggle-dataset, browsing-behavior, content-recommendation","summary":"A Kaggle competition dataset from Outbrain containing user browsing history and click behavior for predicting content engagement. The dataset includes user demographics, page content features, and click/no-click labels for training recommendation models. Commonly used for learning click-through rate prediction techniques and content recommendation system development.","use_cases":"Training models to predict which recommended articles users will click based on their browsing patterns, Benchmarking different feature engineering approaches for content recommendation systems","audience":"Junior-DS, Mid-DS"},{"id":"dataset-soso-(kdd-cup-2012)","type":"dataset","name":"Soso (KDD Cup 2012)","description":"KDD Cup 2012 Track 2 for sponsored search CTR prediction","category":"Advertising","url":"https://www.kaggle.com/competitions/kddcup2012-track2","difficulty":"intermediate","prerequisites":"logistic-regression, python-pandas, feature-engineering","topic_tags":"click-through-rate, sponsored-search, competition-dataset, advertising-optimization, binary-classification","summary":"The KDD Cup 2012 Track 2 dataset contains sponsored search advertising data for predicting click-through rates on search ads. It's a classic benchmark dataset used by data scientists and researchers to develop and evaluate CTR prediction models. The dataset includes features like query terms, ad content, user behavior, and advertiser information.","use_cases":"Training machine learning models to predict which search ads users are likely to click, Benchmarking new CTR prediction algorithms against established baselines from the competition","audience":"Mid-DS, Junior-DS"},{"id":"dataset-real-time-advertisers-auction","type":"dataset","name":"Real-Time Advertisers Auction","description":"Real-time advertiser auction dataset for RTB research","category":"Advertising","url":"https://www.kaggle.com/datasets/saurav9786/real-time-advertisers-auction","difficulty":"intermediate","prerequisites":"auction-theory, python-pandas, statistical-inference","topic_tags":"real-time-bidding, auction-mechanisms, programmatic-advertising, dataset, behavioral-data","summary":"A dataset containing real-time bidding auction data from programmatic advertising platforms, including bid prices, advertiser behavior, and auction outcomes. Used by researchers and data scientists to study auction mechanisms, bidding strategies, and market dynamics in digital advertising. Provides ground truth data for developing and evaluating RTB algorithms and pricing models.","use_cases":"Testing bid optimization algorithms against historical auction data, Analyzing market concentration and competitive dynamics in programmatic advertising","audience":"Mid-DS, Senior-DS"},{"id":"dataset-icpsr-auction-studies","type":"dataset","name":"ICPSR Auction Studies","description":"Search results for auction studies from ICPSR","category":"Advertising","url":"https://www.openicpsr.org/openicpsr/search/studies","difficulty":"intermediate","prerequisites":"econometrics-basics, auction-theory, stata-or-r","topic_tags":"auction-mechanisms, experimental-economics, bidding-behavior, market-design, social-science-data","summary":"ICPSR Auction Studies is a collection of datasets from experimental and field studies examining bidding behavior, auction mechanisms, and market outcomes. These datasets are commonly used by economists and social scientists to test auction theory predictions and understand strategic behavior in different auction formats. The collection includes both laboratory experiments and real-world auction data with detailed participant and outcome information.","use_cases":"Testing whether bidding behavior matches theoretical predictions in first-price sealed-bid auctions, Analyzing the revenue effects of different auction formats using experimental data","audience":"Early-PhD, Senior-DS"},{"id":"dataset-harvard-dataverse-auctions","type":"dataset","name":"Harvard Dataverse Auctions","description":"Auction-related replication datasets from Harvard Dataverse","category":"Advertising","url":"https://dataverse.harvard.edu/dataverse/harvard","difficulty":"beginner","prerequisites":"python-pandas, basic-econometrics, data-cleaning","topic_tags":"auctions, replication-data, advertising, harvard-dataverse, empirical-research","summary":"A collection of auction-related datasets from Harvard Dataverse specifically curated for replication studies in advertising and auction research. These datasets enable researchers and practitioners to reproduce published academic findings and validate auction models. The data typically includes bid amounts, auction outcomes, participant behavior, and contextual variables from real-world auction environments.","use_cases":"Replicating seminal auction theory papers for thesis research, Validating programmatic advertising bidding strategies using historical auction data","audience":"Early-PhD, Junior-DS"},{"id":"dataset-cainiao-last-mile-(msom18)","type":"dataset","name":"Cainiao Last-Mile (MSOM18)","description":"Cainiao Last-Mile Delivery dataset from MSOM 2018","category":"Food & Delivery","url":"https://tianchi.aliyun.com/competition/entrance/231623/information","difficulty":"intermediate","prerequisites":"python-pandas, network-analysis, descriptive-statistics","topic_tags":"last-mile-delivery, logistics-optimization, supply-chain, operations-research, dataset","summary":"Real-world dataset from Cainiao's last-mile delivery operations, published in Manufacturing & Service Operations Management 2018. Contains delivery routes, timing, and operational metrics from one of China's largest logistics networks. Useful for studying delivery optimization, route planning, and supply chain analytics.","use_cases":"Analyzing delivery route efficiency and identifying bottlenecks in urban logistics networks, Benchmarking last-mile delivery performance metrics against industry standards from a major e-commerce platform","audience":"Mid-DS, Early-PhD"},{"id":"dataset-bts-airline-on-time-performance","type":"dataset","name":"BTS Airline On-Time Performance","description":"All US flights since 1987. Delays, cancellations, fares, capacity. Revenue management research goldmine","category":"Transportation & Mobility","url":"https://www.transtats.bts.gov/ontime/","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, time-series-analysis","topic_tags":"airline-data, delay-prediction, pricing-analysis, transportation, large-dataset","summary":"Comprehensive dataset containing all US commercial flights from 1987 onwards with detailed information on delays, cancellations, fares, and capacity. This is a go-to resource for transportation economists and data scientists studying airline operations, pricing strategies, and service quality. The dataset's size and temporal span make it ideal for learning large-scale data analysis and time series methods.","use_cases":"Building delay prediction models to optimize flight scheduling and passenger experience, Analyzing airline pricing strategies and competitive dynamics across different routes and time periods","audience":"Junior-DS, Curious-browser"},{"id":"dataset-amazon-last-mile","type":"dataset","name":"Amazon Last Mile","description":"9,184 historical routes across 5 US metro areas","category":"Logistics & Supply Chain","url":"https://registry.opendata.aws/amazon-last-mile-challenges/","difficulty":"beginner","prerequisites":"python-pandas, geospatial-data-analysis, basic-optimization","topic_tags":"routing-optimization, last-mile-delivery, geospatial-analysis, operations-research, dataset","summary":"A comprehensive dataset containing 9,184 historical delivery routes from Amazon's last-mile operations across 5 major US metropolitan areas. This dataset provides real-world routing data that researchers and practitioners can use to benchmark routing algorithms, analyze delivery patterns, and develop optimization models. It's particularly valuable for understanding the complexities of urban delivery logistics and testing theoretical models against actual operational data.","use_cases":"Benchmarking vehicle routing algorithms against real Amazon delivery data, Analyzing delivery efficiency patterns across different urban environments","audience":"Junior-DS, Mid-DS"},{"id":"dataset-lade-last-mile-delivery","type":"dataset","name":"LaDe Last-Mile Delivery","description":"10.6M+ packages, 619k trajectories with GPS data","category":"Logistics & Supply Chain","url":"https://arxiv.org/html/2306.10675v2","difficulty":"intermediate","prerequisites":"python-pandas, geospatial-analysis, SQL-queries","topic_tags":"last-mile-delivery, GPS-tracking, logistics-optimization, trajectory-analysis, supply-chain","summary":"Large-scale dataset containing over 10.6 million package deliveries with detailed GPS trajectory data from 619,000 delivery routes. Primarily used by logistics researchers and data scientists to analyze delivery patterns, optimize routing algorithms, and study last-mile delivery efficiency. The dataset provides real-world delivery behavior data for developing predictive models and operational improvements.","use_cases":"Building route optimization algorithms for delivery companies to reduce fuel costs and delivery times, Analyzing delivery success rates and identifying factors that lead to failed deliveries or delays","audience":"Mid-DS, Senior-DS"},{"id":"dataset-dataco-supply-chain","type":"dataset","name":"DataCo Supply Chain","description":"Synthetic supply chain dataset covering sales and returns","category":"Logistics & Supply Chain","url":"https://tianchi.aliyun.com/dataset/89959","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-SQL","topic_tags":"supply-chain-analytics, synthetic-data, logistics, dataset, operations","summary":"A synthetic dataset simulating supply chain operations including sales transactions, product returns, and logistics data. Designed for learning supply chain analytics without proprietary business data constraints. Ideal for students and practitioners wanting to explore inventory optimization, demand forecasting, and return rate analysis.","use_cases":"Learning supply chain KPIs and building dashboards for inventory turnover and fill rates, Practicing demand forecasting models to predict seasonal sales patterns","audience":"Junior-DS, Curious-browser"},{"id":"dataset-drone-delivery","type":"dataset","name":"Drone Delivery","description":"Drone delivery logistics and operations dataset","category":"Logistics & Supply Chain","url":"https://tianchi.aliyun.com/dataset/89726","difficulty":"intermediate","prerequisites":"python-pandas, geospatial-analysis, optimization-algorithms","topic_tags":"drone-delivery, last-mile-logistics, route-optimization, autonomous-vehicles, supply-chain","summary":"Comprehensive dataset covering drone delivery operations including flight paths, delivery times, weather conditions, and operational costs. Used by logistics companies and researchers to optimize delivery routes and analyze autonomous delivery performance. Contains real-world operational data for evaluating drone deployment strategies and efficiency metrics.","use_cases":"Optimizing drone delivery routes for e-commerce companies to minimize delivery time and operational costs, Analyzing weather impact on drone delivery success rates for logistics planning and risk assessment","audience":"Mid-DS, Junior-DS"},{"id":"dataset-natural-driving-in-ohio","type":"dataset","name":"Natural Driving in Ohio","description":"ADAS-equipped vehicles with driving behavior events","category":"Transportation & Mobility","url":"https://data.transportation.gov/Automobiles/Advanced-Driver-Assistance-System-ADAS-Equipped-Si/iie8-uenj/about_data","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"driving-behavior, ADAS, transportation-data, government-dataset","summary":"A government dataset containing driving behavior events from vehicles equipped with Advanced Driver Assistance Systems (ADAS) in Ohio. The dataset captures real-world driving patterns, safety events, and system interventions from ADAS-enabled vehicles. This data is valuable for transportation researchers, automotive engineers, and data scientists studying driver behavior and autonomous vehicle safety.","use_cases":"Analyzing the effectiveness of ADAS features in preventing accidents or unsafe driving behaviors, Building predictive models to identify high-risk driving scenarios or locations for traffic safety improvements","audience":"Junior-DS, Mid-DS"},{"id":"dataset-ngsim-vehicle-trajectories","type":"dataset","name":"NGSIM Vehicle Trajectories","description":"Vehicle trajectory data for traffic flow modeling","category":"Transportation & Mobility","url":"https://data.transportation.gov/Automobiles/Next-Generation-Simulation-NGSIM-Vehicle-Trajector/8ect-6jqj/about_data","difficulty":"intermediate","prerequisites":"python-pandas, spatial-data-analysis, time-series-processing","topic_tags":"vehicle-trajectories, traffic-flow, transportation-data, microsimulation, mobility-analysis","summary":"NGSIM (Next Generation Simulation) contains high-resolution vehicle trajectory data collected from real highway segments, capturing individual vehicle positions, speeds, and movements over time. This dataset is widely used by transportation researchers and data scientists for developing and validating traffic flow models, autonomous vehicle algorithms, and mobility analytics. The data provides ground truth for understanding driving behavior patterns and traffic dynamics at the microscopic level.","use_cases":"Calibrating car-following models for autonomous vehicle simulation systems, Analyzing lane-changing behavior patterns to improve traffic management algorithms","audience":"Mid-DS, Senior-DS"},{"id":"dataset-grab-driving-gps-traces","type":"dataset","name":"Grab Driving GPS Traces","description":"GPS trace data from Grab ride-hailing platform","category":"Transportation & Mobility","url":"https://engineering.grab.com/grab-posisi","difficulty":"beginner","prerequisites":"python-pandas, geospatial-analysis, data-cleaning","topic_tags":"GPS-data, ride-hailing, transportation-analysis, geospatial-datasets, Southeast-Asia","summary":"GPS trace data from Grab's ride-hailing platform covering Southeast Asian markets. This dataset provides real-world mobility patterns and routing behavior from one of the region's largest transportation platforms. Useful for studying urban mobility, route optimization, and transportation demand patterns in emerging markets.","use_cases":"Analyzing traffic patterns and congestion hotspots in Southeast Asian cities, Building route recommendation systems for ride-hailing applications","audience":"Junior-DS, Mid-DS"},{"id":"dataset-nyc-tlc-trip-records","type":"dataset","name":"NYC TLC Trip Records","description":"3B+ taxi and rideshare trips since 2009. Fares, tips, surge pricing, driver pay. The gold standard for marketplace analytics","category":"Transportation & Mobility","url":"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, statistical-hypothesis-testing","topic_tags":"transportation-data, marketplace-dynamics, surge-pricing, large-datasets, urban-analytics","summary":"Comprehensive dataset of over 3 billion taxi and rideshare trips in NYC from 2009 onwards, including detailed fare structures, tip patterns, and surge pricing data. Widely used by researchers and practitioners studying two-sided marketplaces, urban mobility patterns, and dynamic pricing strategies. Considered the benchmark dataset for transportation economics and marketplace analysis.","use_cases":"Analyzing surge pricing effectiveness and consumer response patterns during peak demand periods, Building predictive models for taxi demand forecasting across different NYC neighborhoods and time periods","audience":"Mid-DS, Senior-DS"},{"id":"dataset-uber-movement","type":"dataset","name":"Uber Movement","description":"Zone-to-zone travel times and street speeds for 50+ cities worldwide. Congestion patterns from actual Uber rides","category":"Transportation & Mobility","url":"https://www.kaggle.com/datasets/ishandutta/uber-travel-movement-data-2-billion-trips","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, geospatial-analysis","topic_tags":"urban-mobility, travel-time-data, congestion-analysis, geospatial-data, transportation-economics","summary":"Uber Movement provides aggregated travel time and speed data from Uber trips across 50+ major cities worldwide. The dataset offers zone-to-zone movement patterns and congestion insights derived from real ride-sharing data. It's valuable for urban planners, transportation researchers, and data scientists studying mobility patterns and traffic optimization.","use_cases":"Analyzing how COVID-19 lockdowns affected urban mobility patterns across different city zones, Optimizing delivery routes by identifying consistently congested areas during peak hours","audience":"Junior-DS, Curious-browser"},{"id":"dataset-airbnb-(inside-airbnb)","type":"dataset","name":"AirBnb (Inside Airbnb)","description":"6M+ listings, 190M+ reviews with pricing and amenities","category":"Real Estate","url":"http://insideairbnb.com/explore","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"airbnb, pricing-data, hospitality, geospatial, dataset","summary":"Inside Airbnb provides comprehensive data on 6+ million Airbnb listings across global cities, including detailed pricing, amenities, host information, and 190+ million guest reviews. This open dataset is widely used by researchers, analysts, and policymakers to study short-term rental markets, housing impacts, and tourism patterns. The data includes rich geographic information and temporal snapshots, making it ideal for market analysis and academic research.","use_cases":"Analyzing rental price determinants across different neighborhoods and cities, Studying the impact of short-term rentals on local housing markets and availability","audience":"Junior-DS, Curious-browser"},{"id":"dataset-chicago-property-data","type":"dataset","name":"Chicago Property Data","description":"Property assessment values and sales data from Cook County","category":"Real Estate","url":"https://datacatalog.cookcountyil.gov/","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-cleaning","topic_tags":"property-values, real-estate, government-data, Chicago, tabular-data","summary":"Cook County property assessment and sales records providing detailed information on property values, characteristics, and transaction history in Chicago. This government dataset is commonly used by urban economists, real estate analysts, and policy researchers. The data enables analysis of housing markets, property tax equity, and neighborhood economic trends.","use_cases":"Analyzing property tax assessment accuracy and potential bias across different neighborhoods, Building hedonic pricing models to understand how property characteristics affect market values","audience":"Junior-DS, Curious-browser"},{"id":"dataset-nyc-property-sales","type":"dataset","name":"NYC Property Sales","description":"NYC property sales transactions across all boroughs","category":"Real Estate","url":"https://data.cityofnewyork.us/Housing-Development/NYC-Calendar-Sales-Archive-/uzf5-f8n2/about_data","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, basic-SQL","topic_tags":"real-estate, NYC, government-data, property-values, transactions","summary":"Comprehensive dataset of property sales transactions across all five NYC boroughs, maintained by the Department of Finance. This dataset provides detailed information on sales prices, property characteristics, and transaction dates. It's ideal for learning data analysis fundamentals while exploring real estate market dynamics in one of the world's most complex property markets.","use_cases":"analyzing neighborhood price trends and gentrification patterns, building predictive models for property valuations","audience":"Junior-DS, Curious-browser"},{"id":"dataset-yelp-dataset","type":"dataset","name":"Yelp Dataset","description":"Business attributes, reviews, user data, and check-ins","category":"Social & Web","url":"https://www.yelp.com/dataset","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, SQL-basics","topic_tags":"restaurant-data, sentiment-analysis, recommendation-systems, location-analytics, user-reviews","summary":"Large-scale dataset containing millions of business reviews, ratings, and user interactions from Yelp's platform. Includes rich metadata like business categories, location data, user networks, and temporal check-in patterns. Widely used for learning NLP techniques, recommendation systems, and local business analytics.","use_cases":"Building restaurant recommendation engines based on user preferences and review sentiment, Analyzing local business performance and customer satisfaction trends across different cities","audience":"Junior-DS, Curious-browser"},{"id":"dataset-wikipedia-pageviews","type":"dataset","name":"Wikipedia Pageviews","description":"296B views/year since 2007. Hourly pageview data for all Wikimedia projects. attention metrics at scale","category":"Social & Web","url":"https://dumps.wikimedia.org/other/pageviews/","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, data-visualization","topic_tags":"wikipedia, pageviews, attention-metrics, time-series, web-analytics","summary":"Comprehensive dataset containing hourly pageview counts for all Wikipedia articles and Wikimedia projects since 2007, totaling 296 billion views annually. This large-scale attention data provides insights into information consumption patterns, trending topics, and collective behavior across different languages and cultures. Ideal for studying digital attention dynamics, content popularity, and real-world event impacts on information seeking.","use_cases":"Analyzing how news events drive Wikipedia traffic spikes to measure public interest, Building predictive models for content popularity based on historical pageview patterns","audience":"Junior-DS, Curious-browser"},{"id":"dataset-pushshift-reddit-archive","type":"dataset","name":"Pushshift Reddit Archive","description":"5.6B comments, 651M posts since 2005. Full Reddit history for social/economic research. 100+ papers published","category":"Social & Web","url":"https://arxiv.org/abs/2001.08435","difficulty":"intermediate","prerequisites":"python-pandas, API-requests, text-preprocessing","topic_tags":"reddit-data, social-media-analysis, comment-mining, user-behavior, text-corpus","summary":"Complete historical archive of Reddit containing 5.6 billion comments and 651 million posts from 2005 onwards. This dataset has been used in over 100 research papers for studying online social dynamics, content evolution, and user behavior patterns. Provides unprecedented scale for natural language processing and social network analysis in digital communities.","use_cases":"Analyzing how political discourse evolved on Reddit during election cycles, Training language models on conversational text patterns from different subreddit communities","audience":"Mid-DS, Senior-DS"},{"id":"dataset-stack-overflow-data-dump","type":"dataset","name":"Stack Overflow Data Dump","description":"Full Q&A archive + annual developer survey (49K+ responses). Salaries, tech adoption, developer analytics","category":"Social & Web","url":"https://archive.org/details/stackexchange","difficulty":"beginner","prerequisites":"SQL-queries, python-pandas, data-visualization","topic_tags":"developer-surveys, salary-data, tech-adoption, Q&A-analysis, workforce-analytics","summary":"Complete Stack Overflow data archive including all questions, answers, and comprehensive annual developer surveys with 49K+ responses. Contains rich data on developer salaries, technology adoption trends, and programming community insights. Widely used for understanding tech workforce dynamics and developer behavior patterns.","use_cases":"Analyzing salary trends across programming languages and geographic regions for compensation benchmarking, Tracking technology adoption patterns over time to inform product strategy decisions","audience":"Junior-DS, Mid-DS"},{"id":"dataset-common-crawl","type":"dataset","name":"Common Crawl","description":"250TB/month web crawl. 9.5 PB archive since 2008. Product listings, pricing, economic text at web scale","category":"Social & Web","url":"https://commoncrawl.org/","difficulty":"intermediate","prerequisites":"python-requests, data-parsing, distributed-computing","topic_tags":"web-crawling, large-scale-data, text-mining, pricing-data, petabyte-scale","summary":"Common Crawl is a massive open dataset containing petabytes of web crawl data collected monthly since 2008. It provides researchers and data scientists with unprecedented access to web-scale text, product listings, and pricing information for economic analysis and research.","use_cases":"Training large language models on diverse web text for economic research, Analyzing e-commerce pricing trends across millions of product listings over time","audience":"Mid-DS, Senior-DS"},{"id":"dataset-google-trends-datastore","type":"dataset","name":"Google Trends Datastore","description":"Search interest data for nowcasting. Economic indicators, demand prediction, event detection","category":"Social & Web","url":"https://googletrends.github.io/data/","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, API-requests","topic_tags":"google-trends, nowcasting, economic-indicators, time-series, search-data","summary":"Google Trends provides search volume data that can predict economic activity in real-time. Researchers and analysts use this data to forecast unemployment, retail sales, housing demand, and other indicators weeks before official statistics are released. The dataset enables early detection of market shifts and consumer behavior changes.","use_cases":"Predicting quarterly GDP growth using search terms like 'unemployment benefits' and 'job search', Forecasting retail sales during holiday seasons by tracking product-related search volumes","audience":"Mid-DS, Junior-DS"},{"id":"dataset-yandex-datasets","type":"dataset","name":"Yandex Datasets","description":"Search ranking, translation quality, and ML task datasets","category":"Data Portals","url":"https://research.yandex.com/datasets","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, basic-ML-evaluation","topic_tags":"search-ranking, translation-quality, russian-datasets, ML-benchmarks, yandex","summary":"Collection of datasets from Yandex covering search ranking evaluation, translation quality assessment, and various machine learning tasks. These datasets are particularly valuable for researchers working on information retrieval and NLP problems, offering real-world data from one of Russia's largest tech companies. The datasets include both labeled examples and evaluation benchmarks commonly used in academic research.","use_cases":"Benchmarking search ranking algorithms against industry-standard datasets, Training and evaluating machine translation models on Russian-English language pairs","audience":"Junior-DS, Early-PhD"},{"id":"dataset-meta-(facebook)-research","type":"dataset","name":"Meta (Facebook) Research","description":"1.1B+ public FB/IG posts with engagement metrics","category":"Social & Web","url":"https://fort.fb.com/researcher-datasets","difficulty":"intermediate","prerequisites":"python-pandas, social-network-analysis, statistical-sampling","topic_tags":"social-media-data, engagement-metrics, large-scale-dataset, behavioral-analysis, platform-research","summary":"A massive dataset containing over 1.1 billion public posts from Facebook and Instagram with associated engagement metrics like likes, shares, and comments. This dataset is valuable for researchers and data scientists studying social media behavior, viral content patterns, and platform dynamics at unprecedented scale.","use_cases":"Analyzing factors that drive viral content spread across different demographics and post types, Building predictive models for engagement rates to optimize social media marketing strategies","audience":"Mid-DS, Senior-DS"},{"id":"dataset-microsoft-research","type":"dataset","name":"Microsoft Research","description":"Research tools and datasets across multiple domains","category":"Data Portals","url":"https://www.microsoft.com/en-us/research/tools/","difficulty":"beginner","prerequisites":"python-pandas, data-analysis-basics","topic_tags":"microsoft-research, datasets, research-data, multi-domain, open-data","summary":"Microsoft Research provides a comprehensive collection of research datasets and tools spanning computer vision, natural language processing, machine learning, and other domains. The platform offers both raw datasets and accompanying research tools developed by Microsoft's research teams. It serves as a valuable resource for researchers and practitioners looking for high-quality, well-documented datasets to support their projects.","use_cases":"Training computer vision models using Microsoft's image datasets, Benchmarking NLP algorithms against Microsoft's language processing datasets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-amazon-aws-open-data","type":"dataset","name":"Amazon AWS Open Data","description":"Registry of Open Data with analysis-ready datasets","category":"Data Portals","url":"https://registry.opendata.aws/","difficulty":"beginner","prerequisites":"python-boto3, cloud-storage-concepts","topic_tags":"open-data, cloud-computing, data-discovery, AWS, public-datasets","summary":"AWS Open Data is a registry of publicly available datasets hosted on Amazon's cloud infrastructure, covering domains from genomics to satellite imagery. The platform provides analysis-ready datasets that can be accessed directly through AWS services without download fees. It's designed to make large-scale public data more accessible for research and commercial applications.","use_cases":"Accessing satellite imagery data for environmental research without managing large file transfers, Finding genomics datasets for machine learning model training that are already optimized for cloud computing","audience":"Junior-DS, Curious-browser"},{"id":"dataset-netflix-prize","type":"dataset","name":"Netflix Prize","description":"100M+ anonymous movie ratings from 480k users","category":"Entertainment & Media","url":"https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data","difficulty":"beginner","prerequisites":"python-pandas, collaborative-filtering, matrix-factorization","topic_tags":"collaborative-filtering, movie-recommendations, rating-prediction, sparse-matrices","summary":"The Netflix Prize dataset contains over 100 million anonymous movie ratings from 480,000 users on 17,000+ films, released for a famous $1M competition to improve recommendation accuracy by 10%. This classic dataset became the gold standard for testing collaborative filtering and matrix factorization techniques. It's ideal for learning recommendation systems fundamentals and benchmarking new algorithms.","use_cases":"Learning collaborative filtering by predicting user ratings for unseen movies, Benchmarking new recommendation algorithms against established baselines","audience":"Junior-DS, Early-PhD"},{"id":"dataset-jd.com-open-datasets","type":"dataset","name":"JD.com Open Datasets","description":"Open dataset portal for e-commerce and logistics from JD.com","category":"Data Portals","url":"https://datascience.jd.com/page/opendataset.html","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-cleaning","topic_tags":"e-commerce-data, logistics-datasets, chinese-market, open-data, retail-analytics","summary":"JD.com's open dataset portal provides access to real-world e-commerce and logistics data from one of China's largest online retailers. The datasets cover areas like customer behavior, supply chain operations, and market dynamics in the Chinese e-commerce ecosystem. This resource is valuable for researchers and practitioners studying online retail patterns, logistics optimization, and cross-cultural consumer behavior.","use_cases":"Analyzing customer purchase patterns and recommendation systems using JD.com transaction data, Studying logistics network efficiency and delivery optimization in Chinese urban markets","audience":"Junior-DS, Curious-browser"},{"id":"dataset-rakuten-data-release","type":"dataset","name":"Rakuten Data Release","description":"E-commerce, advertising, and multimedia datasets from Rakuten","category":"Data Portals","url":"https://rit.rakuten.com/data_release/#access","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, SQL-basics","topic_tags":"e-commerce-data, advertising-datasets, multimedia-data, retail-analytics, recommendation-systems","summary":"Rakuten Data Release provides publicly available datasets from Japan's largest e-commerce platform, covering user behavior, product catalogs, advertising campaigns, and multimedia content. These datasets are commonly used by researchers and data scientists studying online marketplace dynamics, recommendation algorithms, and consumer behavior patterns. The collection includes both structured transaction data and unstructured multimedia content like product images and reviews.","use_cases":"Building recommendation systems for e-commerce platforms using historical purchase and browsing data, Analyzing advertising campaign effectiveness and user engagement patterns in online marketplaces","audience":"Junior-DS, Mid-DS"},{"id":"dataset-ibm-developer-data","type":"dataset","name":"IBM Developer Data","description":"AI, data science, healthcare, and weather datasets from IBM","category":"Data Portals","url":"https://developer.ibm.com/technologies/artificial-intelligence/data/","difficulty":"beginner","prerequisites":"python-pandas, basic-data-analysis, API-requests","topic_tags":"datasets, data-portal, IBM, healthcare-data, weather-data","summary":"IBM Developer Data is a collection of curated datasets spanning AI, data science, healthcare, and weather domains provided by IBM. The datasets are designed for developers and data scientists to practice analysis techniques and build applications. They offer clean, well-documented data across various industries and use cases.","use_cases":"Junior data scientist needs healthcare datasets to practice predictive modeling for patient outcomes, Developer building a weather application requires historical weather data for training machine learning models","audience":"Junior-DS, Curious-browser"},{"id":"dataset-baidu-ai-datasets","type":"dataset","name":"Baidu AI Datasets","description":"AI, NLP, computer vision, and autonomous driving datasets","category":"Data Portals","url":"https://aistudio.baidu.com/datasetoverview","difficulty":"beginner","prerequisites":"python-pandas, tensorflow-keras, opencv-basics","topic_tags":"datasets, chinese-nlp, computer-vision, autonomous-driving, baidu","summary":"Baidu AI Datasets is a collection of machine learning datasets covering natural language processing, computer vision, and autonomous driving applications. The datasets are particularly valuable for Chinese language processing and include real-world data from Baidu's products and services. These resources are commonly used for training models, benchmarking algorithms, and academic research in AI applications.","use_cases":"Training Chinese language models for sentiment analysis or text classification, Developing computer vision models for autonomous vehicle perception systems","audience":"Junior-DS, Mid-DS"},{"id":"dataset-inside-airbnb-raw-data","type":"dataset","name":"Inside Airbnb Raw Data","description":"Raw data files from Inside Airbnb project","category":"Data Portals","url":"http://insideairbnb.com/get-the-data/","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, CSV-handling","topic_tags":"airbnb-data, rental-market, raw-datasets, hospitality-economics, urban-planning","summary":"Raw data files from the Inside Airbnb project containing detailed listings, reviews, and calendar information for Airbnb properties across major cities worldwide. This community-sourced dataset provides unprocessed rental market data that researchers and analysts use to study short-term rental impacts on housing markets. The data includes property details, pricing, availability, host information, and guest reviews in CSV format.","use_cases":"Analyzing rental price trends and market dynamics in different neighborhoods, Research on Airbnb's impact on local housing affordability and availability","audience":"Junior-DS, Curious-browser"},{"id":"dataset-yongfeng-dataset-collection","type":"dataset","name":"Yongfeng Dataset Collection","description":"E-commerce and recommendation system datasets","category":"Data Portals","url":"https://www.yongfeng.me/dataset/","difficulty":"beginner","prerequisites":"python-pandas, recommender-systems, data-preprocessing","topic_tags":"recommender-systems, e-commerce, datasets, collaborative-filtering, user-behavior","summary":"A curated collection of datasets specifically designed for recommendation system research and e-commerce analysis. Contains user-item interaction data, product catalogs, and user behavior logs from various domains. Widely used by researchers and practitioners to benchmark recommendation algorithms and study consumer behavior patterns.","use_cases":"Benchmarking collaborative filtering algorithms against standard datasets, Training recommendation models for academic research or thesis projects","audience":"Early-PhD, Junior-DS"},{"id":"dataset-julian-mcauley-datasets","type":"dataset","name":"Julian McAuley Datasets","description":"Reviews, recommendations, and social network data","category":"Data Portals","url":"https://cseweb.ucsd.edu/~jmcauley/datasets.html","difficulty":"beginner","prerequisites":"python-pandas, basic-data-cleaning, json-parsing","topic_tags":"product-reviews, recommendation-systems, social-networks, e-commerce, dataset-collection","summary":"A collection of publicly available datasets from UCSD containing product reviews, user ratings, and social network data from various platforms like Amazon, Yelp, and others. These datasets are widely used in academic research for recommendation systems, sentiment analysis, and social network studies. The data is preprocessed and ready for analysis, making it accessible for researchers and practitioners working on user behavior and product recommendation problems.","use_cases":"Building a recommendation system for an e-commerce platform using Amazon review data, Analyzing sentiment patterns in restaurant reviews to understand customer preferences","audience":"Early-PhD, Junior-DS"},{"id":"dataset-makridakis-competitions","type":"dataset","name":"Makridakis Competitions","description":"Time series data for forecasting competitions (M1-M5)","category":"Data Portals","url":"https://www.mcompetitions.unic.ac.cy/the-dataset/","difficulty":"beginner","prerequisites":"time-series-analysis, python-pandas, forecasting-basics","topic_tags":"time-series, forecasting, benchmark-datasets, competitions, historical-data","summary":"The Makridakis Competitions (M1-M5) are a series of influential forecasting competitions that provide standardized time series datasets for benchmarking forecasting methods. These datasets span decades and include various types of time series data from business, economics, and other domains. They serve as the gold standard for evaluating and comparing forecasting algorithms in academic research and industry practice.","use_cases":"Benchmarking a new forecasting algorithm against established baselines using standardized competition data, Teaching forecasting methods by having students practice on well-documented historical datasets with known performance benchmarks","audience":"Junior-DS, Early-PhD"},{"id":"dataset-recsys-datasets-collection","type":"dataset","name":"RecSys Datasets Collection","description":"Datasets from ACM Recommender Systems challenges","category":"Data Portals","url":"https://github.com/RUCAIBox/RecSysDatasets","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, collaborative-filtering","topic_tags":"recommender-systems, datasets, collaborative-filtering, ACM-challenges, benchmark-data","summary":"A curated collection of datasets from ACM RecSys challenges, providing standardized benchmarks for recommender systems research and development. These datasets include user-item interactions, ratings, and contextual information from various domains like movies, music, and e-commerce. Widely used by researchers and practitioners to evaluate recommendation algorithms and compare performance across different approaches.","use_cases":"Benchmarking a new collaborative filtering algorithm against established baselines, Learning recommender systems by implementing basic algorithms on clean, well-documented datasets","audience":"Junior-DS, Early-PhD"},{"id":"dataset-neurips-competition-data","type":"dataset","name":"NeurIPS Competition Data","description":"Top-tier conference with competitions and benchmarks","category":"Data Portals","url":"https://nips.cc/","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, pytorch-basics","topic_tags":"competition-data, ml-benchmarks, neurips, datasets, model-evaluation","summary":"NeurIPS Competition Data provides curated datasets and benchmarks from the premier machine learning conference's annual competitions. These datasets cover diverse ML challenges from computer vision to reinforcement learning, with established evaluation metrics and baselines. Perfect for learning state-of-the-art methods, comparing model performance, and understanding how top researchers approach complex problems.","use_cases":"Benchmarking a new computer vision model against competition winners to validate performance claims, Learning reinforcement learning by reproducing winning solutions from past NeurIPS competitions","audience":"Junior-DS, Curious-browser"},{"id":"dataset-ijcai-competitions","type":"dataset","name":"IJCAI Competitions","description":"International AI conference with competitions","category":"Data Portals","url":"https://www.ijcai.org/","difficulty":"intermediate","prerequisites":"python-scikit-learn, kaggle-competitions, model-evaluation","topic_tags":"AI-competitions, benchmark-datasets, competition-platforms, machine-learning, academic-contests","summary":"IJCAI (International Joint Conference on Artificial Intelligence) hosts annual AI competitions featuring diverse machine learning challenges and benchmark datasets. These competitions provide standardized evaluation frameworks for comparing AI methods across domains like computer vision, NLP, and reinforcement learning. Participants can access high-quality datasets, baseline models, and leaderboards to test their algorithms against state-of-the-art approaches.","use_cases":"Benchmarking a new machine learning algorithm against established baselines on standardized competition datasets, Finding curated datasets with clear evaluation metrics for academic research or method validation","audience":"Mid-DS, Senior-DS"},{"id":"dataset-msom-data-challenges","type":"dataset","name":"MSOM Data Challenges","description":"Manufacturing & Service Operations Management challenges","category":"Data Portals","url":"https://pubsonline.informs.org/journal/msom","difficulty":"intermediate","prerequisites":"python-pandas, operations-research-basics, data-visualization","topic_tags":"operations-management, supply-chain, manufacturing, service-operations, competition-datasets","summary":"MSOM Data Challenges are annual competitions hosted by INFORMS featuring real-world operations management datasets from manufacturing and service industries. These challenges provide practitioners and researchers with access to high-quality, industry-relevant data for developing and testing operations research methods. The datasets typically focus on supply chain optimization, demand forecasting, inventory management, and service delivery problems.","use_cases":"Developing demand forecasting models for retail inventory management using real transaction data, Optimizing manufacturing scheduling algorithms with actual production line constraints and performance metrics","audience":"Mid-DS, Early-PhD"},{"id":"dataset-data-mining-cup","type":"dataset","name":"Data Mining Cup","description":"Industry-sponsored data mining competitions","category":"Data Portals","url":"https://www.data-mining-cup.com/","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, exploratory-data-analysis","topic_tags":"data-mining, competitions, industry-datasets, predictive-modeling, benchmarking","summary":"Data Mining Cup provides industry-sponsored data mining competitions with real-world datasets and business problems. These competitions offer hands-on experience with practical data science challenges while allowing participants to benchmark their skills against others. The datasets typically come from actual companies looking to solve specific business problems through data analysis.","use_cases":"Junior data scientist wanting to practice on real industry problems before applying techniques at work, PhD student seeking to test academic methods on practical business datasets with ground truth","audience":"Junior-DS, Early-PhD"},{"id":"dataset-kdd-cup","type":"dataset","name":"KDD Cup","description":"ACM SIGKDD annual data mining competition","category":"Data Portals","url":"https://kdd.org/kdd-cup","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, exploratory-data-analysis","topic_tags":"data-mining, machine-learning-competitions, benchmark-datasets, classification, clustering","summary":"KDD Cup is the premier annual data mining competition organized by ACM SIGKDD, featuring real-world datasets and challenging machine learning problems. It provides standardized benchmark datasets that have become foundational for evaluating new algorithms and methods in data science. The competition attracts thousands of participants globally and serves as a testing ground for cutting-edge data mining techniques.","use_cases":"Benchmarking a new classification algorithm against established baselines using historical KDD Cup datasets, Learning practical data mining skills by participating in the current year's competition with real industry problems","audience":"Junior-DS, Mid-DS"},{"id":"dataset-marketing-science-databases","type":"dataset","name":"Marketing Science Databases","description":"INFORMS conference with data-focused opportunities","category":"Data Portals","url":"https://pubsonline.informs.org/page/mksc/online-databases","difficulty":"beginner","prerequisites":"SQL-basics, research-design-fundamentals","topic_tags":"marketing-data, academic-databases, consumer-behavior, INFORMS, research-datasets","summary":"Marketing Science Databases is a collection of research datasets made available through INFORMS conferences and publications. These databases contain real-world marketing data including consumer behavior, advertising effectiveness, and market research studies. The datasets are primarily used by academics and industry researchers for empirical marketing research and methodology development.","use_cases":"Academic researcher studying consumer response to digital advertising campaigns using real transaction and exposure data, Marketing analyst validating pricing models against historical customer purchase behavior from retail chains","audience":"Early-PhD, Curious-browser"},{"id":"dataset-drivendata","type":"dataset","name":"DrivenData","description":"Data science competitions for social impact","category":"Data Portals","url":"https://www.drivendata.org/","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, jupyter-notebooks","topic_tags":"data-competitions, social-impact, public-datasets, kaggle-style, non-profit","summary":"DrivenData hosts data science competitions focused on solving social and environmental challenges for non-profit organizations. Unlike traditional competitions, these emphasize real-world impact in areas like health, education, and sustainability. Participants can access curated datasets, compete for prizes, and contribute to meaningful causes while building portfolio projects.","use_cases":"Building a portfolio with social impact projects while learning competition-style data science, Accessing real-world datasets from non-profits for educational or research purposes","audience":"Junior-DS, Curious-browser"},{"id":"dataset-codalab","type":"dataset","name":"CodaLab","description":"Platform for competitions, benchmarks, and reproducible research","category":"Data Portals","url":"https://codalab.lisn.upsaclay.fr/","difficulty":"beginner","prerequisites":"python-basics, git-version-control","topic_tags":"research-competitions, model-benchmarking, reproducible-research, dataset-hosting","summary":"CodaLab is a collaborative platform that hosts machine learning competitions, research benchmarks, and enables reproducible computational research. It allows researchers to share datasets, code, and evaluation metrics while providing standardized environments for fair model comparisons. The platform is widely used for organizing challenges and maintaining leaderboards across various ML domains.","use_cases":"Participating in a computer vision challenge with standardized evaluation metrics, Hosting a research benchmark to compare different NLP models on the same dataset","audience":"Junior-DS, Early-PhD"},{"id":"dataset-openml","type":"dataset","name":"OpenML","description":"Platform for sharing datasets, tasks, and ML code","category":"Data Portals","url":"https://www.openml.org/","difficulty":"beginner","prerequisites":"python-scikit-learn, machine-learning-basics, data-preprocessing","topic_tags":"open-data, ml-benchmarks, reproducible-research, dataset-sharing, model-evaluation","summary":"OpenML is a collaborative platform for sharing machine learning datasets, experiments, and code with standardized formats and APIs. It provides access to thousands of curated datasets with metadata, enabling reproducible research and fair model comparisons. The platform is widely used by researchers and practitioners for benchmarking algorithms and sharing experimental results.","use_cases":"Comparing multiple ML algorithms on standardized benchmark datasets for research publication, Finding pre-processed datasets with established baselines for prototyping new models","audience":"Junior-DS, Early-PhD"},{"id":"dataset-recsys-challenge-2025-(synerise)","type":"dataset","name":"RecSys Challenge 2025 (Synerise)","description":"1M users, 6 months of real e-commerce behavior logs with 5 event types for universal behavioral modeling","category":"Data Portals","url":"https://recsys.synerise.com/data-set","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, jupyter-notebooks","topic_tags":"recommender-systems, e-commerce-data, behavioral-analytics, large-scale-datasets","summary":"A comprehensive dataset from the 2025 RecSys Challenge containing 1 million users' e-commerce behavioral logs over 6 months. Features 5 distinct event types capturing real shopping interactions for developing and benchmarking recommendation algorithms. Ideal for learning recommendation systems and testing behavioral modeling approaches on realistic, large-scale data.","use_cases":"Building recommendation models for e-commerce platforms using real user interaction patterns, Benchmarking collaborative filtering algorithms against industry-standard datasets","audience":"Junior-DS, Mid-DS"},{"id":"dataset-recsys-challenge-2024-(eb-nerd)","type":"dataset","name":"RecSys Challenge 2024 (EB-NeRD)","description":"2.3M users, 380M+ news impressions from Ekstra Bladet for news recommendation research","category":"Data Portals","url":"https://www.recsyschallenge.com/2024/","difficulty":"intermediate","prerequisites":"python-pandas, recommender-systems, implicit-feedback","topic_tags":"news-recommendation, large-scale-datasets, user-behavior, implicit-feedback, recsys-challenge","summary":"A massive dataset from Ekstra Bladet containing 2.3 million users and 380+ million news article impressions, designed for the 2024 RecSys Challenge. This real-world dataset enables researchers to develop and benchmark news recommendation algorithms on authentic user behavior patterns. It's particularly valuable for studying implicit feedback scenarios where user engagement signals drive recommendations.","use_cases":"Benchmarking news recommendation algorithms against other RecSys Challenge participants, Training deep learning models for personalized news delivery in production systems","audience":"Mid-DS, Senior-DS"},{"id":"dataset-amazon-shopbench-(kdd-cup-2024)","type":"dataset","name":"Amazon ShopBench (KDD Cup 2024)","description":"57 tasks, 20K questions derived from real Amazon shopping data for LLM shopping assistants","category":"Data Portals","url":"https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms","difficulty":"intermediate","prerequisites":"python-transformers, pytorch-datasets, multi-task-learning","topic_tags":"shopping-assistant, e-commerce-nlp, llm-evaluation, multi-task-benchmark, conversational-ai","summary":"Amazon ShopBench is a comprehensive benchmark dataset from KDD Cup 2024 containing 57 diverse tasks and 20,000 questions derived from real Amazon shopping scenarios. It's designed to evaluate and train LLM-based shopping assistants across multiple e-commerce use cases including product search, recommendation, and customer service. The dataset provides a standardized way to assess conversational AI performance in retail contexts.","use_cases":"Training and evaluating chatbots for e-commerce customer support and product recommendations, Benchmarking multi-task LLM performance on real-world shopping assistant scenarios","audience":"Mid-DS, Senior-DS"},{"id":"dataset-drivendata-water-supply-forecasting-(2024)","type":"dataset","name":"DrivenData Water Supply Forecasting (2024)","description":"Western US water supply data from Bureau of Reclamation, $500K prize pool for seasonal forecasting","category":"Data Portals","url":"https://www.drivendata.org/competitions/","difficulty":"intermediate","prerequisites":"time-series-analysis, python-pandas, cross-validation","topic_tags":"water-forecasting, seasonal-prediction, government-datasets, climate-modeling, competition-data","summary":"A comprehensive dataset from the US Bureau of Reclamation containing Western US water supply measurements for seasonal forecasting challenges. This competition dataset offers real-world hydrology data with a $500K prize pool, making it ideal for practicing time series forecasting on climate-critical infrastructure. The data includes historical water supply measurements across multiple Western US locations with associated meteorological and geographic features.","use_cases":"Building seasonal water supply prediction models for municipal planning, Benchmarking time series forecasting algorithms on real climate data","audience":"Mid-DS, Junior-DS"},{"id":"dataset-openstreetmap-planet","type":"dataset","name":"OpenStreetMap Planet","description":"84GB PBF (2TB+ uncompressed) complete world map database with full edit history, weekly updates","category":"Social & Web","url":"https://planet.openstreetmap.org/","difficulty":"intermediate","prerequisites":"PostgreSQL, python-geopandas, PostGIS","topic_tags":"geospatial-data, open-data, database-management, spatial-analysis, data-processing","summary":"OpenStreetMap Planet is the complete global database of crowdsourced geographic data, containing roads, buildings, points of interest, and their full edit histories. This massive dataset requires specialized tools and infrastructure to process but provides unparalleled global coverage for spatial analysis. It's the go-to resource for researchers and practitioners working with real-world geographic data at scale.","use_cases":"Building location-based recommendation systems using POI data and road networks, Analyzing urban development patterns by comparing map edits over time across different cities","audience":"Mid-DS, Senior-DS"},{"id":"dataset-wikipedia-full-database-dump","type":"dataset","name":"Wikipedia Full Database Dump","description":"Complete Wikipedia content and metadata in SQL/XML format, includes all revisions and edit history","category":"Social & Web","url":"https://dumps.wikimedia.org/","difficulty":"intermediate","prerequisites":"SQL-queries, python-pandas, text-preprocessing","topic_tags":"wikipedia-data, text-mining, database-dump, revision-history, large-scale-text","summary":"Complete Wikipedia database containing all articles, edit histories, and metadata in structured SQL/XML format. This massive dataset enables researchers to study collaborative knowledge creation, information diffusion, and large-scale text analysis. The full revision history makes it valuable for studying how information evolves over time and analyzing editor behavior patterns.","use_cases":"Analyzing how controversial topics evolve by tracking edit patterns and revision histories across politically sensitive articles, Building large-scale natural language processing models using Wikipedia's structured, multilingual text corpus with metadata","audience":"Mid-DS, Senior-DS"},{"id":"dataset-uk-land-registry-price-paid","type":"dataset","name":"UK Land Registry Price Paid","description":"4.3GB of UK property sales transactions going back decades, messy real-world government data","category":"Real Estate","url":"https://www.gov.uk/government/collections/price-paid-data","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, SQL-basics","topic_tags":"real-estate, government-data, UK-housing, transaction-data, data-cleaning","summary":"The UK Land Registry Price Paid dataset contains 4.3GB of property sales transactions spanning decades of UK housing market activity. This messy, real-world government dataset provides comprehensive records of residential and commercial property purchases across England and Wales. It's an excellent resource for learning data cleaning techniques while exploring housing market trends and building real estate analytics models.","use_cases":"Building a housing price prediction model for UK properties, Analyzing regional housing market trends and gentrification patterns over time","audience":"Junior-DS, Curious-browser"},{"id":"dataset-redfin-housing-market-data","type":"dataset","name":"Redfin Housing Market Data","description":"Downloadable housing market data: home prices, sales, inventory, listings by metro/city/zip. Updated weekly from MLS","category":"Real Estate","url":"https://www.redfin.com/news/data-center/","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-statistics","topic_tags":"housing-market, time-series-data, real-estate-analytics, MLS-data, market-trends","summary":"Comprehensive housing market dataset from Redfin containing weekly updates on home prices, sales volumes, inventory levels, and listings across US metros, cities, and zip codes. The data is sourced from Multiple Listing Services (MLS) and provides ready-to-use insights for real estate market analysis. Ideal for practitioners learning time series analysis or conducting housing market research.","use_cases":"Analyzing housing price trends and seasonality patterns across different metropolitan areas, Building predictive models for real estate investment decisions using inventory and sales data","audience":"Junior-DS, Curious-browser"},{"id":"dataset-zillow-research-data","type":"dataset","name":"Zillow Research Data","description":"Home values (ZHVI), rents (ZORI), inventory, and market heat indices across US metros and zip codes","category":"Real Estate","url":"https://www.zillow.com/research/data/","difficulty":"beginner","prerequisites":"python-pandas, time-series-basics, data-visualization","topic_tags":"housing-data, time-series, real-estate-economics, market-analysis, zillow","summary":"Comprehensive dataset from Zillow containing standardized home values, rental prices, inventory levels, and market activity metrics across US metropolitan areas and zip codes. The data includes their flagship Home Value Index (ZHVI) and rental index (ZORI) with historical time series going back over a decade. Essential resource for housing market research, real estate economics, and regional economic analysis.","use_cases":"Analyzing housing affordability trends across different metropolitan areas for urban economics research, Building predictive models for real estate investment decisions using historical price and inventory data","audience":"Junior-DS, Curious-browser"},{"id":"dataset-ieee-cis-fraud-detection","type":"dataset","name":"IEEE-CIS Fraud Detection","description":"590K card-not-present transactions with 393 features from Vesta Corp. Real messy fraud data (3.5% fraud rate)","category":"Financial Services","url":"https://www.kaggle.com/competitions/ieee-fraud-detection","difficulty":"intermediate","prerequisites":"python-pandas, imbalanced-classification, feature-engineering","topic_tags":"fraud-detection, financial-services, imbalanced-data, feature-engineering, kaggle-dataset","summary":"A large-scale fraud detection dataset with 590K real-world card-not-present transactions from Vesta Corp, featuring 393 anonymized features and a 3.5% fraud rate. This messy, realistic dataset was used in a Kaggle competition and represents the challenges of production fraud detection systems. Perfect for practicing feature engineering, handling imbalanced data, and building robust classification models on noisy financial data.","use_cases":"Building fraud detection models for payment processors or fintech companies, Benchmarking machine learning algorithms on imbalanced classification problems","audience":"Junior-DS, Mid-DS"},{"id":"dataset-msom-pharma-manufacturing-(2024)","type":"dataset","name":"MSOM Pharma Manufacturing (2024)","description":"Continuous pharmaceutical manufacturing data from MSD. Real production processes for operations management research","category":"Logistics & Supply Chain","url":"https://pubsonline.informs.org/page/msom/data-driven-challenge","difficulty":"intermediate","prerequisites":"python-pandas, operations-research, statistical-process-control","topic_tags":"pharmaceutical-manufacturing, operations-research, supply-chain-optimization, process-data, INFORMS","summary":"Real-world continuous pharmaceutical manufacturing dataset from MSD containing production process data for operations management research. This dataset provides authentic industry data for analyzing manufacturing efficiency, quality control, and supply chain optimization in pharmaceutical production. Researchers and practitioners can use it to develop and validate operations research models for pharmaceutical manufacturing.","use_cases":"Developing predictive models for pharmaceutical production yield and quality optimization, Benchmarking supply chain disruption mitigation strategies using real manufacturing process data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-nber-public-use-data-archive","type":"dataset","name":"NBER Public Use Data Archive","description":"Eclectic mix of economic, demographic, and enterprise data from NBER-affiliated research projects","category":"Data Portals","url":"https://www.nber.org/research/data","difficulty":"beginner","prerequisites":"python-pandas, data-cleaning, descriptive-statistics","topic_tags":"economic-data, demographics, research-datasets, NBER, public-data","summary":"The NBER Public Use Data Archive provides free access to datasets from National Bureau of Economic Research projects, covering topics from labor economics to firm-level analysis. These datasets have been used in published academic research and offer cleaned, documented data for replication and new studies. It's particularly valuable for researchers and students who need established datasets with clear provenance.","use_cases":"Replicating results from published NBER working papers using the original datasets, Finding demographic or economic panel data for thesis research or course projects","audience":"Early-PhD, Curious-browser"},{"id":"dataset-paysim-synthetic-transactions","type":"dataset","name":"PaySim Synthetic Transactions","description":"6M+ mobile money transactions simulating real fraud patterns. Agent-based model calibrated on real African mobile money logs","category":"Financial Services","url":"https://www.kaggle.com/datasets/ealaxi/paysim1","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, imbalanced-learn","topic_tags":"fraud-detection, mobile-payments, synthetic-data, financial-transactions, large-scale-dataset","summary":"PaySim is a synthetic dataset containing over 6 million mobile money transactions designed to simulate real-world fraud patterns from African mobile payment systems. The dataset was generated using an agent-based model calibrated on actual transaction logs, making it ideal for fraud detection research and model development. It provides a realistic, large-scale playground for testing machine learning approaches without privacy concerns.","use_cases":"Building and benchmarking fraud detection models for mobile payment systems, Learning data science techniques on a realistic large-scale financial dataset","audience":"Junior-DS, Mid-DS"},{"id":"dataset-chicago-tnc-trips","type":"dataset","name":"Chicago TNC Trips","description":"100M+ rideshare trips with fares (unlike NYC which lacks fare data). Trip-level pricing for Uber/Lyft economic analysis","category":"Transportation & Mobility","url":"https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p","difficulty":"intermediate","prerequisites":"python-pandas, regression-analysis, SQL-aggregations","topic_tags":"rideshare-pricing, fare-data, transportation-economics, demand-modeling, chicago-data","summary":"Comprehensive dataset of 100M+ Chicago rideshare trips including detailed fare information for Uber and Lyft rides. Unlike other major city datasets (such as NYC), this includes complete pricing data enabling economic analysis of rideshare markets. Ideal for studying pricing strategies, demand patterns, and competitive dynamics in the gig economy transportation sector.","use_cases":"Analyzing surge pricing algorithms and demand elasticity across different Chicago neighborhoods and time periods, Building predictive models for rideshare pricing to understand competitive dynamics between Uber and Lyft","audience":"Mid-DS, Senior-DS"},{"id":"dataset-criteo-counterfactual-learning","type":"dataset","name":"Criteo Counterfactual Learning","description":"25M logged interactions with counterfactual propensity scores. Gold standard for offline policy evaluation and causal inference in ads","category":"Advertising","url":"https://ailab.criteo.com/criteo-uplift-prediction-dataset/","difficulty":"advanced","prerequisites":"propensity-score-matching, inverse-probability-weighting, python-scikit-learn","topic_tags":"counterfactual-learning, offline-policy-evaluation, logged-bandit-feedback, ad-targeting, causal-inference","summary":"A large-scale dataset of 25 million real-world advertising interactions with pre-computed propensity scores for counterfactual analysis. This is the gold standard benchmark for researchers developing offline policy evaluation methods and testing causal inference algorithms in advertising contexts. The dataset enables rigorous comparison of different approaches for learning from logged bandit feedback without online experimentation.","use_cases":"Benchmarking new offline policy evaluation algorithms against established baselines, Training counterfactual models to predict ad campaign performance before deployment","audience":"Senior-DS, Early-PhD"},{"id":"dataset-otto-session-based-recommendations","type":"dataset","name":"OTTO Session-based Recommendations","description":"12M+ e-commerce sessions with click \u2192 cart \u2192 order sequences. Real multi-stage conversion funnel data from German retailer","category":"E-Commerce","url":"https://www.kaggle.com/datasets/otto/recsys-dataset","difficulty":"intermediate","prerequisites":"python-pandas, recommendation-systems, session-data-analysis","topic_tags":"session-based-recommendations, conversion-funnel, e-commerce-data, multi-stage-modeling, kaggle-dataset","summary":"Large-scale dataset of 12M+ real e-commerce user sessions from a German retailer, capturing the complete customer journey from clicks to cart additions to purchases. Contains sequential behavioral data ideal for building session-based recommendation systems and analyzing conversion funnels. Popular Kaggle competition dataset that provides realistic multi-stage conversion patterns for experimentation.","use_cases":"Building session-based recommendation models that predict next item interactions based on user click sequences, Analyzing conversion funnel drop-offs to optimize e-commerce checkout flows and reduce cart abandonment","audience":"Junior-DS, Mid-DS"},{"id":"dataset-lendingclub-loans","type":"dataset","name":"LendingClub Loans","description":"2.7M loans (2007-2019) with 151 features. Interest rates, credit scores, defaults. The canonical P2P lending dataset for credit risk modeling","category":"Financial Services","url":"https://www.kaggle.com/datasets/wordsforthewise/lending-club","difficulty":"beginner","prerequisites":"python-pandas, logistic-regression, feature-engineering","topic_tags":"credit-risk, p2p-lending, default-prediction, fintech, tabular-data","summary":"A comprehensive dataset of 2.7 million peer-to-peer loans from LendingClub spanning 2007-2019, featuring 151 variables including borrower demographics, credit scores, loan terms, and default outcomes. This is the go-to dataset for learning credit risk modeling and default prediction in fintech applications. Perfect for practicing classification techniques and understanding how lending platforms assess borrower risk.","use_cases":"Building default prediction models for loan approval systems, Analyzing factors that drive interest rate pricing in peer-to-peer lending","audience":"Junior-DS, Early-PhD"},{"id":"dataset-amazon-fraud-detection-benchmark","type":"dataset","name":"Amazon Fraud Detection Benchmark","description":"9 consolidated fraud datasets with unified format. Includes IEEE-CIS, credit card, e-commerce fraud. Benchmark for fraud ML research","category":"Financial Services","url":"https://github.com/amazon-science/fraud-dataset-benchmark","difficulty":"beginner","prerequisites":"python-pandas, scikit-learn, binary-classification","topic_tags":"fraud-detection, benchmark-datasets, financial-ml, classification, fintech","summary":"A collection of 9 standardized fraud detection datasets from Amazon Research, consolidating major public datasets like IEEE-CIS and credit card fraud data into a unified format. This benchmark enables researchers and practitioners to compare fraud detection algorithms across consistent data formats and evaluation metrics. Perfect for learning fraud ML techniques or testing new detection methods.","use_cases":"Testing a new fraud detection algorithm against established benchmarks, Learning fraud detection by practicing on real-world formatted datasets","audience":"Junior-DS, Mid-DS"},{"id":"dataset-orbitaal-bitcoin-transactions","type":"dataset","name":"ORBITAAL Bitcoin Transactions","description":"13 years of Bitcoin transaction graphs (2009-2022). Complete blockchain with labeled entities. network analysis at scale","category":"Financial Services","url":"https://zenodo.org/records/7958648","difficulty":"intermediate","prerequisites":"python-networkx, graph-theory, pandas-dataframes","topic_tags":"bitcoin-blockchain, transaction-networks, cryptocurrency-analysis, temporal-graphs, labeled-entities","summary":"Complete 13-year Bitcoin blockchain dataset with transaction graphs and labeled entities from 2009-2022. Essential resource for cryptocurrency researchers and data scientists studying blockchain networks. Enables large-scale analysis of payment flows, entity behavior, and network evolution over Bitcoin's entire history.","use_cases":"Analyzing money laundering patterns and suspicious transaction flows for compliance research, Studying Bitcoin network evolution and adoption patterns for cryptocurrency market analysis","audience":"Mid-DS, Senior-DS"},{"id":"dataset-lobster-order-book","type":"dataset","name":"LOBSTER Order Book","description":"NASDAQ limit order book data at millisecond precision. Level 1-10 depth, message-by-message reconstruction. Market microstructure research","category":"Financial Services","url":"https://lobsterdata.com/","difficulty":"advanced","prerequisites":"python-pandas, time-series-analysis, financial-markets-knowledge","topic_tags":"limit-order-book, high-frequency-trading, market-microstructure, financial-data, millisecond-data","summary":"NASDAQ's millisecond-precision limit order book data providing complete market depth and message-by-message reconstruction. Essential for market microstructure research, high-frequency trading analysis, and understanding price formation dynamics. Enables detailed study of order flow, liquidity patterns, and market maker behavior.","use_cases":"Analyzing market impact of large trades and optimal execution strategies, Studying bid-ask spread dynamics and liquidity provision patterns during market stress","audience":"Senior-DS, Early-PhD"},{"id":"dataset-fi-2010-limit-order-book","type":"dataset","name":"FI-2010 Limit Order Book","description":"4.3M samples of NASDAQ Nordic limit order book data. 10 depth levels, 5 stocks, normalized features. Benchmark for price prediction","category":"Financial Services","url":"https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, neural-networks","topic_tags":"limit-order-book, high-frequency-trading, price-prediction, financial-microstructure, benchmark-dataset","summary":"High-frequency NASDAQ Nordic limit order book data with 4.3 million samples across 5 stocks and 10 depth levels. Widely used benchmark dataset for developing and evaluating algorithmic trading models and price movement prediction algorithms. Features are normalized and structured for machine learning applications in financial markets.","use_cases":"Training deep learning models to predict short-term price movements in equity markets, Benchmarking high-frequency trading algorithms against standardized market microstructure data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-optn-organ-transplant","type":"dataset","name":"OPTN Organ Transplant","description":"Complete US organ donation records since 1987. Waiting lists, donor-recipient matches, outcomes. Market design and matching research","category":"Healthcare","url":"https://optn.transplant.hrsa.gov/data/","difficulty":"intermediate","prerequisites":"python-pandas, survival-analysis, matching-algorithms","topic_tags":"organ-transplant, matching-markets, healthcare-data, survival-analysis, market-design","summary":"Comprehensive dataset of US organ donation and transplant records from 1987 to present, maintained by the Organ Procurement and Transplantation Network. Contains detailed information on waiting lists, donor-recipient matching, transplant outcomes, and patient survival rates. Widely used by economists and researchers studying matching markets, healthcare allocation mechanisms, and medical outcomes.","use_cases":"Analyzing the effectiveness of kidney allocation algorithms and their impact on patient outcomes, Studying geographic disparities in organ availability and wait times across different regions","audience":"Mid-DS, Senior-DS"},{"id":"dataset-fcc-spectrum-auctions","type":"dataset","name":"FCC Spectrum Auctions","description":"87+ auctions (1994-present) with round-by-round bidding data. Complete bid histories, reserve prices, winners. Auction theory empirics","category":"Auctions & Marketplaces","url":"https://www.fcc.gov/auctions-summary","difficulty":"intermediate","prerequisites":"python-pandas, auction-theory, regression-analysis","topic_tags":"spectrum-auctions, bidding-data, auction-theory, telecommunications, empirical-analysis","summary":"Complete bidding dataset from 87+ FCC spectrum auctions spanning 1994 to present, containing round-by-round bid histories, reserve prices, and winner information. This rich empirical dataset enables researchers to test auction theory predictions and analyze bidding strategies in high-stakes telecommunications markets. The data supports both descriptive analysis of auction outcomes and structural modeling of bidder behavior.","use_cases":"Testing whether bidding follows theoretical predictions like revenue equivalence or strategic demand reduction, Estimating bidder valuations and market power effects in telecommunications spectrum markets","audience":"Early-PhD, Senior-DS"},{"id":"dataset-usaspending-federal-awards","type":"dataset","name":"USASpending Federal Awards","description":"All federal contracts, grants, loans since 2001. 400+ variables, $50T+ in awards. Government procurement analytics","category":"Data Portals","url":"https://www.usaspending.gov/download_center/award_data_archive","difficulty":"beginner","prerequisites":"python-pandas, SQL-queries, data-visualization","topic_tags":"government-data, procurement-analysis, public-spending, contract-data, federal-awards","summary":"Comprehensive database of all federal government spending including contracts, grants, and loans since 2001, totaling over $50 trillion in awards. Contains detailed information on recipients, award amounts, agencies, and procurement methods across 400+ variables. Essential resource for analyzing government spending patterns, vendor relationships, and public sector economics.","use_cases":"Analyzing which companies receive the most federal contracts in specific industries, Studying geographic distribution of federal grant funding across states and congressional districts","audience":"Junior-DS, Curious-browser"},{"id":"dataset-census-business-dynamics-statistics","type":"dataset","name":"Census Business Dynamics Statistics","description":"8M+ establishments with firm age data. Job creation/destruction, startups, exits. Longitudinal firm dynamics since 1977","category":"Data Portals","url":"https://www.census.gov/programs-surveys/bds.html","difficulty":"intermediate","prerequisites":"python-pandas, stata-basics, panel-data-analysis","topic_tags":"firm-dynamics, business-demographics, longitudinal-data, establishment-data, job-flows","summary":"The Census Business Dynamics Statistics provides comprehensive longitudinal data on over 8 million U.S. establishments, tracking firm births, deaths, job creation and destruction from 1977 onwards. This dataset is essential for researchers studying entrepreneurship, labor market dynamics, and business cycle effects on firm behavior. It enables analysis of startup rates, firm survival, employment growth patterns, and regional economic development.","use_cases":"Analyzing how startup formation varies across industries and regions during economic recessions, Measuring job reallocation rates and studying which firm characteristics predict high growth","audience":"Mid-DS, Senior-DS"},{"id":"dataset-patentsview","type":"dataset","name":"PatentsView","description":"13M+ US patents (1976-present) with citations, inventors, assignees. Full patent text and claims. innovation research at scale","category":"Data Portals","url":"https://patentsview.org/download/data-download-tables","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, data-visualization","topic_tags":"patent-data, innovation-metrics, citation-networks, intellectual-property, research-datasets","summary":"PatentsView provides comprehensive access to over 13 million US patents from 1976 to present, including full text, citations, inventor details, and assignee information. This USPTO-maintained database enables large-scale innovation research and patent analytics. The dataset is particularly valuable for studying technology trends, company innovation strategies, and knowledge spillovers through citation networks.","use_cases":"Analyzing technology diffusion patterns by tracking patent citations across companies and time periods, Building innovation metrics for tech companies by measuring patent volume, quality, and cross-industry impact","audience":"Junior-DS, Curious-browser"},{"id":"dataset-eu-ted-procurement","type":"dataset","name":"EU TED Procurement","description":"800K+ procurement notices annually. All EU public contracts above thresholds. Structured XML since 2006. Cross-country procurement research","category":"Auctions & Marketplaces","url":"https://ted.europa.eu/TED/browse/browseByMap.do","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, regression-analysis","topic_tags":"procurement-data, government-contracts, cross-country-analysis, auction-theory, XML-data","summary":"Comprehensive dataset of 800K+ annual EU public procurement notices covering all contracts above regulatory thresholds since 2006. Contains structured bidding information, contract values, and supplier details across all EU member states. Essential resource for studying government procurement patterns, market competition, and cross-country institutional differences.","use_cases":"Analyzing bid competition and pricing patterns across different EU countries and sectors, Studying the effectiveness of procurement regulations and threshold policies on market outcomes","audience":"Mid-DS, Senior-DS"},{"id":"dataset-cms-hospital-price-transparency","type":"dataset","name":"CMS Hospital Price Transparency","description":"Hospital pricing data mandated since 2021. Negotiated rates, chargemaster prices across 6,000+ hospitals. Healthcare pricing research","category":"Healthcare","url":"https://www.cms.gov/hospital-price-transparency","difficulty":"intermediate","prerequisites":"python-pandas, healthcare-economics, data-cleaning","topic_tags":"hospital-pricing, healthcare-transparency, CMS-data, price-variation, negotiated-rates","summary":"Comprehensive dataset of hospital pricing information mandated by CMS transparency rules starting in 2021. Contains negotiated insurance rates and chargemaster prices from over 6,000 hospitals across the US. Essential resource for healthcare economists studying price variation, market competition, and the effects of transparency regulations.","use_cases":"Analyzing price variation across hospitals and geographic regions to study healthcare market competition, Evaluating the impact of price transparency mandates on negotiated rates between hospitals and insurers","audience":"Mid-DS, Senior-DS"},{"id":"dataset-mendeley-food-delivery-reviews","type":"dataset","name":"Mendeley Food Delivery Reviews","description":"1.69M reviews from DoorDash, Grubhub, Uber Eats. Ratings, text reviews, restaurant metadata. Gig economy platform research","category":"Food & Delivery","url":"https://data.mendeley.com/datasets/m5jk7wzyg7/1","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, basic-statistics","topic_tags":"food-delivery, customer-reviews, gig-economy, platform-data, sentiment-analysis","summary":"A comprehensive dataset containing 1.69 million customer reviews across major food delivery platforms (DoorDash, Grubhub, Uber Eats) with ratings, text feedback, and restaurant metadata. This dataset is valuable for researchers and analysts studying gig economy platforms, consumer behavior, and food delivery market dynamics. The rich combination of structured ratings and unstructured text makes it suitable for both exploratory analysis and machine learning applications.","use_cases":"Analyzing customer satisfaction patterns across different food delivery platforms to understand competitive positioning, Building sentiment analysis models to predict restaurant success based on review text and ratings","audience":"Junior-DS, Mid-DS"},{"id":"dataset-didi-gaia-open-data","type":"dataset","name":"DiDi GAIA Open Data","description":"Billions of GPS points and ride trajectories from China's largest ride-hailing platform. Driver behavior and urban mobility patterns","category":"Transportation & Mobility","url":"https://gaia.didichuxing.com/","difficulty":"intermediate","prerequisites":"python-pandas, geospatial-analysis, SQL-queries","topic_tags":"GPS-data, ride-hailing, urban-mobility, geospatial-datasets, transportation-economics","summary":"Massive GPS trajectory dataset from DiDi's ride-hailing platform containing billions of data points from Chinese cities. Researchers and analysts use this data to study urban mobility patterns, driver behavior, and transportation network effects. The dataset provides unprecedented scale for understanding ride-sharing economics and city-level transportation dynamics.","use_cases":"Analyzing surge pricing effects on driver supply and passenger demand across different urban areas, Studying traffic congestion patterns and optimal routing algorithms using real-world trajectory data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-prosper-loans","type":"dataset","name":"Prosper Loans","description":"113K P2P loans with borrower characteristics, credit grades, and loan outcomes. Alternative to LendingClub for P2P lending research","category":"Financial Services","url":"https://www.prosper.com/plp/about/","difficulty":"beginner","prerequisites":"python-pandas, logistic-regression, basic-SQL","topic_tags":"peer-to-peer-lending, credit-scoring, financial-risk, loan-default, fintech-data","summary":"A comprehensive dataset of 113,000 peer-to-peer loans from Prosper Marketplace containing borrower demographics, credit information, loan terms, and repayment outcomes. This dataset serves as an excellent alternative to LendingClub data for researchers studying P2P lending markets, credit risk assessment, and alternative finance mechanisms. It's particularly valuable for learning credit modeling techniques and understanding factors that drive loan performance in marketplace lending.","use_cases":"Building credit risk models to predict loan default probability using borrower characteristics and credit grades, Analyzing the relationship between interest rates, borrower profiles, and loan outcomes in P2P lending markets","audience":"Junior-DS, Early-PhD"},{"id":"dataset-google-bigquery-crypto","type":"dataset","name":"Google BigQuery Crypto","description":"8 complete blockchain histories (Bitcoin, Ethereum, etc.) with daily updates. Transaction-level data for crypto analytics research","category":"Financial Services","url":"https://cloud.google.com/bigquery/public-data","difficulty":"intermediate","prerequisites":"SQL-queries, BigQuery-API, blockchain-fundamentals","topic_tags":"cryptocurrency-data, blockchain-analytics, transaction-analysis, BigQuery-datasets, financial-data","summary":"Comprehensive dataset containing complete transaction histories for 8 major blockchains including Bitcoin and Ethereum, updated daily in Google BigQuery. Provides transaction-level granularity for researchers and analysts studying cryptocurrency markets, user behavior, and blockchain economics. Essential resource for crypto analytics requiring large-scale, structured blockchain data.","use_cases":"Analyzing Bitcoin transaction patterns to identify market manipulation or whale behavior, Building Ethereum DeFi protocol usage dashboards with real-time transaction monitoring","audience":"Junior-DS, Mid-DS"},{"id":"dataset-netflix-viewing-behavior","type":"dataset","name":"Netflix Viewing Behavior","description":"1.7M episodes/movies watched by 1,060 users over 1 year. Watch patterns, session length, preferences, predictability metrics","category":"Entertainment & Media","url":"https://ieeexplore.ieee.org/document/9500874","difficulty":"beginner","prerequisites":"python-pandas, SQL-queries, descriptive-statistics","topic_tags":"streaming-data, user-behavior, media-consumption, session-analysis, entertainment","summary":"A comprehensive dataset of Netflix viewing patterns from over 1,000 users across one year, containing 1.7M viewing records with session details and user preferences. This dataset is ideal for analyzing streaming behavior, content recommendation systems, and media consumption patterns. Perfect for data scientists learning user behavior analytics or studying entertainment industry metrics.","use_cases":"Building recommendation systems based on viewing patterns and session data, Analyzing user engagement metrics to optimize content strategy and retention","audience":"Junior-DS, Curious-browser"},{"id":"dataset-netflix-engagement-reports","type":"dataset","name":"Netflix Engagement Reports","description":"Hours viewed for every Netflix title (original and licensed) watched >50K hours. First public streaming metrics since 2021","category":"Entertainment & Media","url":"https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"streaming-data, entertainment-analytics, engagement-metrics, viewership-analysis, media-consumption","summary":"Netflix's first public release of comprehensive viewing metrics showing hours watched for all titles with >50K hours engagement since 2021. This dataset provides unprecedented transparency into streaming consumption patterns across Netflix's global catalog of original and licensed content. Essential for understanding modern media consumption behaviors and content performance benchmarks.","use_cases":"Analyzing content performance patterns to inform streaming strategy decisions, Benchmarking engagement metrics for entertainment industry market research","audience":"Junior-DS, Curious-browser"},{"id":"dataset-youtube-user-watch-history","type":"dataset","name":"YouTube User Watch History","description":"1.8M videos watched by 243 users over 1.5 years. Recommendation engine performance, caching research, viewing patterns","category":"Entertainment & Media","url":"https://netsg.cs.sfu.ca/youtubedata/","difficulty":"beginner","prerequisites":"python-pandas, exploratory-data-analysis, basic-statistics","topic_tags":"youtube-data, user-behavior, recommendation-systems, video-analytics, longitudinal-data","summary":"A longitudinal dataset containing 1.8 million video watch records from 243 YouTube users tracked over 1.5 years. This rich behavioral dataset enables analysis of viewing patterns, recommendation algorithm effectiveness, and user engagement trends. Ideal for researchers studying digital media consumption, recommendation systems, or user behavior analytics.","use_cases":"Analyzing recommendation algorithm performance by comparing suggested vs. actually watched videos, Building predictive models for user engagement and video popularity trends","audience":"Junior-DS, Mid-DS"},{"id":"dataset-youtube-engagement-dataset","type":"dataset","name":"YouTube Engagement Dataset","description":"5M videos with watch percentage, engagement maps, Freebase topic labels. Video-level engagement metrics for content research","category":"Entertainment & Media","url":"https://github.com/avalanchesiqi/youtube-engagement","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-visualization","topic_tags":"youtube-analytics, video-engagement, content-metrics, media-research, behavioral-data","summary":"A comprehensive dataset of 5 million YouTube videos with detailed engagement metrics including watch percentage, engagement maps, and Freebase topic classifications. This dataset enables researchers and analysts to study video content performance, audience behavior patterns, and topic-based engagement trends across the YouTube platform.","use_cases":"Analyzing which video topics and formats drive highest audience retention for content strategy optimization, Building predictive models to forecast video engagement based on content characteristics and topic categories","audience":"Junior-DS, Mid-DS"},{"id":"dataset-youtube-8m","type":"dataset","name":"YouTube-8M","description":"8M videos with video-level features for large-scale video understanding. Google Research benchmark for video classification","category":"Entertainment & Media","url":"https://research.google.com/youtube8m/","difficulty":"intermediate","prerequisites":"tensorflow-keras, python-pandas, neural-networks","topic_tags":"video-classification, large-scale-dataset, benchmark, deep-learning, computer-vision","summary":"YouTube-8M is a massive dataset containing 8 million YouTube videos with pre-extracted features designed for video classification tasks. It serves as a standard benchmark in the computer vision community for developing and evaluating large-scale video understanding models. The dataset is particularly valuable for researchers working on video content analysis without requiring raw video processing.","use_cases":"Benchmarking video classification models against industry standard, Training content recommendation systems for video platforms","audience":"Mid-DS, Senior-DS"},{"id":"dataset-twitch-gamers-social-network","type":"dataset","name":"Twitch Gamers Social Network","description":"168K nodes with mutual follower relationships. 6 ML tasks including churn, affiliate status, view count prediction","category":"Entertainment & Media","url":"https://snap.stanford.edu/data/twitch-social-networks.html","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, network-analysis","topic_tags":"social-networks, twitch-data, user-behavior, churn-prediction, graph-datasets","summary":"A large-scale social network dataset from Twitch containing 168,000 gaming streamers and their mutual follower relationships. The dataset includes user features and supports 6 different machine learning tasks including churn prediction, affiliate status classification, and view count forecasting. Ideal for practitioners learning social network analysis or testing recommendation and prediction algorithms on real gaming platform data.","use_cases":"Building churn prediction models for gaming or social media platforms, Testing graph neural networks and social network analysis algorithms on real follower data","audience":"Junior-DS, Mid-DS"},{"id":"dataset-twitch-streaming-dataset","type":"dataset","name":"Twitch Streaming Dataset","description":"16 days of viewer counts, stream metadata, game categories from Oct 2017. Live streaming platform dynamics","category":"Entertainment & Media","url":"https://github.com/mingt2019/Twitch-Dataset","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-time-series","topic_tags":"streaming-data, viewership-analytics, gaming-industry, time-series, social-media","summary":"A dataset containing 16 days of Twitch streaming data from October 2017, including viewer counts, stream metadata, and game categories. Perfect for analyzing live streaming platform dynamics and understanding viewer behavior patterns. Accessible format ideal for learning exploratory data analysis and time series methods in the entertainment industry context.","use_cases":"Analyzing peak viewing times and content preferences to optimize streaming schedules, Building predictive models for stream popularity based on game categories and metadata","audience":"Junior-DS, Curious-browser"},{"id":"dataset-lastfm-1b","type":"dataset","name":"LastFM-1B","description":"1 billion listening events with long-term user histories. Music recommendation and listening behavior research","category":"Entertainment & Media","url":"http://www.cp.jku.at/datasets/LFM-1b/","difficulty":"intermediate","prerequisites":"python-pandas, collaborative-filtering, implicit-feedback-models","topic_tags":"music-recommendation, implicit-feedback, large-scale-datasets, user-behavior, entertainment-data","summary":"LastFM-1B contains one billion music listening events with extended user listening histories from the Last.fm platform. This large-scale dataset is widely used by researchers and practitioners developing music recommendation systems and studying long-term user listening patterns. The dataset enables analysis of implicit feedback behaviors and temporal listening dynamics at unprecedented scale.","use_cases":"Building and benchmarking collaborative filtering algorithms for music streaming platforms, Analyzing long-term user preference drift and seasonal listening patterns in music consumption","audience":"Mid-DS, Senior-DS"},{"id":"dataset-spotify-million-playlist","type":"dataset","name":"Spotify Million Playlist","description":"1M playlists with 2M unique tracks from 300K artists. RecSys 2018 Challenge for playlist continuation research","category":"Entertainment & Media","url":"https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge","difficulty":"beginner","prerequisites":"python-pandas, collaborative-filtering, matrix-factorization","topic_tags":"music-recommendation, playlist-dataset, collaborative-filtering, sequential-data, user-behavior","summary":"Large-scale dataset containing one million Spotify playlists with detailed track and artist metadata, originally created for the RecSys 2018 Challenge. Perfect for learning recommendation system fundamentals and experimenting with playlist continuation algorithms. Provides real-world music consumption patterns at scale with rich sequential listening behavior data.","use_cases":"Building a playlist recommendation system to suggest next songs based on existing tracks, Analyzing music listening patterns and user preferences across different genres and artists","audience":"Junior-DS, Curious-browser"},{"id":"dataset-yfcc100m","type":"dataset","name":"YFCC100M","description":"100M Flickr photos/videos with metadata under Creative Commons. Yahoo/Flickr dataset for multimedia research","category":"Entertainment & Media","url":"https://multimediacommons.wordpress.com/yfcc100m-core-dataset/","difficulty":"beginner","prerequisites":"python-pandas, image-processing-libraries, data-cleaning","topic_tags":"multimedia-data, creative-commons, computer-vision, social-media-analysis","summary":"YFCC100M is a massive dataset containing 100 million photos and videos from Flickr with associated metadata, all released under Creative Commons licenses. It serves as a benchmark dataset for multimedia research, computer vision, and social media analysis. The dataset includes rich metadata like timestamps, geolocation, tags, and user information making it valuable for studying visual content at scale.","use_cases":"Training computer vision models for image classification or object detection using real-world social media photos, Analyzing geographic and temporal patterns in user-generated content for social media research","audience":"Junior-DS, Curious-browser"},{"id":"dataset-meta-content-library","type":"dataset","name":"Meta Content Library","description":"Full Facebook/Instagram public archive via ICPSR application. Posts, Pages, groups, events for academic research","category":"Social & Web","url":"https://transparency.meta.com/researchtools/meta-content-library","difficulty":"intermediate","prerequisites":"python-pandas, API-authentication, data-privacy-regulations","topic_tags":"social-media-data, facebook-research, content-analysis, platform-data, ICPSR","summary":"The Meta Content Library provides researchers with access to Facebook and Instagram's public content archive through ICPSR's secure application process. This comprehensive dataset includes posts, pages, groups, and events specifically curated for academic research purposes. Researchers can analyze social media behavior, content trends, and platform dynamics at scale while maintaining compliance with privacy regulations.","use_cases":"Studying misinformation spread patterns across Facebook posts and groups during election periods, Analyzing Instagram content trends and engagement patterns to understand social commerce behavior","audience":"Mid-DS, Senior-DS"},{"id":"dataset-facebook-url-shares","type":"dataset","name":"Facebook URL Shares","description":"38M URLs with 10T exposure numbers, fact-checking flags, interaction types (2017-2019). Social Science One initiative","category":"Social & Web","url":"https://socialscience.one/our-facebook-partnership","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, hypothesis-testing","topic_tags":"misinformation-detection, social-media-analysis, fact-checking, url-sharing, exposure-metrics","summary":"Massive dataset of 38 million URLs shared on Facebook from 2017-2019, including 10 trillion exposure measurements, fact-checking labels, and user interaction patterns. Created through Facebook's Social Science One initiative to enable academic research on misinformation spread. Provides unprecedented scale for studying how false information propagates across social networks and measuring the effectiveness of fact-checking interventions.","use_cases":"Measuring the viral spread patterns of misinformation versus factual content across different user demographics, Evaluating the impact of Facebook's fact-checking labels on user engagement and sharing behavior","audience":"Mid-DS, Senior-DS"},{"id":"dataset-snap-facebook-ego-networks","type":"dataset","name":"SNAP Facebook Ego Networks","description":"4K users with social circles and anonymized node features. Stanford Network Analysis Project dataset","category":"Social & Web","url":"https://snap.stanford.edu/data/ego-Facebook.html","difficulty":"beginner","prerequisites":"python-pandas, networkx, graph-visualization","topic_tags":"social-networks, ego-networks, graph-data, facebook-data, network-analysis","summary":"A collection of Facebook social network data containing 4,000 users organized into ego networks (a user and their immediate connections). Each network includes anonymized node features, making it ideal for learning social network analysis techniques. This is one of the most accessible datasets from Stanford's SNAP collection for understanding social graph structures.","use_cases":"Learning social network analysis by exploring how friend circles form and overlap in Facebook networks, Developing community detection algorithms to identify social groups within ego networks","audience":"Early-PhD, Junior-DS"},{"id":"dataset-us-2020-election-study","type":"dataset","name":"US 2020 Election Study","description":"Facebook/Instagram impact on political attitudes. Published in Science/Nature 2023. SOMAR Michigan access","category":"Social & Web","url":"https://www.icpsr.umich.edu/web/ICPSR/series/2045","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, python-pandas, causal-inference","topic_tags":"social-media-research, election-analysis, political-behavior, facebook-data, experimental-design","summary":"Large-scale randomized controlled trial studying how Facebook and Instagram usage affected political attitudes and behaviors during the 2020 US election. Published in top-tier journals with data accessible through SOMAR at University of Michigan. Provides gold-standard experimental evidence on social media's causal impact on democratic processes.","use_cases":"Researchers studying social media's causal impact on political polarization and voter behavior, Policy analysts evaluating platform regulation effects on democratic participation","audience":"Mid-DS, Senior-DS"},{"id":"dataset-mobilerec","type":"dataset","name":"MobileRec","description":"19.3M user reviews from 700K users across 10K apps in 48 categories. Google Play app recommendation research","category":"App Stores","url":"https://github.com/mhmaqbool/mobilerec","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, descriptive-statistics","topic_tags":"mobile-apps, user-reviews, recommendation-systems, app-store-data, google-play","summary":"MobileRec is a large-scale dataset containing 19.3 million user reviews from 700,000 users across 10,000 mobile applications spanning 48 categories on Google Play. This comprehensive dataset is designed for app recommendation research and provides rich user-app interaction data. It's ideal for researchers and practitioners working on mobile app analytics, recommendation algorithms, and understanding user behavior in app ecosystems.","use_cases":"Building recommendation systems to suggest relevant apps to users based on review patterns and app categories, Analyzing user sentiment and preferences across different app categories to inform product development strategies","audience":"Junior-DS, Mid-DS"},{"id":"dataset-google-play-store-dataset","type":"dataset","name":"Google Play Store Dataset","description":"2.3M apps with ratings, reviews, categories, sizes, installs. Android app marketplace data","category":"App Stores","url":"https://www.kaggle.com/datasets/gauthamp10/google-playstore-apps","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, basic-statistics","topic_tags":"mobile-apps, user-behavior, market-analysis, app-store-data, android","summary":"A comprehensive dataset of 2.3 million Android applications from Google Play Store including user ratings, review counts, categories, file sizes, and install numbers. This dataset is ideal for market research, user behavior analysis, and understanding mobile app ecosystem trends. Perfect for exploratory data analysis and learning data science fundamentals with real-world marketplace data.","use_cases":"Analyzing which app categories have highest user engagement and ratings, Predicting app success based on size, category, and pricing strategies","audience":"Junior-DS, Curious-browser"},{"id":"dataset-apple-app-store-dataset","type":"dataset","name":"Apple App Store Dataset","description":"7,200 iOS apps with pricing, ratings, genres, in-app purchases. Apple app marketplace analysis","category":"App Stores","url":"https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"mobile-apps, pricing-analysis, marketplace-data, consumer-behavior, app-economics","summary":"A dataset containing 7,200 iOS applications with comprehensive metadata including pricing, user ratings, genres, and in-app purchase information from the Apple App Store. This dataset enables analysis of mobile app marketplace dynamics, pricing strategies, and consumer preferences. It's ideal for learning data analysis fundamentals while exploring the economics of digital platforms.","use_cases":"Analyzing optimal pricing strategies for mobile app developers by comparing successful apps across different genres, Studying the relationship between app ratings, pricing models, and in-app purchase strategies to understand consumer behavior","audience":"Junior-DS, Curious-browser"},{"id":"dataset-jobhop-(flanders)","type":"dataset","name":"JobHop (Flanders)","description":"2.3M occupations and 391K resumes with real career trajectories mapped to ESCO codes. Labor mobility research","category":"Labor Markets","url":"https://huggingface.co/datasets/VDAB/jobhop","difficulty":"intermediate","prerequisites":"python-pandas, network-analysis, survival-analysis","topic_tags":"career-trajectories, labor-mobility, occupational-transitions, ESCO-taxonomy, longitudinal-data","summary":"A comprehensive dataset containing 2.3 million job positions and 391,000 real resumes from Flanders, Belgium, with career paths mapped to standardized ESCO occupation codes. This longitudinal dataset enables researchers to analyze labor market mobility patterns, career progression dynamics, and occupational transitions at scale. The standardized coding makes it particularly valuable for cross-European labor market comparisons and policy research.","use_cases":"Modeling career transition probabilities between different occupation categories to predict workforce flows, Analyzing the impact of economic shocks on career mobility patterns across different industries and skill levels","audience":"Mid-DS, Senior-DS"},{"id":"dataset-bls-jolts","type":"dataset","name":"BLS JOLTS","description":"Monthly job openings, hires, separations by industry since 2000. Bureau of Labor Statistics time series","category":"Labor Markets","url":"https://www.bls.gov/jlt/data.htm","difficulty":"beginner","prerequisites":"python-pandas, time-series-data, basic-visualization","topic_tags":"labor-economics, time-series, government-data, employment, industry-analysis","summary":"The Bureau of Labor Statistics Job Openings and Labor Turnover Survey (JOLTS) provides monthly data on job openings, hires, and separations across industries since 2000. This dataset is widely used by economists, policymakers, and data scientists to analyze labor market trends and employment dynamics. It offers reliable, granular insights into hiring patterns and job market health across different sectors of the economy.","use_cases":"Analyzing post-recession hiring recovery patterns by industry, Building predictive models for job market tightness using opening-to-hire ratios","audience":"Junior-DS, Early-PhD"},{"id":"dataset-glassdoor-reviews","type":"dataset","name":"Glassdoor Reviews","description":"Company ratings, salary reports, interview experiences. Employer review platform data for labor analytics","category":"Labor Markets","url":"https://www.glassdoor.com/research/","difficulty":"beginner","prerequisites":"python-pandas, basic-regression, data-cleaning","topic_tags":"employer-reviews, salary-data, labor-markets, survey-data, compensation-analysis","summary":"Glassdoor Reviews is a dataset containing employee-generated company ratings, salary reports, and interview experiences from the popular employer review platform. This data provides insights into workplace culture, compensation trends, and hiring practices across companies and industries. It's commonly used by researchers studying labor markets, compensation equity, and organizational behavior.","use_cases":"Analyzing gender pay gaps by comparing salary reports across demographics and companies, Building predictive models for company satisfaction scores based on review text and ratings","audience":"Junior-DS, Mid-DS"},{"id":"dataset-revelio-labs-cosmos","type":"dataset","name":"Revelio Labs COSMOS","description":"4.1B job postings from 6.6M companies. Deduplicated, parsed, enriched workforce data (commercial/academic partnerships)","category":"Labor Markets","url":"https://www.reveliolabs.com/","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, data-cleaning","topic_tags":"job-postings, workforce-analytics, labor-economics, company-data, dataset","summary":"Revelio Labs COSMOS is a massive dataset containing 4.1 billion job postings from 6.6 million companies, offering deduplicated and enriched workforce data. This comprehensive resource enables researchers and analysts to study labor market trends, hiring patterns, and workforce dynamics at scale. The dataset is available through commercial partnerships and academic collaborations.","use_cases":"Analyzing skill demand trends across industries to inform workforce development policy, Building predictive models for labor market tightness and wage growth using company hiring patterns","audience":"Mid-DS, Senior-DS"},{"id":"dataset-hatexplain","type":"dataset","name":"HateXplain","description":"20K social media posts with human rationales across 10 hate speech target categories. Explainable AI for content moderation","category":"Content Moderation","url":"https://github.com/hate-alert/HateXplain","difficulty":"intermediate","prerequisites":"python-pandas, transformers-library, annotation-schemes","topic_tags":"hate-speech, explainable-ai, content-moderation, human-annotations, social-media","summary":"HateXplain is a dataset of 20,000 social media posts labeled for hate speech detection with human-provided rationales explaining the decisions. It covers 10 different hate speech target categories and enables training explainable AI models for content moderation. The dataset is particularly valuable for researchers developing interpretable NLP systems that need to justify their hate speech classifications.","use_cases":"Training explainable hate speech detection models that can highlight specific words or phrases that indicate hateful content, Benchmarking content moderation systems that need to provide human-interpretable explanations for automated decisions","audience":"Mid-DS, Senior-DS"},{"id":"dataset-hateday","type":"dataset","name":"HateDay","description":"Global representative sample of real-world hate speech across languages. 2024 benchmark for content moderation","category":"Content Moderation","url":"https://arxiv.org/abs/2404.06465","difficulty":"intermediate","prerequisites":"python-pandas, multilingual-NLP, classification-metrics","topic_tags":"hate-speech, multilingual-datasets, content-moderation, benchmark-evaluation, safety-AI","summary":"HateDay is a comprehensive global dataset containing real-world hate speech examples across multiple languages, serving as a standardized benchmark for evaluating content moderation systems. It provides researchers and practitioners with representative samples to test and compare hate speech detection models. The dataset is particularly valuable for developing robust multilingual content moderation tools that work across diverse linguistic and cultural contexts.","use_cases":"Benchmarking a new hate speech detection model against existing state-of-the-art systems, Training multilingual content moderation systems for global social media platforms","audience":"Mid-DS, Senior-DS"},{"id":"dataset-ethos-hate-speech","type":"dataset","name":"ETHOS Hate Speech","description":"998 online comments labeled for hate speech detection in English. Binary and multi-label annotations","category":"Content Moderation","url":"https://zenodo.org/records/4459923","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, classification-metrics","topic_tags":"hate-speech-detection, text-classification, content-moderation, labeled-dataset, NLP","summary":"ETHOS is a labeled dataset of 998 English online comments annotated for hate speech detection research. It provides both binary (hate/not hate) and multi-label classifications, making it useful for training and evaluating content moderation models. The dataset is particularly valuable for researchers and practitioners working on automated hate speech detection systems.","use_cases":"Training machine learning models to automatically flag hateful comments on social media platforms, Benchmarking different NLP approaches for content moderation systems","audience":"Junior-DS, Mid-DS"},{"id":"dataset-hate-speech-data-catalogue","type":"dataset","name":"Hate Speech Data Catalogue","description":"50+ hate speech datasets across languages compiled at hatespeechdata.com. Meta-resource for content moderation research","category":"Content Moderation","url":"https://hatespeechdata.com/","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, dataset-handling","topic_tags":"hate-speech, content-moderation, multilingual-datasets, meta-resource, catalogue","summary":"A comprehensive catalogue of 50+ hate speech datasets spanning multiple languages, hosted at hatespeechdata.com. This meta-resource serves as a central hub for researchers and practitioners working on content moderation systems. It provides structured access to diverse hate speech datasets for training and evaluating detection models.","use_cases":"Building multilingual hate speech detection models for social media platforms, Benchmarking content moderation algorithms across different languages and cultural contexts","audience":"Junior-DS, Mid-DS"},{"id":"dataset-coaid-covid-misinformation","type":"dataset","name":"CoAID COVID Misinformation","description":"4,251 news articles and 296K claims about COVID-19 healthcare misinformation. Fact-checked with ground truth labels","category":"Content Moderation","url":"https://github.com/cuilimeng/CoAID","difficulty":"intermediate","prerequisites":"python-pandas, natural-language-processing, classification-algorithms","topic_tags":"misinformation-detection, covid-19, fact-checking, content-moderation, dataset","summary":"A comprehensive dataset containing 4,251 COVID-19 related news articles and 296K health claims with verified fact-checking labels. This resource enables researchers and data scientists to build and evaluate misinformation detection systems specifically for healthcare content during pandemic situations.","use_cases":"Training machine learning models to automatically detect COVID-19 health misinformation on social media platforms, Benchmarking fact-checking algorithms against ground truth labels for pandemic-related content","audience":"Mid-DS, Senior-DS"},{"id":"dataset-liar-fact-checking","type":"dataset","name":"LIAR Fact-Checking","description":"12.8K fact-checked political statements with speaker metadata and 6-way truthfulness labels. Politifact benchmark","category":"Content Moderation","url":"https://www.cs.ucsb.edu/~william/data/liar_dataset.zip","difficulty":"beginner","prerequisites":"python-pandas, text-preprocessing, classification-metrics","topic_tags":"fact-checking, political-text, misinformation-detection, benchmark-dataset, multi-class-classification","summary":"A widely-used benchmark dataset containing 12,800 political statements from Politifact with 6-level truthfulness ratings (pants-on-fire to true) plus speaker metadata. Popular starting point for researchers building automated fact-checking systems and studying misinformation patterns in political discourse.","use_cases":"Training ML models to automatically classify statement truthfulness for content moderation platforms, Analyzing patterns in political misinformation by party, speaker, or topic for research papers","audience":"Junior-DS, Early-PhD"},{"id":"dataset-fakenewsnet","type":"dataset","name":"FakeNewsNet","description":"23K news articles labeled fake/real with social context. Includes PolitiFact and GossipCop sources","category":"Content Moderation","url":"https://github.com/KaiDMML/FakeNewsNet","difficulty":"beginner","prerequisites":"python-pandas, basic-classification, text-preprocessing","topic_tags":"fake-news, misinformation, social-media, content-moderation, labeled-dataset","summary":"FakeNewsNet is a comprehensive dataset containing 23,000 news articles labeled as fake or real, sourced from PolitiFact and GossipCop with accompanying social media context. It provides researchers and practitioners with ground truth data for developing and testing misinformation detection algorithms. The dataset includes both textual content and social engagement metrics, making it valuable for studying how false information spreads online.","use_cases":"Training machine learning models to automatically detect fake news articles on social media platforms, Analyzing patterns in how misinformation spreads compared to legitimate news stories","audience":"Junior-DS, Curious-browser"},{"id":"dataset-patreon-creator-data","type":"dataset","name":"Patreon Creator Data","description":"279K+ active creators with membership tiers and patron counts. Creator economy platform metrics from Graphtreon","category":"Creator Economy","url":"https://graphtreon.com/","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, descriptive-statistics","topic_tags":"patreon-data, creator-economy, subscription-metrics, platform-data, membership-tiers","summary":"A comprehensive dataset of 279K+ active Patreon creators including their membership tier structures and patron counts from Graphtreon. This dataset provides insights into the creator economy landscape, allowing analysis of subscription patterns, creator success metrics, and platform dynamics. Useful for understanding monetization strategies and market trends in the digital creator space.","use_cases":"Analyzing creator revenue distribution and success factors across different content categories, Building predictive models for creator growth based on membership tier pricing strategies","audience":"Junior-DS, Curious-browser"},{"id":"dataset-social-blade","type":"dataset","name":"Social Blade","description":"Public subscriber/follower counts and growth metrics across YouTube, Twitch, Instagram, Twitter, TikTok","category":"Creator Economy","url":"https://socialblade.com/","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, API-requests","topic_tags":"social-media-analytics, creator-economy, growth-tracking, platform-metrics, influencer-data","summary":"Social Blade provides publicly available subscriber and follower counts across major social platforms including YouTube, Twitch, Instagram, Twitter, and TikTok. The dataset includes historical growth metrics and engagement statistics that are commonly used by creators, marketers, and researchers. This data is particularly valuable for analyzing creator economy trends and platform-specific growth patterns.","use_cases":"Analyzing YouTube creator growth patterns to identify successful content strategies, Comparing influencer reach across platforms for brand partnership decisions","audience":"Junior-DS, Curious-browser"},{"id":"dataset-creator-economy-reports","type":"dataset","name":"Creator Economy Reports","description":"Survey-based earnings breakdowns by platform (YouTube, TikTok, Instagram, Twitch). Influencer Marketing Factory research","category":"Creator Economy","url":"https://theinfluencermarketingfactory.com/creator-economy/","difficulty":"beginner","prerequisites":"descriptive-statistics, data-visualization","topic_tags":"creator-economy, platform-earnings, survey-data, influencer-marketing","summary":"Survey-based dataset from Influencer Marketing Factory showing earnings breakdowns across major creator platforms including YouTube, TikTok, Instagram, and Twitch. The data provides insights into creator monetization patterns and income distribution across different social media platforms. Useful for understanding the economics of content creation and platform-specific earning potential.","use_cases":"Benchmarking creator earnings against platform averages for partnership negotiations, Market research on creator economy trends for platform strategy or investment decisions","audience":"Curious-browser, Junior-DS"},{"id":"dataset-medicare-provider-utilization","type":"dataset","name":"Medicare Provider Utilization","description":"All Medicare providers with service utilization and payment data. CMS public use files for healthcare analytics","category":"Healthcare","url":"https://data.cms.gov/provider-summary-by-type-of-service","difficulty":"beginner","prerequisites":"python-pandas, healthcare-basics, data-cleaning","topic_tags":"medicare-data, healthcare-analytics, provider-payments, cms-data, public-datasets","summary":"Comprehensive dataset containing utilization and payment information for all Medicare providers from the Centers for Medicare & Medicaid Services. This public use file enables analysis of healthcare spending patterns, provider behavior, and geographic variations in Medicare services. Essential resource for healthcare economists studying payment systems and service delivery.","use_cases":"Analyzing geographic variation in Medicare spending per beneficiary across different regions, Identifying high-volume providers and their payment patterns for fraud detection research","audience":"Junior-DS, Curious-browser"},{"id":"dataset-google-dataset-search","type":"dataset","name":"Google Dataset Search","description":"Universal search engine for datasets across the web. Meta-tool for discovering research data","category":"Data Portals","url":"https://datasetsearch.research.google.com/","difficulty":"beginner","prerequisites":"basic-web-search, dataset-formats","topic_tags":"data-discovery, research-datasets, search-engine, open-data","summary":"Google Dataset Search is a specialized search engine that indexes datasets from across the web, making it easy to discover publicly available research data. It aggregates datasets from repositories, government sites, news organizations, and academic publishers in one searchable interface. Researchers and data scientists use it to find relevant datasets without having to search individual data portals separately.","use_cases":"Finding public datasets for a machine learning project on climate change, Discovering government economic data for policy research analysis","audience":"Junior-DS, Curious-browser"},{"id":"dataset-hugging-face-datasets","type":"dataset","name":"Hugging Face Datasets","description":"ML/NLP datasets hub with 100K+ datasets. Easy loading via Python library. Community-driven repository","category":"Data Portals","url":"https://huggingface.co/datasets","difficulty":"beginner","prerequisites":"python-basics, pandas-dataframes","topic_tags":"datasets, machine-learning, NLP, data-loading, community-repository","summary":"Hugging Face Datasets is a comprehensive hub containing over 100,000 machine learning and NLP datasets with a simple Python library for easy loading. It's a community-driven platform that standardizes dataset access and preprocessing for ML practitioners. The library handles caching, streaming, and format conversion automatically.","use_cases":"Loading pre-processed text datasets for training transformer models, Finding benchmark datasets for comparing model performance across standard evaluation tasks","audience":"Junior-DS, Mid-DS"},{"id":"dataset-criteo-terabyte","type":"dataset","name":"Criteo Terabyte","description":"342GB, 45M samples with 13 integer features and 26 hashed categorical features for CTR prediction","category":"Advertising","url":"https://huggingface.co/datasets/criteo/CriteoClickLogs","difficulty":"intermediate","prerequisites":"python-pandas, machine-learning-classification, feature-engineering","topic_tags":"click-through-rate, advertising, large-scale-data, benchmark-dataset, categorical-features","summary":"The Criteo Terabyte dataset is a massive 342GB collection of 45 million click-through rate prediction samples from online advertising. It contains 13 integer features and 26 hashed categorical features, making it the standard benchmark for evaluating CTR prediction models at scale. This dataset is widely used by researchers and practitioners to test algorithms on realistic advertising data with production-scale volume.","use_cases":"Benchmarking new CTR prediction algorithms against state-of-the-art baselines, Testing scalability of machine learning systems with terabyte-scale advertising data","audience":"Mid-DS, Senior-DS"},{"id":"dataset-open-e-commerce-1.0","type":"dataset","name":"Open e-commerce 1.0","description":"1.85M Amazon purchases from 5,027 US consumers (2018-2022) linked to demographics (age, gender, income, education)","category":"E-Commerce","url":"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YGLYDY","difficulty":"beginner","prerequisites":"python-pandas, SQL-joins, descriptive-statistics","topic_tags":"consumer-behavior, amazon-data, demographic-analysis, purchase-patterns, longitudinal-data","summary":"A comprehensive dataset containing 1.85 million Amazon purchase records from over 5,000 US consumers spanning 2018-2022, with linked demographic information including age, gender, income, and education levels. This dataset enables researchers and analysts to study consumer behavior patterns and demographic influences on e-commerce purchasing decisions. The multi-year timeframe allows for longitudinal analysis of shopping trends and consumer segments.","use_cases":"Analyzing how demographic factors (age, income, education) influence Amazon purchase categories and spending patterns, Building customer segmentation models to identify distinct consumer groups based on purchasing behavior and demographics","audience":"Junior-DS, Curious-browser"},{"id":"dataset-otto-session-data","type":"dataset","name":"OTTO Session Data","description":"12M German e-commerce sessions with click \u2192 cart \u2192 order sequences. RecSys 2022 competition","category":"E-Commerce","url":"https://github.com/otto-de/recsys-dataset","difficulty":"beginner","prerequisites":"python-pandas, basic-SQL, recommendation-systems-concepts","topic_tags":"session-data, e-commerce-analytics, recommendation-systems, sequential-data, conversion-funnel","summary":"A large dataset of 12 million German e-commerce user sessions tracking the customer journey from clicks to cart additions to purchases. Created for the RecSys 2022 competition, it provides real-world sequential interaction data ideal for building and evaluating recommendation systems. The dataset captures the complete conversion funnel with temporal ordering of user actions.","use_cases":"Building next-item recommendation models for e-commerce platforms, Analyzing conversion rates and drop-off patterns in online shopping funnels","audience":"Junior-DS, Mid-DS"},{"id":"dataset-asos-digital-experiments","type":"dataset","name":"ASOS Digital Experiments","description":"99 real A/B experiments with 24,153 time-granular snapshots for adaptive stopping research","category":"E-Commerce","url":"https://osf.io/64jsb/","difficulty":"intermediate","prerequisites":"python-pandas, statistical-hypothesis-testing, A/B-test-design","topic_tags":"A/B-testing, adaptive-stopping, e-commerce, experimental-design, real-world-data","summary":"A collection of 99 real A/B experiments from ASOS with over 24,000 time-granular snapshots, designed for studying adaptive stopping methods in digital experimentation. This dataset provides researchers and practitioners with authentic e-commerce experimental data to develop and validate sequential testing approaches. The time-series nature allows for analysis of when experiments should be stopped based on accumulating evidence.","use_cases":"Developing and benchmarking adaptive stopping rules for A/B tests to reduce experiment duration while maintaining statistical validity, Training machine learning models to predict optimal experiment stopping times based on real e-commerce conversion patterns","audience":"Mid-DS, Senior-DS"},{"id":"dataset-prosper-loan-data","type":"dataset","name":"Prosper Loan Data","description":"113K P2P loans with borrower characteristics and outcomes","category":"Financial Services","url":"https://www.kaggle.com/datasets/henryokam/prosper-loan-data","difficulty":"beginner","prerequisites":"python-pandas, logistic-regression, data-visualization","topic_tags":"peer-to-peer, credit-risk, financial-services, loan-default, dataset","summary":"A comprehensive dataset of 113,000 peer-to-peer loans from Prosper marketplace containing borrower demographics, credit scores, loan terms, and repayment outcomes. Commonly used by data scientists and researchers studying credit risk modeling and alternative lending markets. Perfect for building predictive models of loan default and analyzing factors that influence lending decisions.","use_cases":"Building machine learning models to predict loan default probability based on borrower characteristics, Analyzing bias in peer-to-peer lending decisions across different demographic groups","audience":"Junior-DS, Mid-DS"},{"id":"dataset-orbitaal-bitcoin-graph","type":"dataset","name":"ORBITAAL Bitcoin Graph","description":"13 years (2009-2021) of entity-level Bitcoin transaction networks with BTC/USD values","category":"Financial Services","url":"https://www.nature.com/articles/s41597-023-02416-6","difficulty":"intermediate","prerequisites":"python-pandas, graph-analysis, SQL-joins","topic_tags":"bitcoin-transactions, cryptocurrency-networks, graph-data, financial-networks, blockchain-analysis","summary":"A comprehensive dataset containing 13 years of Bitcoin transaction networks organized at the entity level, with corresponding BTC/USD exchange rates. This dataset enables researchers and data scientists to analyze cryptocurrency flow patterns, entity behavior, and network evolution over Bitcoin's entire history. The graph structure allows for network analysis of Bitcoin's transaction ecosystem.","use_cases":"Analyzing money laundering patterns and suspicious transaction flows in cryptocurrency networks, Studying the evolution of Bitcoin's network structure and identifying key entities or hubs over time","audience":"Mid-DS, Senior-DS"},{"id":"dataset-stack-overflow-developer-survey","type":"dataset","name":"Stack Overflow Developer Survey","description":"49K+ annual responses with salaries, tech adoption, and developer analytics","category":"Labor Markets","url":"https://survey.stackoverflow.co/","difficulty":"beginner","prerequisites":"python-pandas, descriptive-statistics, data-visualization","topic_tags":"developer-survey, salary-data, tech-adoption, workforce-analytics, survey-data","summary":"Annual comprehensive survey dataset from Stack Overflow containing responses from 49,000+ developers worldwide. Includes detailed information on salaries, technology preferences, job satisfaction, and demographic data. Widely used for understanding tech labor market trends and developer ecosystem dynamics.","use_cases":"Benchmarking salary expectations for different programming languages and experience levels, Analyzing technology adoption patterns to inform product roadmaps or hiring decisions","audience":"Junior-DS, Curious-browser"},{"id":"dataset-liar","type":"dataset","name":"LIAR","description":"12.8K fact-checked political statements with speaker metadata","category":"Content Moderation","url":"https://sites.cs.ucsb.edu/~william/software.html","difficulty":"beginner","prerequisites":"python-pandas, text-classification, natural-language-processing","topic_tags":"fact-checking, political-statements, misinformation-detection, labeled-dataset, content-moderation","summary":"LIAR is a dataset containing 12,800 manually fact-checked political statements from PolitiFact, labeled with truthfulness ratings and enriched with speaker metadata. It's commonly used for building automated fact-checking systems and studying misinformation patterns in political discourse. The dataset provides a standardized benchmark for researchers working on misinformation detection and content moderation applications.","use_cases":"Training machine learning models to automatically classify political statements as true, false, or misleading, Analyzing patterns in political misinformation by speaker demographics, party affiliation, or statement topics","audience":"Junior-DS, Early-PhD"},{"id":"dataset-lade-(cainiao)","type":"dataset","name":"LaDe (Cainiao)","description":"10.6M+ packages with 619K trajectories and GPS data from Alibaba logistics","category":"Logistics & Supply Chain","url":"https://huggingface.co/datasets/Cainiao-AI/LaDe","difficulty":"intermediate","prerequisites":"python-pandas, geospatial-analysis, time-series-analysis","topic_tags":"logistics-data, trajectory-analysis, supply-chain, geospatial, delivery-optimization","summary":"LaDe is a massive logistics dataset from Alibaba's Cainiao network containing over 10.6 million package records with 619K delivery trajectories and GPS tracking data. It provides real-world insights into last-mile delivery operations, route optimization, and supply chain efficiency at unprecedented scale. The dataset is valuable for researchers and practitioners working on logistics optimization, delivery prediction models, and urban mobility analysis.","use_cases":"Building delivery time prediction models using trajectory and GPS data, Analyzing route optimization patterns for last-mile delivery efficiency","audience":"Mid-DS, Senior-DS"},{"id":"resource-pymc-labs-blog","type":"resource","name":"PyMC Labs Blog","description":"Bayesian causal inference done right. MCMC, probabilistic programming, and causal models from the PyMC team.","category":"Bayesian Methods","url":"https://www.pymc-labs.com/blog-posts/","difficulty":"intermediate","prerequisites":"python-programming, bayesian-statistics, causal-inference-fundamentals","topic_tags":"bayesian-causal-inference, MCMC, probabilistic-programming, PyMC, blog-posts","summary":"PyMC Labs Blog provides practical guidance on implementing Bayesian causal inference methods using probabilistic programming. The blog covers MCMC techniques, causal model specification, and real-world applications from the team behind the PyMC library. It bridges theory and practice with code examples and case studies for data scientists working on causal problems.","use_cases":"Implementing Bayesian A/B testing with proper uncertainty quantification, Building causal models to estimate treatment effects from observational data","audience":"Mid-DS, Senior-DS"},{"id":"resource-coding-for-economists","type":"resource","name":"Coding for Economists","description":"Arthur Turrell's practical guide. Python basics through advanced workflows \u2014 built specifically for econ researchers.","category":"Python","url":"https://aeturrell.github.io/coding-for-economists/","difficulty":"beginner","prerequisites":"basic-programming-concepts, economics-fundamentals","topic_tags":"python-programming, economics-research, data-analysis, beginner-guide, online-book","summary":"Arthur Turrell's comprehensive introduction to Python programming tailored specifically for economics researchers. Covers everything from basic syntax to advanced data workflows, with examples and applications directly relevant to economic analysis. Designed to take economists from zero programming experience to confidently implementing research projects in Python.","use_cases":"PhD student needs to learn Python for dissertation data analysis, Economics researcher transitioning from Stata/R wants to pick up Python skills","audience":"Early-PhD, Curious-browser"},{"id":"resource-the-missing-semester-(mit)","type":"resource","name":"The Missing Semester (MIT)","description":"Command line, Git, debugging, shell scripting. The CS skills they don't teach in econ PhD programs but you absolutely need.","category":"Software Engineering","url":"https://missing.csail.mit.edu/","difficulty":"beginner","prerequisites":"basic-computer-literacy, terminal-access","topic_tags":"command-line, git-version-control, shell-scripting, debugging, developer-tools","summary":"MIT's comprehensive course covering essential software engineering skills that economics PhD programs typically skip. Teaches command line navigation, Git version control, debugging techniques, and shell scripting - foundational tools for any data scientist or researcher working with code.","use_cases":"Setting up reproducible research workflows with Git for thesis or paper code, Automating data processing tasks and file management for large datasets","audience":"Early-PhD, Junior-DS"},{"id":"resource-beyond-jupyter","type":"resource","name":"Beyond Jupyter","description":"Software design principles for ML applications. Go from messy notebooks to maintainable, modular code with OOP essentials and refactoring guides.","category":"Software Engineering","url":"https://github.com/aai-institute/beyond-jupyter","difficulty":"intermediate","prerequisites":"jupyter-notebooks, python-classes, git-version-control","topic_tags":"software-engineering, code-refactoring, object-oriented-programming, MLOps, tutorial","summary":"This tutorial teaches data scientists how to transform experimental Jupyter notebooks into production-ready, maintainable code using object-oriented programming principles. It covers software design patterns, code organization, and refactoring techniques specifically tailored for machine learning applications. Essential for transitioning from prototype to scalable ML systems.","use_cases":"Converting a messy exploratory data analysis notebook into a reusable data pipeline for production, Refactoring a complex model training script into modular components that can be easily tested and maintained","audience":"Junior-DS, Mid-DS"},{"id":"resource-the-theory-and-practice-of-revenue-management","type":"resource","name":"The Theory and Practice of Revenue Management","description":"Talluri & van Ryzin's comprehensive textbook. Dynamic pricing, capacity allocation, overbooking \u2014 the bible of RM.","category":"Pricing & Revenue","url":"http://ndl.ethernet.edu.et/bitstream/123456789/21707/1/306.pdf","difficulty":"advanced","prerequisites":"linear-programming, probability-theory, dynamic-programming","topic_tags":"revenue-management, dynamic-pricing, capacity-allocation, overbooking, textbook","summary":"Talluri & van Ryzin's foundational textbook covering the mathematical theory and practical implementation of revenue management systems. The comprehensive resource covers dynamic pricing models, capacity allocation algorithms, and overbooking strategies used across airlines, hotels, and other capacity-constrained industries. Essential reference for understanding both the optimization theory and real-world applications of revenue management.","use_cases":"Designing dynamic pricing algorithms for airline seat inventory management, Building hotel room allocation systems that optimize revenue across different booking channels","audience":"Senior-DS, Early-PhD"},{"id":"resource-stitch-fix:-algorithms-tour","type":"resource","name":"Stitch Fix: Algorithms Tour","description":"The single best piece of data journalism in tech. Interactive, animated tour of how they combine styles, logistics, and feedback loops.","category":"Routing & Logistics","url":"https://algorithms-tour.stitchfix.com/","difficulty":"beginner","prerequisites":"basic-statistics, recommendation-systems","topic_tags":"recommendation-systems, supply-chain, interactive-visualization, business-strategy, data-journalism","summary":"An award-winning interactive visualization that walks through Stitch Fix's end-to-end algorithmic approach to personalized fashion retail. The piece elegantly explains how they combine customer preference modeling, inventory optimization, and feedback loops in their styling algorithm. Perfect for understanding how data science creates business value in consumer-facing applications.","use_cases":"Understanding how recommendation systems work in practice at scale, Learning to communicate complex algorithmic systems to non-technical stakeholders","audience":"Junior-DS, Curious-browser"},{"id":"resource-auctions-in-ad-tech-(sanjiv-das)","type":"resource","name":"Auctions in Ad Tech (Sanjiv Das)","description":"GSP auctions, quality scores, AdRank \u2014 how Google/Meta ad auctions actually work. Chapter 21.","category":"Ads & Attribution","url":"https://srdas.github.io/MLBook/Auctions.html","difficulty":"intermediate","prerequisites":"microeconomics, probability-theory, game-theory","topic_tags":"generalized-second-price, ad-auctions, quality-score, adrank, mechanism-design","summary":"Explains how Google and Meta's ad auction systems work, focusing on Generalized Second Price (GSP) auctions, quality scores, and AdRank calculations. Covers the economic theory behind how ads are selected and priced in real-time bidding environments. Essential reading for understanding the market mechanisms that power digital advertising platforms.","use_cases":"Understanding how to optimize ad bidding strategies and quality scores for digital marketing campaigns, Designing auction mechanisms for marketplace platforms or advertising products","audience":"Mid-DS, Junior-DS"},{"id":"resource-uber-engineering","type":"resource","name":"Uber Engineering","description":"Surge pricing, marketplace design, causal inference at scale. See how researchers tackle real problems at Uber.","category":"Marketplace Economics","url":"https://www.uber.com/blog/engineering/","difficulty":"intermediate","prerequisites":"python-pandas, causal-inference, A-B-testing","topic_tags":"surge-pricing, marketplace-design, causal-inference, tech-industry, applied-economics","summary":"Uber Engineering's blog showcases real-world applications of economics and data science at massive scale. Posts cover surge pricing algorithms, marketplace matching, and causal inference methods used to optimize rider-driver markets. Essential reading for understanding how economic theory translates to production systems serving millions of users.","use_cases":"Learning how surge pricing algorithms balance supply and demand in real-time marketplaces, Understanding causal inference techniques for measuring the impact of marketplace interventions","audience":"Mid-DS, Junior-DS"},{"id":"resource-spotify-r&d","type":"resource","name":"Spotify R&D","description":"How do you recommend songs to 500M users? Personalization, search, and ML at audio scale.","category":"Frameworks & Strategy","url":"https://research.atspotify.com/","difficulty":"intermediate","prerequisites":"collaborative-filtering, python-scikit-learn, A-B-testing","topic_tags":"recommender-systems, personalization, audio-streaming, industry-scale, spotify","summary":"Spotify's R&D blog documenting their approach to building recommendation systems and personalization features for hundreds of millions of users. The content covers machine learning techniques for music discovery, audio processing, and large-scale experimentation in the streaming industry. A valuable resource for understanding how theoretical ML concepts are applied to real-world recommendation challenges at massive scale.","use_cases":"Building recommendation systems for content platforms with millions of users, Learning how to scale personalization algorithms from research prototypes to production systems","audience":"Mid-DS, Senior-DS"},{"id":"resource-doordash-engineering","type":"resource","name":"DoorDash Engineering","description":"marketplace analytics, delivery optimization, and experimentation. Great posts on real-time pricing and logistics.","category":"Routing & Logistics","url":"https://doordash.engineering/","difficulty":"intermediate","prerequisites":"python-pandas, A-B-testing, SQL-queries","topic_tags":"marketplace-analytics, delivery-optimization, real-time-pricing, logistics, experimentation","summary":"DoorDash Engineering's blog provides in-depth technical posts on marketplace analytics, delivery optimization, and experimentation methods used at scale. The content covers real-world applications of pricing algorithms, logistics optimization, and A/B testing in the food delivery industry. It's particularly valuable for understanding how theoretical concepts translate to production systems serving millions of users.","use_cases":"Learning how to implement dynamic pricing algorithms for marketplace platforms, Understanding logistics optimization strategies for delivery route planning","audience":"Mid-DS, Senior-DS"},{"id":"resource-lyft:-quantifying-efficiency-in-ridesharing","type":"resource","name":"Lyft: Quantifying Efficiency in Ridesharing","description":"Efficiency isn't speed\u2014it's an economic equilibrium. A masterclass in defining the objective function for marketplace optimization.","category":"Marketplace Economics","url":"https://eng.lyft.com/quantifying-efficiency-in-ridesharing-marketplaces-affd53043db2","difficulty":"intermediate","prerequisites":"microeconomics-equilibrium, optimization-theory, marketplace-design","topic_tags":"marketplace-optimization, ridesharing-economics, efficiency-metrics, two-sided-markets, objective-functions","summary":"Lyft's approach to defining and measuring efficiency in their ridesharing marketplace, focusing on economic equilibrium rather than simple speed metrics. The post demonstrates how to construct proper objective functions for marketplace optimization that balance rider and driver interests. Essential reading for anyone working on two-sided marketplace problems or platform economics.","use_cases":"Designing KPIs for a two-sided marketplace platform, Optimizing matching algorithms for supply-demand platforms","audience":"Mid-DS, Senior-DS"},{"id":"resource-noahpinion-(noah-smith)","type":"resource","name":"Noahpinion (Noah Smith)","description":"applied analytics, AI, innovation, growth. Deep dives with data, accessible to non-specialists. The researcher's tech newsletter.","category":"Frameworks & Strategy","url":"https://noahpinion.substack.com/","difficulty":"beginner","prerequisites":"basic-economics, data-interpretation","topic_tags":"tech-economics, AI-strategy, innovation-policy, newsletter, applied-research","summary":"Noah Smith's accessible newsletter covering tech economics, AI trends, and innovation policy through data-driven analysis. Written for both practitioners and general audiences interested in understanding how technology shapes economic outcomes. Combines academic rigor with clear explanations of complex economic concepts.","use_cases":"Staying current on AI economic impacts and policy developments, Finding accessible explanations of complex tech-economy relationships for presentations or research","audience":"Curious-browser, Junior-DS"},{"id":"resource-ben-evans-newsletter","type":"resource","name":"Ben Evans Newsletter","description":"Tech market trends and strategic analysis. What's happening in tech and why it matters.","category":"Frameworks & Strategy","url":"https://www.ben-evans.com/newsletter","difficulty":"beginner","prerequisites":"business-strategy-basics, tech-industry-knowledge","topic_tags":"tech-trends, market-analysis, strategic-insights, business-intelligence, newsletter","summary":"Ben Evans Newsletter provides strategic analysis of technology market trends and business developments. It translates complex tech industry movements into accessible insights about what's happening and why it matters. Popular among data scientists and researchers who need to understand the broader business context of their technical work.","use_cases":"Understanding market context when designing product experiments or choosing which metrics to prioritize, Staying informed about industry trends that might impact data strategy or create new opportunities for analysis","audience":"Junior-DS, Curious-browser"},{"id":"resource-stitch-fix-algorithms-blog","type":"resource","name":"Stitch Fix Algorithms Blog","description":"Demand forecasting, inventory optimization, and personalization. Unique blend of fashion retail + serious data science.","category":"Routing & Logistics","url":"https://multithreaded.stitchfix.com/algorithms/blog/","difficulty":"intermediate","prerequisites":"python-pandas, machine-learning-basics, A-B-testing","topic_tags":"demand-forecasting, inventory-optimization, fashion-retail, personalization, industry-blog","summary":"Stitch Fix's engineering blog showcasing real-world data science applications in fashion retail. Features detailed case studies on demand forecasting, inventory management, and personalization algorithms used at scale. Provides practical insights into how a major fashion company applies data science to solve complex business problems.","use_cases":"Learning how to implement demand forecasting for retail inventory, Understanding personalization algorithms for recommendation systems","audience":"Junior-DS, Mid-DS"},{"id":"resource-meta-engineering---data-science","type":"resource","name":"Meta Engineering - Data Science","description":"Large-scale experimentation, ML infrastructure, and data discovery at Facebook scale. Posts on causal inference and data tools.","category":"Case Studies","url":"https://engineering.fb.com/","difficulty":"intermediate","prerequisites":"a-b-testing, python-pandas, sql-queries","topic_tags":"experimentation, causal-inference, ml-infrastructure, facebook, industry-case-studies","summary":"Meta's engineering blog covering large-scale experimentation and ML infrastructure used at Facebook. Provides insights into causal inference methods, data discovery tools, and operational challenges at billion-user scale. Valuable for understanding how tech giants implement data science in production.","use_cases":"Learning how to scale A/B testing infrastructure for millions of users, Understanding ML deployment patterns and data tooling at major tech companies","audience":"Mid-DS, Junior-DS"},{"id":"resource-instacart-tech-blog","type":"resource","name":"Instacart Tech Blog","description":"Marketplace balancing, delivery optimization, demand forecasting. Making on-demand grocery profitable.","category":"Marketplace Economics","url":"https://tech.instacart.com/","difficulty":"intermediate","prerequisites":"python-pandas, A-B-testing, basic-econometrics","topic_tags":"marketplace-design, demand-forecasting, delivery-optimization, on-demand-economics, industry-case-studies","summary":"Instacart's engineering blog covering technical approaches to marketplace economics challenges like balancing supply and demand, optimizing delivery routes, and forecasting grocery demand patterns. Posts blend engineering implementation details with economic insights from running a large-scale on-demand grocery platform. Valuable for understanding how marketplace theory translates to production systems at scale.","use_cases":"Learning how to implement demand forecasting models for perishable goods in a two-sided marketplace, Understanding technical approaches to delivery route optimization and driver matching algorithms","audience":"Mid-DS, Junior-DS"},{"id":"resource-stripe-engineering","type":"resource","name":"Stripe Engineering","description":"Payment economics, fraud detection ML, financial data infrastructure. Building economic infrastructure for the internet.","category":"Trust & Safety","url":"https://stripe.com/blog/engineering","difficulty":"intermediate","prerequisites":"python-scikit-learn, SQL-databases, statistical-testing","topic_tags":"payment-systems, fraud-detection, financial-infrastructure, industry-engineering, fintech","summary":"Stripe Engineering's blog covers payment economics, machine learning for fraud detection, and financial data infrastructure. The content focuses on real-world engineering challenges in building economic infrastructure for internet payments. Posts cover both technical implementations and business economics of payment systems.","use_cases":"Building fraud detection models for financial transactions, Designing scalable payment processing infrastructure","audience":"Mid-DS, Senior-DS"},{"id":"resource-amazon-science","type":"resource","name":"Amazon Science","description":"Research from Amazon's scientists. Causal inference, supply chain optimization, pricing, and forecasting.","category":"Routing & Logistics","url":"https://www.amazon.science/","difficulty":"intermediate","prerequisites":"python-scikit-learn, A/B-testing, linear-regression","topic_tags":"causal-inference, supply-chain, pricing-optimization, forecasting, industry-research","summary":"Amazon Science is the research publication platform showcasing cutting-edge work from Amazon's scientific teams. It covers applied research in causal inference for marketplace interventions, supply chain optimization algorithms, dynamic pricing strategies, and demand forecasting at scale. The content bridges academic rigor with practical implementation challenges faced in large-scale tech operations.","use_cases":"Learning how Amazon applies causal inference methods to measure the impact of product recommendations on sales, Understanding scalable forecasting techniques used for inventory management across millions of products","audience":"Mid-DS, Senior-DS"},{"id":"resource-mode-sql-tutorial","type":"resource","name":"Mode SQL Tutorial","description":"Interactive SQL lessons from basic to advanced. Great for learning JOINs, window functions, and subqueries with a real database.","category":"SQL","url":"https://mode.com/sql-tutorial/","difficulty":"beginner","prerequisites":"basic-database-concepts, data-filtering-logic","topic_tags":"SQL, database-queries, data-analysis, interactive-tutorial, window-functions","summary":"An interactive SQL tutorial covering fundamental to advanced database querying techniques using real datasets. Teaches essential skills like JOINs, window functions, and subqueries through hands-on exercises. Perfect for data scientists transitioning from other tools or learning SQL for the first time.","use_cases":"Junior data scientist needs to query company databases for analysis instead of relying on data exports, PhD student wants to learn SQL to access research datasets stored in university database systems","audience":"Junior-DS, Early-PhD"},{"id":"resource-sqlbolt","type":"resource","name":"SQLBolt","description":"Learn SQL with interactive exercises. No setup required \u2014 run queries right in the browser. Perfect for beginners.","category":"SQL","url":"https://sqlbolt.com/","difficulty":"beginner","prerequisites":"basic-programming-concepts, database-fundamentals","topic_tags":"SQL, interactive-learning, query-fundamentals, database-queries, beginner-tutorial","summary":"SQLBolt is an interactive SQL tutorial platform that teaches database querying through hands-on exercises directly in the browser. It's designed for complete beginners who need to learn SQL without any prior database experience or local setup. The platform covers fundamental SQL concepts from basic SELECT statements to more complex joins and data manipulation.","use_cases":"New data scientist needs to quickly learn SQL for querying company databases, Junior analyst preparing for technical interviews that include SQL questions","audience":"Junior-DS, Curious-browser"},{"id":"resource-leetcode-sql-50","type":"resource","name":"LeetCode SQL 50","description":"50 essential SQL problems to master for interviews. CTEs, window functions, and common patterns used at FAANG.","category":"SQL","url":"https://leetcode.com/studyplan/top-sql-50/","difficulty":"intermediate","prerequisites":"SQL-basic-queries, SQL-joins, SQL-aggregations","topic_tags":"SQL-practice, interview-preparation, window-functions, CTEs, FAANG-interviews","summary":"A curated collection of 50 SQL problems covering essential interview topics including CTEs, window functions, and common data manipulation patterns. Specifically designed to prepare candidates for technical interviews at major tech companies. Focuses on practical problem-solving skills that translate directly to on-the-job SQL work.","use_cases":"Preparing for data scientist or analyst interviews at tech companies, Practicing advanced SQL techniques before implementing complex analytics queries at work","audience":"Junior-DS, Mid-DS"},{"id":"resource-duckdb-documentation","type":"resource","name":"DuckDB Documentation","description":"Modern in-process SQL database. Runs on your laptop, reads Parquet directly, and is perfect for analytics. The new pandas killer.","category":"SQL","url":"https://duckdb.org/docs/","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics, command-line-interface","topic_tags":"duckdb, in-process-database, parquet, analytics, documentation","summary":"DuckDB is a lightweight, in-process SQL database optimized for analytical workloads that runs directly on your machine without requiring a server. It excels at reading columnar formats like Parquet and provides pandas-like performance with familiar SQL syntax. The documentation covers installation, querying, and integration with Python data science workflows.","use_cases":"Analyzing large CSV or Parquet files that don't fit well in pandas, Running SQL queries on local datasets without setting up PostgreSQL or other database servers","audience":"Junior-DS, Mid-DS"},{"id":"resource-neetcode","type":"resource","name":"NeetCode","description":"Curated LeetCode roadmap organized by pattern. Video explanations that actually make sense. The modern way to prep for coding interviews.","category":"SQL","url":"https://neetcode.io/","difficulty":"beginner","prerequisites":"basic-SQL-syntax, database-fundamentals","topic_tags":"coding-interviews, SQL-practice, pattern-recognition, video-tutorials","summary":"NeetCode provides a structured approach to mastering SQL coding interview questions through pattern-based learning and clear video explanations. It's specifically designed for data scientists and software engineers preparing for technical interviews at tech companies. The platform focuses on building intuition around common SQL problem patterns rather than just memorizing solutions.","use_cases":"Preparing for data scientist interviews at FAANG companies, Strengthening SQL skills for analytics engineer roles","audience":"Junior-DS, Mid-DS"},{"id":"resource-blind-75","type":"resource","name":"Blind 75","description":"The 75 most important LeetCode problems. Arrays, strings, trees, graphs, DP \u2014 if you can solve these, you can handle any interview.","category":"SQL","url":"https://www.techinterviewhandbook.org/grind75","difficulty":"intermediate","prerequisites":"python-basics, data-structures, algorithm-complexity","topic_tags":"leetcode, coding-interviews, algorithm-practice, data-structures, programming-problems","summary":"A curated collection of 75 essential LeetCode problems covering fundamental data structures and algorithms. This problem set is widely recognized as the gold standard for technical interview preparation at major tech companies. The problems span arrays, strings, trees, graphs, and dynamic programming with optimal difficulty progression.","use_cases":"Preparing for technical interviews at FAANG companies, Building foundational algorithm skills before starting data science role","audience":"Junior-DS, Mid-DS"},{"id":"resource-leetcode-patterns","type":"resource","name":"LeetCode Patterns","description":"14 patterns to solve any coding interview question. Two pointers, sliding window, BFS/DFS, and more \u2014 with Python templates.","category":"SQL","url":"https://seanprashad.com/leetcode-patterns/","difficulty":"beginner","prerequisites":"python-basics, data-structures, algorithm-fundamentals","topic_tags":"coding-interviews, algorithm-patterns, python-templates, leetcode-prep","summary":"A comprehensive study guide covering 14 essential coding patterns like two pointers, sliding window, and BFS/DFS with Python implementations. Designed to help data scientists and engineers systematically approach coding interview problems by recognizing common patterns. Provides reusable templates that can be adapted to solve hundreds of LeetCode-style questions.","use_cases":"Preparing for technical interviews at tech companies, Building algorithmic problem-solving skills for data engineering roles","audience":"Junior-DS, Curious-browser"},{"id":"resource-automate-the-boring-stuff-with-python","type":"resource","name":"Automate the Boring Stuff with Python","description":"The best free Python book for non-programmers. Web scraping, Excel automation, file management \u2014 practical skills for data work.","category":"Python","url":"https://automatetheboringstuff.com/","difficulty":"beginner","prerequisites":"basic-python-syntax, command-line-basics","topic_tags":"python-automation, web-scraping, excel-automation, file-management, beginner-programming","summary":"A comprehensive free online book that teaches Python programming through practical automation projects. Perfect for economists and data workers who want to automate repetitive tasks like web scraping, Excel manipulation, and file organization without deep programming background. Focuses on immediately useful skills rather than theoretical computer science concepts.","use_cases":"Automatically downloading and organizing research papers from multiple websites, Batch processing Excel files to extract specific data columns for analysis","audience":"Junior-DS, Curious-browser"},{"id":"resource-scrapy-documentation","type":"resource","name":"Scrapy Documentation","description":"The industrial-strength web scraping framework for Python. Build spiders, handle anti-bot measures, and scale to millions of pages.","category":"Python","url":"https://docs.scrapy.org/","difficulty":"intermediate","prerequisites":"python-requests, html-css-selectors, xpath-expressions","topic_tags":"web-scraping, data-collection, python-framework, automation, spider-crawling","summary":"Scrapy is a comprehensive Python framework for building web scrapers that can handle complex crawling tasks at scale. It provides built-in support for handling JavaScript, cookies, user agents, and rate limiting to avoid detection. Data scientists and researchers use it to systematically collect large datasets from websites for analysis and model training.","use_cases":"Collecting product pricing data from e-commerce sites for competitive analysis, Scraping job postings from multiple career sites to analyze labor market trends","audience":"Junior-DS, Mid-DS"},{"id":"resource-real-python:-web-scraping","type":"resource","name":"Real Python: Web Scraping","description":"Practical guide to scraping with BeautifulSoup and requests. Parse HTML, handle pagination, and extract structured data.","category":"Python","url":"https://realpython.com/beautiful-soup-web-scraper-python/","difficulty":"beginner","prerequisites":"python-basics, HTML-fundamentals, HTTP-requests","topic_tags":"web-scraping, beautifulsoup, data-extraction, python-tutorial, automation","summary":"A comprehensive tutorial on web scraping using Python's BeautifulSoup and requests libraries. Covers HTML parsing, handling different webpage structures, and extracting structured data from websites. Perfect for data scientists who need to collect data from web sources for analysis projects.","use_cases":"Collecting product prices from e-commerce sites for market analysis, Extracting job postings from career websites for labor market research","audience":"Junior-DS, Curious-browser"},{"id":"resource-python-for-econometrics","type":"resource","name":"Python for Econometrics","description":"Kevin Sheppard's comprehensive intro for researchers. NumPy, pandas, statsmodels, and econometric applications.","category":"Python","url":"https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/","difficulty":"beginner","prerequisites":"python-basics, basic-statistics","topic_tags":"econometrics, python-tutorial, data-analysis, statsmodels, research-methods","summary":"Kevin Sheppard's comprehensive textbook introducing Python programming for econometric analysis and empirical research. Covers essential data science libraries like NumPy, pandas, and statsmodels with focus on economic applications. Ideal for researchers transitioning from Stata/R to Python or learning quantitative methods.","use_cases":"PhD student learning to implement regression analysis and time series models in Python, Economics researcher switching from Stata to Python for empirical work","audience":"Early-PhD, Junior-DS"},{"id":"resource-statistical-rethinking","type":"resource","name":"Statistical Rethinking","description":"Richard McElreath's Bayesian approach to statistics. PyMC3 translations available. The book that changed how many think about inference.","category":"Bayesian Methods","url":"https://xcelab.net/rm/statistical-rethinking/","difficulty":"intermediate","prerequisites":"basic-probability, linear-regression, python-programming","topic_tags":"bayesian-inference, statistical-modeling, causal-inference, textbook, pymc","summary":"A comprehensive introduction to Bayesian statistics that emphasizes building models from first principles rather than memorizing formulas. McElreath uses practical examples and clear explanations to teach concepts like prior specification, posterior sampling, and model comparison. The book includes companion code in R and community-created PyMC implementations.","use_cases":"Building hierarchical models for user behavior analysis with uncertainty quantification, Running A/B tests with proper prior information and credible intervals instead of p-values","audience":"Early-PhD, Mid-DS"},{"id":"resource-adam-fishman-newsletter","type":"resource","name":"Adam Fishman Newsletter","description":"Ex-Patreon/Reforge. Growth loops, product strategy, and how to structure product analytics.","category":"Frameworks & Strategy","url":"https://www.fishmanafnewsletter.com/","difficulty":"intermediate","prerequisites":"product-metrics, A-B-testing, cohort-analysis","topic_tags":"growth-strategy, product-analytics, business-metrics, newsletter, case-studies","summary":"Newsletter by ex-Patreon/Reforge Adam Fishman covering growth loops, product strategy, and analytics structuring. Provides practical frameworks and real-world examples for product-driven growth. Ideal for data scientists and product managers working on user acquisition, retention, and monetization strategies.","use_cases":"Designing analytics infrastructure to track product-led growth metrics and user lifecycle stages, Implementing growth loop frameworks to optimize user acquisition and retention funnels","audience":"Mid-DS, Junior-DS"},{"id":"resource-sequoia:-data-informed-product-building","type":"resource","name":"Sequoia: Data-Informed Product Building","description":"Metric hierarchies, North Star metrics, and building data-informed products. The definitive framework for product metrics.","category":"Metrics & Measurement","url":"https://medium.com/sequoia-capital/data-informed-product-building-1e509a5c4112","difficulty":"beginner","prerequisites":"basic-statistics, product-analytics","topic_tags":"north-star-metrics, product-metrics, data-driven-decisions, metric-hierarchies, framework","summary":"Sequoia's comprehensive framework for building data-informed products through structured metric hierarchies and North Star metrics. This guide provides practical approaches for product teams to establish meaningful measurement systems that drive decision-making. It covers how to identify, prioritize, and implement metrics that align with business objectives.","use_cases":"Setting up a metric framework for a new product launch, Restructuring existing product analytics to focus on key business drivers","audience":"Junior-DS, Mid-DS"},{"id":"resource-convex-optimization-(boyd-&-vandenberghe)","type":"resource","name":"Convex Optimization (Boyd & Vandenberghe)","description":"The bible of convex optimization \u2014 free online, universally cited. Covers LP, QP, SDP, and more.","category":"Convex Optimization","url":"https://web.stanford.edu/~boyd/cvxbook/","difficulty":"intermediate","prerequisites":"linear-algebra, multivariable-calculus, python-numpy","topic_tags":"convex-optimization, mathematical-optimization, linear-programming, quadratic-programming, textbook","summary":"The definitive textbook on convex optimization theory and algorithms by Boyd and Vandenberghe, available free online. Covers fundamental concepts like linear programming, quadratic programming, and semidefinite programming with rigorous mathematical treatment. Essential reading for anyone working on optimization problems in machine learning, operations research, or quantitative analysis.","use_cases":"Implementing portfolio optimization algorithms with quadratic constraints, Designing machine learning models with convex loss functions and regularization","audience":"Early-PhD, Senior-DS"},{"id":"resource-stanford-ee364a-(youtube)","type":"resource","name":"Stanford EE364A (YouTube)","description":"Boyd's legendary lectures on convex optimization. The gold standard for learning optimization theory.","category":"Convex Optimization","url":"https://www.youtube.com/playlist?list=PL3940DD956CDF0622","difficulty":"intermediate","prerequisites":"linear-algebra, multivariable-calculus, python-numpy","topic_tags":"convex-optimization, mathematical-optimization, video-lectures, stanford, theory","summary":"Stephen Boyd's comprehensive video lecture series covering the fundamentals of convex optimization theory and applications. This Stanford course is widely regarded as the definitive introduction to optimization methods used throughout machine learning and operations research. The lectures build from basic convex analysis to advanced algorithms like interior-point methods.","use_cases":"Learning optimization theory before implementing ML algorithms like SVM or logistic regression, Understanding the mathematical foundations behind hyperparameter tuning and model training","audience":"Early-PhD, Mid-DS"},{"id":"resource-modeling-discrete-optimization-(coursera)","type":"resource","name":"Modeling Discrete Optimization (Coursera)","description":"University of Melbourne's course on constraint programming, local search, and MIP. Covers MiniZinc modeling language.","category":"Convex Optimization","url":"https://www.coursera.org/learn/basic-modeling","difficulty":"intermediate","prerequisites":"linear-algebra, python-programming, basic-optimization","topic_tags":"constraint-programming, mixed-integer-programming, local-search, minizinc, discrete-optimization","summary":"University of Melbourne's comprehensive course teaching discrete optimization through constraint programming, local search algorithms, and mixed-integer programming. Students learn the MiniZinc modeling language to solve complex combinatorial problems. Ideal for data scientists who need to tackle scheduling, resource allocation, and other discrete decision problems.","use_cases":"Optimizing delivery routes and scheduling for logistics operations, Resource allocation and task assignment in project management systems","audience":"Mid-DS, Early-PhD"},{"id":"resource-cvxpy-short-course","type":"resource","name":"CVXPY Short Course","description":"Hands-on convex optimization in Python. Learn to model and solve real problems with CVXPY.","category":"Convex Optimization","url":"https://www.cvxgrp.org/cvx_short_course/docs/index.html","difficulty":"intermediate","prerequisites":"python-numpy, linear-algebra, basic-optimization-theory","topic_tags":"convex-optimization, python-programming, mathematical-modeling, operations-research, hands-on-tutorial","summary":"A practical tutorial for learning convex optimization using the CVXPY Python library. Covers how to formulate and solve real-world optimization problems with hands-on examples. Perfect for data scientists who need to move beyond basic modeling to solve resource allocation, portfolio optimization, and constraint satisfaction problems.","use_cases":"optimizing ad budget allocation across channels with budget constraints, portfolio optimization with risk constraints and transaction costs","audience":"Junior-DS, Mid-DS"},{"id":"resource-walmart-global-tech","type":"resource","name":"Walmart Global Tech","description":"AI-driven retail tech, supply chain optimization, agentic AI, and developer experience. Posts on LLMs for product catalogs, delivery optimization, and cross-lingual search.","category":"Routing & Logistics","url":"https://tech.walmart.com/","difficulty":"intermediate","prerequisites":"python-scikit-learn, SQL-joins, A-B-testing","topic_tags":"retail-analytics, supply-chain, LLM-applications, industry-blog, logistics-optimization","summary":"Walmart Global Tech's blog showcasing AI applications in retail operations, from LLM-powered product catalogs to delivery route optimization. Features real-world case studies and technical insights from one of the world's largest retailers implementing ML at scale. Covers both customer-facing AI features and backend supply chain automation.","use_cases":"Learning how major retailers apply LLMs to product search and recommendation systems, Understanding supply chain optimization techniques for last-mile delivery and inventory management","audience":"Junior-DS, Mid-DS"},{"id":"resource-coursera-pricing-strategy-optimization-(uva-bcg)","type":"resource","name":"Coursera Pricing Strategy Optimization (UVA/BCG)","description":"Price elasticity, WTP estimation, segmentation \u2014 free to audit","category":"Pricing & Revenue","url":"https://www.coursera.org/specializations/uva-darden-bcg-pricing-strategy","difficulty":"beginner","prerequisites":"basic-statistics, excel-or-spreadsheets","topic_tags":"price-elasticity, willingness-to-pay, customer-segmentation, revenue-optimization, online-course","summary":"A foundational course covering price elasticity estimation, willingness-to-pay analysis, and customer segmentation for pricing decisions. Developed by UVA and BCG, it provides practical frameworks for revenue optimization without requiring advanced technical skills. Ideal for building core pricing strategy knowledge applicable across tech companies.","use_cases":"Setting optimal subscription prices for a SaaS product launch, Designing tiered pricing structure for an e-commerce marketplace","audience":"Junior-DS, Curious-browser"},{"id":"resource-chargebee:-saas-pricing-models-guide","type":"resource","name":"Chargebee: SaaS Pricing Models Guide","description":"Usage-based pricing, value metrics, packaging strategies \u2014 free","category":"Pricing & Revenue","url":"https://www.chargebee.com/resources/guides/saas-pricing-models-guide/","difficulty":"beginner","prerequisites":"basic-economics, business-metrics","topic_tags":"saas-pricing, revenue-models, pricing-strategy, value-metrics, subscription-business","summary":"A comprehensive guide covering different SaaS pricing models including usage-based pricing, value metrics, and packaging strategies. Written by Chargebee for product managers and business teams looking to optimize their pricing approach. Provides practical frameworks for choosing and implementing pricing models in subscription businesses.","use_cases":"Setting up pricing for a new SaaS product launch, Evaluating whether to switch from flat-rate to usage-based pricing","audience":"Junior-DS, Curious-browser"},{"id":"resource-monetizing-innovation-(ramanujam)","type":"resource","name":"Monetizing Innovation (Ramanujam)","description":"The industry bible \u2014 design products around price, not vice versa","category":"Pricing & Revenue","url":"https://www.simon-kucher.com/en/insights/monetizing-innovation","difficulty":"beginner","prerequisites":"basic-economics, product-management-fundamentals","topic_tags":"pricing-strategy, product-monetization, value-based-pricing, revenue-optimization, business-strategy","summary":"A comprehensive guide to pricing strategy that advocates for designing products around willingness-to-pay rather than cost-plus pricing. Written for product managers and business leaders, it provides frameworks for understanding customer value perception and implementing pricing strategies that maximize revenue. Essential reading for anyone involved in product pricing decisions at tech companies.","use_cases":"Product manager launching a new SaaS feature needs to determine optimal pricing tiers, Business analyst evaluating whether to bundle services or price them separately","audience":"Junior-DS, Curious-browser"},{"id":"resource-openview-saas-pricing-guide","type":"resource","name":"OpenView SaaS Pricing Guide","description":"Free playbooks on usage-based pricing","category":"Pricing & Revenue","url":"https://openviewpartners.com/blog/saas-pricing-resource-guide/","difficulty":"beginner","prerequisites":"basic-economics, revenue-recognition","topic_tags":"usage-based-pricing, saas-monetization, pricing-strategy, revenue-optimization, playbook","summary":"OpenView's comprehensive guide provides practical playbooks and frameworks for implementing usage-based pricing models in SaaS businesses. The resource covers pricing strategy fundamentals, implementation tactics, and real-world case studies from successful companies. It's designed for practitioners looking to transition from traditional subscription models or optimize existing usage-based approaches.","use_cases":"Product manager designing pricing tiers for a new API service, Revenue team evaluating switch from flat subscription to consumption-based model","audience":"Junior-DS, Mid-DS"},{"id":"resource-lenny's-podcast:-madhavan-ramanujam","type":"resource","name":"Lenny's Podcast: Madhavan Ramanujam","description":"90 minutes on WTP conversations and behavioral pricing","category":"Pricing & Revenue","url":"https://www.lennyspodcast.com/the-art-and-science-of-pricing-madhavan-ramanujam-simon-kucher/","difficulty":"intermediate","prerequisites":"price-elasticity, conjoint-analysis, consumer-surveys","topic_tags":"willingness-to-pay, behavioral-pricing, monetization-strategy, podcast-interview","summary":"A 90-minute podcast interview with Madhavan Ramanujam discussing willingness-to-pay research methods and behavioral pricing strategies. Covers practical approaches to understanding customer price sensitivity and implementing pricing decisions based on behavioral insights. Valuable for practitioners working on product monetization and pricing optimization.","use_cases":"Designing pricing experiments to test customer willingness-to-pay for new product features, Developing behavioral pricing strategies for subscription products or marketplace platforms","audience":"Mid-DS, Curious-browser"},{"id":"resource-display-advertising-with-real-time-bidding","type":"resource","name":"Display Advertising with Real-Time Bidding","description":"Free comprehensive RTB coverage on arXiv","category":"Ads & Attribution","url":"https://arxiv.org/abs/1610.03013","difficulty":"intermediate","prerequisites":"auction-theory, game-theory, python-optimization","topic_tags":"real-time-bidding, programmatic-advertising, auction-mechanisms, computational-advertising","summary":"Comprehensive academic paper covering real-time bidding systems in display advertising, including auction mechanisms, bidding strategies, and market dynamics. Provides theoretical foundations and practical insights for understanding how programmatic ad buying works at scale. Essential reading for anyone working on advertising platforms or auction-based marketplaces.","use_cases":"Building bidding algorithms for demand-side advertising platforms, Designing auction mechanisms for ad exchanges and supply-side platforms","audience":"Mid-DS, Senior-DS"},{"id":"resource-gsp-auction-paper-(edelman-et-al.,-aer-2007)","type":"resource","name":"GSP Auction Paper (Edelman et al., AER 2007)","description":"Foundational paper on search advertising auctions","category":"Ads & Attribution","url":"https://www.benedelman.org/publications/gsp-060801.pdf","difficulty":"intermediate","prerequisites":"game-theory-basics, microeconomics-fundamentals, Nash-equilibrium","topic_tags":"generalized-second-price, search-advertising, auction-theory, mechanism-design, sponsored-search","summary":"Seminal paper analyzing the Generalized Second Price (GSP) auction mechanism used by Google AdWords and other search engines. Demonstrates that GSP auctions have multiple equilibria and are not truthful, unlike Vickrey-Clarke-Groves auctions. Essential reading for understanding how billions of dollars in search advertising are allocated and priced.","use_cases":"Designing auction mechanisms for online advertising platforms, Understanding bidding strategies and equilibrium outcomes in search advertising","audience":"Early-PhD, Senior-DS"},{"id":"resource-adkdd-workshop-papers","type":"resource","name":"AdKDD Workshop Papers","description":"Applied research from Google, Meta, Amazon","category":"Ads & Attribution","url":"https://www.adkdd.org/","difficulty":"advanced","prerequisites":"auction-theory, causal-inference, machine-learning-systems","topic_tags":"ad-auctions, attribution-modeling, computational-advertising, marketplace-design, applied-research","summary":"Collection of cutting-edge research papers from industry practitioners at major tech companies focusing on advertising technology and attribution challenges. These papers bridge academic theory with real-world implementation constraints at scale. Covers topics like auction mechanisms, attribution modeling, and marketplace optimization with billions of users.","use_cases":"Understanding how Google/Meta solve attribution problems at scale, Learning state-of-the-art auction design techniques used in production","audience":"Senior-DS, Early-PhD"},{"id":"resource-pymc-marketing-clv-quickstart","type":"resource","name":"PyMC-Marketing CLV Quickstart","description":"CLV basics, RFM analysis, BG/NBD models \u2014 free official docs","category":"Bayesian Methods","url":"https://www.pymc-marketing.io/en/latest/notebooks/clv/clv_quickstart.html","difficulty":"intermediate","prerequisites":"python-pandas, bayesian-statistics, customer-analytics","topic_tags":"customer-lifetime-value, bayesian-modeling, rfm-analysis, bg-nbd-model, pymc","summary":"Official PyMC-Marketing documentation covering customer lifetime value (CLV) fundamentals, RFM segmentation, and implementation of Beta-Geometric/Negative Binomial Distribution models. Provides hands-on tutorial for applying Bayesian methods to customer behavior modeling and revenue forecasting. Ideal for data scientists wanting to implement probabilistic CLV models in production.","use_cases":"Predicting future revenue from existing customers for subscription businesses, Segmenting customers by purchase behavior to optimize marketing spend allocation","audience":"Mid-DS, Junior-DS"},{"id":"resource-pymc-marketing-documentation","type":"resource","name":"PyMC-Marketing Documentation","description":"BG/NBD and Gamma-Gamma CLV tutorials","category":"Bayesian Methods","url":"https://www.pymc-marketing.io/en/stable/","difficulty":"intermediate","prerequisites":"python-programming, bayesian-inference, customer-segmentation","topic_tags":"customer-lifetime-value, bayesian-modeling, marketing-analytics, pymc, clv-modeling","summary":"PyMC-Marketing documentation provides comprehensive tutorials for implementing BG/NBD (Beta-Geometric/Negative Binomial Distribution) and Gamma-Gamma models for customer lifetime value analysis. These Bayesian approaches help businesses predict customer purchase behavior and monetary value over time. The documentation includes practical examples and code implementations for marketers and data scientists working on customer analytics.","use_cases":"E-commerce company wants to predict which customers will make repeat purchases and their expected value, SaaS business needs to model customer churn probability and optimize retention spending","audience":"Mid-DS, Junior-DS"},{"id":"resource-google-analytics-for-marketing","type":"resource","name":"Google Analytics for Marketing","description":"Free analytics for marketing \u2014 official Google tutorials","category":"Frameworks & Strategy","url":"https://skillshop.exceedlms.com/student/path/508845-google-analytics-certification","difficulty":"beginner","prerequisites":"web-analytics-basics, digital-marketing-fundamentals","topic_tags":"google-analytics, web-analytics, marketing-attribution, conversion-tracking, tutorial","summary":"Official Google tutorials covering Google Analytics fundamentals for marketing applications. Teaches how to set up tracking, measure website performance, and analyze user behavior to optimize marketing campaigns. Ideal for practitioners new to web analytics who need to understand customer acquisition and conversion metrics.","use_cases":"Setting up conversion tracking for e-commerce campaigns to measure ROI, Analyzing user journey data to optimize marketing funnel performance","audience":"Junior-DS, Curious-browser"},{"id":"resource-bruce-hardie's-clv-papers","type":"resource","name":"Bruce Hardie's CLV Papers","description":"Mathematical foundations of CLV models","category":"Growth & Retention","url":"https://www.brucehardie.com/","difficulty":"advanced","prerequisites":"probability-theory, maximum-likelihood-estimation, beta-geometric-models","topic_tags":"customer-lifetime-value, probabilistic-models, retention-modeling, clv-mathematics, academic-papers","summary":"Bruce Hardie's seminal academic papers establishing the mathematical foundations for customer lifetime value modeling, particularly the BG/NBD and Pareto/NBD models. These papers provide rigorous probabilistic frameworks for predicting customer behavior and calculating CLV in contractual and non-contractual settings. Essential reading for understanding the theoretical underpinnings of modern CLV approaches.","use_cases":"Building custom CLV models from first principles for unique business contexts, Academic research extending or validating probabilistic customer behavior models","audience":"Senior-DS, Early-PhD"},{"id":"resource-mit-15.s08-fintech-(gary-gensler)","type":"resource","name":"MIT 15.S08 FinTech (Gary Gensler)","description":"12 lectures from former SEC Chair on AI in finance, risk, and compliance \u2014 free","category":"Case Studies","url":"https://ocw.mit.edu/courses/15-s08-fintech-shaping-the-financial-world-spring-2020/","difficulty":"intermediate","prerequisites":"basic-finance, regulatory-frameworks, python-basics","topic_tags":"fintech, financial-regulation, AI-governance, compliance, risk-management","summary":"12-lecture course from former SEC Chair Gary Gensler covering AI applications in finance, regulatory compliance, and risk management. Provides regulatory perspective on fintech innovations including machine learning, blockchain, and algorithmic trading. Ideal for understanding how financial technology intersects with policy and compliance requirements.","use_cases":"Understanding regulatory constraints when building ML models for financial products, Learning compliance requirements for AI-driven trading or lending algorithms","audience":"Mid-DS, Curious-browser"},{"id":"resource-stripe:-ml-for-fraud-protection","type":"resource","name":"Stripe: ML for Fraud Protection","description":"The definitive intro: features, precision-recall tradeoffs, break-even calculations","category":"Trust & Safety","url":"https://stripe.com/guides/primer-on-machine-learning-for-fraud-protection","difficulty":"intermediate","prerequisites":"supervised-learning, classification-metrics, feature-engineering","topic_tags":"fraud-detection, precision-recall, feature-selection, break-even-analysis, payments","summary":"Stripe's comprehensive guide to building machine learning systems for fraud detection in payment processing. Covers practical feature engineering, model evaluation using precision-recall curves, and economic break-even analysis to optimize fraud prevention systems. Essential reading for understanding real-world ML applications in fintech trust and safety.","use_cases":"Building fraud detection models for payment processors or e-commerce platforms, Optimizing precision-recall tradeoffs in high-stakes classification problems with financial impact","audience":"Mid-DS, Junior-DS"},{"id":"resource-fraud-detection-handbook-(ulb)","type":"resource","name":"Fraud Detection Handbook (ULB)","description":"From the team that created the Kaggle dataset \u2014 rigorous methodology","category":"Trust & Safety","url":"https://fraud-detection-handbook.github.io/fraud-detection-handbook/","difficulty":"intermediate","prerequisites":"python-scikit-learn, classification-algorithms, imbalanced-datasets","topic_tags":"fraud-detection, anomaly-detection, imbalanced-learning, financial-risk, methodology","summary":"A comprehensive handbook on fraud detection methodologies from the University of Brussels team behind the popular Kaggle credit card fraud dataset. Covers practical implementation of machine learning techniques for fraud detection, with emphasis on handling class imbalance and evaluation metrics specific to fraud use cases. Provides rigorous statistical approaches and real-world case studies for building production fraud detection systems.","use_cases":"Building credit card transaction fraud detection system for fintech company, Implementing real-time anomaly detection for e-commerce payment processing","audience":"Mid-DS, Junior-DS"},{"id":"resource-stripe:-how-we-built-radar","type":"resource","name":"Stripe: How We Built Radar","description":"XGBoost\u2192DNN migration, 85% training time reduction","category":"Case Studies","url":"https://stripe.com/blog/how-we-built-it-stripe-radar","difficulty":"intermediate","prerequisites":"xgboost, neural-networks, model-deployment","topic_tags":"fraud-detection, model-migration, xgboost, deep-learning, fintech","summary":"Stripe's case study on migrating their fraud detection system Radar from XGBoost to deep neural networks, achieving 85% reduction in training time while maintaining performance. The post details the technical challenges, architectural decisions, and lessons learned during this large-scale ML system transition at a major fintech company.","use_cases":"Migrating legacy ML models to more efficient architectures in production systems, Optimizing training performance for large-scale fraud detection or risk scoring models","audience":"Mid-DS, Senior-DS"},{"id":"resource-paypal:-graph-database-for-fraud","type":"resource","name":"PayPal: Graph Database for Fraud","description":"Real-time fraud ring detection","category":"Trust & Safety","url":"https://medium.com/paypal-tech/how-paypal-uses-real-time-graph-database-and-graph-analysis-to-fight-fraud-96a2b918619a","difficulty":"intermediate","prerequisites":"graph-databases, neo4j, fraud-detection-basics","topic_tags":"graph-databases, fraud-detection, real-time-systems, paypal, trust-safety","summary":"PayPal's implementation of graph databases for detecting fraud rings in real-time by analyzing relationships between users, devices, and transactions. The system identifies suspicious patterns and connections that traditional rule-based systems might miss. Demonstrates practical application of graph technology at scale for financial crime prevention.","use_cases":"Building fraud detection systems that identify coordinated attacks across multiple accounts, Implementing real-time risk scoring based on network effects and user relationships","audience":"Mid-DS, Senior-DS"},{"id":"resource-linkedin:-defending-against-abuse-at-scale","type":"resource","name":"LinkedIn: Defending Against Abuse at Scale","description":"4M+ TPS, multi-layer defense architecture","category":"Trust & Safety","url":"https://engineering.linkedin.com/blog/2018/12/defending-against-abuse-at-linkedins-scale","difficulty":"intermediate","prerequisites":"machine-learning-classification, system-design-fundamentals, python-scikit-learn","topic_tags":"abuse-detection, fraud-prevention, system-architecture, real-time-ml, content-moderation","summary":"LinkedIn's technical deep-dive into their multi-layered abuse detection system that processes over 4 million transactions per second. The post covers their defense architecture combining rule-based systems, machine learning models, and real-time processing to combat spam, fake accounts, and malicious behavior. Essential reading for data scientists working on trust and safety problems at scale.","use_cases":"Building fraud detection systems for social platforms or marketplaces, Designing real-time content moderation pipelines for user-generated content","audience":"Mid-DS, Senior-DS"},{"id":"resource-meta:-few-shot-learner-for-harmful-content","type":"resource","name":"Meta: Few-Shot Learner for Harmful Content","description":"Adapts to new threats in weeks, 100+ languages","category":"Case Studies","url":"https://about.fb.com/news/2021/12/metas-new-ai-system-tackles-harmful-content/","difficulty":"intermediate","prerequisites":"few-shot-learning, content-moderation-systems, transformer-models","topic_tags":"few-shot-learning, content-moderation, multilingual-ml, meta-research","summary":"Meta's approach to building content moderation systems that can quickly adapt to new types of harmful content using few-shot learning techniques. The system works across 100+ languages and can be deployed within weeks rather than months when new threats emerge. This represents a practical application of few-shot learning at massive scale in production environments.","use_cases":"Rapidly deploying models to detect emerging harmful content trends like new harassment patterns or misinformation tactics, Scaling content moderation to new languages or regions without extensive labeled training data","audience":"Mid-DS, Senior-DS"},{"id":"resource-netflix:-rad-outlier-detection","type":"resource","name":"Netflix: RAD Outlier Detection","description":"Robust PCA at terabyte scale","category":"Trust & Safety","url":"https://netflixtechblog.com/rad-outlier-detection-on-big-data-d6b0ff32fb44","difficulty":"intermediate","prerequisites":"principal-component-analysis, python-sklearn, distributed-computing","topic_tags":"robust-pca, outlier-detection, scalable-ml, anomaly-detection, netflix-engineering","summary":"Netflix's Robust Anomaly Detection (RAD) system uses robust Principal Component Analysis to identify outliers in massive datasets at terabyte scale. The system handles high-dimensional data with noise and missing values to detect anomalous patterns in streaming behavior and content metrics. It's designed for production environments requiring both accuracy and computational efficiency.","use_cases":"detecting fraudulent account activity in streaming platform user behavior, identifying anomalous content performance metrics across millions of titles","audience":"Mid-DS, Senior-DS"},{"id":"resource-google-research:-self-supervised-anomaly-detection","type":"resource","name":"Google Research: Self-Supervised Anomaly Detection","description":"Contrastive learning, CutPaste algorithm","category":"Trust & Safety","url":"https://ai.googleblog.com/2021/09/discovering-anomalous-data-with-self.html","difficulty":"intermediate","prerequisites":"pytorch-training, computer-vision, contrastive-learning","topic_tags":"self-supervised-learning, anomaly-detection, contrastive-learning, cutpaste-algorithm, trust-safety","summary":"Google Research's approach to anomaly detection using self-supervised learning, specifically the CutPaste algorithm that learns normal patterns through contrastive learning. The method trains models to distinguish between normal samples and artificially corrupted versions, enabling detection of anomalies without labeled defect data. Particularly useful for trust and safety applications where anomalous content or behavior needs to be identified.","use_cases":"detecting fraudulent user accounts or suspicious activity patterns on platforms, identifying defective products or quality issues in manufacturing without labeled defect examples","audience":"Mid-DS, Senior-DS"},{"id":"resource-stanford-fintech-lab:-rob-wang-(block)","type":"resource","name":"Stanford FinTech Lab: Rob Wang (Block)","description":"Industry talk on fraud ML tradeoffs","category":"Trust & Safety","url":"https://fintech.stanford.edu/events/aftlab-seminars/rob-wang-square-machine-learning-financial-fraud-detection","difficulty":"intermediate","prerequisites":"scikit-learn, precision-recall-curves, feature-engineering","topic_tags":"fraud-detection, ml-tradeoffs, fintech, industry-talk, trust-safety","summary":"Industry talk by Rob Wang from Block discussing machine learning tradeoffs in fraud detection systems. Covers practical challenges of balancing false positives vs false negatives in production fraud models. Provides real-world insights from Block's experience building scalable fraud prevention systems.","use_cases":"Building fraud detection models for payment platforms, Optimizing precision-recall tradeoffs in financial risk systems","audience":"Mid-DS, Junior-DS"},{"id":"resource-ieee-cis-fraud:-1st-place-solution-(chris-deotte)","type":"resource","name":"IEEE-CIS Fraud: 1st Place Solution (Chris Deotte)","description":"Kaggle Grandmaster, 262 features, RAPIDS GPU","category":"Trust & Safety","url":"https://developer.nvidia.com/blog/leveraging-machine-learning-to-detect-fraud-tips-to-developing-a-winning-kaggle-solution/","difficulty":"intermediate","prerequisites":"python-pandas, xgboost, feature-engineering","topic_tags":"fraud-detection, kaggle-competition, feature-engineering, gpu-acceleration, RAPIDS","summary":"A detailed walkthrough of the winning solution for the IEEE-CIS Fraud Detection Kaggle competition by Chris Deotte, featuring 262 engineered features and RAPIDS GPU acceleration. The solution demonstrates advanced feature engineering techniques and optimization strategies for large-scale fraud detection problems. Provides practical insights into competition-winning approaches that can be applied to real-world fraud detection systems.","use_cases":"Building fraud detection models for payment processors or financial institutions, Learning advanced feature engineering techniques for tabular data competitions","audience":"Mid-DS, Senior-DS"},{"id":"resource-scikit-learn:-outlier-detection","type":"resource","name":"scikit-learn: Outlier Detection","description":"Isolation Forest, LOF, One-Class SVM comparison","category":"Trust & Safety","url":"https://scikit-learn.org/stable/modules/outlier_detection.html","difficulty":"intermediate","prerequisites":"python-scikit-learn, unsupervised-learning, pandas-dataframes","topic_tags":"outlier-detection, anomaly-detection, isolation-forest, one-class-svm, trust-safety","summary":"This resource compares three popular scikit-learn outlier detection methods: Isolation Forest, Local Outlier Factor (LOF), and One-Class SVM. It's designed for data scientists working on trust and safety problems who need to identify anomalous behavior in their datasets. The comparison helps practitioners choose the right algorithm based on their specific data characteristics and performance requirements.","use_cases":"detecting fraudulent user accounts or transactions in marketplace platforms, identifying spam content or abusive behavior in social media feeds","audience":"Mid-DS, Junior-DS"},{"id":"resource-music-tomorrow:-spotify-deep-dive","type":"resource","name":"Music Tomorrow: Spotify Deep Dive","description":"Audio features, accessible depth","category":"Case Studies","url":"https://www.music-tomorrow.com/blog/how-spotify-recommendation-system-works-complete-guide","difficulty":"beginner","prerequisites":"python-pandas, basic-ML-concepts, data-visualization","topic_tags":"spotify, audio-features, music-analytics, recommendation-systems, case-study","summary":"A deep dive case study exploring Spotify's use of audio features and data science techniques in music recommendation and analysis. Provides accessible explanations of how music streaming platforms leverage machine learning and audio data. Ideal for understanding real-world applications of data science in the entertainment industry.","use_cases":"Learning how recommendation systems work in practice at major tech companies, Understanding audio feature engineering for music analysis projects","audience":"Junior-DS, Curious-browser"},{"id":"resource-georgia-tech-(ratliff):-10-rules-for-supply-chain-optimization","type":"resource","name":"Georgia Tech (Ratliff): 10 Rules for Supply Chain Optimization","description":"Practitioner checklist for scoping, data readiness, constraints, deployment \u2014 free PDF","category":"Routing & Logistics","url":"https://www.scl.gatech.edu/sites/default/files/downloads/gtscl-10_rules_supply_chain_logistics_optimization_2.pdf","difficulty":"beginner","prerequisites":"linear-programming, python-pandas, SQL-joins","topic_tags":"supply-chain, optimization-checklist, practitioner-guide, deployment, scoping","summary":"A practical checklist from Georgia Tech providing 10 essential rules for successfully implementing supply chain optimization projects. Covers project scoping, data preparation, constraint identification, and deployment considerations for practitioners new to optimization work. Serves as a field guide to avoid common pitfalls when moving from theoretical optimization to real-world supply chain problems.","use_cases":"Setting up a warehouse routing optimization project and need to validate data quality and business constraints, Leading a supply chain cost reduction initiative and want to ensure proper project scoping before building models","audience":"Junior-DS, Mid-DS"},{"id":"resource-google-or-tools:-vrp-+-vrptw-tutorial","type":"resource","name":"Google OR-Tools: VRP + VRPTW Tutorial","description":"Core logistics vocabulary (depot, fleet, constraints) with working Python baseline","category":"Linear Programming","url":"https://developers.google.com/optimization/routing/vrp","difficulty":"beginner","prerequisites":"python-basics, graph-theory-fundamentals","topic_tags":"vehicle-routing, constraint-programming, logistics-optimization, OR-tools, tutorial","summary":"A hands-on tutorial covering Google OR-Tools for solving Vehicle Routing Problems (VRP) and Vehicle Routing Problems with Time Windows (VRPTW). Introduces core logistics concepts like depots, fleets, and routing constraints with practical Python implementations. Perfect for data scientists entering logistics optimization or operations research applications.","use_cases":"Optimizing delivery routes for e-commerce last-mile logistics, Scheduling service technician visits with time window constraints","audience":"Junior-DS, Curious-browser"},{"id":"resource-doordash:-ml-+-optimization-for-dispatch","type":"resource","name":"DoorDash: ML + Optimization for Dispatch","description":"Clearest 'real system' explanation: predictions feed optimizer, then simulation closes the loop","category":"Routing & Logistics","url":"https://careersatdoordash.com/blog/using-ml-and-optimization-to-solve-doordashs-dispatch-problem/","difficulty":"intermediate","prerequisites":"linear-programming, python-optimization, discrete-choice-models","topic_tags":"dispatch-optimization, real-time-matching, simulation, delivery-logistics, blog-post","summary":"DoorDash's technical blog post explaining how machine learning predictions feed into optimization algorithms for driver dispatch, with simulation validating the complete system. Provides rare insight into how prediction and optimization components work together in a production logistics system. Ideal for understanding the ML-to-optimization pipeline in real-time matching problems.","use_cases":"Building driver-rider matching systems for ride sharing platforms, Designing delivery optimization systems that balance predicted demand with routing constraints","audience":"Mid-DS, Senior-DS"},{"id":"resource-instacart:-predicting-availability-of-200m-grocery-items","type":"resource","name":"Instacart: Predicting Availability of 200M Grocery Items","description":"XGBoost with 130 features scoring 200M+ items every 60 minutes. 15x items with 1/5 resources.","category":"Case Studies","url":"https://tech.instacart.com/predicting-real-time-availability-of-200-million-grocery-items-in-us-canada-stores-61f43a16eafe","difficulty":"intermediate","prerequisites":"xgboost, python-pandas, feature-engineering","topic_tags":"demand-forecasting, inventory-management, xgboost, real-time-ml, grocery-retail","summary":"Instacart's case study on building a real-time availability prediction system using XGBoost with 130 features to score 200M+ grocery items every hour. The system achieved 15x scale improvement while using only 1/5 of the original computational resources. Details implementation challenges and solutions for high-frequency demand forecasting in grocery retail.","use_cases":"Building real-time inventory availability systems for e-commerce platforms, Implementing large-scale demand forecasting for retail operations","audience":"Mid-DS, Senior-DS"},{"id":"resource-mit-15.053:-optimization-methods-in-management-science","type":"resource","name":"MIT 15.053: Optimization Methods in Management Science","description":"Undergraduate course on LP with geometry and visualization before algebra. Interactive spreadsheet exercises.","category":"Convex Optimization","url":"https://ocw.mit.edu/courses/15-053-optimization-methods-in-management-science-spring-2013/","difficulty":"beginner","prerequisites":"basic-algebra, excel-spreadsheets","topic_tags":"linear-programming, optimization-fundamentals, interactive-learning, management-science, geometric-interpretation","summary":"MIT's undergraduate optimization course that teaches linear programming through geometric visualization and interactive spreadsheet exercises before diving into algebraic methods. Designed to build intuition for optimization problems in business and management contexts. Perfect for learning the foundations of constrained optimization with hands-on practice.","use_cases":"Learning linear programming fundamentals with visual intuition before tackling complex optimization algorithms, Understanding resource allocation and production planning problems in business contexts","audience":"Junior-DS, Curious-browser"},{"id":"resource-quantecon:-linear-programming-introduction","type":"resource","name":"QuantEcon: Linear Programming Introduction","description":"Python notebooks from Nobel Laureate Sargent. LP with economics applications using SciPy and OR-Tools.","category":"Linear Programming","url":"https://intro.quantecon.org/lp_intro.html","difficulty":"beginner","prerequisites":"python-basics, scipy-fundamentals, basic-microeconomics","topic_tags":"linear-programming, optimization-tutorial, economics-applications, python-notebooks, quantecon","summary":"Interactive Python notebooks teaching linear programming fundamentals through economics applications, created by Nobel Laureate Thomas Sargent. Covers LP theory and implementation using SciPy and OR-Tools with real economic examples. Perfect introduction to optimization methods for economists and data scientists.","use_cases":"Resource allocation problems in economics research, Learning optimization fundamentals for data science interviews","audience":"Early-PhD, Junior-DS"},{"id":"resource-real-python:-linear-programming-with-python","type":"resource","name":"Real Python: Linear Programming with Python","description":"Comprehensive tutorial covering visualization, feasible regions, SciPy, PuLP, and mixed-integer programming.","category":"Linear Programming","url":"https://realpython.com/linear-programming-python/","difficulty":"beginner","prerequisites":"python-basics, numpy-arrays, basic-algebra","topic_tags":"linear-programming, optimization, scipy, pulp, mixed-integer-programming","summary":"A comprehensive Python tutorial that teaches linear programming fundamentals through practical implementation using SciPy and PuLP libraries. Covers problem visualization, feasible region analysis, and extends to mixed-integer programming scenarios. Perfect for data scientists and economists who need to solve constrained optimization problems in their work.","use_cases":"Resource allocation optimization in tech companies (budget, staffing, server capacity), Supply chain optimization for marketplace platforms (inventory, shipping, cost minimization)","audience":"Junior-DS, Curious-browser"},{"id":"resource-scipy-lecture-notes:-mathematical-optimization","type":"resource","name":"SciPy Lecture Notes: Mathematical Optimization","description":"Academic tutorial with visual explanations. Gradient descent, BFGS, Nelder-Mead with convergence visualizations.","category":"Convex Optimization","url":"https://scipy-lectures.org/advanced/mathematical_optimization/","difficulty":"beginner","prerequisites":"python-basics, calculus, numpy","topic_tags":"gradient-descent, BFGS, nelder-mead, numerical-optimization, scipy","summary":"Academic tutorial covering fundamental optimization algorithms with visual demonstrations of convergence behavior. Explains gradient descent, BFGS, and Nelder-Mead methods through interactive examples and mathematical foundations. Ideal for learning the core optimization techniques used across machine learning and data science.","use_cases":"Implementing custom loss function optimization for machine learning models, Finding optimal parameters for economic models or pricing algorithms","audience":"Early-PhD, Junior-DS"},{"id":"resource-pulp-official-documentation","type":"resource","name":"PuLP Official Documentation","description":"Complete LP/MIP documentation with case studies: blending problem, Sudoku, transportation. Multiple solver support.","category":"Linear Programming","url":"https://coin-or.github.io/pulp/","difficulty":"beginner","prerequisites":"python-basics, linear-algebra","topic_tags":"linear-programming, optimization, python-pulp, mixed-integer-programming, documentation","summary":"Official documentation for PuLP, a Python library for linear and mixed-integer programming problems. Includes comprehensive tutorials, API reference, and practical case studies like supply chain optimization and resource allocation. Essential reference for anyone implementing optimization solutions in Python.","use_cases":"Optimizing product mix and resource allocation in manufacturing, Solving transportation and logistics routing problems","audience":"Junior-DS, Mid-DS"},{"id":"resource-google-or-tools-python-guide","type":"resource","name":"Google OR-Tools Python Guide","description":"Official documentation with setup and examples. CP-SAT solver won MiniZinc Challenge 2013-2024.","category":"Linear Programming","url":"https://developers.google.com/optimization/introduction/python","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, constraint-programming-concepts","topic_tags":"constraint-programming, mixed-integer-programming, operations-research, python-library, solver-documentation","summary":"Official Python documentation for Google OR-Tools, featuring the award-winning CP-SAT constraint solver. Provides setup instructions, API reference, and practical examples for solving optimization problems. Essential starting point for anyone implementing operations research solutions in Python.","use_cases":"Optimizing delivery routes and scheduling for logistics companies, Resource allocation and capacity planning for cloud infrastructure","audience":"Junior-DS, Mid-DS"},{"id":"resource-doordash:-next-generation-dasher-dispatch-optimization","type":"resource","name":"DoorDash: Next-Generation Dasher Dispatch Optimization","description":"Rare solver benchmarking transparency \u2014 compares CBC, XPress, CPLEX, Gurobi (34x faster than CBC).","category":"Linear Programming","url":"https://careersatdoordash.com/blog/next-generation-optimization-for-dasher-dispatch-at-doordash/","difficulty":"intermediate","prerequisites":"linear-programming, optimization-solvers, python-operations-research","topic_tags":"solver-benchmarking, dispatch-optimization, gurobi, cplex, vehicle-routing","summary":"DoorDash's engineering blog post comparing performance of four major optimization solvers (CBC, XPress, CPLEX, Gurobi) for their dasher dispatch system. The post provides rare transparency into commercial solver benchmarking, showing Gurobi achieving 34x speedup over open-source CBC. This is valuable for practitioners choosing optimization tools for large-scale logistics problems.","use_cases":"Selecting optimization solver for delivery routing system, Benchmarking commercial vs open-source solvers for production optimization","audience":"Mid-DS, Senior-DS"},{"id":"resource-uber:-dynamic-pricing-and-matching-in-ride-hailing","type":"resource","name":"Uber: Dynamic Pricing and Matching in Ride-Hailing","description":"Academic rigor with industry application. Joint optimization of pricing and matching.","category":"Case Studies","url":"https://www.uber.com/blog/research/dynamic-pricing-and-matching-in-ride-hailing-platforms/","difficulty":"intermediate","prerequisites":"linear-programming, matching-algorithms, econometric-modeling","topic_tags":"dynamic-pricing, matching-algorithms, ride-hailing, optimization, case-study","summary":"Academic case study examining Uber's joint optimization of pricing and driver-rider matching in real-time markets. Combines rigorous economic theory with practical implementation insights for two-sided marketplace design. Particularly valuable for understanding how platform companies balance supply-demand dynamics through algorithmic pricing.","use_cases":"Designing pricing algorithms for marketplace platforms like delivery services or freelance platforms, Optimizing resource allocation in real-time matching systems for transportation or logistics","audience":"Mid-DS, Senior-DS"},{"id":"resource-mit-6.046j-lecture-15:-linear-programming","type":"resource","name":"MIT 6.046J Lecture 15: Linear Programming","description":"Video intro from algorithmic perspective. LP formulation, reductions, and simplex method.","category":"Linear Programming","url":"https://ocw.mit.edu/courses/6-046j-design-and-analysis-of-algorithms-spring-2015/resources/lecture-15-linear-programming-lp-reductions-simplex/","difficulty":"intermediate","prerequisites":"linear-algebra, algorithm-complexity, basic-calculus","topic_tags":"linear-programming, simplex-method, optimization-algorithms, lectures, MIT","summary":"MIT's algorithmic introduction to linear programming covering problem formulation, constraint optimization, and the simplex method. Designed for computer science students learning optimization from a computational perspective. Provides foundational understanding of how LP solvers work under the hood.","use_cases":"Learning how recommendation systems solve for optimal content allocation, Understanding resource allocation algorithms in cloud computing platforms","audience":"Junior-DS, Early-PhD"},{"id":"resource-gilp:-geometric-interpretation-of-linear-programs-(cornell)","type":"resource","name":"GILP: Geometric Interpretation of Linear Programs (Cornell)","description":"Academic-grade visualization (ACM SIGCSE 2023). Shows feasible regions, simplex iterations, branch-and-bound.","category":"Linear Programming","url":"https://gilp.henryrobbins.com/","difficulty":"beginner","prerequisites":"linear-algebra, basic-optimization, constraint-satisfaction","topic_tags":"linear-programming, optimization-visualization, simplex-algorithm, educational-tool, geometric-interpretation","summary":"GILP is an interactive visualization tool that helps users understand linear programming through geometric representation of feasible regions and solution methods. It shows how the simplex algorithm and branch-and-bound work visually, making abstract optimization concepts concrete. Perfect for learning how linear programs are solved and building intuition about optimization geometry.","use_cases":"Teaching linear programming concepts to students or new team members, Building intuition before implementing complex optimization models in production","audience":"Early-PhD, Junior-DS"},{"id":"resource-amazon-science:-operations-research-and-optimization","type":"resource","name":"Amazon Science: Operations Research and Optimization","description":"Portal to Amazon's OR research on inventory planning, last-mile delivery, and fulfillment at massive scale.","category":"Routing & Logistics","url":"https://www.amazon.science/research-areas/operations-research-and-optimization","difficulty":"intermediate","prerequisites":"linear-programming, graph-algorithms, python-optimization","topic_tags":"operations-research, supply-chain, inventory-optimization, last-mile-delivery, research-portal","summary":"Amazon Science's operations research portal showcases cutting-edge optimization methods for inventory planning, delivery routing, and warehouse fulfillment at unprecedented scale. The resource provides access to research papers, case studies, and methodologies developed by Amazon's OR teams. It's particularly valuable for practitioners working on supply chain optimization and logistics problems in tech companies.","use_cases":"Designing inventory allocation algorithms for multi-warehouse e-commerce systems, Optimizing delivery route planning for same-day fulfillment services","audience":"Mid-DS, Senior-DS"},{"id":"resource-instacart:-delivering-optimal-shopping-experiences-(gurobi)","type":"resource","name":"Instacart: Delivering Optimal Shopping Experiences (Gurobi)","description":"Why Instacart chose commercial solvers. Reliability and innovation speed from Gurobi.","category":"Linear Programming","url":"https://www.gurobi.com/case_studies/instacart-delivering-optimal-shopping-experiences/","difficulty":"intermediate","prerequisites":"linear-programming, optimization-modeling, operations-research","topic_tags":"commercial-solvers, gurobi, instacart, supply-chain, case-study","summary":"A case study explaining why Instacart selected Gurobi's commercial optimization solver over open-source alternatives. Details their decision criteria around reliability, performance, and development speed for production optimization systems. Provides insights into build-vs-buy decisions for optimization infrastructure at scale.","use_cases":"Evaluating commercial vs open-source solvers for production optimization systems, Understanding vendor selection criteria for mission-critical optimization infrastructure","audience":"Mid-DS, Senior-DS"},{"id":"resource-the-cold-start-problem-(andrew-chen)","type":"resource","name":"The Cold Start Problem (Andrew Chen)","description":"Atomic Networks and tipping points of two-sided marketplaces \u2014 why growth stalls","category":"Marketplace Economics","url":"https://www.coldstart.com/","difficulty":"beginner","prerequisites":"basic-economics, product-metrics","topic_tags":"network-effects, marketplace-strategy, growth-frameworks, two-sided-markets, platform-economics","summary":"A strategic framework book explaining how network-effect businesses overcome initial user acquisition challenges and reach critical mass. Chen explores atomic network theory and provides practical playbooks for building two-sided marketplaces. Essential reading for understanding why most network businesses fail and how successful platforms achieve sustainable growth.","use_cases":"Designing launch strategy for a new marketplace or platform product, Diagnosing why user growth has stalled in an existing two-sided market","audience":"Junior-DS, Mid-DS"},{"id":"resource-lenny's-newsletter:-how-duolingo-reignited-user-growth","type":"resource","name":"Lenny's Newsletter: How Duolingo Reignited User Growth","description":"Case study on gamification, streaks, and retention mechanics that drove 4.5x growth","category":"Growth & Retention","url":"https://www.lennysnewsletter.com/p/how-duolingo-reignited-user-growth","difficulty":"beginner","prerequisites":"basic-product-metrics, user-retention-analysis","topic_tags":"gamification, user-retention, product-growth, case-study","summary":"A detailed case study examining how Duolingo redesigned their product features using gamification mechanics like streaks and social features to achieve 4.5x user growth. The analysis breaks down specific retention strategies and their measurable impact on user engagement. Essential reading for anyone working on consumer product growth.","use_cases":"Designing retention features for a consumer app, Building gamification mechanics to increase user engagement","audience":"Junior-DS, Mid-DS"},{"id":"resource-growth-accounting-&-backtraced-growth-accounting","type":"resource","name":"Growth Accounting & Backtraced Growth Accounting","description":"Standard framework for user lifecycle states (New, Retained, Churned, Stale, Resurrected) with weighted backtrace views","category":"Growth & Retention","url":"https://bytepawn.com/growth-accounting-and-backtraced-growth-accounting.html","difficulty":"intermediate","prerequisites":"SQL-cohort-analysis, user-lifecycle-modeling, retention-metrics","topic_tags":"growth-accounting, user-lifecycle, retention-analysis, cohort-tracking, product-analytics","summary":"Growth accounting is a systematic framework for categorizing users into lifecycle states (New, Retained, Churned, Stale, Resurrected) to understand product growth drivers. The backtraced variant provides weighted historical views to better attribute growth contributions over time. This is essential for product teams to diagnose growth issues and prioritize retention vs acquisition efforts.","use_cases":"Diagnosing why monthly active users are declining by decomposing into new user acquisition vs existing user retention, Attributing revenue growth to different user lifecycle segments to inform marketing budget allocation","audience":"Mid-DS, Junior-DS"},{"id":"resource-guide-to-product-metrics","type":"resource","name":"Guide to Product Metrics","description":"26 metrics across AARRR framework: activation, retention, LTV, NRR, Quick Ratio, PMF Score explained","category":"Growth & Retention","url":"https://www.roarkeclinton.com/posts/product-metrics-guide.html","difficulty":"beginner","prerequisites":"basic-analytics, product-management-fundamentals","topic_tags":"product-metrics, aarrr-framework, user-retention, customer-lifetime-value, growth-analytics","summary":"A comprehensive guide covering 26 essential product metrics organized within the AARRR (Acquisition, Activation, Retention, Revenue, Referral) framework. Explains key metrics like activation rates, retention cohorts, customer lifetime value, net revenue retention, and product-market fit scoring. Essential reference for anyone measuring product performance and growth.","use_cases":"Setting up a metrics dashboard for a new product launch to track user engagement and business health, Evaluating product-market fit and growth potential when preparing investor updates or strategic planning","audience":"Junior-DS, Mid-DS"},{"id":"resource-measuring-product-health-(sequoia)","type":"resource","name":"Measuring Product Health (Sequoia)","description":"Definitive guide to growth, retention, stickiness & engagement metrics: DAU/MAU, Lness, cohort curves, Quick Ratio","category":"Growth & Retention","url":"https://articles.sequoiacap.com/measuring-product-health","difficulty":"beginner","prerequisites":"SQL-basic-queries, cohort-analysis, funnel-analysis","topic_tags":"product-metrics, user-engagement, retention-analysis, growth-metrics, DAU-MAU","summary":"Sequoia's comprehensive guide to essential product health metrics including DAU/MAU ratios, L-ness calculations, cohort retention curves, and Quick Ratio for measuring growth efficiency. Provides practical frameworks for measuring user engagement, stickiness, and sustainable growth patterns. Essential reference for anyone building or analyzing consumer products.","use_cases":"Setting up a product metrics dashboard for a new mobile app to track user engagement and retention, Evaluating the health of an existing SaaS product before a funding round by analyzing cohort retention and growth metrics","audience":"Junior-DS, Mid-DS"},{"id":"resource-ken-norton:-how-to-hire-a-product-manager","type":"resource","name":"Ken Norton: How to Hire a Product Manager","description":"Former Google PM (14+ years) who led Docs, Calendar, Mobile Maps. This essay defines what a PM does by revealing hiring criteria \u2014 the map of competencies to develop.","category":"Frameworks & Strategy","url":"https://www.bringthedonuts.com/essays/productmanager.html","difficulty":"beginner","prerequisites":"basic-business-strategy, cross-functional-collaboration","topic_tags":"product-management, hiring-frameworks, career-development, tech-industry, google-practices","summary":"A foundational essay by veteran Google PM Ken Norton that defines product management through the lens of hiring criteria and competencies. The piece breaks down what successful PMs actually do by examining the skills and qualities to look for when hiring them. Essential reading for anyone wanting to understand the PM role or transition into product management.","use_cases":"Data scientists considering a transition to product management roles, Early-career professionals trying to understand what product managers do and how to work with them effectively","audience":"Junior-DS, Curious-browser"},{"id":"resource-svpg:-product-management-start-here","type":"resource","name":"SVPG: Product Management Start Here","description":"Silicon Valley Product Group's curated entry point distinguishing 'empowered product teams' from 'feature teams' \u2014 exposes why most PM work is 'product management theater'.","category":"Frameworks & Strategy","url":"https://www.svpg.com/product-management-start-here/","difficulty":"beginner","prerequisites":"product-roadmap-planning, stakeholder-management","topic_tags":"product-management, team-structure, empowerment, strategy, framework","summary":"SVPG's foundational guide distinguishes empowered product teams that solve customer problems from feature teams that just build requirements. It exposes common 'product management theater' where PMs lack real decision-making authority and instead just coordinate delivery timelines.","use_cases":"Transitioning from feature factory delivery model to outcome-driven product development, Diagnosing why your product team feels like order-takers rather than strategic decision-makers","audience":"Junior-DS, Curious-browser"},{"id":"resource-shreyas-doshi:-lno-framework","type":"resource","name":"Shreyas Doshi: LNO Framework","description":"Former PM leader at Stripe, Twitter, Google. The LNO Framework (Leverage, Neutral, Overhead tasks) is a breakthrough prioritization model \u2014 distinguishes good from exceptional PM thinking.","category":"Frameworks & Strategy","url":"https://shreyasdoshi.com/","difficulty":"beginner","prerequisites":"basic-project-management, stakeholder-communication","topic_tags":"task-prioritization, product-management, decision-frameworks, resource-allocation, strategic-planning","summary":"The LNO Framework categorizes tasks into Leverage (high-impact, multiplicative), Neutral (maintenance, necessary), and Overhead (low-value, time-consuming) buckets. Created by former PM leader Shreyas Doshi, it helps distinguish high-impact work from busy work. This prioritization model is widely adopted by product managers and analysts to optimize time allocation and strategic focus.","use_cases":"Product manager deciding which features to prioritize in next sprint based on potential leverage vs overhead, Data scientist evaluating whether to spend time on model optimization (leverage) vs routine reporting (neutral/overhead)","audience":"Mid-DS, Curious-browser"},{"id":"resource-intercom:-rice-prioritization-framework","type":"resource","name":"Intercom: RICE Prioritization Framework","description":"The RICE framework (Reach, Impact, Confidence, Effort) originated here and is now industry standard \u2014 provides quantitative structure for prioritization.","category":"Frameworks & Strategy","url":"https://www.intercom.com/blog/rice-simple-prioritization-for-product-managers/","difficulty":"beginner","prerequisites":"basic-math, product-management-basics","topic_tags":"product-prioritization, decision-frameworks, quantitative-analysis, product-management, feature-scoring","summary":"RICE is a quantitative framework for prioritizing product features and initiatives by scoring them across four dimensions: Reach (how many users affected), Impact (how much it matters), Confidence (certainty in estimates), and Effort (resources required). Originally developed at Intercom, it's now widely adopted across tech companies to make data-driven prioritization decisions. The framework helps product teams move beyond gut feelings to systematic evaluation of competing initiatives.","use_cases":"Product manager deciding which features to build next quarter from a backlog of 20+ potential initiatives, Data scientist helping leadership choose between different growth experiments or product improvements","audience":"Junior-DS, Mid-DS"},{"id":"resource-intercom:-on-product-management-(free-book)","type":"resource","name":"Intercom: On Product Management (Free Book)","description":"Beautifully designed, practical product content from Intercom's product team led by Des Traynor. Free downloadable PDF covering PM fundamentals.","category":"Frameworks & Strategy","url":"https://www.intercom.com/resources/books/intercom-product-management","difficulty":"beginner","prerequisites":"basic-product-terminology, user-research-fundamentals","topic_tags":"product-management, product-strategy, user-experience, free-book, product-fundamentals","summary":"A comprehensive free book from Intercom covering core product management principles and practices. Written by experienced product leaders, it provides practical frameworks for building products users love. Essential reading for anyone wanting to understand how product decisions impact business outcomes.","use_cases":"Learning product management fundamentals when transitioning from a technical role, Understanding how to work effectively with product teams as a data scientist","audience":"Junior-DS, Curious-browser"},{"id":"resource-gibson-biddle:-dhm-product-strategy-framework","type":"resource","name":"Gibson Biddle: DHM Product Strategy Framework","description":"Former VP Product at Netflix (2005-2010). A 13-essay series walking through exactly how Netflix built its product strategy using DHM (Delight, Hard-to-copy, Margin-enhancing).","category":"Frameworks & Strategy","url":"https://gibsonbiddle.medium.com/intro-to-product-strategy-60bdf72b17e3","difficulty":"beginner","prerequisites":"product-metrics, basic-business-strategy","topic_tags":"product-strategy, netflix-case-study, dhm-framework, product-management, essay-series","summary":"A comprehensive 13-essay series by former Netflix VP Product Gibson Biddle explaining the DHM framework (Delight, Hard-to-copy, Margin-enhancing) used to build Netflix's product strategy from 2005-2010. Provides concrete examples and actionable insights from one of the most successful product transformations in tech history. Essential reading for understanding how to systematically approach product strategy in tech companies.","use_cases":"Learning how to develop product strategy frameworks when transitioning from individual contributor to product leadership roles, Understanding how successful tech companies like Netflix built sustainable competitive advantages through systematic product thinking","audience":"Junior-DS, Curious-browser"},{"id":"resource-teresa-torres:-opportunity-solution-trees","type":"resource","name":"Teresa Torres: Opportunity Solution Trees","description":"Product discovery coach who has trained 17,000+ PMs. The Opportunity Solution Tree framework connects business outcomes \u2192 customer opportunities \u2192 solutions \u2192 experiments.","category":"Frameworks & Strategy","url":"https://www.producttalk.org/opportunity-solution-trees/","difficulty":"beginner","prerequisites":"basic-product-management, customer-research-methods","topic_tags":"product-discovery, customer-research, product-strategy, framework, product-management","summary":"A structured framework for product discovery that maps business outcomes to customer opportunities, potential solutions, and testable experiments. Developed by Teresa Torres for product managers to systematically identify and validate product opportunities. Widely used in tech companies to align product decisions with customer needs and business goals.","use_cases":"Product manager trying to prioritize which customer problems to solve next based on business impact, Data scientist working with PMs to design experiments that validate product hypotheses before building features","audience":"Junior-DS, Curious-browser"},{"id":"resource-marty-cagan:-inspired","type":"resource","name":"Marty Cagan: INSPIRED","description":"THE definitive book on modern product management from SVPG founder. Explains empowered teams, product discovery vs. delivery, and how Amazon, Google, Netflix actually operate.","category":"Frameworks & Strategy","url":"https://www.svpg.com/books/inspired-how-to-create-tech-products-customers-love-2nd-edition/","difficulty":"beginner","prerequisites":"product-roadmaps, user-interviews, A-B-testing-basics","topic_tags":"product-management, team-frameworks, product-discovery, business-strategy, book","summary":"The foundational guide to modern product management by Silicon Valley Product Group founder Marty Cagan. Teaches how to build empowered product teams, distinguish between discovery and delivery phases, and implement practices used by top tech companies. Essential reading for anyone working at the intersection of product, engineering, and data.","use_cases":"Data scientist needs to understand product team dynamics and discovery processes before building models, Junior researcher wants to learn how tech companies actually make product decisions and prioritize features","audience":"Junior-DS, Curious-browser"},{"id":"resource-atlassian:-how-to-write-product-requirements","type":"resource","name":"Atlassian: How to Write Product Requirements","description":"Practical guide to writing PRDs in an agile environment from the makers of Jira and Confluence. Includes templates and explains modern, lightweight documentation.","category":"Metrics & Measurement","url":"https://www.atlassian.com/agile/product-management/requirements","difficulty":"beginner","prerequisites":"agile-methodology, product-development-basics","topic_tags":"product-requirements, documentation, agile-development, product-management, templates","summary":"Atlassian's practical guide teaches how to write effective Product Requirements Documents (PRDs) in modern agile environments. The resource provides templates and emphasizes lightweight, collaborative documentation practices used by product teams. It's designed for anyone who needs to communicate product specifications clearly without heavy bureaucratic overhead.","use_cases":"Data scientist needs to document requirements for a new ML feature before implementation, Product manager creating specifications for an A/B testing platform that engineering and data teams can follow","audience":"Junior-DS, Mid-DS"},{"id":"resource-amplitude:-product-lessons-with-shreyas-doshi","type":"resource","name":"Amplitude: Product Lessons with Shreyas Doshi","description":"Deep conversation on 'The Fundamental Framework of Product Work' (Impact, Execution, Optics levels) \u2014 demonstrates how metrics connect to strategy at sophisticated level.","category":"Frameworks & Strategy","url":"https://amplitude.com/blog/shreyas-doshi-product-lessons","difficulty":"intermediate","prerequisites":"product-metrics, experimentation-design, stakeholder-management","topic_tags":"product-strategy, metrics-frameworks, impact-measurement, product-management, interview-content","summary":"In-depth interview with Shreyas Doshi discussing his fundamental framework for product work, covering Impact, Execution, and Optics levels. The conversation demonstrates how to connect product metrics to strategic decision-making and provides a sophisticated approach to evaluating product initiatives.","use_cases":"Learning how to structure product thinking when transitioning from pure analytics to product-focused roles, Understanding how to communicate data insights effectively across different organizational levels and stakeholder groups","audience":"Mid-DS, Curious-browser"},{"id":"resource-lenny's-newsletter-&-podcast","type":"resource","name":"Lenny's Newsletter & Podcast","description":"Former Airbnb PM, #1 business newsletter on Substack with 700k+ subscribers. The most comprehensive ongoing resource for developing 'product sense' with concrete, tactical frameworks.","category":"Case Studies","url":"https://www.lennysnewsletter.com/","difficulty":"beginner","prerequisites":"basic-product-metrics, user-funnel-analysis","topic_tags":"product-management, growth-frameworks, business-strategy, user-analytics, case-studies","summary":"Lenny's Newsletter is the leading product management resource featuring tactical frameworks, case studies, and interviews from top tech companies. It provides concrete, actionable advice for developing product intuition and decision-making skills. The content covers growth strategies, user research, metrics, and real-world examples from companies like Airbnb, Uber, and Netflix.","use_cases":"Learning how to design and analyze product experiments from real company case studies, Understanding how to prioritize features and measure product-market fit using proven frameworks","audience":"Junior-DS, Mid-DS"},{"id":"resource-150-successful-ml-models-at-booking.com-(kdd-2019)","type":"resource","name":"150 Successful ML Models at Booking.com (KDD 2019)","description":"Reveals that model performance \u2260 business performance. Demonstrates why RCTs are critical for validating ML models in production with framework for hypothesis-driven iteration.","category":"Case Studies","url":"https://dl.acm.org/doi/10.1145/3292500.3330744","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, machine-learning-evaluation, A-B-testing","topic_tags":"model-validation, business-metrics, production-ml, causal-inference, tech-industry","summary":"A KDD 2019 case study from Booking.com analyzing 150 machine learning models in production, revealing the critical disconnect between offline model performance and actual business impact. The paper demonstrates why randomized controlled trials are essential for validating ML systems and provides a framework for hypothesis-driven model iteration in real-world settings.","use_cases":"Validating whether a new recommendation system actually increases revenue despite better offline metrics, Designing experimentation frameworks to test ML model business impact before full deployment","audience":"Mid-DS, Senior-DS"},{"id":"resource-a-quantitative-approach-to-product-market-fit-(tribe-capital)","type":"resource","name":"A Quantitative Approach to Product-Market Fit (Tribe Capital)","description":"The foundational text on growth accounting. MAU growth accounting AND revenue growth accounting. Quick Ratio, Gross Retention, Net Churn explained by the team that pioneered it.","category":"Growth & Retention","url":"https://tribecap.co/a-quantitative-approach-to-product-market-fit/","difficulty":"beginner","prerequisites":"SQL-basics, cohort-analysis, unit-economics","topic_tags":"growth-accounting, product-metrics, retention-analysis, churn-modeling, quick-ratio","summary":"Tribe Capital's foundational framework for measuring product-market fit through quantitative growth accounting methods. Introduces key metrics like Quick Ratio, Gross Retention, and Net Churn for both MAU and revenue analysis. Essential reading for understanding how to systematically measure and improve product growth.","use_cases":"Setting up growth dashboards to track product-market fit metrics for a SaaS platform, Analyzing user retention patterns to identify churn drivers and optimize onboarding flows","audience":"Junior-DS, Mid-DS"},{"id":"resource-the-power-user-curve-(a16z)","type":"resource","name":"The Power User Curve (a16z)","description":"The L30/L28 framework coined by Facebook's growth team. Why Power User Curves beat DAU/MAU: reveals variance, identifies power users, customizable for core actions. Used by a16z to evaluate startups.","category":"Growth & Retention","url":"https://a16z.com/the-power-user-curve-the-best-way-to-understand-your-most-engaged-users/","difficulty":"intermediate","prerequisites":"cohort-analysis, product-metrics, SQL-aggregation","topic_tags":"power-user-curve, L30-L28, user-segmentation, retention-analysis, startup-evaluation","summary":"The L30/L28 framework developed by Facebook's growth team measures power users by analyzing user activity distribution over 30 vs 28 day periods. Unlike simple DAU/MAU ratios, it reveals engagement variance and helps identify your most valuable user segments. Venture capitalists like a16z use this framework to evaluate startup traction and user engagement quality.","use_cases":"Evaluating whether a startup has genuine power users vs casual browsers for investment decisions, Product teams identifying which user segments drive core engagement to focus retention efforts","audience":"Mid-DS, Senior-DS"},{"id":"resource-how-to-measure-cohort-retention-(lenny's-newsletter)","type":"resource","name":"How to Measure Cohort Retention (Lenny's Newsletter)","description":"The most comprehensive retention measurement guide. SQL implementations, bounded vs unbounded retention definitions, visualization best practices. When to use X-day vs unbounded retention.","category":"Probability & Inference","url":"https://www.lennysnewsletter.com/p/measuring-cohort-retention","difficulty":"beginner","prerequisites":"SQL-window-functions, cohort-analysis-basics, data-visualization","topic_tags":"cohort-retention, product-metrics, SQL-tutorial, retention-analysis, user-analytics","summary":"A comprehensive guide to measuring and analyzing user retention across cohorts, covering both bounded and unbounded retention definitions. Provides SQL implementations and visualization best practices for product teams. Essential reading for understanding when different retention metrics are appropriate for business decisions.","use_cases":"Product manager needs to track monthly active user retention for a subscription app, Data scientist building automated retention dashboards for different user cohorts","audience":"Junior-DS, Mid-DS"},{"id":"resource-ultimate-guide:-activation-(aakash-gupta)","type":"resource","name":"Ultimate Guide: Activation (Aakash Gupta)","description":"Traces activation history from Facebook's 2008 growth team, including Chamath's '7 friends in 10 days' discovery. The Setup \u2192 Aha \u2192 Habit framework with data-backed examples.","category":"Growth & Retention","url":"https://www.news.aakashg.com/p/ultimate-guide-activation","difficulty":"beginner","prerequisites":"basic-statistics, product-metrics","topic_tags":"user-activation, growth-hacking, product-analytics, user-onboarding, retention-metrics","summary":"Comprehensive guide to user activation strategies tracing back to Facebook's early growth team discoveries. Introduces the Setup \u2192 Aha \u2192 Habit framework with historical context and data-driven examples from major tech companies. Essential reading for understanding how leading platforms drive early user engagement and long-term retention.","use_cases":"Designing onboarding flows for a new mobile app to maximize Day 7 retention, Analyzing user journey data to identify activation moments for a SaaS product","audience":"Junior-DS, Mid-DS"},{"id":"resource-how-superhuman-built-an-engine-to-find-pmf-(first-round)","type":"resource","name":"How Superhuman Built an Engine to Find PMF (First Round)","description":"Operationalizes Sean Ellis's '40% very disappointed' survey into a systematic process. How Superhuman went from 22% to 58% PMF score using segmentation. Most referenced First Round article.","category":"Probability & Inference","url":"https://review.firstround.com/how-superhuman-built-an-engine-to-find-product-market-fit/","difficulty":"beginner","prerequisites":"survey-design, customer-segmentation, basic-statistics","topic_tags":"product-market-fit, customer-surveys, segmentation-analysis, startup-metrics, case-study","summary":"A detailed case study showing how Superhuman systematically improved their product-market fit from 22% to 58% using Sean Ellis's survey methodology. The article breaks down their segmentation approach to identify which customer types were most likely to be 'very disappointed' without the product. It's become the most referenced example of operationalizing PMF measurement in practice.","use_cases":"Measuring and improving product-market fit for a new product or feature launch, Segmenting users to identify your core valuable customer base and prioritize product development","audience":"Junior-DS, Mid-DS"},{"id":"resource-slack's-2000-messages-activation-metric","type":"resource","name":"Slack's 2000 Messages Activation Metric","description":"Documents Slack's activation discovery \u2014 after 2,000 messages sent per team, 93% remain active. How they identified this leading indicator. Conversion rate significantly above 5% SaaS average.","category":"Growth & Retention","url":"https://www.growth-letter.com/p/inside-slacks-4-billion-growth-system","difficulty":"beginner","prerequisites":"cohort-analysis, conversion-funnels, basic-statistics","topic_tags":"activation-metrics, user-engagement, saas-analytics, product-metrics, retention-analysis","summary":"Slack's famous case study revealing that teams sending 2,000+ messages have 93% retention rates, far above typical SaaS conversion rates. Shows how to identify and validate activation metrics that predict long-term user success. Classic example of finding leading indicators through cohort analysis and behavioral data.","use_cases":"Finding activation thresholds for your own product by analyzing user behavior patterns, Validating whether engagement metrics actually predict retention in your app","audience":"Junior-DS, Mid-DS"},{"id":"resource-coding-for-practitioners","type":"resource","name":"Coding for practitioners","description":"Built specifically for econ researchers","category":"Python","url":"https://aeturrell.github.io/coding-for-economists/intro.html","difficulty":"beginner","prerequisites":"basic-python-syntax, command-line-basics","topic_tags":"python-fundamentals, economics-research, coding-tutorial, data-analysis, research-methods","summary":"A comprehensive Python programming guide tailored specifically for economics researchers and practitioners. This resource covers fundamental programming concepts, data manipulation techniques, and coding best practices within the context of economic analysis and research workflows.","use_cases":"Learning Python syntax and data structures for economic modeling and analysis, Setting up research workflows and reproducible code for academic economics projects","audience":"Early-PhD, Junior-DS"},{"id":"resource-python-data-science-handbook","type":"resource","name":"Python Data Science Handbook","description":"Free reference for NumPy, Pandas, Matplotlib","category":"Python","url":"https://jakevdp.github.io/PythonDataScienceHandbook/","difficulty":"beginner","prerequisites":"basic-python-syntax, command-line-basics","topic_tags":"python-fundamentals, data-manipulation, visualization, reference-guide, numpy-pandas","summary":"Comprehensive open-access handbook covering essential Python libraries for data science including NumPy for numerical computing, Pandas for data manipulation, and Matplotlib for visualization. Written by Jake VanderPlas, it serves as both a learning resource and practical reference guide for data scientists at all levels. The book provides hands-on examples and clear explanations of core data science workflows in Python.","use_cases":"Learning Python data science fundamentals as a new data scientist or researcher, Quick reference lookup for NumPy array operations or Pandas DataFrame methods during analysis","audience":"Junior-DS, Early-PhD"},{"id":"resource-statquest-(josh-starmer)","type":"resource","name":"StatQuest (Josh Starmer)","description":"Visual intuition for stats \u2014 the 'Bill Nye of Statistics'","category":"Probability & Inference","url":"https://www.youtube.com/@statquest","difficulty":"beginner","prerequisites":"basic-algebra, descriptive-statistics","topic_tags":"statistical-concepts, data-visualization, educational-videos, hypothesis-testing, regression-analysis","summary":"StatQuest provides intuitive video explanations of statistical concepts through clear visualizations and step-by-step breakdowns. Josh Starmer makes complex statistical methods accessible by focusing on conceptual understanding rather than mathematical rigor. Perfect for building foundational knowledge before diving into technical implementations.","use_cases":"Understanding what a p-value actually means before running your first A/B test, Grasping the intuition behind linear regression before implementing it in code","audience":"Junior-DS, Curious-browser"},{"id":"resource-seeing-theory-(brown)","type":"resource","name":"Seeing Theory (Brown)","description":"Beautiful interactive visualizations for building intuition","category":"Probability & Inference","url":"https://seeing-theory.brown.edu/","difficulty":"beginner","prerequisites":"basic-probability, descriptive-statistics","topic_tags":"interactive-visualization, probability-concepts, statistical-intuition, educational-resource","summary":"Seeing Theory is an interactive educational platform from Brown University that uses stunning visualizations to build intuitive understanding of probability and statistics concepts. It covers topics from basic probability through advanced inference, making abstract mathematical concepts concrete through hands-on exploration. Perfect for building foundational understanding before diving into technical implementations.","use_cases":"Learning probability distributions and their properties before implementing statistical models, Building intuition for hypothesis testing and confidence intervals before running A/B tests","audience":"Early-PhD, Junior-DS"},{"id":"resource-scipy.stats-documentation","type":"resource","name":"Scipy.stats Documentation","description":"Reference for distributions and tests","category":"Probability & Inference","url":"https://docs.scipy.org/doc/scipy/reference/stats.html","difficulty":"intermediate","prerequisites":"python-basics, numpy-arrays, hypothesis-testing","topic_tags":"statistical-distributions, hypothesis-testing, python-reference, scipy, documentation","summary":"Comprehensive documentation for SciPy's statistics module covering probability distributions, statistical tests, and descriptive statistics functions. Essential reference for data scientists implementing statistical methods in Python. Includes detailed API documentation, examples, and mathematical formulations for distributions and statistical procedures.","use_cases":"Looking up parameters and methods for a specific probability distribution like gamma or beta, Finding the right statistical test function and understanding its output format for A/B test analysis","audience":"Junior-DS, Mid-DS"},{"id":"resource-select-star-sql","type":"resource","name":"SELECT Star SQL","description":"Interactive book teaching SQL through meaningful analysis","category":"SQL","url":"https://selectstarsql.com/","difficulty":"beginner","prerequisites":"basic-programming, spreadsheet-software","topic_tags":"SQL-fundamentals, data-analysis, interactive-learning, query-optimization, database-basics","summary":"An interactive book that teaches SQL fundamentals through hands-on data analysis exercises and real-world examples. Designed for beginners to learn SQL syntax, query structure, and analytical techniques in an engaging format. Provides step-by-step guidance for writing queries to solve meaningful business and research questions.","use_cases":"Learning SQL basics for first data science role, Teaching SQL concepts to students or team members","audience":"Junior-DS, Curious-browser"},{"id":"resource-8-week-sql-challenge-(danny-ma)","type":"resource","name":"8 Week SQL Challenge (Danny Ma)","description":"8 business case studies with CTEs and window functions","category":"SQL","url":"https://8weeksqlchallenge.com/","difficulty":"intermediate","prerequisites":"SQL-basic-queries, relational-databases, business-analytics","topic_tags":"SQL-practice, CTEs, window-functions, business-cases, data-analysis","summary":"A hands-on SQL learning program featuring 8 realistic business case studies that teach advanced SQL concepts through practical applications. Each case study focuses on common data analysis scenarios using Common Table Expressions (CTEs) and window functions. Ideal for data professionals looking to strengthen their SQL skills with real-world business problems.","use_cases":"Preparing for data analyst interviews with hands-on SQL practice, Learning advanced SQL techniques for business intelligence and reporting","audience":"Junior-DS, Mid-DS"},{"id":"resource-datalemur","type":"resource","name":"DataLemur","description":"Real DS interview questions with business context","category":"SQL","url":"https://datalemur.com/","difficulty":"beginner","prerequisites":"basic-SQL, relational-databases","topic_tags":"SQL-practice, interview-preparation, business-analytics, query-optimization","summary":"DataLemur is a platform offering real data science interview questions focused on SQL with business context and scenarios. It helps practitioners prepare for technical interviews while learning practical SQL applications in business settings. The questions simulate real-world data problems commonly encountered at tech companies.","use_cases":"Preparing for data scientist or analyst interviews at tech companies, Practicing SQL skills with realistic business scenarios and datasets","audience":"Junior-DS, Mid-DS"},{"id":"resource-problem-solving-with-algorithms-&-data-structures-(python)","type":"resource","name":"Problem Solving with Algorithms & Data Structures (Python)","description":"Free interactive textbook \u2014 visualizations and runnable code","category":"Software Engineering","url":"https://runestone.academy/ns/books/published/pythonds/index.html","difficulty":"beginner","prerequisites":"basic-python-syntax, mathematical-reasoning","topic_tags":"algorithms, data-structures, python-programming, computer-science-fundamentals, interactive-textbook","summary":"An interactive textbook that teaches fundamental algorithms and data structures using Python with visual demonstrations and executable code examples. Designed for computer science students and practitioners who want to build strong problem-solving foundations. Features hands-on exercises covering sorting, searching, trees, graphs, and algorithmic analysis.","use_cases":"Junior data scientist preparing for technical interviews and needing to understand algorithm complexity, PhD student building foundational computer science knowledge to implement efficient research algorithms","audience":"Junior-DS, Early-PhD"},{"id":"resource-real-python:-data-structures","type":"resource","name":"Real Python: Data Structures","description":"Practical guide with Python-specific implementations","category":"Software Engineering","url":"https://realpython.com/python-data-structures/","difficulty":"beginner","prerequisites":"python-basics, object-oriented-programming","topic_tags":"data-structures, python-implementation, algorithms, programming-fundamentals","summary":"A comprehensive guide to implementing and using data structures in Python, covering lists, dictionaries, sets, stacks, queues, and trees with practical examples. Essential for data scientists who need to optimize code performance and choose appropriate data structures for different analytical tasks. Focuses on Python-specific implementations and best practices rather than theoretical computer science.","use_cases":"Optimizing data processing pipelines by choosing efficient data structures for large datasets, Building custom algorithms for A/B testing frameworks that require specific queue or tree implementations","audience":"Junior-DS, Early-PhD"},{"id":"resource-usf-data-structure-visualizations","type":"resource","name":"USF Data Structure Visualizations","description":"Interactive animations \u2014 see how trees, heaps, and graphs work","category":"Software Engineering","url":"https://www.cs.usfca.edu/~galles/visualization/Algorithms.html","difficulty":"beginner","prerequisites":"basic-programming, algorithm-concepts","topic_tags":"data-structures, algorithms, visualization, computer-science, interactive-learning","summary":"Interactive visual animations that demonstrate how fundamental data structures like trees, heaps, and graphs operate step-by-step. Perfect for learning core computer science concepts through visual exploration rather than just reading code. Helps build intuition for how algorithms manipulate these structures in real-time.","use_cases":"Learning how binary search trees maintain sorted order during insertions and deletions, Understanding how heap data structures work before implementing priority queues in production code","audience":"Junior-DS, Early-PhD"},{"id":"resource-leetcode-explore:-data-structures","type":"resource","name":"LeetCode Explore: Data Structures","description":"Structured practice cards with solutions","category":"Software Engineering","url":"https://leetcode.com/explore/learn/","difficulty":"beginner","prerequisites":"python-basics, algorithm-fundamentals","topic_tags":"data-structures, coding-interviews, algorithm-practice, leetcode, programming-fundamentals","summary":"Interactive learning modules covering fundamental data structures like arrays, linked lists, trees, and graphs with step-by-step explanations and coding exercises. Designed for structured practice with built-in solutions and explanations to help developers master essential computer science concepts. Particularly useful for interview preparation and strengthening programming foundations.","use_cases":"Preparing for technical interviews at tech companies, Building foundational knowledge before diving into advanced algorithms or machine learning implementations","audience":"Junior-DS, Curious-browser"},{"id":"resource-freecodecamp:-algorithms-course","type":"resource","name":"freeCodeCamp: Algorithms Course","description":"8-hour free video course \u2014 clear explanations","category":"Software Engineering","url":"https://www.youtube.com/watch?v=8hly31xKli0","difficulty":"beginner","prerequisites":"basic-programming-concepts, problem-solving-fundamentals","topic_tags":"algorithms, data-structures, computer-science, video-course, fundamentals","summary":"An 8-hour comprehensive video course covering fundamental algorithms and data structures with clear explanations suitable for beginners. This free resource provides a solid foundation in algorithmic thinking and common problem-solving patterns used across software engineering and data science. Perfect for building the computational skills needed for technical interviews and efficient code implementation.","use_cases":"Preparing for technical interviews at tech companies, Building foundational knowledge before diving into machine learning or data analysis roles","audience":"Early-PhD, Junior-DS"},{"id":"resource-abdul-bari-(youtube)","type":"resource","name":"Abdul Bari (YouTube)","description":"Exceptional whiteboard DSA explanations","category":"Software Engineering","url":"https://www.youtube.com/@abdul_bari","difficulty":"beginner","prerequisites":"basic-programming, mathematical-thinking","topic_tags":"data-structures, algorithms, video-tutorials, computer-science, coding-interviews","summary":"Abdul Bari's YouTube channel provides clear, whiteboard-style explanations of data structures and algorithms concepts. His teaching approach breaks down complex algorithmic concepts into digestible visual presentations. This resource is particularly valuable for building foundational computer science knowledge needed for technical interviews and software development.","use_cases":"Preparing for technical coding interviews at tech companies, Learning fundamental data structures and algorithms for software engineering roles","audience":"Junior-DS, Curious-browser"},{"id":"resource-visualgo","type":"resource","name":"VisuAlgo","description":"Animated algorithm visualizations \u2014 sorting, graphs, DP","category":"Software Engineering","url":"https://visualgo.net/","difficulty":"beginner","prerequisites":"basic-data-structures, algorithm-complexity","topic_tags":"algorithm-visualization, interactive-learning, computer-science, educational-tools","summary":"VisuAlgo is an interactive platform that provides animated visualizations of fundamental algorithms including sorting, graph traversal, and dynamic programming. It's designed as an educational tool to help students and practitioners understand how algorithms work step-by-step through visual demonstrations. The platform is particularly valuable for learning algorithm mechanics and complexity analysis through hands-on exploration.","use_cases":"Understanding how quicksort partitioning works before implementing it in production code, Learning graph algorithms like Dijkstra's shortest path for network optimization problems","audience":"Early-PhD, Junior-DS"},{"id":"resource-thealgorithms-python","type":"resource","name":"TheAlgorithms/Python","description":"200+ algorithm implementations in Python \u2014 reference code","category":"Software Engineering","url":"https://github.com/TheAlgorithms/Python","difficulty":"beginner","prerequisites":"python-basics, data-structures, big-o-notation","topic_tags":"algorithms, python-implementation, reference-code, computer-science, educational","summary":"A comprehensive collection of 200+ classic algorithm implementations in Python, providing clean reference code for fundamental computer science algorithms. The repository serves as both a learning resource for understanding algorithmic concepts and a practical reference for implementing common algorithms. It covers sorting, searching, graph algorithms, dynamic programming, and many other foundational topics with well-documented Python code.","use_cases":"Learning algorithm implementations while preparing for technical interviews, Finding reference code to implement a specific algorithm in a production system","audience":"Junior-DS, Early-PhD"},{"id":"resource-postman-academy","type":"resource","name":"Postman Academy","description":"Free API certification path \u2014 often more useful than scraping","category":"Software Engineering","url":"https://academy.postman.com/","difficulty":"beginner","prerequisites":"HTTP-requests, JSON-parsing","topic_tags":"API-integration, data-collection, web-services, certification","summary":"Postman Academy provides free certification courses for learning API fundamentals, testing, and integration techniques. It's particularly valuable for data scientists who need to collect data from web APIs instead of scraping websites. The structured learning path covers authentication, request handling, and best practices for working with RESTful services.","use_cases":"Collecting social media data from Twitter/LinkedIn APIs for analysis instead of web scraping, Integrating third-party payment or geolocation APIs into data pipelines","audience":"Junior-DS, Mid-DS"},{"id":"resource-playwright-for-python","type":"resource","name":"Playwright for Python","description":"Modern browser automation (faster than Selenium)","category":"Software Engineering","url":"https://playwright.dev/python/","difficulty":"beginner","prerequisites":"python-basics, web-scraping-concepts, HTML-CSS-selectors","topic_tags":"web-automation, browser-testing, data-collection, python-tools, web-scraping","summary":"Playwright is a modern Python library for automating web browsers that's significantly faster and more reliable than Selenium. It enables programmatic control of Chrome, Firefox, and Safari for web scraping, testing, and data collection tasks. Tech economists use it to gather data from dynamic websites, automate repetitive browser tasks, and build robust data pipelines.","use_cases":"Scraping dynamic pricing data from e-commerce sites that load content via JavaScript, Automating data collection from internal company dashboards and web applications","audience":"Junior-DS, Mid-DS"},{"id":"resource-discrete-optimization-(coursera)","type":"resource","name":"Discrete Optimization (Coursera)","description":"Van Hentenryck's course \u2014 actually makes you implement","category":"Linear Programming","url":"https://www.coursera.org/learn/solving-algorithms-discrete-optimization","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, algorithm-design","topic_tags":"discrete-optimization, constraint-programming, operations-research, implementation-focused, coursera","summary":"Van Hentenryck's hands-on Coursera course on discrete optimization that emphasizes practical implementation over theory. The course covers constraint programming, local search, and mixed integer programming with real coding assignments. Particularly valuable for learning how optimization algorithms actually work under the hood through direct implementation.","use_cases":"Learning to implement custom optimization solvers for resource allocation problems, Understanding optimization algorithms deeply enough to debug and tune performance in production systems","audience":"Mid-DS, Early-PhD"},{"id":"resource-brady-neal's-introduction-to-causal-inference","type":"resource","name":"Brady Neal's Introduction to Causal Inference","description":"14-week video course covering potential outcomes, DAGs, do-calculus, and causal discovery. Features guest lectures from Susan Athey, Alberto Abadie, and Yoshua Bengio. Bridges ML and econometric traditions.","category":"Fundamentals","url":"https://www.bradyneal.com/causal-inference-course","difficulty":"intermediate","prerequisites":"linear-regression, probability-theory, python-basics","topic_tags":"causal-inference, potential-outcomes, directed-acyclic-graphs, video-lectures, econometrics","summary":"A comprehensive 14-week video course teaching causal inference fundamentals including potential outcomes framework, DAGs, and do-calculus. Features guest lectures from leading researchers and bridges machine learning and econometric approaches to causal analysis.","use_cases":"Learning rigorous causal inference methods for A/B testing and observational studies, Transitioning from correlational analysis to causal modeling in product analytics","audience":"Junior-DS, Early-PhD"},{"id":"resource-stanford-ml-&-causal-inference-short-course","type":"resource","name":"Stanford ML & Causal Inference Short Course","description":"Video lectures from Susan Athey, Jann Spiess, and Stefan Wager covering ML vs. econometrics, ATEs with propensity scores, CATE estimation with causal forests, and loss functions for causal inference.","category":"Fundamentals","url":"https://www.gsb.stanford.edu/faculty-research/labs-initiatives/sil/research/methods/ai-machine-learning/short-course","difficulty":"intermediate","prerequisites":"linear-regression, python-scikit-learn, randomized-controlled-trials","topic_tags":"causal-inference, machine-learning, propensity-scores, causal-forests, video-lectures","summary":"Video course from Stanford faculty covering the intersection of machine learning and causal inference methods. Teaches how to estimate treatment effects using ML techniques like causal forests and propensity score methods. Ideal for data scientists wanting to move beyond correlational analysis to causal questions.","use_cases":"Measuring the causal impact of product features on user engagement using observational data, Estimating heterogeneous treatment effects across customer segments in marketing experiments","audience":"Junior-DS, Mid-DS"},{"id":"resource-matteo-courthoud's-causal-inference-blog","type":"resource","name":"Matteo Courthoud's Causal Inference Blog","description":"PhD economist writing for data scientists in tech. Covers selection bias, Frisch-Waugh-Lovell, weighting vs. matching, DAGs, and CUPED. Every post includes Python code with realistic examples.","category":"Fundamentals","url":"https://matteocourthoud.github.io/post/","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, statistical-significance","topic_tags":"causal-inference, selection-bias, DAGs, python-tutorials, experimentation","summary":"A comprehensive blog by PhD economist Matteo Courthoud that translates causal inference methods for data scientists working in tech companies. Each post combines theoretical foundations with practical Python implementations using realistic examples from tech scenarios.","use_cases":"Learning how to properly analyze A/B tests with selection bias using matching and weighting techniques, Understanding when and how to apply CUPED methodology to reduce variance in experiment analysis","audience":"Junior-DS, Mid-DS"},{"id":"resource-andrew-heiss's-dag-and-backdoor-tutorials","type":"resource","name":"Andrew Heiss's DAG and Backdoor Tutorials","description":"Hands-on tutorials on building DAGs with ggdag, backdoor criterion, confounders/colliders, d-separation, and propensity scores. Uses real variable names with complete R code.","category":"Fundamentals","url":"https://www.andrewheiss.com/blog/2020/02/25/closing-backdoors-dags/","difficulty":"beginner","prerequisites":"basic-R, ggplot2, linear-regression","topic_tags":"directed-acyclic-graphs, backdoor-criterion, confounders, propensity-scores, r-programming","summary":"Comprehensive R tutorials teaching how to build and analyze directed acyclic graphs (DAGs) using the ggdag package, with practical examples of identifying confounders, colliders, and applying the backdoor criterion. Covers essential causal inference concepts with complete, runnable code using realistic variable names rather than abstract examples.","use_cases":"Identifying which variables to control for when estimating treatment effects in observational studies, Building causal models to understand relationships between product features and user behavior","audience":"Early-PhD, Junior-DS"},{"id":"resource-uber-engineering:-causal-inference-at-uber","type":"resource","name":"Uber Engineering: Causal Inference at Uber","description":"Real industry application showing how PhD-level methods translate to business problems. Covers propensity score matching at scale, RDD for dynamic pricing, and mediation modeling.","category":"Fundamentals","url":"https://www.uber.com/blog/causal-inference-at-uber/","difficulty":"intermediate","prerequisites":"basic-regression, python-pandas, experimental-design","topic_tags":"causal-inference, propensity-score-matching, regression-discontinuity, mediation-analysis, industry-application","summary":"Uber Engineering's comprehensive guide to implementing causal inference methods in production systems. Shows how to scale propensity score matching, apply regression discontinuity design to dynamic pricing, and build mediation models for complex business problems. Bridges the gap between academic theory and real-world tech company applications.","use_cases":"measuring impact of product changes on user behavior at scale, evaluating dynamic pricing strategies using natural experiments","audience":"Mid-DS, Junior-DS"},{"id":"resource-asjad-naqvi's-did-repository","type":"resource","name":"Asjad Naqvi's DiD Repository","description":"The definitive meta-resource for modern DiD. Covers TWFE failures, Goodman-Bacon decomposition, all major estimators (Callaway-Sant'Anna, Sun-Abraham, etc.) with code in Stata, R, Python, and Julia. Updated quarterly.","category":"Difference-in-Differences","url":"https://asjadnaqvi.github.io/DiD/","difficulty":"intermediate","prerequisites":"difference-in-differences, panel-data-analysis, causal-inference-fundamentals","topic_tags":"difference-in-differences, causal-inference, staggered-adoption, TWFE, code-repository","summary":"A comprehensive repository covering modern difference-in-differences methods, addressing issues with traditional two-way fixed effects estimators. Includes implementation guides for all major estimators across multiple programming languages, making it the go-to resource for practitioners working with staggered treatment adoption designs.","use_cases":"Evaluating policy rollouts with different implementation dates across states or regions, Measuring impact of product feature launches that occurred at different times across user segments","audience":"Mid-DS, Senior-DS"},{"id":"resource-pedro-sant'anna's-did-resources","type":"resource","name":"Pedro Sant'Anna's DiD Resources","description":"14 lecture slide decks from the co-creator of Callaway-Sant'Anna. Covers classical DiD, parallel trends, ML for DiD, event studies, TWFE problems, and treatments turning on-and-off.","category":"Difference-in-Differences","url":"https://psantanna.com/did-resources/","difficulty":"intermediate","prerequisites":"regression-analysis, difference-in-differences, panel-data","topic_tags":"difference-in-differences, causal-inference, lecture-slides, TWFE, event-studies","summary":"Comprehensive lecture slides from Pedro Sant'Anna, co-creator of the Callaway-Sant'Anna DiD estimator. Covers modern DiD methods including staggered treatment timing, TWFE problems, and advanced applications with machine learning. Essential resource for understanding cutting-edge developments in difference-in-differences methodology.","use_cases":"Learning modern DiD methods to handle staggered treatment adoption in tech product rollouts, Understanding TWFE bias issues when evaluating policy interventions with heterogeneous treatment timing","audience":"Early-PhD, Mid-DS"},{"id":"resource-jonathan-roth's-did-resources","type":"resource","name":"Jonathan Roth's DiD Resources","description":"Course slides and coding exercises focusing on pre-trends testing limitations and HonestDiD sensitivity analysis. Created the HonestDiD and pretrends R packages. Includes practitioner checklists.","category":"Difference-in-Differences","url":"https://www.jonathandroth.com/did-resources/","difficulty":"intermediate","prerequisites":"difference-in-differences, R-programming, linear-regression","topic_tags":"difference-in-differences, pre-trends-testing, sensitivity-analysis, causal-inference, R-packages","summary":"Jonathan Roth's comprehensive DiD resources covering advanced robustness techniques including pre-trends testing and sensitivity analysis. Features the HonestDiD and pretrends R packages with practical implementation guides and checklists for practitioners.","use_cases":"Testing robustness of DiD estimates when parallel trends assumption is questionable, Implementing sensitivity analysis for policy evaluation studies with potential pre-existing trends","audience":"Mid-DS, Senior-DS"},{"id":"resource-matteo-courthoud's-did-tutorial","type":"resource","name":"Matteo Courthoud's DiD Tutorial","description":"Industry perspective with full Python code. Covers classic DiD with potential outcomes, parallel trends testing, multiple time periods, Card-Krueger replication, and business applications.","category":"Difference-in-Differences","url":"https://matteocourthoud.github.io/post/diff_in_diffs/","difficulty":"intermediate","prerequisites":"python-pandas, basic-regression, causal-inference-fundamentals","topic_tags":"difference-in-differences, causal-inference, python-tutorial, business-applications, potential-outcomes","summary":"A comprehensive Python tutorial on Difference-in-Differences methodology from an industry practitioner's perspective. Covers foundational DiD concepts using potential outcomes framework, parallel trends testing, and extensions to multiple time periods with full code implementation. Includes the classic Card-Krueger minimum wage study replication and practical business applications.","use_cases":"Evaluating impact of policy changes or product launches on business metrics, Measuring causal effects of interventions when randomized experiments aren't feasible","audience":"Junior-DS, Mid-DS"},{"id":"resource-mixtape-sessions-github-repository","type":"resource","name":"Mixtape Sessions GitHub Repository","description":"Free workshop materials from sessions taught at Facebook, eBay, LSE, and Oxford. Covers advanced DiD, staggered timing, PT violations, with coding labs and interactive apps.","category":"Difference-in-Differences","url":"https://github.com/Mixtape-Sessions","difficulty":"intermediate","prerequisites":"difference-in-differences, R-programming, causal-inference-basics","topic_tags":"difference-in-differences, causal-inference, workshop-materials, staggered-adoption, coding-labs","summary":"Comprehensive workshop materials from top-tier institutions covering advanced difference-in-differences methods including staggered timing and parallel trends violations. Features hands-on coding labs and interactive applications for practical implementation of modern DiD techniques.","use_cases":"Learning how to handle staggered treatment adoption in product rollout analysis, Implementing robust DiD estimators when parallel trends assumption is violated","audience":"Mid-DS, Early-PhD"},{"id":"resource-matteo-courthoud's-iv-tutorial","type":"resource","name":"Matteo Courthoud's IV Tutorial","description":"IV in experimental settings with realistic tech examples (newsletter subscription as instrument). Covers LATE/Compliers interpretation, exclusion restriction, weak instruments diagnostics. Complete Python code.","category":"IV & RDD","url":"https://matteocourthoud.github.io/post/instrumental_variables/","difficulty":"intermediate","prerequisites":"python-pandas, basic-regression, experimental-design","topic_tags":"instrumental-variables, LATE, experimental-methods, tech-economics, python-tutorial","summary":"A comprehensive tutorial on instrumental variables in experimental settings with practical tech industry examples like newsletter subscriptions as instruments. Covers Local Average Treatment Effects (LATE), compliers interpretation, exclusion restriction validation, and weak instruments diagnostics with complete Python implementation.","use_cases":"measuring causal effect of product feature adoption when randomized encouragement doesn't achieve full compliance, evaluating impact of training programs when participation is voluntary despite random assignment to receive invitations","audience":"Junior-DS, Mid-DS"},{"id":"resource-matteo-courthoud's-rdd-tutorial","type":"resource","name":"Matteo Courthoud's RDD Tutorial","description":"RDD fundamentals, bandwidth selection methods, and replication of Lee, Moretti, Butler (2004). Practical implementation with Python code using statsmodels.","category":"IV & RDD","url":"https://matteocourthoud.github.io/post/regression_discontinuity/","difficulty":"beginner","prerequisites":"python-pandas, basic-econometrics, statsmodels","topic_tags":"regression-discontinuity, causal-inference, python-tutorial, bandwidth-selection, replication-study","summary":"A comprehensive tutorial covering regression discontinuity design fundamentals, including bandwidth selection techniques and hands-on replication of the classic Lee, Moretti, Butler (2004) paper. Provides practical Python implementation using statsmodels with step-by-step code examples for learning RDD methodology.","use_cases":"Evaluating impact of policy changes with eligibility thresholds, Analyzing treatment effects when assignment is based on continuous scoring rules","audience":"Early-PhD, Junior-DS"},{"id":"resource-andrew-heiss's-rdd-course-examples","type":"resource","name":"Andrew Heiss's RDD Course Examples","description":"Complete sharp vs. fuzzy RDD comparison with downloadable datasets. Shows rdrobust() usage, 2SLS with iv_robust(), and compliance visualization. Reproducible R code with tidyverse.","category":"IV & RDD","url":"https://evalf20.classes.andrewheiss.com/example/rdd/","difficulty":"intermediate","prerequisites":"R-programming, regression-analysis, instrumental-variables","topic_tags":"regression-discontinuity, causal-inference, R-tutorials, econometric-methods, reproducible-research","summary":"Comprehensive tutorial comparing sharp and fuzzy regression discontinuity designs with hands-on R implementation. Covers rdrobust() package usage and 2SLS estimation with iv_robust(), including practical examples with real datasets. Perfect for learning RDD methodology through reproducible code examples.","use_cases":"Evaluating policy interventions with arbitrary cutoff thresholds, Analyzing treatment effects when compliance varies around discontinuity points","audience":"Junior-DS, Early-PhD"},{"id":"resource-tilburg-science-hub-rdd-tutorials","type":"resource","name":"Tilburg Science Hub RDD Tutorials","description":"Based on Cattaneo, Idrobo & Titiunik. Covers ITT vs. LATE, monotonicity, bandwidth selection for fuzzy designs, and multi-dimensional RDD. Includes Colombian education subsidy replication.","category":"IV & RDD","url":"https://tilburgsciencehub.com/topics/analyze/causal-inference/rdd/fuzzy-rdd/","difficulty":"intermediate","prerequisites":"instrumental-variables, basic-econometrics, R-programming","topic_tags":"regression-discontinuity, fuzzy-RDD, bandwidth-selection, causal-inference, tutorial","summary":"Comprehensive tutorial series on regression discontinuity design based on the authoritative Cattaneo, Idrobo & Titiunik framework. Covers advanced topics like fuzzy RDD, bandwidth optimization, and multi-dimensional designs with hands-on replication of Colombian education policy research.","use_cases":"Evaluating impact of scholarship programs with income eligibility thresholds, Analyzing effects of policy interventions with age or score-based cutoffs","audience":"Early-PhD, Mid-DS"},{"id":"resource-teconomics-blog:-ml-meets-instrumental-variables","type":"resource","name":"Teconomics Blog: ML Meets Instrumental Variables","description":"How to reframe past A/B tests as instruments for behaviors you cannot randomize. Covers IV for behavioral effects, Deep IV, and ML for instrument selection. Actionable for data scientists.","category":"IV & RDD","url":"https://medium.com/teconomics-blog/machine-learning-meets-instrumental-variables-c8eecf5cec95","difficulty":"intermediate","prerequisites":"instrumental-variables, python-scikit-learn, A-B-testing","topic_tags":"instrumental-variables, deep-iv, causal-inference, behavioral-analysis, experiment-design","summary":"A practical guide for data scientists on using machine learning techniques with instrumental variables to analyze behavioral effects from past A/B tests. Covers reframing experiments as instruments for non-randomizable behaviors and selecting valid instruments using ML methods. Provides actionable frameworks for measuring indirect causal effects in tech settings.","use_cases":"Using past feature rollout experiments as instruments to measure how user engagement affects long-term retention, Leveraging randomized notification experiments to estimate causal effects of app usage on purchasing behavior","audience":"Mid-DS, Junior-DS"},{"id":"resource-matteo-courthoud's-synthetic-control-tutorial","type":"resource","name":"Matteo Courthoud's Synthetic Control Tutorial","description":"SCM for industry practitioners with references to Google, Uber, Facebook use cases. Python implementation with sklearn and cvxpy. Explains SCM as 'transpose of regression' with placebo inference.","category":"Synthetic Control","url":"https://matteocourthoud.github.io/post/synth/","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, causal-inference-basics","topic_tags":"synthetic-control, causal-inference, python-implementation, industry-applications, placebo-testing","summary":"A practical tutorial on Synthetic Control Methods for industry data scientists, featuring real examples from major tech companies like Google, Uber, and Facebook. Includes Python implementation using sklearn and cvxpy, with emphasis on placebo inference and understanding SCM as the 'transpose of regression'.","use_cases":"Measuring impact of product launches when randomized experiments aren't feasible, Evaluating policy changes or interventions across different markets or regions","audience":"Junior-DS, Mid-DS"},{"id":"resource-alberto-abadie's-nber-methods-lecture","type":"resource","name":"Alberto Abadie's NBER Methods Lecture","description":"Directly from the inventor of synthetic control methods. NBER Summer Institute lecture on foundational theory, best practices, when to use SCM vs. alternatives, and recent developments.","category":"Synthetic Control","url":"https://www.nber.org/research/videos/2021-methods-lecture-alberto-abadie-synthetic-controls-methods-and-practice","difficulty":"intermediate","prerequisites":"difference-in-differences, regression-analysis, panel-data","topic_tags":"synthetic-control, causal-inference, NBER-lecture, policy-evaluation, counterfactual-analysis","summary":"NBER Summer Institute lecture by Alberto Abadie, the creator of synthetic control methods, covering foundational theory and practical implementation guidance. Covers when to use synthetic control versus other causal inference methods, best practices for implementation, and recent methodological developments. Essential viewing for anyone looking to understand or apply synthetic control methods properly.","use_cases":"Evaluating the causal impact of a policy change in one state/country using other regions as controls, Measuring the effect of a product launch in one market by creating a synthetic control from similar untreated markets","audience":"Mid-DS, Early-PhD"},{"id":"resource-google's-causalimpact-blog-post","type":"resource","name":"Google's CausalImpact Blog Post","description":"Production-grade tool from Google's advertising team. Bayesian structural time-series approach with automatic variable selection and uncertainty quantification. Widely used for marketing impact analysis.","category":"Synthetic Control","url":"https://opensource.googleblog.com/2014/09/causalimpact-new-open-source-package.html","difficulty":"intermediate","prerequisites":"R-programming, bayesian-inference, time-series-analysis","topic_tags":"causal-impact, marketing-attribution, bayesian-structural-time-series, google-tools, blog-post","summary":"Google's CausalImpact is a production-ready R package that uses Bayesian structural time-series models to estimate causal effects of interventions. Originally developed by Google's advertising team, it automatically handles variable selection and provides uncertainty quantification for impact analysis. The tool is particularly popular in marketing and product analytics for measuring the incremental impact of campaigns or feature launches.","use_cases":"measuring-incremental-lift-from-marketing-campaigns, evaluating-impact-of-product-feature-launches","audience":"Mid-DS, Junior-DS"},{"id":"resource-stitch-fix:-market-matching-with-causalimpact","type":"resource","name":"Stitch Fix: Market Matching with CausalImpact","description":"Industry application combining dynamic time warping with CausalImpact for marketing intervention analysis. Shows how synthetic control concepts are adapted for real business problems at scale.","category":"Synthetic Control","url":"https://multithreaded.stitchfix.com/blog/2016/01/13/market-watch/","difficulty":"intermediate","prerequisites":"causalimpact-package, dynamic-time-warping, synthetic-control-methods","topic_tags":"synthetic-control, causal-inference, marketing-analytics, industry-case-study, time-series","summary":"Real-world case study from Stitch Fix showing how to combine dynamic time warping with Google's CausalImpact package for marketing intervention analysis. Demonstrates practical implementation of synthetic control methods for measuring campaign effectiveness in an e-commerce setting at scale.","use_cases":"measuring impact of marketing campaigns on customer acquisition, evaluating effectiveness of promotional interventions in retail","audience":"Mid-DS, Junior-DS"},{"id":"resource-matteo-courthoud's-meta-learners-tutorial","type":"resource","name":"Matteo Courthoud's Meta-Learners Tutorial","description":"S-learner, T-learner, X-learner with detailed math, causal trees/forests, AIPW estimators. Uses Uber's CausalML package for demos. Complete Jupyter notebooks on GitHub.","category":"Causal ML","url":"https://matteocourthoud.github.io/post/meta_learners/","difficulty":"intermediate","prerequisites":"python-scikit-learn, regression-analysis, treatment-effect-estimation","topic_tags":"meta-learners, causal-ml, heterogeneous-treatment-effects, jupyter-notebooks, causalml-package","summary":"Comprehensive tutorial covering meta-learner approaches (S-learner, T-learner, X-learner) for estimating heterogeneous treatment effects in machine learning settings. Includes mathematical foundations, causal trees/forests, and AIPW estimators with hands-on implementation using Uber's CausalML package. Features complete Jupyter notebooks with practical examples for learning and application.","use_cases":"Estimating personalized treatment effects in A/B tests with heterogeneous user populations, Building recommendation systems that account for differential treatment responses across customer segments","audience":"Mid-DS, Junior-DS"},{"id":"resource-kdd-2021-tutorial:-causal-inference-with-econml-and-causalml","type":"resource","name":"KDD 2021 Tutorial: Causal Inference with EconML and CausalML","description":"Industry workshop with 4 case studies from Uber, TripAdvisor, Microsoft. Ready-to-run Google Colab notebooks covering uplift modeling, customer segmentation, and long-term ROI estimation.","category":"Causal ML","url":"https://causal-machine-learning.github.io/kdd2021-tutorial/","difficulty":"intermediate","prerequisites":"python-pandas, regression-analysis, A/B-testing","topic_tags":"causal-inference, uplift-modeling, econml, causalml, tutorial","summary":"Hands-on tutorial from KDD 2021 featuring industry practitioners from major tech companies demonstrating causal inference applications. Includes ready-to-run Google Colab notebooks with real-world case studies covering uplift modeling, customer segmentation, and ROI measurement using EconML and CausalML packages.","use_cases":"Measuring incremental impact of marketing campaigns on customer conversion, Estimating long-term revenue effects of product feature changes","audience":"Junior-DS, Mid-DS"},{"id":"resource-double-debiased-machine-learning-guide","type":"resource","name":"Double/Debiased Machine Learning Guide","description":"From the original DML authors. Explains Neyman orthogonality, cross-fitting, DML with text/complex data. Focuses on practical implementation rather than theory.","category":"Causal ML","url":"https://dmlguide.github.io/","difficulty":"intermediate","prerequisites":"scikit-learn, causal-inference-basics, cross-validation","topic_tags":"double-machine-learning, neyman-orthogonality, cross-fitting, treatment-effects, implementation-guide","summary":"A practical guide to Double/Debiased Machine Learning (DML) written by the original method creators. Covers key concepts like Neyman orthogonality and cross-fitting with focus on real-world implementation including text and complex data applications. Emphasizes practical coding and deployment over mathematical theory.","use_cases":"Estimating causal effects of product features using observational data with high-dimensional controls, Measuring impact of marketing campaigns while controlling for complex user behavior patterns","audience":"Mid-DS, Junior-DS"},{"id":"resource-mark-white's-practical-causal-forest-tutorial","type":"resource","name":"Mark White's Practical Causal Forest Tutorial","description":"Explains why optimize directly on causal effects, not outcomes. Complete workflow from data prep to interpretation using GRF package. Written for applied researchers transitioning to causal ML.","category":"Causal ML","url":"https://www.markhw.com/blog/causalforestintro","difficulty":"intermediate","prerequisites":"random-forests, causal-inference-basics, R-programming","topic_tags":"causal-forests, heterogeneous-treatment-effects, GRF-package, tutorial, causal-ML","summary":"A practical tutorial explaining how to implement causal forests using the GRF package, focusing on optimizing directly on causal effects rather than outcomes. Provides a complete workflow from data preparation to interpretation specifically designed for applied researchers making the transition from traditional causal inference to causal machine learning methods.","use_cases":"estimating heterogeneous treatment effects in A/B tests across user segments, identifying which customers benefit most from a pricing intervention","audience":"Mid-DS, Junior-DS"},{"id":"resource-uber-engineering:-uplift-modeling-for-multiple-treatments","type":"resource","name":"Uber Engineering: Uplift Modeling for Multiple Treatments","description":"Extending X-Learner and R-Learner to multiple treatments with cost optimization. Production system design for uplift models at scale with cost-aware treatment allocation.","category":"Causal ML","url":"https://www.uber.com/blog/research/uplift-modeling-for-multiple-treatments-with-cost-optimization/","difficulty":"advanced","prerequisites":"causal-inference-fundamentals, x-learner, r-learner","topic_tags":"uplift-modeling, multiple-treatments, causal-ml, production-systems, cost-optimization","summary":"Advanced uplift modeling techniques extending X-Learner and R-Learner frameworks to handle multiple treatment scenarios with integrated cost considerations. Covers production-scale implementation strategies for deploying uplift models in real-world systems where treatment allocation decisions must optimize for both effectiveness and cost constraints.","use_cases":"Multi-tier pricing optimization where you need to decide between discount levels, free trials, and premium upgrades, Marketing campaign allocation across email, push notifications, and SMS with different costs per channel","audience":"Senior-DS, Mid-DS"},{"id":"resource-evan-miller's-a-b-testing-tools","type":"resource","name":"Evan Miller's A/B Testing Tools","description":"Interactive calculators for sample size, chi-squared, sequential sampling, and t-tests. The companion article 'How Not To Run an A/B Test' is the canonical reference on why repeated significance testing inflates false positives.","category":"A/B Testing Fundamentals","url":"https://www.evanmiller.org/ab-testing/","difficulty":"beginner","prerequisites":"basic-statistics, hypothesis-testing","topic_tags":"sample-size-calculation, statistical-significance, online-experimentation, interactive-calculators","summary":"Collection of interactive web calculators for A/B testing fundamentals including sample size determination, statistical significance testing, and sequential analysis. Paired with essential reading on common A/B testing pitfalls, particularly the dangers of peeking at results before completion.","use_cases":"Calculating required sample size before launching a product feature test, Determining if conversion rate differences between variants are statistically significant","audience":"Junior-DS, Mid-DS"},{"id":"resource-growthbook's-experimentation-fundamentals","type":"resource","name":"GrowthBook's Experimentation Fundamentals","description":"Complete single-page reference covering hypothesis formation, statistical significance, Type I/II errors, MDE, power analysis, A/A tests, novelty effects, and experiment interactions. Notes that industry success rates are only ~33%.","category":"A/B Testing Fundamentals","url":"https://docs.growthbook.io/using/fundamentals","difficulty":"beginner","prerequisites":"basic-statistics, hypothesis-testing","topic_tags":"experimentation, statistical-significance, power-analysis, reference-guide","summary":"Comprehensive single-page guide covering all fundamentals of running A/B tests, from hypothesis formation to statistical concepts like power analysis and effect sizes. Essential reference for anyone starting with experimentation, providing both theoretical foundations and practical insights like realistic industry success rates.","use_cases":"Learning how to design and analyze your first A/B test at a tech company, Quick reference when setting up experiment parameters like minimum detectable effect and sample size","audience":"Junior-DS, Early-PhD"},{"id":"resource-matteo-courthoud's-experimentation-series","type":"resource","name":"Matteo Courthoud's Experimentation Series","description":"Connects experimentation to econometric foundations. Covers CUPED (linking to DiD), group sequential testing, Bayesian A/B testing, and clustered standard errors. Every post includes complete Python code.","category":"A/B Testing Fundamentals","url":"https://matteocourthoud.github.io/post/","difficulty":"intermediate","prerequisites":"python-pandas, hypothesis-testing, regression-analysis","topic_tags":"experimentation, CUPED, bayesian-ab-testing, clustered-standard-errors, python-tutorials","summary":"A comprehensive tutorial series that bridges classical econometric methods with modern A/B testing practices. Covers advanced variance reduction techniques like CUPED, sequential testing approaches, and Bayesian methods with full Python implementations. Ideal for data scientists who want to understand the statistical foundations behind experimentation frameworks.","use_cases":"Implementing CUPED to reduce variance in product experiments at a tech company, Setting up group sequential testing for early stopping decisions in marketing campaigns","audience":"Junior-DS, Mid-DS"},{"id":"resource-netflix-tech-blog:-what-is-an-a-b-test?","type":"resource","name":"Netflix Tech Blog: What is an A/B Test?","description":"Multi-part series covering metric selection, sequential testing at scale, quasi-experimentation when SUTVA is violated, and interleaving for recommendation testing. Published at KDD.","category":"A/B Testing Fundamentals","url":"https://netflixtechblog.com/what-is-an-a-b-test-b08cc1b57962","difficulty":"intermediate","prerequisites":"hypothesis-testing, basic-statistics, randomized-controlled-trials","topic_tags":"a-b-testing, experimentation, causal-inference, netflix, tech-blog","summary":"Netflix's comprehensive guide to A/B testing methodology covering practical implementation challenges at scale. The series addresses advanced topics like metric selection, sequential testing, quasi-experimental methods when randomization assumptions are violated, and interleaving techniques for recommendation systems. Essential reading for practitioners running experiments in tech environments.","use_cases":"designing and analyzing product feature tests at a tech company, implementing recommendation system experiments with proper statistical controls","audience":"Junior-DS, Mid-DS"},{"id":"resource-understanding-cuped-by-matteo-courthoud","type":"resource","name":"Understanding CUPED by Matteo Courthoud","description":"Mathematical derivation from first principles: optimal covariate formula \u03b8 = Cov(X,Y)/Var(X) and variance reduction Var(\u0176_cuped) = Var(\u0232)(1 - \u03c1\u00b2). Compares with DiD and Frisch-Waugh-Lovell theorem. Full Python code.","category":"Variance Reduction","url":"https://matteocourthoud.github.io/post/cuped/","difficulty":"intermediate","prerequisites":"linear-regression, covariance-analysis, python-pandas","topic_tags":"cuped, variance-reduction, ab-testing, covariate-adjustment, python-tutorial","summary":"This resource provides a complete mathematical derivation of CUPED (Controlled-experiment Using Pre-Experiment Data) from first principles, showing how pre-experiment covariates reduce variance in A/B tests. It includes the optimal weight formula and connects CUPED to difference-in-differences and regression theory. Complete with Python implementation for practical application.","use_cases":"Reducing variance in A/B test metrics when you have pre-experiment user behavior data, Improving statistical power of experiments by leveraging historical baseline measurements","audience":"Mid-DS, Early-PhD"},{"id":"resource-booking.com:-increasing-power-with-cuped","type":"resource","name":"Booking.com: Increasing Power with CUPED","description":"Production-ready Hive SQL and Spark/R implementations for big-data scale. Handles missing pre-experiment data gracefully with real A/B test case study showing faster significance achievement.","category":"Variance Reduction","url":"https://booking.ai/how-booking-com-increases-the-power-of-online-experiments-with-cuped-995d186fff1d","difficulty":"intermediate","prerequisites":"SQL-window-functions, A-B-testing, hive-sql","topic_tags":"CUPED, variance-reduction, production-implementation, big-data, spark","summary":"Production-ready implementation of CUPED (Controlled-experiments Using Pre-Experiment Data) for reducing variance in A/B tests at scale. Includes Hive SQL and Spark/R code that handles real-world data issues like missing pre-experiment values. Shows how to achieve statistical significance faster through variance reduction techniques.","use_cases":"Running A/B tests on large user bases where pre-experiment behavioral data can reduce noise, Implementing CUPED in production data pipelines to speed up experiment decision-making","audience":"Mid-DS, Senior-DS"},{"id":"resource-statsig's-cuped-deep-dive","type":"resource","name":"Statsig's CUPED Deep Dive","description":"Outstanding pedagogy using running/weights example. Demonstrates t-test and OLS regression equivalence, shows standard error reduction from 4.73 to 2.13, covers stratification approaches.","category":"Variance Reduction","url":"https://www.statsig.com/blog/cuped","difficulty":"intermediate","prerequisites":"t-tests, linear-regression, experimental-design","topic_tags":"CUPED, variance-reduction, A-B-testing, causal-inference, tutorial","summary":"A comprehensive tutorial on CUPED (Controlled-experiments Using Pre-Existing Data) for reducing variance in A/B tests. Uses an intuitive running/weights example to show how incorporating pre-treatment covariates can dramatically reduce standard errors and improve experimental power. Demonstrates the mathematical equivalence between t-test and OLS approaches while covering practical stratification techniques.","use_cases":"Improving power in low-conversion A/B tests by using historical user behavior data, Reducing sample size requirements for experiments by leveraging pre-treatment metrics","audience":"Junior-DS, Mid-DS"},{"id":"resource-eppo:-cuped++-for-extended-variance-reduction","type":"resource","name":"Eppo: CUPED++ for Extended Variance Reduction","description":"CUPED++ extension using multiple pre-experiment metrics as covariates. Addresses 'new users have no pre-data' limitation. Quantifies impact: experiments can conclude 65% faster.","category":"Variance Reduction","url":"https://www.geteppo.com/blog/cuped-bending-time-in-experimentation","difficulty":"intermediate","prerequisites":"A/B-testing, CUPED, linear-regression","topic_tags":"CUPED, variance-reduction, A/B-testing, experimentation, covariates","summary":"CUPED++ extends the classic CUPED variance reduction technique by using multiple pre-experiment metrics as covariates instead of just one. This advancement specifically addresses the limitation where new users lack historical data, enabling experiments to reach statistical significance 65% faster across broader user populations.","use_cases":"Reducing experiment runtime when testing product changes on mixed populations of new and existing users, Improving statistical power in A/B tests for mobile apps or platforms with high user churn rates","audience":"Mid-DS, Senior-DS"},{"id":"resource-doordash:-cupac-for-ml-enhanced-variance-reduction","type":"resource","name":"DoorDash: CUPAC for ML-Enhanced Variance Reduction","description":"CUPAC (Control Using Predictions As Covariate) - ML-based CUPED extension for when standard CUPED fails. Achieved 25%+ reduction in switchback test duration.","category":"Variance Reduction","url":"https://careersatdoordash.com/blog/improving-experimental-power-through-control-using-predictions-as-covariate-cupac/","difficulty":"intermediate","prerequisites":"CUPED, control-variates, regression-analysis","topic_tags":"CUPAC, variance-reduction, experimentation, A/B-testing, machine-learning","summary":"CUPAC extends CUPED by using machine learning predictions as control variates when standard CUPED assumptions fail. DoorDash developed this method to achieve 25%+ reduction in switchback test duration by leveraging ML models to create better variance reduction controls.","use_cases":"Reducing variance in marketplace experiments where traditional pre-period controls don't satisfy CUPED assumptions, Shortening switchback experiment duration by using ML predictions to control for confounding factors","audience":"Mid-DS, Senior-DS"},{"id":"resource-spotify:-choosing-a-sequential-testing-framework","type":"resource","name":"Spotify: Choosing a Sequential Testing Framework","description":"The definitive industry comparison of five frameworks: GST, mSPRT, GAVI, Corrected-Alpha, Bonferroni. Monte Carlo simulations comparing power. Maps methods to companies: GST (Spotify), mSPRT (Optimizely, Uber, Netflix).","category":"Sequential Testing","url":"https://engineering.atspotify.com/2023/03/choosing-sequential-testing-framework-comparisons-and-discussions","difficulty":"intermediate","prerequisites":"hypothesis-testing, statistical-power-analysis, monte-carlo-simulation","topic_tags":"sequential-testing, a-b-testing, experimental-design, statistical-power, industry-comparison","summary":"A comprehensive industry comparison of five sequential testing frameworks used by major tech companies, evaluated through Monte Carlo simulations for statistical power. Maps specific methods to real companies: GST at Spotify, mSPRT at Optimizely/Uber/Netflix, providing practical guidance for choosing frameworks. Essential reference for data scientists implementing continuous experimentation systems.","use_cases":"Selecting the right sequential testing framework for your company's A/B testing platform, Benchmarking statistical power trade-offs when implementing early stopping rules for experiments","audience":"Mid-DS, Senior-DS"},{"id":"resource-evan-miller:-simple-sequential-a-b-testing","type":"resource","name":"Evan Miller: Simple Sequential A/B Testing","description":"Derives a simple sequential test using gambler's ruin: stop when T-C reaches 2\u221aN. Elegant and implementable with basic arithmetic. Includes interactive calculator.","category":"Sequential Testing","url":"https://www.evanmiller.org/sequential-ab-testing.html","difficulty":"intermediate","prerequisites":"hypothesis-testing, probability-theory, basic-calculus","topic_tags":"sequential-testing, ab-testing, stopping-rules, experimentation, gamblers-ruin","summary":"Evan Miller presents an elegant sequential A/B testing method derived from gambler's ruin theory, with a simple stopping rule: stop when T-C reaches 2\u221aN. This approach allows practitioners to monitor experiments continuously and stop early when significance is reached, using only basic arithmetic rather than complex statistical software.","use_cases":"Running product experiments where you want to stop as soon as statistical significance is achieved to save time and resources, Implementing sequential testing in production systems where complex statistical libraries aren't available but basic math operations are feasible","audience":"Mid-DS, Junior-DS"},{"id":"resource-matteo-courthoud:-group-sequential-testing","type":"resource","name":"Matteo Courthoud: Group Sequential Testing","description":"Pedagogical progression from peeking problem through Bonferroni, Pocock, O'Brien-Fleming to Lan-DeMets alpha-spending. Simulates 10,000 experiments showing Type I error rates. Full Python code.","category":"Sequential Testing","url":"https://matteocourthoud.github.io/post/group_sequential_testing/","difficulty":"intermediate","prerequisites":"hypothesis-testing, python-scipy, monte-carlo-simulation","topic_tags":"group-sequential-testing, alpha-spending, bonferroni-correction, experimentation-methods, python-tutorial","summary":"A comprehensive tutorial on group sequential testing methods that addresses the multiple testing problem when analyzing experiments before completion. Covers classical approaches like Bonferroni and Pocock boundaries, modern alpha-spending functions, and includes Monte Carlo simulations to demonstrate Type I error control. Essential for data scientists running experiments who need to peek at results while maintaining statistical validity.","use_cases":"A/B testing at a tech company where business stakeholders want weekly updates on experiment progress, Clinical trial analysis where interim monitoring is required for safety and efficacy decisions","audience":"Mid-DS, Junior-DS"},{"id":"resource-netflix:-sequential-a-b-testing-keeps-the-world-streaming","type":"resource","name":"Netflix: Sequential A/B Testing Keeps the World Streaming","description":"Anytime-valid inference at production scale. Real case study: detecting play-delay issues that would have prevented 60% of devices from streaming. Covers time-uniform confidence bands.","category":"Sequential Testing","url":"https://netflixtechblog.com/sequential-a-b-testing-keeps-the-world-streaming-netflix-part-1-continuous-data-cba6c7ed49df","difficulty":"intermediate","prerequisites":"hypothesis-testing, confidence-intervals, A-B-testing-fundamentals","topic_tags":"sequential-testing, anytime-valid-inference, production-experimentation, netflix-case-study","summary":"Netflix's approach to sequential A/B testing using anytime-valid inference methods for production-scale experimentation. Demonstrates how time-uniform confidence bands enabled detection of critical streaming issues affecting majority of devices. Shows practical implementation of sequential testing to make decisions before traditional fixed-horizon experiments conclude.","use_cases":"Detecting critical product issues early in A/B tests before waiting for full experiment duration, Running continuous monitoring of product changes with valid statistical inference at any time point","audience":"Mid-DS, Senior-DS"},{"id":"resource-doordash:-switchback-tests-under-network-effects","type":"resource","name":"DoorDash: Switchback Tests Under Network Effects","description":"Why traditional A/B tests fail in three-sided marketplaces and how switchback testing with region-time randomization solves interference. Uses 30-minute time windows.","category":"Interference & Switchback","url":"https://careersatdoordash.com/blog/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash/","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, statistical-inference, causal-inference","topic_tags":"switchback-testing, network-effects, marketplace-experimentation, causal-inference, doordash","summary":"DoorDash's approach to experimentation in three-sided marketplaces where traditional A/B tests fail due to interference between users, drivers, and merchants. Uses switchback methodology with geographic and temporal randomization in 30-minute windows to isolate treatment effects and handle network spillovers.","use_cases":"Testing pricing changes in rideshare/delivery platforms where driver supply affects all users, Evaluating marketplace features where merchant behavior impacts customer experience across regions","audience":"Mid-DS, Senior-DS"},{"id":"resource-doordash:-statistical-analysis-for-switchback-experiments","type":"resource","name":"DoorDash: Statistical Analysis for Switchback Experiments","description":"Deep methodology comparing OLS, Multi-Level Modeling, and Cluster Robust Standard Errors for switchback analysis. Addresses small independent units problem. Achieved 30% faster iterations.","category":"Interference & Switchback","url":"https://doordash.engineering/2019/02/20/experiment-rigor-for-switchback-experiment-analysis/","difficulty":"advanced","prerequisites":"linear-regression, clustered-standard-errors, multilevel-modeling","topic_tags":"switchback-experiments, statistical-inference, causal-analysis, marketplace-experiments, methodology-comparison","summary":"DoorDash's comprehensive statistical methodology guide for analyzing switchback experiments, comparing three key approaches: OLS, Multi-Level Modeling, and Cluster Robust Standard Errors. Specifically addresses the challenge of small independent units in marketplace settings and demonstrates how proper statistical methods can accelerate experiment iteration cycles by 30%.","use_cases":"Analyzing marketplace experiments where users switch between treatment and control over time, Choosing appropriate statistical methods when you have limited independent clusters in your switchback design","audience":"Senior-DS, Mid-DS"},{"id":"resource-lyft:-experimentation-in-a-ridesharing-marketplace","type":"resource","name":"Lyft: Experimentation in a Ridesharing Marketplace","description":"Foundational article on SUTVA violations through potential outcomes framework. The bias-variance tradeoff table for randomization schemes (user to city level) is highly cited.","category":"Interference & Switchback","url":"https://eng.lyft.com/experimentation-in-a-ridesharing-marketplace-b39db027a66e","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, potential-outcomes-framework, statistical-inference","topic_tags":"SUTVA-violations, marketplace-experiments, randomization-schemes, bias-variance-tradeoff, network-effects","summary":"This foundational article explains how standard experimental assumptions (SUTVA) break down in ridesharing marketplaces due to network effects and interference between users. It provides a framework for understanding different randomization schemes from user-level to city-level and their associated bias-variance tradeoffs. The resource is essential for anyone designing experiments in two-sided marketplaces or networked environments.","use_cases":"Designing A/B tests for marketplace platforms where treatment of some users affects others, Choosing appropriate randomization units when network effects violate standard experimental assumptions","audience":"Mid-DS, Senior-DS"},{"id":"resource-statsig:-switchback-experiments-overview","type":"resource","name":"Statsig: Switchback Experiments Overview","description":"Best introductory resource with clear visual diagrams showing traditional A/B vs. switchback designs. Covers burn-in and burn-out periods to prevent cross-contamination.","category":"Interference & Switchback","url":"https://www.statsig.com/blog/switchback-experiments","difficulty":"beginner","prerequisites":"A-B-testing-basics, experimental-design-fundamentals","topic_tags":"switchback-experiments, interference-mitigation, experimentation-design, A-B-testing, visual-guide","summary":"An introductory guide to switchback experiments that addresses interference problems in traditional A/B tests. Uses clear visual diagrams to explain how switchback designs alternate treatments over time and includes burn-in/burn-out periods to prevent contamination. Essential reading for anyone dealing with network effects or spillover in experiments.","use_cases":"Testing ride-sharing pricing changes where driver behavior affects both treatment and control users, Evaluating marketplace features where seller actions impact buyers across experimental groups","audience":"Junior-DS, Mid-DS"},{"id":"resource-wayfair:-geo-experiments-for-incrementality","type":"resource","name":"Wayfair: Geo Experiments for Incrementality","description":"Convex optimization for treatment assignment when simple randomization won't work. Covers synthetic control matching and practical constraints like maximum geo share limits.","category":"Interference & Switchback","url":"https://www.aboutwayfair.com/careers/tech-blog/how-wayfair-uses-geo-experiments-to-measure-incrementality","difficulty":"intermediate","prerequisites":"A/B-testing-fundamentals, convex-optimization, synthetic-control-methods","topic_tags":"geo-experiments, incrementality-measurement, synthetic-control, treatment-assignment, spatial-interference","summary":"A guide to using convex optimization for geographic experiment design when standard randomization fails due to spillover effects or business constraints. Covers synthetic control matching techniques and practical implementation considerations like geographic share limits for treatment assignment.","use_cases":"Measuring incrementality of marketing campaigns across cities when users can easily cross geographic boundaries, Testing supply chain or fulfillment changes where spillover effects between regions invalidate standard A/B tests","audience":"Mid-DS, Senior-DS"},{"id":"resource-eugene-yan:-bandits-for-recommender-systems","type":"resource","name":"Eugene Yan: Bandits for Recommender Systems","description":"The definitive practitioner's guide synthesizing implementations from 12+ tech companies (Spotify, Netflix, Yahoo, DoorDash, Twitter, Alibaba, Amazon). Covers \u03b5-greedy, UCB, Thompson Sampling.","category":"Bandits & Adaptive","url":"https://eugeneyan.com/writing/bandits/","difficulty":"intermediate","prerequisites":"A-B-testing, python-scikit-learn, reinforcement-learning-basics","topic_tags":"multi-armed-bandits, recommendation-systems, online-learning, tech-industry, practitioner-guide","summary":"A comprehensive practitioner's guide to implementing bandit algorithms for recommendation systems, synthesizing real-world approaches from major tech companies. Covers core algorithms like \u03b5-greedy, UCB, and Thompson Sampling with production implementation details. Essential reading for data scientists building adaptive recommendation systems at scale.","use_cases":"Building a content recommendation system that learns user preferences in real-time, Optimizing product recommendations on an e-commerce platform while balancing exploration vs exploitation","audience":"Mid-DS, Junior-DS"},{"id":"resource-eppo:-bandit-vs.-experiment-testing-decision-guide","type":"resource","name":"Eppo: Bandit vs. Experiment Testing Decision Guide","description":"The single best resource for when to use bandits vs. experiments. Covers perishable decisions, impact estimation challenges, why A/B tests win for complex multi-metric decisions.","category":"Bandits & Adaptive","url":"https://www.geteppo.com/blog/bandit-or-experiment","difficulty":"intermediate","prerequisites":"a-b-testing, multi-armed-bandits, causal-inference","topic_tags":"bandits, experimentation, decision-framework, adaptive-testing, resource-guide","summary":"A comprehensive decision framework for choosing between bandit algorithms and traditional A/B tests. Provides clear guidance on when each approach is optimal based on decision characteristics, measurement complexity, and business constraints. Essential reading for practitioners designing adaptive experimentation strategies.","use_cases":"Deciding whether to use a bandit or A/B test for a new product feature launch with multiple variants, Choosing the right experimentation approach for ad optimization where conversion tracking has delays","audience":"Mid-DS, Junior-DS"},{"id":"resource-stitch-fix:-multi-armed-bandits-experimentation-platform","type":"resource","name":"Stitch Fix: Multi-Armed Bandits Experimentation Platform","description":"Inside look at building bandit infrastructure. Covers Thompson Sampling convergence, deterministic allocation via hashing, and reward services architecture with feedback loop diagrams.","category":"Bandits & Adaptive","url":"https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/","difficulty":"intermediate","prerequisites":"A-B-testing, python-programming, bayesian-statistics","topic_tags":"multi-armed-bandits, thompson-sampling, experimentation-platform, infrastructure, case-study","summary":"Detailed case study of Stitch Fix's production multi-armed bandit platform implementation. Covers practical engineering considerations including Thompson Sampling algorithms, deterministic user allocation, and reward feedback architecture. Provides real-world insights into building scalable experimentation infrastructure at a major tech company.","use_cases":"Building experimentation infrastructure for dynamic content recommendation, Implementing adaptive testing systems that optimize while collecting data","audience":"Mid-DS, Senior-DS"},{"id":"resource-eppo:-how-netflix,-lyft,-and-yahoo-use-contextual-bandits","type":"resource","name":"Eppo: How Netflix, Lyft, and Yahoo Use Contextual Bandits","description":"Case studies: Netflix artwork personalization, Lyft pricing optimization, Yahoo news with LinUCB. Explains why contextual bandits beat full recommenders for smaller action spaces.","category":"Bandits & Adaptive","url":"https://www.geteppo.com/blog/netflix-lyft-yahoo-contextual-bandits","difficulty":"intermediate","prerequisites":"multi-armed-bandits, A/B-testing, reinforcement-learning-basics","topic_tags":"contextual-bandits, personalization, real-time-optimization, case-studies","summary":"This resource showcases how major tech companies implement contextual bandits for real-world optimization problems. It covers Netflix's artwork personalization, Lyft's pricing strategies, and Yahoo's news recommendations using LinUCB algorithm. The content explains when contextual bandits are preferable to full recommendation systems, particularly for scenarios with limited action spaces.","use_cases":"Optimizing content personalization with limited creative variants, Dynamic pricing strategies that adapt to user context and market conditions","audience":"Mid-DS, Junior-DS"},{"id":"resource-google-machine-learning-crash-course","type":"resource","name":"Google Machine Learning Crash Course","description":"15-hour interactive course originally for Google engineers, refreshed 2024 with LLMs/AutoML. Covers supervised learning, feature engineering, and production ML with Colab exercises. Teaches exact mental models Google engineers use.","category":"Fundamentals","url":"https://developers.google.com/machine-learning/crash-course","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, pandas-dataframes","topic_tags":"machine-learning, supervised-learning, feature-engineering, google-ml, interactive-course","summary":"Google's internal 15-hour machine learning course designed to teach engineers production ML fundamentals. Covers supervised learning, feature engineering, and model deployment with hands-on Colab exercises and recently updated with LLM content. Provides the exact mental models and best practices used by Google engineers in production systems.","use_cases":"New data scientist at tech company needs to understand ML fundamentals used in production, Software engineer transitioning to ML role wants industry-standard practices and frameworks","audience":"Junior-DS, Curious-browser"},{"id":"resource-andrew-ng's-machine-learning-specialization","type":"resource","name":"Andrew Ng's Machine Learning Specialization","description":"Comprehensive theoretical grounding redesigned 2022 with modern Python. Three-course sequence on supervised/unsupervised learning and recommender systems. 4.9/5 from 37,000+ reviews. Free to audit.","category":"Fundamentals","url":"https://www.coursera.org/specializations/machine-learning-introduction","difficulty":"beginner","prerequisites":"basic-python, linear-algebra, calculus","topic_tags":"supervised-learning, unsupervised-learning, recommender-systems, online-course, python","summary":"Andrew Ng's updated machine learning specialization providing comprehensive theoretical foundations with modern Python implementations. Covers supervised learning, unsupervised learning, and recommender systems across three courses. Highly rated foundational course sequence ideal for building core ML understanding from scratch.","use_cases":"Building foundational ML knowledge before starting first data science role, Academic preparation for ML-focused PhD coursework or thesis research","audience":"Early-PhD, Junior-DS"},{"id":"resource-statquest-with-josh-starmer","type":"resource","name":"StatQuest with Josh Starmer","description":"Visual explanations of cross-validation, regularization, gradient boosting, PCA, and bias-variance tradeoff. 675,000+ subscribers. Fills conceptual gaps that course-based learning misses.","category":"Fundamentals","url":"https://www.youtube.com/@statquest","difficulty":"beginner","prerequisites":"basic-linear-algebra, python-numpy","topic_tags":"cross-validation, regularization, gradient-boosting, PCA, bias-variance","summary":"StatQuest provides intuitive visual explanations of core machine learning concepts through animated videos and clear examples. Josh Starmer breaks down complex statistical methods into digestible segments that help bridge the gap between theory and practical understanding. The channel is particularly valuable for solidifying conceptual understanding of methods you'll implement in practice.","use_cases":"Understanding why your regularized model performs better before presenting results to stakeholders, Grasping the intuition behind PCA before applying dimensionality reduction to high-dimensional user data","audience":"Junior-DS, Early-PhD"},{"id":"resource-made-with-ml","type":"resource","name":"Made With ML","description":"Implementation-first approach: build models from scratch with NumPy before PyTorch. Emphasizes clean, production-quality code with proper software engineering practices. By Goku Mohandas (ex-Apple ML).","category":"Fundamentals","url":"https://madewithml.com/courses/foundations/","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, numpy-arrays","topic_tags":"machine-learning, implementation-from-scratch, production-code, software-engineering, pytorch","summary":"A comprehensive machine learning course that teaches implementation fundamentals by building models from scratch using NumPy before moving to PyTorch. Emphasizes production-quality code with proper software engineering practices, making it ideal for practitioners who want to understand ML algorithms deeply while learning industry best practices.","use_cases":"Junior data scientists wanting to understand ML algorithms beyond black-box usage, Bootcamp graduates preparing for technical interviews requiring ML implementation knowledge","audience":"Junior-DS, Early-PhD"},{"id":"resource-kaggle's-intermediate-machine-learning","type":"resource","name":"Kaggle's Intermediate Machine Learning","description":"Hands-on XGBoost with graded exercises. Covers missing values, categorical encoding, pipelines, cross-validation, then XGBoost tuning (n_estimators, early_stopping, learning_rate). Free certificate.","category":"Gradient Boosting","url":"https://www.kaggle.com/learn/intermediate-machine-learning","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn-basics, train-test-split","topic_tags":"xgboost, gradient-boosting, hyperparameter-tuning, cross-validation, hands-on-tutorial","summary":"Kaggle's hands-on course teaching XGBoost implementation with practical exercises and automatic grading. Covers data preprocessing fundamentals like handling missing values and categorical encoding, then dives into XGBoost parameter tuning including n_estimators, early stopping, and learning rate optimization. Includes free certificate upon completion.","use_cases":"Building your first production-ready gradient boosting model for tabular prediction problems, Learning XGBoost hyperparameter optimization techniques for Kaggle competitions","audience":"Junior-DS, Mid-DS"},{"id":"resource-neptune.ai:-when-to-choose-catboost-over-xgboost","type":"resource","name":"Neptune.ai: When to Choose CatBoost Over XGBoost","description":"Algorithm selection with benchmark comparisons. Explains CatBoost's ordered boosting (preventing target leakage), symmetric vs. asymmetric trees. Decision framework practitioners need.","category":"Gradient Boosting","url":"https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm","difficulty":"intermediate","prerequisites":"gradient-boosting-basics, python-sklearn, hyperparameter-tuning","topic_tags":"catboost, xgboost, algorithm-selection, benchmark-comparison, ensemble-methods","summary":"Practical guide comparing CatBoost and XGBoost gradient boosting algorithms with performance benchmarks. Explains CatBoost's unique ordered boosting approach that prevents target leakage and compares symmetric vs asymmetric tree structures. Provides decision framework for practitioners to choose the right algorithm for their specific use case.","use_cases":"Selecting optimal boosting algorithm for tabular prediction tasks with categorical features, Comparing model performance when dealing with datasets prone to overfitting or target leakage","audience":"Mid-DS, Junior-DS"},{"id":"resource-mljar:-feature-importance-with-xgboost","type":"resource","name":"MLJAR: Feature Importance with XGBoost","description":"Definitive guide covering three importance methods: gain, weight, and SHAP. Complete Colab code comparing built-in importance vs. permutation vs. SHAP values. Essential for model interpretation.","category":"Gradient Boosting","url":"https://mljar.com/blog/feature-importance-xgboost/","difficulty":"intermediate","prerequisites":"python-pandas, xgboost, scikit-learn","topic_tags":"feature-importance, model-interpretation, xgboost, shap-values, tutorial","summary":"Comprehensive tutorial comparing three XGBoost feature importance methods: gain, weight, and SHAP values. Includes complete code examples and practical comparisons to help practitioners choose the right interpretation method for their models. Essential for understanding which features drive XGBoost predictions.","use_cases":"Explaining model predictions to business stakeholders, Feature selection and engineering for improved model performance","audience":"Junior-DS, Mid-DS"},{"id":"resource-analytics-vidhya:-hyperparameter-tuning-guide","type":"resource","name":"Analytics Vidhya: Hyperparameter Tuning Guide","description":"Systematic tuning methodology from Kaggle winners. Sequential approach: fix tree params, tune learning rate/iterations, add regularization. Key insight: 10\u00d7 decrease in learning_rate needs ~10\u00d7 increase in n_estimators.","category":"Gradient Boosting","url":"https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/","difficulty":"intermediate","prerequisites":"gradient-boosting-algorithms, python-scikit-learn, cross-validation","topic_tags":"hyperparameter-tuning, gradient-boosting, model-optimization, kaggle-methods, practical-guide","summary":"A systematic methodology for tuning gradient boosting models based on proven Kaggle competition strategies. Provides a sequential approach to parameter optimization with practical insights about the trade-offs between learning rate and iteration count. Essential reading for data scientists looking to improve their model tuning workflow beyond random search.","use_cases":"Optimizing XGBoost/LightGBM models for a machine learning competition, Systematically tuning gradient boosting parameters for a production recommendation system","audience":"Junior-DS, Mid-DS"},{"id":"resource-fast.ai-practical-deep-learning-for-coders","type":"resource","name":"Fast.ai Practical Deep Learning for Coders","description":"Top-down approach: deploying models by lesson 2, then progressively revealing mechanics. Part 1: vision, NLP, tabular, collaborative filtering. Part 2: backprop to Stable Diffusion. Alumni at Google Brain, OpenAI, Tesla.","category":"Deep Learning","url":"https://course.fast.ai","difficulty":"beginner","prerequisites":"basic-python, high-school-math, jupyter-notebooks","topic_tags":"practical-deep-learning, computer-vision, natural-language-processing, hands-on-tutorial, pytorch","summary":"A hands-on deep learning course that gets you building and deploying real models from day one, then teaches the underlying theory. Covers practical applications across vision, NLP, tabular data, and recommender systems with a focus on implementation over mathematics. Alumni have gone on to work at top AI companies, making this a proven pathway from beginner to practitioner.","use_cases":"Junior developer wanting to add deep learning skills to build recommendation systems or image classifiers, Career changer from traditional analytics looking to transition into modern ML roles at tech companies","audience":"Junior-DS, Curious-browser"},{"id":"resource-andrej-karpathy's-neural-networks:-zero-to-hero","type":"resource","name":"Andrej Karpathy's Neural Networks: Zero to Hero","description":"Build understanding through implementation. From backprop in 100 lines to building GPT from scratch. By OpenAI founding member and former Tesla AI Director. PyTorch naming conventions for production code.","category":"Deep Learning","url":"https://karpathy.ai/zero-to-hero.html","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, calculus-derivatives","topic_tags":"neural-networks, pytorch, backpropagation, GPT, hands-on-coding","summary":"A practical video course that teaches neural networks through hands-on implementation, starting with basic backpropagation and progressing to building GPT from scratch. Created by Andrej Karpathy, this series emphasizes understanding through coding rather than theory, using PyTorch conventions suitable for production environments.","use_cases":"Learning neural network fundamentals by implementing backprop and basic architectures from scratch, Building a GPT model step-by-step to understand transformer architecture and modern language models","audience":"Junior-DS, Curious-browser"},{"id":"resource-andrew-ng's-deep-learning-specialization","type":"resource","name":"Andrew Ng's Deep Learning Specialization","description":"5 courses: neural network foundations, optimization/regularization, ML projects, CNNs, sequence models including transformers. 120,000+ five-star reviews. Free to audit. Balance of intuition, math, and application.","category":"Deep Learning","url":"https://www.coursera.org/specializations/deep-learning","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, calculus","topic_tags":"neural-networks, computer-vision, sequence-modeling, online-course, transformers","summary":"Comprehensive 5-course specialization covering deep learning fundamentals from neural network basics to advanced architectures like CNNs and transformers. Designed by Andrew Ng with balance of theory and practical implementation, suitable for beginners with strong math background. Over 120,000 students have completed this highly-rated program that's free to audit.","use_cases":"Junior data scientist learning deep learning fundamentals for first ML role, PhD student building foundation in neural networks before specializing in computer vision research","audience":"Junior-DS, Early-PhD"},{"id":"resource-3blue1brown-neural-network-series","type":"resource","name":"3Blue1Brown Neural Network Series","description":"Unparalleled mathematical visualization. Grant Sanderson's custom animations make backpropagation and gradient descent genuinely intuitive. Newer transformer and LLM explainer videos particularly valuable.","category":"Deep Learning","url":"https://www.3blue1brown.com/topics/neural-networks","difficulty":"beginner","prerequisites":"basic-calculus, linear-algebra, python-basics","topic_tags":"neural-networks, backpropagation, gradient-descent, transformers, visual-learning","summary":"Grant Sanderson's animated video series that makes neural network concepts visually intuitive through custom mathematical visualizations. Covers fundamentals like backpropagation and gradient descent, plus modern topics like transformers and LLMs. Perfect for building conceptual understanding before diving into implementation.","use_cases":"Getting intuitive understanding before implementing first neural network, Explaining ML concepts to non-technical stakeholders or team members","audience":"Junior-DS, Curious-browser"},{"id":"resource-jay-alammar's-illustrated-transformer","type":"resource","name":"Jay Alammar's Illustrated Transformer","description":"Definitive visual guide to attention mechanisms, referenced at Stanford, Harvard, MIT, Princeton, CMU. Step-by-step illustrations of self-attention, multi-head attention, positional encoding. Covers BERT, GPT-2, retrieval transformers.","category":"Deep Learning","url":"https://jalammar.github.io/illustrated-transformer/","difficulty":"beginner","prerequisites":"neural-networks, python-numpy, backpropagation","topic_tags":"transformers, attention-mechanisms, visual-guide, deep-learning, NLP","summary":"Jay Alammar's visual tutorial breaks down transformer architecture using clear illustrations and animations. It explains self-attention, multi-head attention, and positional encoding in an accessible way that's become the go-to resource at top universities. Perfect for understanding the foundation behind BERT, GPT, and modern language models.","use_cases":"Understanding how ChatGPT and GPT models process text, Learning transformer architecture before implementing BERT for text classification","audience":"Junior-DS, Early-PhD"},{"id":"resource-google's-recommendation-systems-course","type":"resource","name":"Google's Recommendation Systems Course","description":"Industry-standard architecture: candidate retrieval \u2192 scoring \u2192 re-ranking. Built by YouTube RecSys engineers. 4-hour course on collaborative filtering, matrix factorization, embeddings, deep approaches. YouTube case study at 2B+ user scale.","category":"Recommender Systems","url":"https://developers.google.com/machine-learning/recommendation","difficulty":"intermediate","prerequisites":"python-scikit-learn, matrix-multiplication, tensorflow-basics","topic_tags":"collaborative-filtering, matrix-factorization, deep-learning, embeddings, youtube-case-study","summary":"Google's comprehensive course on building production recommendation systems, covering the three-stage pipeline from candidate retrieval through scoring to re-ranking. Taught by YouTube engineers who built systems serving billions of users, with hands-on examples of collaborative filtering, matrix factorization, and deep learning approaches. Ideal for practitioners who need to understand both the theory and real-world implementation challenges of large-scale recommendation systems.","use_cases":"Building product recommendation engine for e-commerce platform, Implementing content recommendation system for streaming service","audience":"Junior-DS, Mid-DS"},{"id":"resource-eugene-yan:-system-design-for-recommendations","type":"resource","name":"Eugene Yan: System Design for Recommendations","description":"Production patterns from Alibaba, Facebook, DoorDash, LinkedIn in a 2\u00d72 framework (offline/online \u00d7 retrieval/ranking). By Amazon Principal Applied Scientist. Referenced by NVIDIA as canonical industry reading.","category":"Recommender Systems","url":"https://eugeneyan.com/writing/system-design-for-discovery/","difficulty":"intermediate","prerequisites":"python-scikit-learn, A-B-testing, SQL-joins","topic_tags":"system-design, production-ml, recommendation-engines, industry-patterns, ml-architecture","summary":"A comprehensive guide to building production recommendation systems using a 2\u00d72 framework that organizes approaches by offline/online processing and retrieval/ranking stages. Features real implementation patterns from major tech companies like Alibaba, Facebook, and LinkedIn. Essential reading for data scientists moving from prototype models to scalable recommendation infrastructure.","use_cases":"Designing a new recommendation system architecture for an e-commerce platform, Scaling an existing ML recommendation model from prototype to production serving millions of users","audience":"Mid-DS, Senior-DS"},{"id":"resource-netflix-technology-blog:-recommendation-systems","type":"resource","name":"Netflix Technology Blog: Recommendation Systems","description":"How Netflix Prize pioneers continue innovating. Foundation models with transformers, multi-task learning across surfaces, RecSysOps for production monitoring at 200M+ user scale. Lessons unavailable elsewhere.","category":"Recommender Systems","url":"https://netflixtechblog.com/tagged/recommendation-system","difficulty":"advanced","prerequisites":"deep-learning, transformer-architectures, production-ml-systems","topic_tags":"recommender-systems, netflix, foundation-models, multi-task-learning, production-ml","summary":"Netflix's technical blog documenting their evolution from collaborative filtering to modern foundation models and transformers for recommendations. Covers multi-task learning across different product surfaces and RecSysOps practices for monitoring recommendation systems at massive scale. Provides rare insights into production challenges and solutions from one of the world's largest recommendation platforms.","use_cases":"Building multi-surface recommendation systems that work across web, mobile, and TV interfaces, Implementing production monitoring and ops practices for large-scale recommendation engines","audience":"Senior-DS, Mid-DS"},{"id":"resource-tensorflow-recommenders-tutorials","type":"resource","name":"TensorFlow Recommenders Tutorials","description":"Executable code for two-tower architecture used at Google, YouTube, Pinterest. MovieLens examples: user/item embeddings, retrieval models, ranking layers, serving with approximate nearest neighbors. Concept to deployment.","category":"Recommender Systems","url":"https://www.tensorflow.org/recommenders","difficulty":"intermediate","prerequisites":"tensorflow, python-pandas, neural-networks","topic_tags":"two-tower-architecture, embedding-models, tensorflow-recommenders, retrieval-ranking, tutorial","summary":"Hands-on tutorials for building production-scale recommender systems using TensorFlow Recommenders, featuring the two-tower architecture deployed at major tech companies. Covers the full pipeline from user/item embeddings through retrieval and ranking to model serving with approximate nearest neighbors. Uses MovieLens dataset to demonstrate real-world implementation patterns.","use_cases":"Building a movie/content recommendation system with separate user and item towers, Implementing large-scale retrieval and ranking pipeline for e-commerce product recommendations","audience":"Junior-DS, Mid-DS"},{"id":"resource-eugene-yan:-position-bias-in-search","type":"resource","name":"Eugene Yan: Position Bias in Search","description":"Measurement and mitigation techniques: RandPair, FairPairs, propensity scoring. Essential for production ranking systems where position corrupts training data.","category":"Search & Ranking","url":"https://eugeneyan.com/writing/position-bias/","difficulty":"intermediate","prerequisites":"A/B-testing, machine-learning-evaluation, ranking-systems","topic_tags":"position-bias, search-ranking, bias-mitigation, production-ML, evaluation-metrics","summary":"Position bias occurs in search and recommendation systems when user clicks are influenced by item position rather than true relevance, corrupting training data. This resource covers measurement techniques like RandPair and FairPairs, plus propensity scoring methods to correct for positional effects. Essential knowledge for anyone building or evaluating production ranking systems where click data drives model training.","use_cases":"Improving search result quality by debiasing click-through rate data used for model training, Evaluating recommendation system performance while accounting for position-dependent user behavior","audience":"Mid-DS, Senior-DS"},{"id":"resource-airbnb:-ml-powered-search-ranking","type":"resource","name":"Airbnb: ML-Powered Search Ranking","description":"Masterclass in production search evolution. 4-stage journey from baseline to personalized GBDT ranking with A/B test results (+13%, +7.9%, +5.1% booking improvements). Feature engineering for two-sided marketplaces.","category":"Search & Ranking","url":"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789","difficulty":"intermediate","prerequisites":"gradient-boosting, A-B-testing, feature-engineering","topic_tags":"search-ranking, two-sided-marketplaces, GBDT, personalization, production-ML","summary":"Detailed case study of how Airbnb evolved their search ranking system through four stages, from basic scoring to personalized machine learning models. Shows real A/B test results and practical feature engineering techniques for matching guests with hosts in a two-sided marketplace.","use_cases":"Building ML-powered search ranking for marketplace platforms, Implementing personalized recommendation systems with measurable business impact","audience":"Mid-DS, Senior-DS"},{"id":"resource-olx-engineering:-from-ranknet-to-lambdamart","type":"resource","name":"OLX Engineering: From RankNet to LambdaMART","description":"Clearest learning-to-rank explanation with code. Why ranking differs from classification, pointwise vs. pairwise vs. listwise approaches. Implementing RankNet and LambdaMART with XGBoost rank:pairwise and rank:ndcg.","category":"Search & Ranking","url":"https://tech.olx.com/from-ranknet-to-lambdamart-leveraging-xgboost-for-enhanced-ranking-models-cf21f33350fb","difficulty":"intermediate","prerequisites":"python-scikit-learn, gradient-boosting, xgboost","topic_tags":"learning-to-rank, ranknet, lambdamart, search-algorithms, xgboost-ranking","summary":"Comprehensive tutorial explaining learning-to-rank fundamentals with practical implementations. Covers the progression from basic RankNet neural networks to advanced LambdaMART algorithms using XGBoost. Includes working code examples and clear explanations of why ranking problems require different approaches than standard classification.","use_cases":"Building search result ranking systems for e-commerce platforms, Ranking job recommendations or content feeds based on user preferences","audience":"Junior-DS, Mid-DS"},{"id":"resource-linkedin:-ai-behind-recruiter-search","type":"resource","name":"LinkedIn: AI Behind Recruiter Search","description":"Enterprise-scale search: multi-layer ranking (L1 retrieval \u2192 L2 ranking), evolution from linear to GBDT to neural, GLMix personalization. Among the largest learning-to-rank systems in production.","category":"Search & Ranking","url":"https://www.linkedin.com/blog/engineering/recommendations/ai-behind-linkedin-recruiter-search-and-recommendation-systems","difficulty":"intermediate","prerequisites":"learning-to-rank, gradient-boosting, neural-networks","topic_tags":"learning-to-rank, enterprise-search, multi-stage-ranking, personalization, production-systems","summary":"LinkedIn's enterprise search system demonstrates multi-layer ranking architecture at massive scale, progressing from linear models to gradient boosting to neural approaches. The system showcases GLMix personalization framework and represents one of the largest learning-to-rank deployments in production. Essential reading for understanding how to scale search ranking systems beyond academic toy problems.","use_cases":"Designing multi-stage ranking pipeline for large-scale search or recommendation system, Implementing personalized ranking at enterprise scale with millions of users","audience":"Mid-DS, Senior-DS"},{"id":"resource-openai-cookbook:-semantic-search-with-embeddings","type":"resource","name":"OpenAI Cookbook: Semantic Search with Embeddings","description":"Modern embedding-based retrieval end-to-end. Embedding generation with OpenAI API, Pinecone vector database, cosine similarity search. Foundation for semantic search and RAG systems.","category":"Search & Ranking","url":"https://cookbook.openai.com/examples/vector_databases/pinecone/semantic_search","difficulty":"intermediate","prerequisites":"python-requests, vector-databases, cosine-similarity","topic_tags":"semantic-search, embeddings, vector-databases, openai-api, pinecone","summary":"A comprehensive guide to building semantic search systems using OpenAI's embedding models and Pinecone vector database. Shows the complete pipeline from text preprocessing to similarity-based retrieval using cosine distance. Essential foundation for building RAG applications and modern search experiences.","use_cases":"Building a document search system for internal company knowledge base, Creating semantic product search for e-commerce recommendations","audience":"Junior-DS, Mid-DS"},{"id":"resource-langchain-academy:-intro-to-langgraph","type":"resource","name":"LangChain Academy: Intro to LangGraph","description":"Most comprehensive free agent-building course. 6-hour, 55-lesson course on state management, memory, human-in-the-loop, parallelization, deployment. Used in production at Klarna, LinkedIn, Elastic.","category":"LLMs & Agents","url":"https://academy.langchain.com/courses/intro-to-langgraph","difficulty":"intermediate","prerequisites":"python-programming, langchain-basics, REST-APIs","topic_tags":"agent-frameworks, state-management, production-deployment, human-in-the-loop, llm-orchestration","summary":"A comprehensive 55-lesson course teaching LangGraph for building production-ready AI agents with advanced features like state management, memory, and human oversight. Used by major companies like Klarna and LinkedIn, this free course covers the full pipeline from development to deployment. Essential for data scientists wanting to move beyond simple LLM calls to sophisticated agent systems.","use_cases":"Building customer service chatbots that maintain conversation context and escalate to humans when needed, Creating data analysis agents that can run experiments, remember results, and coordinate multiple AI models in parallel","audience":"Junior-DS, Mid-DS"},{"id":"resource-anthropic's-prompt-engineering-tutorial","type":"resource","name":"Anthropic's Prompt Engineering Tutorial","description":"Definitive prompting from Claude's creators. 26,000+ GitHub stars. Interactive notebooks on direct prompting, chain-of-thought, output formatting, hallucination avoidance, tool use. 'Best LLM vendor documentation' - Simon Willison.","category":"LLMs & Agents","url":"https://github.com/anthropics/prompt-eng-interactive-tutorial","difficulty":"beginner","prerequisites":"python-basics, API-requests","topic_tags":"prompt-engineering, claude-api, interactive-tutorials, llm-optimization, output-formatting","summary":"Comprehensive tutorial from Anthropic covering prompt engineering techniques for Claude and other LLMs. Features interactive Jupyter notebooks demonstrating direct prompting, chain-of-thought reasoning, output formatting, and tool integration. Highly regarded as the gold standard for learning systematic prompt optimization.","use_cases":"Building reliable AI chatbots with consistent output formats, Creating LLM-powered data analysis workflows that minimize hallucinations","audience":"Junior-DS, Mid-DS"},{"id":"resource-eugene-yan:-patterns-for-building-llm-based-systems","type":"resource","name":"Eugene Yan: Patterns for Building LLM-based Systems","description":"7 production patterns: Evals, RAG, Fine-tuning, Caching, Guardrails, Defensive UX, User Feedback. 66-minute read with evaluation metrics (BLEU, ROUGE, BERTScore), RAG patterns, fine-tuning decisions. From Amazon experience.","category":"LLMs & Agents","url":"https://eugeneyan.com/writing/llm-patterns/","difficulty":"intermediate","prerequisites":"python-programming, transformer-architectures, REST-APIs","topic_tags":"LLM-systems, production-ML, evaluation-metrics, retrieval-augmented-generation, model-fine-tuning","summary":"Comprehensive guide covering 7 essential patterns for building production LLM systems, including evaluation frameworks, RAG implementation, and fine-tuning decisions. Based on real Amazon experience, provides practical metrics like BLEU and ROUGE for system assessment. Essential reading for data scientists moving from experimentation to production LLM deployment.","use_cases":"Building a customer service chatbot that needs reliable evaluation and guardrails, Implementing a document Q&A system with RAG and proper caching strategies","audience":"Mid-DS, Senior-DS"},{"id":"resource-deeplearning.ai-short-courses","type":"resource","name":"DeepLearning.AI Short Courses","description":"Rapid skill-building in 1-2 hours. Key free courses: LangChain for LLM Apps (Harrison Chase), Building Systems with ChatGPT, Functions/Tools/Agents. Interactive Jupyter notebooks, zero setup.","category":"LLMs & Agents","url":"https://learn.deeplearning.ai","difficulty":"beginner","prerequisites":"python-basics, jupyter-notebooks, API-calls","topic_tags":"langchain, chatgpt-api, llm-applications, interactive-tutorials, hands-on-learning","summary":"DeepLearning.AI offers bite-sized interactive courses that teach practical LLM application development in 1-2 hours. These hands-on tutorials use pre-configured Jupyter notebooks to walk through building real systems with LangChain, ChatGPT APIs, and agent frameworks. Perfect for quickly getting up to speed on LLM tooling without environment setup hassles.","use_cases":"Building a customer service chatbot using LangChain and OpenAI APIs, Creating an AI assistant that can call external tools and APIs to answer complex queries","audience":"Junior-DS, Curious-browser"},{"id":"resource-freecodecamp:-rag-from-scratch","type":"resource","name":"FreeCodeCamp: RAG from Scratch","description":"Deep RAG understanding by Lance Martin (LangChain engineer, Stanford PhD). 2.5-hour video on advanced techniques: Multi-Query, RAG Fusion, Decomposition, Step Back, HyDE, Corrective RAG, Self-RAG patterns.","category":"LLMs & Agents","url":"https://www.freecodecamp.org/news/mastering-rag-from-scratch/","difficulty":"intermediate","prerequisites":"python-langchain, vector-databases, transformer-embeddings","topic_tags":"retrieval-augmented-generation, langchain, vector-search, llm-engineering, video-tutorial","summary":"Comprehensive 2.5-hour tutorial by LangChain engineer Lance Martin covering advanced RAG patterns from first principles. Goes beyond basic RAG to explore sophisticated techniques like Multi-Query, RAG Fusion, and Self-RAG for production applications. Perfect for practitioners wanting deep understanding of modern retrieval-augmented generation systems.","use_cases":"Building production RAG systems for enterprise knowledge bases, Improving retrieval quality in customer support chatbots using advanced RAG patterns","audience":"Mid-DS, Junior-DS"},{"id":"resource-lyft-engineering","type":"resource","name":"Lyft Engineering","description":"Rideshare economics, forecasting, and marketplace efficiency. Technical deep-dives on pricing, dispatch, and causal inference.","category":"Marketplace Economics","url":"https://eng.lyft.com/","difficulty":"intermediate","prerequisites":"python-pandas, A-B-testing, basic-econometrics","topic_tags":"marketplace-design, pricing-algorithms, causal-inference, demand-forecasting, rideshare","summary":"Lyft's engineering blog features technical posts on marketplace economics, dynamic pricing, and causal inference methods used in ridesharing. The content covers real-world applications of econometric methods, machine learning for demand forecasting, and optimization algorithms for driver-rider matching. Posts typically include code examples and detailed methodology explanations from Lyft's data science and economics teams.","use_cases":"Learning how to implement dynamic pricing algorithms for marketplace platforms, Understanding causal inference techniques for measuring the impact of marketplace interventions","audience":"Mid-DS, Junior-DS"},{"id":"resource-netflix-tech-blog","type":"resource","name":"Netflix Tech Blog","description":"Streaming personalization, A/B testing at scale, recommendations. How Netflix builds data products for 200M+ subscribers.","category":"Search & Ranking","url":"https://netflixtechblog.com/","difficulty":"intermediate","prerequisites":"python-pandas, statistical-hypothesis-testing, collaborative-filtering","topic_tags":"recommendation-systems, ab-testing, personalization, streaming-platforms, tech-blog","summary":"Netflix's technical blog documenting their approach to building recommendation systems and running experiments at massive scale. Covers real-world implementations of personalization algorithms, A/B testing infrastructure, and data products serving 200M+ users. Essential reading for understanding how streaming platforms optimize user experience through data science.","use_cases":"Building recommendation systems for content platforms or e-commerce sites, Designing A/B testing infrastructure for high-traffic applications","audience":"Mid-DS, Senior-DS"},{"id":"resource-linkedin-engineering","type":"resource","name":"LinkedIn Engineering","description":"Professional network data science, feed ranking, economic graph insights. ML and economics at scale.","category":"Search & Ranking","url":"https://engineering.linkedin.com/blog","difficulty":"intermediate","prerequisites":"python-scikit-learn, network-analysis, ranking-algorithms","topic_tags":"social-networks, recommendation-systems, feed-ranking, graph-algorithms, network-effects","summary":"LinkedIn Engineering's technical blog and resources covering large-scale data science applications in professional networking. Focus on feed ranking algorithms, economic graph analysis, and machine learning systems that power LinkedIn's platform. Provides insights into real-world implementation of network analysis and recommendation systems at massive scale.","use_cases":"Building recommendation systems for social or professional networks, Implementing feed ranking algorithms for content platforms","audience":"Mid-DS, Senior-DS"},{"id":"resource-google-ai-blog","type":"resource","name":"Google AI Blog","description":"Research publications from Google AI. Covers ML, NLP, computer vision, and applied AI research.","category":"LLMs & Agents","url":"https://ai.googleblog.com/","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, neural-networks","topic_tags":"machine-learning, deep-learning, research-papers, google-ai, blog-posts","summary":"Google AI Blog is the official research publication platform where Google's AI teams share their latest findings in machine learning, natural language processing, computer vision, and applied AI. The blog covers both theoretical breakthroughs and practical applications, making cutting-edge research accessible to practitioners. Posts typically include detailed explanations, code examples, and links to full research papers.","use_cases":"Staying current with state-of-the-art ML techniques and Google's latest AI developments, Finding implementation details and practical insights for reproducing research results in production systems","audience":"Mid-DS, Senior-DS"},{"id":"resource-tim-roughgarden's-cs269i:-incentives-in-computer-science","type":"resource","name":"Tim Roughgarden's CS269I: Incentives in Computer Science","description":"20+ hours of video with publication-quality notes. Covers Gale-Shapley, NRMP matching, deferred acceptance, strategyproofness proofs, cryptocurrency incentives. Uniquely bridges classical stable matching with modern applications.","category":"Market Design & Matching","url":"https://timroughgarden.org/f16/f16.html","difficulty":"intermediate","prerequisites":"game-theory-basics, mathematical-proofs, algorithm-analysis","topic_tags":"stable-matching, mechanism-design, strategyproof-algorithms, video-lectures, academic-course","summary":"Tim Roughgarden's comprehensive Stanford course bridging classical matching theory with modern applications in tech and crypto. Features rigorous treatment of Gale-Shapley algorithm, medical residency matching, and strategic behavior in algorithmic systems. Combines theoretical foundations with practical implementation insights through high-quality video lectures and detailed notes.","use_cases":"Designing matching systems for two-sided markets like job platforms or dating apps, Understanding incentive structures in cryptocurrency protocols and blockchain mechanisms","audience":"Early-PhD, Mid-DS"},{"id":"resource-tim-roughgarden's-cs364a:-kidney-exchange","type":"resource","name":"Tim Roughgarden's CS364A: Kidney Exchange","description":"Definitive algorithmic treatment of kidney exchange. Covers Top Trading Cycles, cycle packing, incentive-compatible organ allocation. The actual algorithms used by the Alliance for Paired Kidney Donation.","category":"Market Design & Matching","url":"https://timroughgarden.org/f13/l/l10.pdf","difficulty":"intermediate","prerequisites":"graph-theory, linear-programming, game-theory-basics","topic_tags":"kidney-exchange, matching-algorithms, top-trading-cycles, mechanism-design, healthcare-economics","summary":"Tim Roughgarden's comprehensive course on the algorithms powering real kidney exchange systems. Covers the theoretical foundations and practical implementations of matching algorithms like Top Trading Cycles used by organ donation networks. Essential resource for understanding how market design theory translates into life-saving healthcare applications.","use_cases":"Designing matching systems for healthcare resource allocation, Understanding algorithmic approaches to two-sided markets with compatibility constraints","audience":"Early-PhD, Senior-DS"},{"id":"resource-uber-engineering:-marketplace-matching","type":"resource","name":"Uber Engineering: Marketplace Matching","description":"How classical two-sided matching translates to 30M+ predictions/minute. MDP framework, batch vs. greedy matching, bipartite graph algorithms, RL for supply-demand balance. Quantitative production results.","category":"Market Design & Matching","url":"https://www.uber.com/blog/research/dynamic-pricing-and-matching-in-ride-hailing-platforms/","difficulty":"intermediate","prerequisites":"graph-algorithms, reinforcement-learning, markov-decision-processes","topic_tags":"two-sided-matching, marketplace-optimization, bipartite-graphs, real-time-systems, production-engineering","summary":"Uber's engineering approach to scaling classical two-sided matching theory to handle 30+ million predictions per minute in their rider-driver marketplace. Covers the transition from theoretical matching algorithms to production systems using MDP frameworks, batch vs greedy matching strategies, and reinforcement learning for supply-demand optimization. Includes quantitative results and performance metrics from Uber's live marketplace.","use_cases":"Building matching systems for ride-sharing or delivery platforms, Optimizing real-time marketplace allocation with millions of participants","audience":"Mid-DS, Senior-DS"},{"id":"resource-airbnb-engineering:-two-sided-marketplace-matching","type":"resource","name":"Airbnb Engineering: Two-Sided Marketplace Matching","description":"Unique focus on 'both sides must accept' constraint. Host acceptance prediction, listing embeddings, cold start solutions. Shows how to infer host preferences from behavior\u20143.75% booking improvement.","category":"Market Design & Matching","url":"https://medium.com/airbnb-engineering/how-airbnb-uses-machine-learning-to-detect-host-preferences-18ce07150fa3","difficulty":"intermediate","prerequisites":"machine-learning-embeddings, logistic-regression, python-scikit-learn","topic_tags":"two-sided-markets, recommendation-systems, host-guest-matching, marketplace-optimization, behavioral-inference","summary":"Airbnb's approach to solving the unique challenge of two-sided marketplace matching where both hosts and guests must accept each other. The resource details how to predict host acceptance behavior, create listing embeddings, and handle cold start problems in marketplace settings. Shows practical implementation that achieved measurable business impact through behavioral inference techniques.","use_cases":"Building recommendation systems for platforms where both parties must approve the match (dating apps, freelance marketplaces, rental platforms), Improving conversion rates in marketplaces by predicting and optimizing for mutual acceptance probability","audience":"Mid-DS, Senior-DS"},{"id":"resource-tim-roughgarden's-cs364a:-mechanism-design","type":"resource","name":"Tim Roughgarden's CS364A: Mechanism Design","description":"The definitive free resource from a G\u00f6del Prize winner. 20 video lectures (~75 min each) covering Vickrey auctions, Myerson's Lemma, VCG, sponsored search, combinatorial auctions, revenue-maximizing mechanisms.","category":"Auction Theory","url":"https://timroughgarden.org/f13/f13.html","difficulty":"advanced","prerequisites":"microeconomics-theory, game-theory, mathematical-optimization","topic_tags":"mechanism-design, auction-theory, game-theory, video-lectures, sponsored-search","summary":"Comprehensive video lecture series on mechanism design by G\u00f6del Prize winner Tim Roughgarden, covering foundational auction theory from Vickrey auctions to modern applications. Essential resource for understanding how to design systems where strategic agents truthfully reveal private information. Covers both theoretical foundations and practical applications like sponsored search auctions.","use_cases":"Designing auction mechanisms for ad platforms or marketplace bidding systems, Understanding revenue optimization strategies for multi-item auctions in e-commerce","audience":"Early-PhD, Senior-DS"},{"id":"resource-easley-&-kleinberg:-sponsored-search-markets","type":"resource","name":"Easley & Kleinberg: Sponsored Search Markets","description":"Clearest pedagogical treatment of online ad auctions. VCG from 'harm principle,' GSP mechanics, GSP vs VCG comparison with worked examples, why truth-telling isn't dominant in GSP. Perfect for understanding Google/Facebook ads.","category":"Auction Theory","url":"https://www.cs.cornell.edu/home/kleinber/networks-book/networks-book-ch15.pdf","difficulty":"intermediate","prerequisites":"game-theory-basics, microeconomics-fundamentals, mechanism-design","topic_tags":"auction-theory, sponsored-search, vcg-auctions, ad-markets, mechanism-design","summary":"Comprehensive textbook chapter explaining how online advertising auctions work, covering both theoretical VCG auctions and practical Generalized Second Price (GSP) mechanisms used by Google and Facebook. Provides clear mathematical foundations with worked examples showing why advertisers don't always bid truthfully in real ad platforms.","use_cases":"Understanding how to optimize bidding strategies for Google Ads or Facebook advertising campaigns, Designing auction mechanisms for marketplace platforms or analyzing competitive dynamics in digital advertising markets","audience":"Early-PhD, Mid-DS"},{"id":"resource-jonathan-levin's-revenue-equivalence-notes","type":"resource","name":"Jonathan Levin's Revenue Equivalence Notes","description":"Concise, rigorous proof from leading auction theorist (Susan Athey co-author). Revenue Equivalence Theorem, first-price vs. second-price, Dutch/English equivalence. Essential for understanding when auction format matters.","category":"Auction Theory","url":"https://economics.utoronto.ca/damiano/ps426/RET-Levin-Notes.pdf","difficulty":"intermediate","prerequisites":"game-theory-basics, probability-theory, mathematical-proofs","topic_tags":"revenue-equivalence, auction-design, mechanism-design, economic-theory, mathematical-economics","summary":"Rigorous mathematical notes proving the Revenue Equivalence Theorem by Jonathan Levin, demonstrating when different auction formats yield identical expected revenue. Essential reading for understanding auction mechanism design and when format choice matters for revenue optimization. Provides clear proofs connecting first-price, second-price, Dutch, and English auction equivalences.","use_cases":"Designing optimal auction mechanisms for marketplace platforms, Understanding when to use different bidding formats in advertising auctions","audience":"Early-PhD, Senior-DS"},{"id":"resource-kevin-leyton-brown's-vcg-mechanism-lectures","type":"resource","name":"Kevin Leyton-Brown's VCG Mechanism Lectures","description":"Structured theorem-proof format with worked examples. VCG formal definition, DSIC proofs, Clarke pivot rule, budget balance, shortest path auctions. Shows exactly how second-price sealed-bid is VCG special case.","category":"Auction Theory","url":"https://www.cs.ubc.ca/~kevinlb/teaching/cs532l%20-%202007-8/lectures/lect16.pdf","difficulty":"intermediate","prerequisites":"game-theory-basics, mathematical-proofs, optimization-theory","topic_tags":"VCG-mechanism, auction-design, mechanism-design, dominant-strategy, lecture-series","summary":"Comprehensive lecture series on Vickrey-Clarke-Groves (VCG) mechanisms covering formal definitions, dominant strategy incentive compatibility proofs, and practical implementations. Uses structured theorem-proof format with worked examples including Clarke pivot rule and shortest path auctions. Essential foundational material for understanding modern auction theory and mechanism design.","use_cases":"Designing online advertising auctions with truthful bidding incentives, Creating fair allocation mechanisms for computational resources in cloud platforms","audience":"Early-PhD, Senior-DS"},{"id":"resource-google-research:-market-algorithms-team","type":"resource","name":"Google Research: Market Algorithms Team","description":"Direct from engineers designing Google's auction systems. Ad exchange design, budget-constrained mechanisms, autobidding formulas, Price of Anarchy. Collaboration between Roughgarden, Tardos, and Google engineers.","category":"Auction Theory","url":"https://research.google/teams/market-algorithms/","difficulty":"advanced","prerequisites":"game-theory, mechanism-design, convex-optimization","topic_tags":"auction-mechanisms, ad-exchanges, algorithmic-game-theory, price-of-anarchy, autobidding","summary":"Research collaboration between Google engineers and academic economists on designing auction systems for ad exchanges. Covers budget-constrained mechanisms, autobidding algorithms, and theoretical analysis of market efficiency through Price of Anarchy metrics. Provides insights into real-world implementation of auction theory at massive scale.","use_cases":"designing auction mechanisms for two-sided marketplaces, implementing autobidding systems for advertising platforms","audience":"Senior-DS, Early-PhD"},{"id":"resource-nfx-network-effects-bible","type":"resource","name":"NFX Network Effects Bible","description":"The definitive practitioner reference. Sarnoff's/Metcalfe's/Reed's Laws, critical mass, same-side vs. cross-side effects, chicken-and-egg solutions, switching costs. Continuously updated with visual diagrams.","category":"Platform Economics","url":"https://www.nfx.com/post/network-effects-bible","difficulty":"beginner","prerequisites":"basic-microeconomics, business-strategy-fundamentals","topic_tags":"network-effects, platform-strategy, market-dynamics, business-models, competitive-moats","summary":"A comprehensive practitioner's guide to understanding and applying network effects in business strategy. Covers foundational laws like Metcalfe's and Reed's, practical frameworks for identifying network effects, and strategies for overcoming chicken-and-egg problems. Essential reading for anyone working on platforms, marketplaces, or products where user value increases with network size.","use_cases":"Designing growth strategies for a two-sided marketplace platform, Analyzing competitive advantages and switching costs for social media products","audience":"Junior-DS, Curious-browser"},{"id":"resource-nfx-network-effects-manual:-16-types","type":"resource","name":"NFX Network Effects Manual: 16 Types","description":"Most granular taxonomy: Physical, Protocol, Personal Utility, Marketplace, Platform, Asymptotic, Data, Tech Performance, Language, Belief, Bandwagon, Tribal effects. Explains why Uber/Lyft face asymptotic effects.","category":"Platform Economics","url":"https://www.nfx.com/post/network-effects-manual","difficulty":"beginner","prerequisites":"basic-microeconomics, business-strategy-frameworks","topic_tags":"network-effects, platform-strategy, competitive-moats, business-models","summary":"A comprehensive taxonomy breaking down network effects into 16 distinct types, from physical networks to psychological effects like bandwagon and tribal behaviors. This manual provides frameworks for understanding how different platforms create value through user connections and explains strategic implications like why ride-sharing companies face diminishing returns at scale.","use_cases":"Evaluating competitive advantages when analyzing platform companies like marketplaces or social networks, Designing growth strategies for two-sided platforms by identifying which network effects to prioritize","audience":"Junior-DS, Curious-browser"},{"id":"resource-nfx-network-effects-masterclass","type":"resource","name":"NFX Network Effects Masterclass","description":"3+ hour video course from operators who built 10+ companies with $10B+ in exits. 16 network effect types, case studies (Uber, Facebook, Bitcoin), Network Bonding Theory, cold start, Web3 applications.","category":"Platform Economics","url":"https://www.nfx.com/masterclass","difficulty":"beginner","prerequisites":"basic-microeconomics, business-strategy-fundamentals","topic_tags":"network-effects, platform-strategy, cold-start-problem, web3-economics, video-course","summary":"A comprehensive video masterclass teaching 16 types of network effects through real case studies from companies like Uber, Facebook, and Bitcoin. Created by experienced operators, it covers Network Bonding Theory, cold start strategies, and Web3 applications for building network-driven businesses.","use_cases":"Understanding how to build network effects into a new platform or marketplace product, Analyzing why certain tech companies achieved massive scale and defensibility through network dynamics","audience":"Junior-DS, Curious-browser"},{"id":"resource-stratechery-aggregation-theory","type":"resource","name":"Stratechery Aggregation Theory","description":"Most cited framework for understanding internet platform dominance. Zero distribution/marginal/transaction costs, aggregator virtuous cycle, winner-take-all dynamics, platform vs. aggregator distinction.","category":"Platform Economics","url":"https://stratechery.com/aggregation-theory/","difficulty":"beginner","prerequisites":"basic-microeconomics, network-effects-concepts","topic_tags":"aggregation-theory, platform-economics, network-effects, business-strategy, internet-platforms","summary":"Stratechery's Aggregation Theory explains how internet platforms achieve dominance through zero marginal costs and direct customer relationships. The framework describes the virtuous cycle where platforms attract users, then suppliers, creating winner-take-all dynamics. It's essential reading for understanding modern tech company strategy and market structure.","use_cases":"Analyzing why Google/Facebook dominate their markets and how new platforms might compete, Designing product strategy for a two-sided marketplace or platform business","audience":"Junior-DS, Curious-browser"},{"id":"resource-a16z:-measuring-network-effects","type":"resource","name":"a16z: Measuring Network Effects","description":"Quantitative measurement frameworks. Network effects vs. virality vs. scale, multi-tenanting impact, practical KPIs (DAU/MAU by density, organic vs. paid ratios, market-by-market unit economics).","category":"Platform Economics","url":"https://a16z.com/tag/all-about-network-effects/","difficulty":"intermediate","prerequisites":"cohort-analysis, funnel-metrics, basic-econometrics","topic_tags":"network-effects, platform-metrics, growth-measurement, marketplace-economics, kpi-frameworks","summary":"A16z's framework for quantitatively measuring network effects in platform businesses, distinguishing them from virality and scale effects. Provides practical KPI methodologies including density-based DAU/MAU ratios, organic vs paid user acquisition metrics, and market-by-market unit economics for multi-sided platforms.","use_cases":"Product manager at a marketplace needs to prove network effects are driving growth vs just viral marketing, Data scientist building dashboards to track platform health across different geographic markets","audience":"Mid-DS, Junior-DS"},{"id":"resource-quantecon:-discrete-state-dynamic-programming","type":"resource","name":"QuantEcon: Discrete State Dynamic Programming","description":"Gold standard for DP in economics. Bellman equation, value/policy iteration, contraction mapping proofs, stochastic optimal growth. Runnable Jupyter notebooks implement DiscreteDP class.","category":"Computational Economics","url":"https://python-advanced.quantecon.org/discrete_dp.html","difficulty":"intermediate","prerequisites":"python-programming, linear-algebra, optimization-theory","topic_tags":"dynamic-programming, bellman-equation, value-iteration, jupyter-notebooks, computational-economics","summary":"Comprehensive tutorial on discrete state dynamic programming with rigorous mathematical foundations and practical implementation. Covers the Bellman equation, value and policy iteration algorithms, and contraction mapping theory with runnable Python code. Essential resource for economists and data scientists working on sequential decision problems.","use_cases":"Modeling optimal investment decisions over time with uncertainty, Solving inventory management problems with stochastic demand","audience":"Early-PhD, Mid-DS"},{"id":"resource-matteo-courthoud's-blp-demand-estimation","type":"resource","name":"Matteo Courthoud's BLP Demand Estimation","description":"Exceptionally clear BLP from first principles. Share inversion, nested fixed-point step-by-step, instrument selection (BLP, Hausman, cost shifters), GMM estimation. Python implementation included.","category":"Computational Economics","url":"https://matteocourthoud.github.io/course/empirical-io/02_demand_estimation/","difficulty":"advanced","prerequisites":"industrial-organization, python-numpy, gmm-estimation","topic_tags":"blp-estimation, demand-modeling, industrial-organization, python-implementation, gmm","summary":"A comprehensive tutorial on Berry-Levinsohn-Pakes (BLP) demand estimation methodology, covering the complete workflow from theoretical foundations to practical implementation. Explains share inversion, nested fixed-point algorithms, and instrument selection strategies with working Python code. Essential for researchers analyzing product markets and estimating demand elasticities in differentiated product industries.","use_cases":"Estimating demand elasticities for products in differentiated markets like automobiles or cereals, Analyzing market power and competitive effects in merger simulations for antitrust policy","audience":"Early-PhD, Senior-DS"},{"id":"resource-frank-pinter's-demand-estimation-notes","type":"resource","name":"Frank Pinter's Demand Estimation Notes","description":"Builds intuition from multinomial logit \u2192 Berry (1994) \u2192 full BLP. MPEC vs. nested fixed-point, micro BLP with second-choice data. Written for PhD field exam prep with red bus-blue bus example.","category":"Computational Economics","url":"https://frankpinter.com/notes/Demand_Estimation_Notes.pdf","difficulty":"intermediate","prerequisites":"multinomial-logit, maximum-likelihood-estimation, numerical-optimization","topic_tags":"demand-estimation, blp-model, industrial-organization, structural-economics, mpec","summary":"Comprehensive notes on demand estimation methods progressing from basic multinomial logit to the full Berry-Levinsohn-Pakes (BLP) model. Covers both mathematical foundation and computational implementation, including MPEC vs nested fixed-point approaches and extensions to micro BLP with second-choice data. Written as PhD field exam preparation material with intuitive examples.","use_cases":"PhD student preparing for industrial organization comprehensive exams, Researcher implementing BLP demand estimation for market structure analysis","audience":"Early-PhD, Senior-DS"},{"id":"resource-aea:-machine-learning-and-econometrics-(athey-imbens)","type":"resource","name":"AEA: Machine Learning and Econometrics (Athey/Imbens)","description":"9 hours from two of the most influential computational economists. ML vs. causal inference, heterogeneous treatment effects, LASSO/random forests, causal forests, policy learning. Athey pioneered ML in economics; Imbens won 2021 Nobel.","category":"Computational Economics","url":"https://www.aeaweb.org/conference/cont-ed/2018-webcasts","difficulty":"intermediate","prerequisites":"linear-regression, python-scikit-learn, difference-in-differences","topic_tags":"causal-inference, machine-learning, econometrics, treatment-effects, video-lectures","summary":"Comprehensive 9-hour lecture series from Nobel laureate Guido Imbens and Susan Athey covering the intersection of machine learning and causal inference. Covers heterogeneous treatment effects, causal forests, policy learning, and when to use ML vs traditional econometric methods. Essential viewing for anyone applying ML methods to causal questions in economics or industry.","use_cases":"Estimating personalized treatment effects in A/B tests with machine learning, Learning policy optimization and causal forest implementation for heterogeneous effects","audience":"Mid-DS, Early-PhD"},{"id":"resource-mit-ocw:-dynamic-programming-(bertsekas)","type":"resource","name":"MIT OCW: Dynamic Programming (Bertsekas)","description":"6 advanced lectures (~12 hours) from the definitive DP authority. Approximate DP, large-scale infinite horizon problems, policy iteration with function approximation, temporal difference, neuro-dynamic programming.","category":"Computational Economics","url":"https://ocw.mit.edu/courses/6-231-dynamic-programming-and-stochastic-control-fall-2015/pages/related-video-lectures/","difficulty":"advanced","prerequisites":"markov-decision-processes, linear-algebra, optimization-theory","topic_tags":"dynamic-programming, reinforcement-learning, function-approximation, neuro-dynamic-programming, lectures","summary":"Advanced lecture series from Dimitri Bertsekas covering cutting-edge dynamic programming methods for large-scale problems. Focuses on approximate solutions, policy iteration with function approximation, and neuro-dynamic programming techniques. Essential for researchers working on reinforcement learning, optimal control, and complex sequential decision problems.","use_cases":"Building reinforcement learning models for large state spaces where exact DP is computationally infeasible, Developing optimal bidding strategies in ad auctions with complex state dynamics and function approximation","audience":"Senior-DS, Early-PhD"},{"id":"resource-open-source-economics:-structural-estimation","type":"resource","name":"Open Source Economics: Structural Estimation","description":"From UChicago's Masters in Computational Social Science. Structural vs. reduced-form, MLE, GMM, Simulated Method of Moments. Complete GitHub repositories with Python/Jupyter implementations.","category":"Computational Economics","url":"https://opensourceecon.github.io/CompMethods/struct_est/intro.html","difficulty":"intermediate","prerequisites":"python-pandas, maximum-likelihood-estimation, microeconomics-theory","topic_tags":"structural-estimation, computational-economics, maximum-likelihood, jupyter-notebooks, econometrics","summary":"University of Chicago course materials teaching structural estimation methods for economists, contrasting with reduced-form approaches. Covers maximum likelihood estimation, GMM, and Simulated Method of Moments with hands-on Python implementations. Provides complete GitHub repositories with Jupyter notebooks for practical learning of advanced econometric techniques.","use_cases":"Estimating consumer demand models to understand price elasticity and market structure, Building dynamic models of firm investment decisions using structural parameters","audience":"Early-PhD, Mid-DS"},{"id":"resource-ritvikmath-time-series-youtube-+-github","type":"resource","name":"ritvikmath Time Series YouTube + GitHub","description":"Hand-drawn diagrams build intuition before code. Covers AR, MA, ARMA, ARIMA, SARIMA, stationarity, ACF/PACF, GARCH. GitHub repo (700+ stars) with complete Jupyter notebooks. Explains why not just how.","category":"Classical Methods","url":"https://www.youtube.com/@ritvikmath","difficulty":"beginner","prerequisites":"python-basics, pandas-dataframes, basic-statistics","topic_tags":"time-series-analysis, forecasting-models, youtube-tutorials, jupyter-notebooks, visual-learning","summary":"Visual YouTube series teaching time series fundamentals through hand-drawn diagrams before diving into code implementation. Covers classical forecasting methods like ARIMA and GARCH with accompanying GitHub notebooks that explain the intuition behind each technique.","use_cases":"Learning time series forecasting for first data science project involving sales or demand prediction, Understanding stationarity concepts before implementing ARIMA models for financial data analysis","audience":"Junior-DS, Curious-browser"},{"id":"resource-interpreting-acf-and-pacf-plots","type":"resource","name":"Interpreting ACF and PACF Plots","description":"Uses synthetic data with known parameters to demonstrate what patterns indicate which model types. Clear decision rules for AR/MA order selection. Visual approach builds pattern recognition skill.","category":"Classical Methods","url":"https://towardsdatascience.com/interpreting-acf-and-pacf-plots-for-time-series-forecasting-af0d6db4061c/","difficulty":"beginner","prerequisites":"time-series-basics, autoregression-concepts, moving-averages","topic_tags":"ACF-PACF, ARIMA-modeling, pattern-recognition, model-selection, visual-diagnostics","summary":"A tutorial using synthetic datasets to teach pattern recognition in ACF and PACF plots for time series model identification. Provides clear decision rules for determining AR and MA orders through visual inspection. Essential skill for classical time series analysis before fitting ARIMA models.","use_cases":"Identifying appropriate ARIMA model order before forecasting sales or demand data, Diagnosing time series structure in A/B test metrics with temporal dependencies","audience":"Early-PhD, Junior-DS"},{"id":"resource-mstl-multi-seasonal-decomposition-in-python","type":"resource","name":"MSTL Multi-Seasonal Decomposition in Python","description":"Written by the engineer who contributed MSTL to statsmodels. STL algorithm internals, LOESS smoothing foundations, comparison to Prophet/TBATS. Electricity demand example with step-by-step algorithm walkthrough.","category":"Classical Methods","url":"https://www.blog.trainindata.com/multi-seasonal-time-series-decomposition-using-mstl-in-python/","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, statsmodels","topic_tags":"seasonal-decomposition, MSTL, LOESS-smoothing, time-series, electricity-demand","summary":"Deep dive into MSTL (Multiple Seasonal-Trend decomposition using Loess) written by the original contributor to statsmodels. Covers STL algorithm internals, LOESS smoothing foundations, and practical comparisons to Prophet and TBATS. Includes step-by-step implementation with electricity demand forecasting example.","use_cases":"Decomposing electricity demand with daily and weekly seasonality, Analyzing retail sales data with multiple seasonal patterns","audience":"Mid-DS, Senior-DS"},{"id":"resource-time-series-handbook:-lightgbm-for-m5","type":"resource","name":"Time Series Handbook: LightGBM for M5","description":"Complete Jupyter Book with runnable code. LightGBM MAE (200.5) vs. naive baseline (698.0). Feature engineering (lags, rolling windows), recursive vs. direct forecasting, hyperparameter tuning. Free via GitHub with Binder.","category":"Machine Learning","url":"https://phdinds-aim.github.io/time_series_handbook/08_WinningestMethods/lightgbm_m5_forecasting.html","difficulty":"intermediate","prerequisites":"python-pandas, gradient-boosting, time-series-fundamentals","topic_tags":"lightgbm, m5-competition, time-series-forecasting, feature-engineering, jupyter-book","summary":"A comprehensive Jupyter Book demonstrating LightGBM for time series forecasting using the M5 competition dataset. Covers feature engineering techniques like lags and rolling windows, compares recursive vs. direct forecasting approaches, and includes hyperparameter optimization. Achieves MAE of 200.5 compared to 698.0 naive baseline with fully runnable code examples.","use_cases":"Building demand forecasting models for retail inventory planning, Creating sales prediction systems with gradient boosting methods","audience":"Junior-DS, Mid-DS"},{"id":"resource-blocked-time-series-cross-validation","type":"resource","name":"Blocked Time Series Cross Validation","description":"Addresses critical issue: expanding window CV produces overly optimistic estimates. Drop-in sklearn-compatible code. Explains why blocked CV gives realistic production performance estimates.","category":"Machine Learning","url":"https://towardsdatascience.com/reduce-bias-in-time-series-cross-validation-with-blocked-split-4ecbfc88f5a4/","difficulty":"intermediate","prerequisites":"scikit-learn, time-series-analysis, python-pandas","topic_tags":"time-series, cross-validation, forecasting, model-evaluation, sklearn","summary":"A cross-validation technique specifically designed for time series data that prevents data leakage by creating time-based blocks instead of random splits. Provides more realistic performance estimates for production forecasting models compared to standard expanding window approaches. Essential for anyone building time-dependent predictive models in tech environments.","use_cases":"Evaluating demand forecasting models for e-commerce inventory management, Validating user engagement prediction models with sequential behavioral data","audience":"Junior-DS, Mid-DS"},{"id":"resource-m5-competition-analysis:-learnings-and-winning-solutions","type":"resource","name":"M5 Competition Analysis: Learnings and Winning Solutions","description":"Synthesizes learnings from 5,558 teams on 42,840 time series. Key finding: ML beats statistical when you have many correlated series, exogenous variables, hierarchical structure. LightGBM vs. N-BEATS vs. seq2seq comparison.","category":"Machine Learning","url":"https://medium.com/analytics-vidhya/predicting-the-future-with-learnings-from-the-m5-competition-d54e84ca3d0d","difficulty":"intermediate","prerequisites":"time-series-analysis, lightgbm, neural-networks","topic_tags":"forecasting, competition-analysis, lightgbm, neural-networks, hierarchical-forecasting","summary":"Comprehensive analysis of the M5 forecasting competition results from over 5,500 teams predicting 42,840 time series. Shows when machine learning methods outperform statistical approaches and compares popular models like LightGBM, N-BEATS, and seq2seq. Provides practical guidance for choosing forecasting methods based on data characteristics.","use_cases":"Selecting appropriate forecasting methods for retail demand prediction with hierarchical product categories, Benchmarking ML vs statistical approaches for multi-series forecasting problems","audience":"Mid-DS, Senior-DS"},{"id":"resource-tensorflow-time-series-forecasting-tutorial","type":"resource","name":"TensorFlow Time Series Forecasting Tutorial","description":"Official Google documentation with production-quality code. Builds models incrementally: linear \u2192 dense \u2192 CNN \u2192 LSTM. Includes baseline comparisons so you can assess if DL is worth the complexity. Runnable in Colab.","category":"Deep Learning","url":"https://www.tensorflow.org/tutorials/structured_data/time_series","difficulty":"intermediate","prerequisites":"python-tensorflow, neural-networks, time-series-basics","topic_tags":"time-series-forecasting, tensorflow, LSTM, CNN, tutorial","summary":"A comprehensive TensorFlow tutorial that teaches time series forecasting by building increasingly complex models from linear regression to LSTMs. Includes production-ready code, baseline comparisons, and guidance on when deep learning approaches are justified over simpler methods.","use_cases":"Forecasting product demand or user engagement metrics at a tech company, Building predictive models for financial time series or sensor data","audience":"Junior-DS, Mid-DS"},{"id":"resource-temporal-fusion-transformer:-complete-tutorial","type":"resource","name":"Temporal Fusion Transformer: Complete Tutorial","description":"End-to-end TFT with PyTorch Forecasting. Handles heterogeneous features (static, time-varying known/unknown). Interpretability via variable importance and attention. Shows when TFT outperforms simpler methods.","category":"Deep Learning","url":"https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91/","difficulty":"intermediate","prerequisites":"pytorch-basics, time-series-analysis, transformer-architecture","topic_tags":"temporal-fusion-transformer, time-series-forecasting, pytorch-forecasting, attention-mechanism, interpretable-ml","summary":"Complete tutorial on Temporal Fusion Transformer (TFT), a state-of-the-art deep learning model for time series forecasting that handles multiple types of features and provides interpretability. Uses PyTorch Forecasting for implementation and shows how to leverage attention mechanisms and variable importance for explainable predictions. Includes guidance on when TFT is worth the complexity over simpler forecasting methods.","use_cases":"demand-forecasting-with-promotional-calendar-and-weather-data, financial-time-series-prediction-with-mixed-categorical-and-numerical-features","audience":"Mid-DS, Senior-DS"},{"id":"resource-time-series-forecasting-with-lag-llama","type":"resource","name":"Time Series Forecasting with Lag-Llama","description":"Foundation models landscape (Lag-Llama, TimesFM, Moirai, TimeGPT-1). Zero-shot vs. fine-tuning decision framework. Probabilistic forecasts with uncertainty quantification. Complete Python with GluonTS.","category":"Deep Learning","url":"https://www.ibm.com/think/tutorials/lag-llama","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, pytorch-basics","topic_tags":"time-series-forecasting, foundation-models, probabilistic-forecasting, gluonts, python-tutorial","summary":"A comprehensive guide to modern foundation models for time series forecasting, comparing Lag-Llama, TimesFM, Moirai, and TimeGPT-1. Provides a decision framework for choosing between zero-shot predictions and fine-tuning approaches. Includes hands-on Python implementation using GluonTS for probabilistic forecasting with uncertainty quantification.","use_cases":"Forecasting product demand across multiple SKUs without historical model training, Predicting user engagement metrics with confidence intervals for A/B test planning","audience":"Mid-DS, Junior-DS"},{"id":"resource-chronos-bolt:-fast-zero-shot-forecasting-(aws)","type":"resource","name":"Chronos-Bolt: Fast Zero-Shot Forecasting (AWS)","description":"T5 architecture with patching. Quantifies efficiency-accuracy tradeoff: 250x faster, 20x more memory efficient than original Chronos. Benchmarked on 27 datasets. Shows combining univariate foundation models with exogenous features.","category":"Deep Learning","url":"https://aws.amazon.com/blogs/machine-learning/fast-and-accurate-zero-shot-forecasting-with-chronos-bolt-and-autogluon/","difficulty":"intermediate","prerequisites":"pytorch-transformers, time-series-analysis, transformer-architectures","topic_tags":"zero-shot-forecasting, foundation-models, time-series, model-efficiency, aws","summary":"Chronos-Bolt is AWS's optimized version of the Chronos forecasting foundation model, built on T5 architecture with patching techniques. It delivers 250x speed improvement and 20x memory efficiency while maintaining competitive accuracy across 27 benchmark datasets. The model demonstrates how to effectively combine univariate foundation models with external features for zero-shot time series forecasting.","use_cases":"Deploying fast forecasting models in production environments where latency and memory constraints are critical, Running zero-shot forecasting experiments across multiple time series without domain-specific training data","audience":"Mid-DS, Senior-DS"},{"id":"resource-uber:-forecasting-introduction","type":"resource","name":"Uber: Forecasting Introduction","description":"Written by M4 Competition winner team. Covers 15 million trips/day across 600+ cities. Explicitly addresses ML vs. statistical methods decision. Use cases: marketplace, capacity planning, marketing.","category":"Production Systems","url":"https://www.uber.com/blog/forecasting-introduction/","difficulty":"intermediate","prerequisites":"time-series-analysis, python-pandas, statistical-modeling","topic_tags":"time-series-forecasting, production-systems, statistical-methods, marketplace-optimization, capacity-planning","summary":"Production-scale forecasting guide from Uber's M4 Competition winning team covering 15 million daily trips across 600+ cities. Provides practical framework for choosing between ML and statistical approaches in high-volume forecasting scenarios. Includes real-world applications for marketplace dynamics, capacity planning, and marketing optimization.","use_cases":"Predicting demand surge patterns for ride-sharing platforms to optimize driver allocation, Forecasting customer acquisition volumes for marketing budget planning in two-sided marketplaces","audience":"Mid-DS, Junior-DS"},{"id":"resource-uber:-backtesting-at-scale","type":"resource","name":"Uber: Backtesting at Scale","description":"Architecture for ~10 million backtests. Four backtesting vectors (cities, windows, variants, granularity). Go/Cadence workflows. Evolution from Omphalos framework to handle exponential growth.","category":"Production Systems","url":"https://www.uber.com/blog/backtesting-at-scale/","difficulty":"intermediate","prerequisites":"time-series-forecasting, distributed-systems, workflow-orchestration","topic_tags":"backtesting, scalable-architecture, forecasting-systems, production-engineering, workflow-management","summary":"Uber's architecture for running ~10 million backtests across cities, time windows, model variants, and granularities. Uses Go and Cadence workflows to handle exponential growth beyond their original Omphalos framework. Shows how to scale forecasting validation from prototype to production at massive scale.","use_cases":"Building scalable backtesting infrastructure for demand forecasting across multiple markets, Designing distributed systems to validate time series models across thousands of parameter combinations","audience":"Mid-DS, Senior-DS"},{"id":"resource-doordash:-elite-ensemble-learning","type":"resource","name":"DoorDash: ELITE Ensemble Learning","description":"ELITE (Ensemble Learning for Improved Time-series Estimation). Addresses accuracy vs. speed/cost tradeoffs. Scales to tens of thousands of targets. Practical engineering decisions for when perfect is enemy of good.","category":"Production Systems","url":"https://doordash.engineering/2023/06/20/how-doordash-built-an-ensemble-learning-model-for-time-series-forecasting/","difficulty":"intermediate","prerequisites":"time-series-forecasting, ensemble-methods, python-scikit-learn","topic_tags":"ensemble-learning, time-series, production-forecasting, scalability, doordash","summary":"DoorDash's ELITE framework combines multiple forecasting models to improve prediction accuracy while maintaining computational efficiency at scale. The system handles tens of thousands of forecasting targets simultaneously, making practical engineering tradeoffs between model complexity and operational requirements. It demonstrates how to operationalize ensemble methods for real-world time-series problems where perfect accuracy must be balanced against speed and cost constraints.","use_cases":"Forecasting delivery demand across thousands of restaurant locations with varying traffic patterns, Predicting inventory needs for multiple product categories while managing computational costs in production","audience":"Mid-DS, Senior-DS"},{"id":"resource-instacart-anytime:-data-science-paradigm","type":"resource","name":"Instacart Anytime: Data Science Paradigm","description":"End-to-end system: forecasting integrates with supply planning and capacity decisions. Key metrics: Availability, Idleness, Unmet Demand. Multi-horizon forecasting (weeks ahead for acquisition, hourly for store-level).","category":"Production Systems","url":"https://tech.instacart.com/instacart-anytime-a-data-science-paradigm-33eb25a5c32d","difficulty":"intermediate","prerequisites":"time-series-forecasting, python-pandas, supply-chain-basics","topic_tags":"demand-forecasting, supply-chain, multi-horizon-prediction, production-systems, instacart","summary":"Instacart's end-to-end forecasting system that integrates demand prediction with supply planning and capacity decisions. The system handles multiple time horizons from hourly store-level forecasts to weeks-ahead acquisition planning. Key focus on balancing availability, shopper idleness, and unmet demand through coordinated forecasting.","use_cases":"Building integrated forecasting systems for marketplace platforms with supply and demand matching, Designing multi-horizon prediction pipelines for retail operations with capacity constraints","audience":"Mid-DS, Senior-DS"},{"id":"resource-causal-inference-for-the-brave-and-true:-time-series","type":"resource","name":"Causal Inference for the Brave and True: Time Series","description":"By economist at Nubank. Chapters 13-15, 24-25 address panel data/time series causal analysis. DiD, synthetic controls, RDD with time dimension. Bridges econometrics and ML with executable notebooks.","category":"Specialized Methods","url":"https://matheusfacure.github.io/python-causality-handbook/landing-page.html","difficulty":"intermediate","prerequisites":"python-pandas, basic-regression, difference-in-differences","topic_tags":"time-series-causal-inference, synthetic-control, regression-discontinuity, panel-data, jupyter-notebooks","summary":"A practical guide to causal inference methods specifically for time series and panel data, written by a Nubank economist. Covers difference-in-differences, synthetic controls, and regression discontinuity with time dimensions through executable Python notebooks. Bridges traditional econometric methods with modern machine learning implementation approaches.","use_cases":"Measuring impact of product feature launch on user engagement over time, Evaluating policy interventions using regional panel data with synthetic control groups","audience":"Mid-DS, Junior-DS"},{"id":"resource-conformal-prediction-intervals-for-time-series","type":"resource","name":"Conformal Prediction Intervals for Time Series","description":"Distribution-free uncertainty quantification without Gaussian assumptions. Model-agnostic approach works with any forecasting method. Addresses limitation of bootstrap (only captures data uncertainty). MAPIE implementation.","category":"Specialized Methods","url":"https://towardsdatascience.com/time-series-forecasting-with-conformal-prediction-intervals-scikit-learn-is-all-you-need-4b68143a027a/","difficulty":"intermediate","prerequisites":"python-time-series, quantile-regression, cross-validation","topic_tags":"conformal-prediction, uncertainty-quantification, time-series, forecasting, model-agnostic","summary":"Conformal prediction provides distribution-free uncertainty intervals for time series forecasts without assuming Gaussian errors. This model-agnostic approach works with any forecasting method and captures both model and data uncertainty. The MAPIE library provides practical implementation for Python users.","use_cases":"Creating prediction intervals for revenue forecasts when unsure about error distribution assumptions, Quantifying uncertainty in demand forecasting models for inventory planning decisions","audience":"Mid-DS, Senior-DS"},{"id":"resource-anomaly-detection-in-time-series","type":"resource","name":"Anomaly Detection in Time Series","description":"Systematic coverage: point outliers, subsequence outliers. Methods from simple to complex: STL-based, Isolation Forest, ARIMA/Prophet-based, autoencoders with PyOD. Critical for pre-forecasting data cleaning.","category":"Specialized Methods","url":"https://neptune.ai/blog/anomaly-detection-in-time-series","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, time-series-basics","topic_tags":"anomaly-detection, time-series, outlier-detection, data-preprocessing, forecasting-prep","summary":"A comprehensive guide to detecting anomalies in time series data, covering both point and subsequence outliers. Progresses from simple statistical methods like STL decomposition to advanced techniques including Isolation Forest and neural autoencoders, with practical PyOD implementations for data scientists preparing forecasting pipelines.","use_cases":"Cleaning historical sales data before building demand forecasting models, Identifying unusual user behavior patterns in app usage metrics before A/B testing","audience":"Mid-DS, Junior-DS"},{"id":"resource-change-point-detection-in-time-series","type":"resource","name":"Change Point Detection in Time Series","description":"Six algorithms via ruptures library (PELT, Dynamic Programming, Binary Segmentation, Window-based, Bottom-up, Kernel CPD). Real Google Search Console application. Discusses computational complexity tradeoffs.","category":"Specialized Methods","url":"https://forecastegy.com/posts/change-point-detection-time-series-python/","difficulty":"intermediate","prerequisites":"python-pandas, time-series-analysis, scikit-learn","topic_tags":"change-point-detection, time-series, ruptures-library, anomaly-detection, structural-breaks","summary":"A comprehensive guide to detecting structural breaks in time series using six different algorithms implemented in the ruptures Python library. Compares computational complexity and performance tradeoffs between methods like PELT, Dynamic Programming, and Binary Segmentation. Includes a practical application using Google Search Console data to demonstrate real-world implementation.","use_cases":"Detecting when user engagement patterns change after product launches or marketing campaigns, Identifying structural breaks in business metrics like revenue or conversion rates during economic shifts","audience":"Mid-DS, Junior-DS"},{"id":"talk-susan-athey:-applied-researchers-&-causation","type":"talk","name":"Susan Athey: applied researchers & Causation","description":"World of DaaS podcast. How she 'invented' the applied researcher role at Microsoft. The difference between prediction and 'what if' questions.","category":"Causal Inference & ML","url":"https://www.youtube.com/watch?v=q4hWBep5RIc","difficulty":"beginner","prerequisites":"basic-statistics, regression-analysis","topic_tags":"causal-inference, applied-research, tech-industry, podcast, career-development","summary":"Susan Athey discusses her pioneering role as an applied researcher at Microsoft and explains the fundamental distinction between predictive modeling and causal 'what if' questions. This podcast provides insights into how academic economists can transition to tech roles and apply causal thinking to business problems.","use_cases":"Understanding how to transition from academic economics to tech industry research roles, Learning when to use causal inference versus prediction models for business decision-making","audience":"Early-PhD, Curious-browser"},{"id":"talk-susan-athey:-applied-researchers-wanted","type":"talk","name":"Susan Athey: applied researchers Wanted","description":"AEA Research Highlights. Why companies like Airbnb need researchers to solve marketplace design problems.","category":"Strategy & Digital Platforms","url":"https://www.aeaweb.org/research/athey-luca-interview-tech-economics","difficulty":"beginner","prerequisites":"basic-economics, marketplace-concepts","topic_tags":"marketplace-design, platform-economics, research-careers, industry-academia, applied-economics","summary":"Susan Athey discusses the critical need for applied researchers in tech companies to solve complex marketplace design problems. She explains how companies like Airbnb require economists and data scientists who can bridge academic theory with practical business challenges. The talk highlights career opportunities and the value of research skills in platform businesses.","use_cases":"Understanding career paths from academia to tech industry research roles, Learning how economic theory applies to real marketplace design problems at scale","audience":"Early-PhD, Curious-browser"},{"id":"talk-susan-athey:-economics-&-ai","type":"talk","name":"Susan Athey: Economics & AI","description":"Stanford GSB Fireside Chat on the intersection of economics and artificial intelligence.","category":"Causal Inference & ML","url":"https://www.youtube.com/watch?v=lNsl76AD1kE","difficulty":"intermediate","prerequisites":"basic-econometrics, machine-learning-fundamentals, causal-inference-concepts","topic_tags":"economics-AI, causal-inference, machine-learning, fireside-chat, video-content","summary":"Stanford GSB fireside chat featuring Susan Athey discussing how economics and artificial intelligence intersect, particularly in causal inference applications. Covers practical insights on applying economic thinking to AI problems and using ML methods for causal analysis. Valuable for practitioners bridging economics and data science in tech environments.","use_cases":"Understanding how to apply economic frameworks when building AI systems for business decisions, Learning approaches to combine machine learning with causal inference for policy evaluation or product impact analysis","audience":"Mid-DS, Curious-browser"},{"id":"talk-susan-athey:-economics-of-transformative-ai","type":"talk","name":"Susan Athey: Economics of Transformative AI","description":"NBER lecture on how AI is transforming economic research and industry applications.","category":"Strategy & Digital Platforms","url":"https://www.youtube.com/watch?v=ifdSUKrJxqM","difficulty":"intermediate","prerequisites":"basic-econometrics, machine-learning-fundamentals, causal-inference","topic_tags":"artificial-intelligence, economic-research, digital-transformation, NBER-lecture, video-content","summary":"Susan Athey's NBER lecture examining how AI technologies are revolutionizing economic research methodologies and creating new opportunities in industry applications. She discusses the intersection of machine learning and causal inference, highlighting how economists can leverage AI tools for better policy analysis and business decision-making. The talk covers both theoretical frameworks and practical implementations of AI in economic contexts.","use_cases":"Understanding how to integrate machine learning methods into traditional economic research workflows, Learning about AI applications in digital platform strategy and market design","audience":"Mid-DS, Senior-DS"},{"id":"talk-steve-tadelis:-causal-inference-in-tech","type":"talk","name":"Steve Tadelis: Causal Inference in Tech","description":"UC Berkeley / ex-eBay. Deep dive into causal inference methods used in tech companies.","category":"Causal Inference & ML","url":"https://www.youtube.com/watch?v=0l4cAWWMAKQ","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, regression-discontinuity, instrumental-variables","topic_tags":"causal-inference, tech-industry, experimentation, video-lecture, applied-methods","summary":"Steve Tadelis, UC Berkeley professor and former eBay economist, presents practical causal inference methods used in tech companies. The talk covers how to identify causal effects in digital environments where traditional experiments may not be feasible. Essential viewing for data scientists working on product decisions and business impact measurement.","use_cases":"Measuring the causal impact of product features on user engagement when A/B testing isn't possible, Evaluating the effectiveness of marketing campaigns using observational data from digital platforms","audience":"Mid-DS, Senior-DS"},{"id":"talk-hal-varian:-googlenomics-q&a","type":"talk","name":"Hal Varian: Googlenomics Q&A","description":"AEI podcast. The 'Adam Smith of Googlenomics' on auction design and why productivity metrics fail in the digital age.","category":"Market Design & Auctions","url":"https://www.aei.org/economics/googlenomics-a-long-read-qa-with-chief-economist-hal-varian/","difficulty":"beginner","prerequisites":"microeconomics-basics, auction-theory-fundamentals","topic_tags":"auction-design, tech-economics, productivity-measurement, digital-markets, podcast-interview","summary":"Hal Varian, Google's Chief Economist, discusses fundamental concepts in auction design and the challenges of measuring productivity in digital companies. The interview covers key insights from Google's experience with auction mechanisms and broader questions about economic measurement in the tech sector.","use_cases":"Understanding how major tech platforms design their auction systems, Learning why traditional productivity metrics don't work for digital businesses","audience":"Curious-browser, Early-PhD"},{"id":"talk-hal-varian:-chief-scientist-at-google","type":"talk","name":"Hal Varian: Chief Scientist at Google","description":"Room for Discussion. Why every company needs a chief scientist for forecasting, pricing, and market design.","category":"Market Design & Auctions","url":"https://www.youtube.com/watch?v=d3CtB_gVV18","difficulty":"beginner","prerequisites":"basic-economics, business-strategy","topic_tags":"chief-scientist, business-economics, forecasting, pricing-strategy, organizational-roles","summary":"Hal Varian, Google's Chief Economist, discusses the strategic value of having a chief scientist role in companies for economic decision-making. He covers how this role applies economic principles to solve business problems in forecasting, pricing optimization, and market design. The talk provides insights into bridging academic economics with practical business applications.","use_cases":"Understanding how to structure data science teams with economic expertise, Learning how major tech companies apply economic principles to business strategy","audience":"Curious-browser, Junior-DS"},{"id":"talk-hal-varian:-doing-economics-at-google","type":"talk","name":"Hal Varian: Doing Economics at Google","description":"CEPR interview on search dynamics, ad auctions, and forecasting with Google Trends.","category":"Market Design & Auctions","url":"https://cepr.org/multimedia/doing-economics-google","difficulty":"intermediate","prerequisites":"auction-theory, econometrics-basics, regression-analysis","topic_tags":"auction-mechanisms, search-economics, google-trends, ad-auctions, economics-interview","summary":"Google's Chief Economist Hal Varian discusses how economic principles are applied at scale in Google's products, particularly in search algorithms and advertising auctions. The interview covers practical applications of auction theory, using Google Trends for economic forecasting, and insights into how tech companies use market design principles. This provides real-world context for how academic economics translates into billion-dollar tech platforms.","use_cases":"Understanding how auction theory applies to real-world ad marketplaces and platform design, Learning how to use search data and Google Trends for economic forecasting and nowcasting","audience":"Mid-DS, Curious-browser"},{"id":"talk-john-list:-scale,-uber-&-the-voltage-effect","type":"talk","name":"John List: Scale, Uber & The Voltage Effect","description":"EconTalk. Former Chief Scientist at Uber and Lyft shares war stories on field experiments and driver incentives.","category":"Experimentation & Scaling","url":"https://www.econtalk.org/john-list-on-scale-uber-and-the-voltage-effect/","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, causal-inference, field-experiments","topic_tags":"field-experiments, uber-economics, driver-incentives, scaling-experiments, podcast","summary":"Former Uber and Lyft Chief Scientist John List discusses practical challenges of running large-scale field experiments in rideshare platforms. He shares real-world insights on driver incentive schemes, experiment design at scale, and lessons from The Voltage Effect book. Essential listening for practitioners wanting to understand how academic experimental methods translate to tech industry applications.","use_cases":"Designing driver or user incentive experiments at a rideshare or delivery platform, Understanding how to scale successful pilot experiments to full product launches","audience":"Mid-DS, Senior-DS"},{"id":"talk-john-list:-scaling-proven-ideas","type":"talk","name":"John List: Scaling Proven Ideas","description":"How to scale ideas at Uber, Lyft, and Walmart. Why most interventions fail when you try to grow them.","category":"Experimentation & Scaling","url":"https://mikemalatesta.com/podcast/john-list-scaling-proven-ideas-for-uber-lyft-walmart-260/","difficulty":"beginner","prerequisites":"randomized-controlled-trials, statistical-significance","topic_tags":"scaling-experiments, external-validity, field-experiments, tech-platforms, causal-inference","summary":"John List discusses the challenges of scaling successful small-scale interventions at major tech companies like Uber, Lyft, and Walmart. He explores why most proven ideas fail when expanded to larger populations and different contexts. The talk provides practical insights on external validity and the scaling problem in real-world experimentation.","use_cases":"Planning to roll out a successful A/B test result to a broader user base, Understanding why a pilot program's results didn't replicate when scaled company-wide","audience":"Mid-DS, Senior-DS"},{"id":"talk-john-list:-market-design-in-ride-sharing","type":"talk","name":"John List: Market Design in Ride-Sharing","description":"How ride-sharing platforms design markets for drivers and riders. Insights from Uber and Lyft.","category":"Market Design & Auctions","url":"https://www.youtube.com/watch?v=CF7FQnD-2jg","difficulty":"intermediate","prerequisites":"microeconomics-theory, game-theory-basics, A-B-testing","topic_tags":"market-design, ride-sharing, platform-economics, auction-theory, video","summary":"John List explains how ride-sharing platforms like Uber and Lyft design two-sided markets to efficiently match drivers and riders. The talk covers pricing mechanisms, surge pricing, and market design principles that maximize platform efficiency and user satisfaction. Essential viewing for understanding how tech platforms create and optimize marketplace dynamics.","use_cases":"Designing pricing algorithms for a new ride-sharing or delivery platform, Optimizing marketplace matching mechanisms to reduce wait times and increase driver utilization","audience":"Mid-DS, Senior-DS"},{"id":"talk-kyle-kretschman:-economics-at-spotify","type":"talk","name":"Kyle Kretschman: Economics at Spotify","description":"Causal Inference Podcast. A rare look at a working applied researcher role \u2014 running experimentation teams at a streaming giant.","category":"Experimentation & Scaling","url":"https://causalinf.substack.com/p/s1e27-interview-with-kyle-kretschman","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference-basics, experimentation-design","topic_tags":"spotify, tech-industry, experimentation-management, applied-research, podcast","summary":"A podcast interview with Kyle Kretschman discussing his role running experimentation teams at Spotify. Provides insights into how causal inference and A/B testing work in practice at a major streaming platform, covering team management, technical challenges, and real-world application of experimental methods.","use_cases":"Understanding how experimentation teams operate at major tech companies, Learning about career paths for applied researchers in industry","audience":"Mid-DS, Junior-DS"},{"id":"talk-pat-bajari:-building-applied-analytics-at-amazon","type":"talk","name":"Pat Bajari: Building applied analytics at Amazon","description":"Keystone interview. How Amazon's Chief Scientist built applied research from scratch with 400+ PhD researchers.","category":"Strategy & Digital Platforms","url":"https://www.keystone.ai/news-publications/patrick-bajari-qa","difficulty":"beginner","prerequisites":"basic-statistics, business-strategy-fundamentals","topic_tags":"research-organization, applied-economics, tech-strategy, team-building, interview","summary":"Pat Bajari, Amazon's Chief Scientist, shares insights on building and scaling applied research teams from the ground up. He discusses the challenges and strategies for integrating 400+ PhD researchers into a tech company's business operations. The interview covers organizational design, hiring practices, and translating academic research into business value.","use_cases":"Building or scaling an applied research team at a tech company, Understanding how to transition from academic research to industry applications","audience":"Senior-DS, Curious-browser"},{"id":"talk-preston-mcafee:-auction-design-&-applied-analytics","type":"talk","name":"Preston McAfee: Auction Design & applied analytics","description":"Chief Scientist at Yahoo, Google, Microsoft. Golden Goose Award winner. Deep interview on auction theory, ad markets, and mechanism design.","category":"Market Design & Auctions","url":"https://www.richmondfed.org/publications/research/econ_focus/2018/q4/interview","difficulty":"intermediate","prerequisites":"microeconomics-fundamentals, game-theory-basics, probability-theory","topic_tags":"auction-theory, mechanism-design, ad-markets, interview, applied-economics","summary":"Deep interview with Preston McAfee, former Chief Scientist at major tech companies and Golden Goose Award winner, discussing auction theory and its applications in digital advertising markets. Covers fundamental auction design principles and real-world implementation challenges in tech platforms. Essential listening for understanding how economic theory translates to practical market design in the digital economy.","use_cases":"Understanding how search and display ad auctions work at major tech platforms, Learning career paths from academic economics to applied tech roles","audience":"Mid-DS, Senior-DS"},{"id":"talk-sean-taylor:-when-do-we-need-causal-inference?","type":"talk","name":"Sean Taylor: When Do We Need Causal Inference?","description":"Former Lyft/Facebook DS lead. This talk saves you from over-engineering. Know when correlation is enough.","category":"Causal Inference & ML","url":"https://www.youtube.com/watch?v=2dv7NrYExzo","difficulty":"beginner","prerequisites":"basic-statistics, correlation-vs-causation","topic_tags":"causal-inference, decision-making, research-design, experimentation, talk","summary":"Sean Taylor, former DS lead at Lyft and Facebook, explains when causal inference is necessary versus when simple correlation analysis suffices. This practical talk helps data scientists avoid over-engineering solutions by understanding the decision context and business requirements. Essential viewing for practitioners learning to choose appropriate analytical approaches.","use_cases":"Deciding whether to run an A/B test or use observational data for a product feature analysis, Determining if complex causal methods are needed for a business metric investigation","audience":"Junior-DS, Mid-DS"},{"id":"talk-ml-for-pricing-&-auctions-(icml)","type":"talk","name":"ML for Pricing & Auctions (ICML)","description":"Design the mechanism, don't just bid in it. RegretNet and deep learning for auction design.","category":"Market Design & Auctions","url":"https://www.youtube.com/watch?v=gsPWQqVhb74","difficulty":"advanced","prerequisites":"neural-networks, game-theory, optimization-theory","topic_tags":"auction-design, mechanism-design, deep-learning, regretnet, ICML","summary":"This ICML talk covers RegretNet and deep learning approaches to auction mechanism design, focusing on designing optimal auction mechanisms rather than just bidding strategies. It demonstrates how machine learning can solve complex mechanism design problems that are intractable with traditional analytical methods.","use_cases":"Designing revenue-maximizing auction formats for digital advertising platforms, Creating fair and efficient spectrum allocation mechanisms for telecom regulators","audience":"Senior-DS, Early-PhD"},{"id":"talk-nikhil-devanur:-lagrangian-duality-in-mechanism-design","type":"talk","name":"Nikhil Devanur: Lagrangian Duality in Mechanism Design","description":"Microsoft Research. How to design revenue-maximizing auctions using duality \u2014 simple auctions, budget smoothing, and optimal mechanisms.","category":"Market Design & Auctions","url":"https://mediaspace.gatech.edu/media/Nikhil+Devanur+-+Lagrangian+Duality+in+Mechanism+Design/1_oj4qzj8x","difficulty":"advanced","prerequisites":"lagrangian-optimization, convex-optimization, auction-theory","topic_tags":"mechanism-design, auction-optimization, lagrangian-duality, revenue-maximization, mathematical-economics","summary":"A technical presentation on using Lagrangian duality theory to design optimal revenue-maximizing auction mechanisms. Covers mathematical frameworks for auction design, budget constraint handling, and deriving simple auction formats from complex optimization problems.","use_cases":"Designing ad auction mechanisms for platforms like Google or Facebook, Creating marketplace pricing strategies for two-sided markets with budget constraints","audience":"Senior-DS, Early-PhD"},{"id":"talk-guido-imbens:-nobel-lecture-2021","type":"talk","name":"Guido Imbens: Nobel Lecture 2021","description":"Stanford, Nobel Laureate. The authoritative overview connecting the credibility revolution to modern instrumental variables and regression discontinuity.","category":"Nobel Lectures","url":"https://www.youtube.com/watch?v=yTrVg-t8O8A","difficulty":"intermediate","prerequisites":"difference-in-differences, instrumental-variables, regression-discontinuity","topic_tags":"causal-inference, econometrics, credibility-revolution, nobel-prize, video-lecture","summary":"Nobel Prize winner Guido Imbens delivers the definitive overview of how causal inference methods transformed empirical economics. He traces the evolution from traditional regression to modern techniques like instrumental variables and regression discontinuity that enable credible causal identification. Essential viewing for understanding the theoretical foundations behind today's experimental design practices.","use_cases":"Understanding the historical development and theoretical justification for modern causal inference methods, Learning authoritative explanations of IV and RDD from the Nobel laureate who helped develop them","audience":"Early-PhD, Senior-DS"},{"id":"talk-jean-tirole:-nobel-lecture-2014","type":"talk","name":"Jean Tirole: Nobel Lecture 2014","description":"Co-founder of two-sided market theory. Explains platform pricing and why traditional antitrust fails for digital markets.","category":"Nobel Lectures","url":"https://www.youtube.com/watch?v=vYPWe_S-BeY","difficulty":"intermediate","prerequisites":"microeconomics, industrial-organization, game-theory","topic_tags":"two-sided-markets, platform-economics, antitrust, digital-markets, nobel-lecture","summary":"Jean Tirole's 2014 Nobel lecture explaining his groundbreaking work on two-sided market theory and platform economics. He demonstrates why traditional antitrust approaches fail in digital markets where platforms must balance pricing between different user groups. Essential viewing for understanding the economic foundations of modern platform regulation.","use_cases":"Understanding why platforms like credit cards or app stores price differently to buyers vs sellers, Analyzing antitrust cases involving tech platforms like Google, Apple, or Amazon","audience":"Early-PhD, Curious-browser"},{"id":"talk-paul-milgrom:-nobel-lecture-2020","type":"talk","name":"Paul Milgrom: Nobel Lecture 2020","description":"Auction Research Evolving. Traces development from theoretical foundations through FCC spectrum auctions to internet advertising.","category":"Nobel Lectures","url":"https://www.youtube.com/watch?v=JhfDyBLRnrM","difficulty":"intermediate","prerequisites":"game-theory, microeconomic-theory, auction-mechanisms","topic_tags":"auction-theory, mechanism-design, spectrum-auctions, advertising-markets, nobel-prize","summary":"Nobel Prize winner Paul Milgrom traces the evolution of auction theory from foundational economic research to real-world applications in FCC spectrum auctions and internet advertising markets. He explains how theoretical insights about bidding strategies and market design were adapted to solve complex allocation problems in technology markets. Essential viewing for understanding how economic theory translates into multi-billion dollar market mechanisms.","use_cases":"Understanding the theoretical foundations behind ad auction platforms like Google Ads, Learning how economic principles guide spectrum allocation and telecommunications policy","audience":"Early-PhD, Curious-browser"},{"id":"talk-alvin-roth:-nobel-lecture-2012","type":"talk","name":"Alvin Roth: Nobel Lecture 2012","description":"Market design and matching markets. Directly relevant for researchers at Airbnb, Uber, and similar platforms.","category":"Nobel Lectures","url":"https://www.youtube.com/watch?v=A2XXItBvQi8","difficulty":"intermediate","prerequisites":"microeconomics-theory, game-theory, optimization-methods","topic_tags":"market-design, matching-theory, platform-economics, auction-theory, nobel-lectures","summary":"Alvin Roth's Nobel Prize lecture explaining the theory and practice of market design, focusing on matching markets where prices alone don't clear markets. Essential viewing for understanding two-sided marketplaces, assignment problems, and mechanism design principles used in modern tech platforms.","use_cases":"Designing rider-driver matching algorithms for rideshare platforms, Creating fair and efficient allocation systems for marketplace platforms","audience":"Mid-DS, Senior-DS"},{"id":"talk-victor-chernozhukov:-double-debiased-ml","type":"talk","name":"Victor Chernozhukov: Double/Debiased ML","description":"MIT. The foundational Double ML methodology for high-dimensional causal inference. BFI presentation with accompanying DoubleML package.","category":"Causal Inference & ML","url":"https://www.nber.org/research/videos/2013-methods-lecture-victor-chernozhukov-econometrics-high-dimensional-sparse-models","difficulty":"intermediate","prerequisites":"linear-regression, cross-validation, regularization-methods","topic_tags":"double-machine-learning, high-dimensional-inference, causal-estimation, debiased-ml, video-lecture","summary":"Victor Chernozhukov presents the foundational Double/Debiased Machine Learning methodology for causal inference in high-dimensional settings. The approach combines machine learning flexibility with rigorous statistical inference to estimate treatment effects when you have many confounding variables. Includes practical implementation guidance through the DoubleML package.","use_cases":"Estimating price elasticity from observational data with hundreds of potential confounders, Measuring marketing campaign effectiveness when user features are high-dimensional","audience":"Mid-DS, Senior-DS"},{"id":"talk-susan-athey:-the-mixtape-podcast","type":"talk","name":"Susan Athey: The Mixtape Podcast","description":"Career journey from academia to pioneering the applied researcher role at Microsoft. With Scott Cunningham.","category":"Causal Inference & ML","url":"https://www.youtube.com/watch?v=Kk7MAWRRhXs","difficulty":"beginner","prerequisites":"basic-statistics, research-fundamentals","topic_tags":"career-advice, academia-to-industry, applied-research, microsoft-research, interview","summary":"Susan Athey discusses her career transition from academic economics to creating the applied researcher role at Microsoft, bridging theory and practice. She shares insights on how economists can contribute to tech companies and the evolution of data science roles. The conversation covers her pioneering work in bringing rigorous causal inference methods to industry applications.","use_cases":"Understanding career paths from academia to tech industry, Learning how to position economics skills in data science roles","audience":"Early-PhD, Curious-browser"},{"id":"talk-hal-varian:-conversations-with-tyler","type":"talk","name":"Hal Varian: Conversations with Tyler","description":"Episode 69. Google's shift from second-price to first-price auctions, quality scores, price discrimination, and nowcasting.","category":"Market Design & Auctions","url":"https://conversationswithtyler.com/episodes/hal-varian/","difficulty":"intermediate","prerequisites":"auction-theory, microeconomics, basic-statistics","topic_tags":"auction-mechanisms, price-discrimination, nowcasting, google-economics, podcast","summary":"Hal Varian, Google's Chief Economist, discusses the company's transition from second-price to first-price auctions in ad markets, explaining quality scores and price discrimination mechanisms. The conversation covers practical applications of auction theory at scale and Google's approach to economic nowcasting using search data.","use_cases":"Understanding how major tech platforms design and optimize their auction mechanisms, Learning how search data can be used for real-time economic forecasting and market analysis","audience":"Mid-DS, Senior-DS"},{"id":"talk-glen-weyl:-radical-markets","type":"talk","name":"Glen Weyl: Radical Markets","description":"Data as labor, quadratic voting, and mechanism design for platforms. Bridging theory and practice.","category":"Strategy & Digital Platforms","url":"https://www.youtube.com/watch?v=yxVikHslgHA","difficulty":"intermediate","prerequisites":"microeconomics-basics, game-theory-fundamentals, mechanism-design-concepts","topic_tags":"radical-markets, quadratic-voting, data-labor, mechanism-design, platform-economics","summary":"Glen Weyl discusses innovative market mechanisms including treating data as labor and quadratic voting systems for more democratic decision-making. The talk bridges economic theory with practical applications for digital platforms and tech companies. Covers how mechanism design can create fairer, more efficient markets in the digital economy.","use_cases":"Designing voting mechanisms for platform governance or organizational decision-making, Developing fair compensation models for user-generated data in tech companies","audience":"Mid-DS, Senior-DS"},{"id":"talk-erik-brynjolfsson:-ai-and-the-economy","type":"talk","name":"Erik Brynjolfsson: AI and the Economy","description":"Stanford Digital Economy Lab. HBS Managing the Future of Work on J-curve of AI productivity and 14-35% productivity gains from AI.","category":"AI & Labor","url":"https://www.hbs.edu/managing-the-future-of-work/podcast/Pages/podcast-details.aspx?episode=9166436185","difficulty":"beginner","prerequisites":"basic-economics, productivity-measurement","topic_tags":"AI-productivity, economic-impact, labor-economics, technology-adoption, talk","summary":"Erik Brynjolfsson discusses the J-curve pattern of AI productivity adoption and research showing 14-35% productivity gains from AI implementation. This talk covers economic theory and empirical evidence on how AI technologies impact workforce productivity and economic growth. Accessible overview of current research on AI's economic implications from a leading digital economy researcher.","use_cases":"Understanding the timeline and magnitude of AI productivity impacts for strategic planning, Learning about empirical methods for measuring AI's economic effects in organizations","audience":"Curious-browser, Junior-DS"},{"id":"talk-erik-brynjolfsson:-lex-fridman-podcast","type":"talk","name":"Erik Brynjolfsson: Lex Fridman Podcast","description":"Second Machine Age thesis. Which jobs are safe from automation and dangers of the Turing Trap.","category":"AI & Labor","url":"https://www.youtube.com/watch?v=NOReE-3EBhI","difficulty":"beginner","prerequisites":"basic-economics, technology-fundamentals","topic_tags":"automation, future-of-work, technological-unemployment, AI-economics, podcast","summary":"Erik Brynjolfsson discusses his Second Machine Age thesis on the Lex Fridman podcast, exploring which jobs will survive automation and the risks of the Turing Trap. This accessible conversation covers the economic implications of AI and automation on employment and society. Perfect for understanding foundational concepts in AI economics without technical prerequisites.","use_cases":"Understanding automation's impact on your industry or career path, Preparing strategic workforce planning presentations for leadership teams","audience":"Curious-browser, Junior-DS"},{"id":"talk-daron-acemoglu:-new-tasks-framework","type":"talk","name":"Daron Acemoglu: New Tasks Framework","description":"Social Science Bites podcast. When technology benefits workers vs. replaces them.","category":"AI & Labor","url":"https://www.socialsciencespace.com/2024/09/daron-acemoglu-on-artificial-intelligence/","difficulty":"beginner","prerequisites":"basic-economics, labor-market-concepts","topic_tags":"automation-economics, labor-displacement, technology-policy, podcast-interview, economic-theory","summary":"MIT economist Daron Acemoglu discusses his influential framework for understanding when new technologies complement workers versus replace them. He explains how the design and deployment of AI and automation can either augment human capabilities or lead to job displacement. The framework provides economists and policymakers with tools to analyze technology's impact on employment and wages.","use_cases":"Policy analysts evaluating the employment effects of AI implementation in different industries, Tech company executives designing automation systems that complement rather than replace human workers","audience":"Curious-browser, Early-PhD"},{"id":"talk-david-autor:-ai-and-the-future-of-work","type":"talk","name":"David Autor: AI and the Future of Work","description":"MIT, NBER Co-Director. Fed SF presentation arguing AI's key risk is 'devaluation of expertise' rather than job loss.","category":"AI & Labor","url":"https://www.frbsf.org/news-and-media/events/2024/12/david-autor-expertise-artificial-intelligence-and-work-of-the-future/","difficulty":"beginner","prerequisites":"basic-economics, labor-market-theory","topic_tags":"artificial-intelligence, labor-economics, automation, future-of-work, expert-knowledge","summary":"MIT economist David Autor presents his research on how AI will impact the labor market, focusing on the 'devaluation of expertise' as the primary concern rather than widespread job displacement. He discusses how AI may democratize access to expert knowledge while potentially reducing the premium for specialized skills. The talk provides an economic framework for understanding AI's effects on different types of work and worker categories.","use_cases":"Understanding how AI might affect your career trajectory in tech or economics, Developing workforce strategy for companies implementing AI tools","audience":"Curious-browser, Early-PhD"},{"id":"talk-sendhil-mullainathan:-before-agi-podcast","type":"talk","name":"Sendhil Mullainathan: Before AGI Podcast","description":"MIT. Journey from behavioral economics to AI, algorithmic bias mitigation.","category":"AI & Labor","url":"https://www.youtube.com/watch?v=7GGuFjrfShs","difficulty":"beginner","prerequisites":"behavioral-economics-basics, algorithmic-fairness-concepts","topic_tags":"behavioral-economics, algorithmic-bias, AI-ethics, podcast, career-transitions","summary":"MIT economist Sendhil Mullainathan discusses his career evolution from behavioral economics to AI research, focusing on understanding and mitigating algorithmic bias. He explores how behavioral insights can inform AI development and the challenges of ensuring fairness in automated systems. The conversation provides valuable perspective on interdisciplinary research and the intersection of human behavior and machine learning.","use_cases":"Understanding career paths from economics to AI research, Learning about algorithmic bias from a behavioral economics perspective","audience":"Curious-browser, Early-PhD"},{"id":"talk-sendhil-mullainathan:-cornell-messenger-lectures","type":"talk","name":"Sendhil Mullainathan: Cornell Messenger Lectures","description":"2024 three-part series on algorithms enhancing human capacity.","category":"AI & Labor","url":"https://events.cornell.edu/event/messenger-lecture-sendhil-mullainathan","difficulty":"beginner","prerequisites":"basic-economics, linear-regression","topic_tags":"human-AI-collaboration, algorithmic-decision-making, labor-economics, machine-learning-applications, video-lecture","summary":"Three-part Cornell Messenger Lecture series by Sendhil Mullainathan exploring how algorithms can augment rather than replace human decision-making and cognitive capacity. The talks examine the intersection of behavioral economics, machine learning, and labor markets with accessible explanations suitable for broad audiences. Covers both theoretical foundations and practical applications of human-AI collaboration.","use_cases":"Understanding how to design AI systems that complement human judgment in business decisions, Learning frameworks for evaluating when algorithms should assist versus replace human workers","audience":"Curious-browser, Early-PhD"},{"id":"talk-keith-chen:-your-brain-on-uber","type":"talk","name":"Keith Chen: Your Brain on Uber","description":"NPR Hidden Brain. Uber researcher on surge pricing dynamics: users accept 2.1x surge more than 2.0x, low battery increases acceptance.","category":"Pricing & Behavioral","url":"https://hiddenbrain.org/podcast/your-brain-on-uber/","difficulty":"beginner","prerequisites":"basic-statistics, behavioral-economics-concepts","topic_tags":"surge-pricing, behavioral-economics, user-psychology, pricing-strategy, podcast","summary":"NPR Hidden Brain podcast featuring Uber researcher Keith Chen discussing behavioral insights from surge pricing experiments. Chen reveals counterintuitive findings like users accepting 2.1x surge pricing more readily than 2.0x, and how low phone battery affects price acceptance. The talk provides accessible insights into how psychological factors influence economic decision-making in tech platforms.","use_cases":"Understanding how psychological anchoring affects dynamic pricing strategy, Learning about real-world behavioral economics applications in ride-sharing platforms","audience":"Curious-browser, Junior-DS"},{"id":"talk-why-uber-is-an-economist's-dream","type":"talk","name":"Why Uber Is an Economist's Dream","description":"Freakonomics with Steven Levitt. Demand elasticity of -0.6 to -0.7 from 54M user sessions.","category":"Pricing & Behavioral","url":"https://freakonomics.com/podcast/uber-researchers-dream/","difficulty":"beginner","prerequisites":"basic-microeconomics, demand-curves","topic_tags":"demand-elasticity, surge-pricing, rideshare-economics, behavioral-economics, podcast","summary":"Steven Levitt discusses Uber's pricing strategy and reveals demand elasticity findings from 54 million user sessions showing -0.6 to -0.7 elasticity. The conversation explores how ride-sharing platforms provide natural experiments for understanding consumer behavior and price sensitivity. Perfect introduction to applied pricing economics using real-world data at massive scale.","use_cases":"Understanding how surge pricing affects rider demand in your own marketplace, Learning foundational concepts of demand elasticity through a familiar consumer product","audience":"Curious-browser, Junior-DS"},{"id":"talk-uber-gender-pay-gap-study","type":"talk","name":"Uber Gender Pay Gap Study","description":"Freakonomics. Jonathan Hall (Uber), Rebecca Diamond, John List. 1M+ drivers: 7% gap explained by experience and speed.","category":"AI & Labor","url":"https://freakonomics.com/podcast/what-can-uber-teach-us-about-the-gender-pay-gap/","difficulty":"beginner","prerequisites":"basic-statistics, regression-analysis","topic_tags":"gender-pay-gap, labor-economics, gig-economy, uber-case-study, freakonomics","summary":"Freakonomics podcast episode featuring Uber researchers discussing their study of gender pay gaps among 1M+ drivers, finding a 7% gap explained by experience and driving speed differences. The research provides insights into how algorithmic platforms can still exhibit pay disparities despite seemingly neutral pricing mechanisms. Accessible discussion of a large-scale empirical study relevant to anyone interested in labor economics and platform work.","use_cases":"Understanding how gender pay gaps manifest in gig economy platforms, Learning about natural experiments in digital labor markets","audience":"Junior-DS, Curious-browser"},{"id":"talk-fiona-scott-morton:-tech-antitrust-testimony","type":"talk","name":"Fiona Scott Morton: Tech Antitrust Testimony","description":"Yale, former DOJ Chief Scientist. C-SPAN congressional testimony and Digital Markets Act analysis.","category":"Antitrust & Competition","url":"https://www.c-span.org/program/public-affairs-event/yelp-conference-on-antitrust-law-and-technology-fiona-scott-morton/503495","difficulty":"beginner","prerequisites":"microeconomics-fundamentals, market-structure-analysis","topic_tags":"antitrust-policy, tech-regulation, congressional-testimony, digital-markets, competition-economics","summary":"Congressional testimony and policy analysis by Yale economist Fiona Scott Morton, former DOJ Chief Scientist, covering antitrust enforcement in tech markets and the Digital Markets Act. Provides accessible expert perspective on competition policy and regulatory approaches to big tech platforms. Essential viewing for understanding current policy debates around tech market concentration.","use_cases":"Understanding regulatory landscape when joining a tech company's policy or legal team, Preparing academic research on digital platform regulation and competition policy","audience":"Curious-browser, Early-PhD"},{"id":"talk-tim-wu:-the-age-of-extraction","type":"talk","name":"Tim Wu: The Age of Extraction","description":"Columbia, former Biden Administration. Brookings TechTank on platform extraction and antitrust history.","category":"Antitrust & Competition","url":"https://www.brookings.edu/articles/the-age-of-extraction-a-discussion-on-tim-wus-new-book-the-techtank-podcast/","difficulty":"beginner","prerequisites":"microeconomics-basics, market-structure-analysis","topic_tags":"platform-economics, antitrust-policy, tech-regulation, market-concentration, video-content","summary":"Tim Wu discusses the shift from tech platforms creating value to extracting it from users and markets, drawing on historical antitrust patterns. This accessible talk connects economic theory to current platform behaviors and regulatory responses. Essential viewing for understanding the economic foundations of tech antitrust policy.","use_cases":"Understanding regulatory arguments against big tech platforms, Learning historical context for current antitrust enforcement trends","audience":"Curious-browser, Early-PhD"},{"id":"talk-jean-tirole:-platform-regulation","type":"talk","name":"Jean Tirole: Platform Regulation","description":"NBER 2022 keynote on why traditional antitrust fails for digital platforms and the EU Digital Markets Act.","category":"Antitrust & Competition","url":"https://www.nber.org/lecture/jean-tirole-2022-martin-feldstein-lecture","difficulty":"intermediate","prerequisites":"microeconomics-theory, antitrust-law-basics, market-structure-analysis","topic_tags":"platform-regulation, digital-markets-act, two-sided-markets, keynote-talk, policy-analysis","summary":"Jean Tirole's 2022 NBER keynote explaining why traditional antitrust frameworks are inadequate for regulating digital platforms and examining the European Union's Digital Markets Act as a regulatory response. The talk covers the unique economic characteristics of digital platforms, including network effects and two-sided markets, that challenge conventional competition policy. Essential viewing for understanding current debates around tech platform regulation and policy design.","use_cases":"Understanding regulatory approaches when analyzing big tech company strategies or market entry decisions, Preparing policy recommendations or research on digital platform competition and market power","audience":"Mid-DS, Senior-DS"},{"id":"talk-jean-tirole:-richmond-fed-interview","type":"talk","name":"Jean Tirole: Richmond Fed Interview","description":"Deep dive into pricing on both sides of platforms and the economics of 'free' services.","category":"Strategy & Digital Platforms","url":"https://www.richmondfed.org/publications/research/econ_focus/2017/q4/interview","difficulty":"intermediate","prerequisites":"microeconomics-theory, network-effects, platform-business-models","topic_tags":"two-sided-markets, platform-pricing, nobel-economics, freemium-models, interview","summary":"Nobel laureate Jean Tirole discusses the economic principles behind platform pricing strategies and how companies monetize 'free' services through two-sided market dynamics. He explores the delicate balance platforms must strike between attracting users and generating revenue from different sides of their markets. This interview provides foundational insights for understanding modern digital platform economics.","use_cases":"Understanding how to price products in marketplace platforms where you need to balance buyer and seller incentives, Analyzing the economics behind freemium business models and ad-supported services","audience":"Mid-DS, Senior-DS"},{"id":"talk-alvin-roth:-google-tech-talk-on-matching","type":"talk","name":"Alvin Roth: Google Tech Talk on Matching","description":"Nobel laureate on matching markets. Directly applicable to marketplace platforms.","category":"Market Design & Auctions","url":"https://www.youtube.com/watch?v=4tdOY-HHC7s","difficulty":"beginner","prerequisites":"microeconomics-basics, game-theory-fundamentals","topic_tags":"matching-theory, two-sided-markets, platform-design, tech-talk, nobel-prize","summary":"Nobel Prize winner Alvin Roth explains matching theory and how it applies to two-sided markets like rideshare, dating apps, and job platforms. Covers stable matching algorithms and market design principles that tech companies use to optimize marketplace outcomes. Essential foundational knowledge for anyone working on platform products.","use_cases":"Designing matching algorithms for rideshare or delivery platforms, Optimizing job board or dating app recommendation systems","audience":"Junior-DS, Curious-browser"},{"id":"talk-ronny-kohavi:-experimentation-wisdom","type":"talk","name":"Ronny Kohavi: Experimentation Wisdom","description":"The godfather of online experimentation. Decades of A/B testing wisdom from Microsoft and Amazon.","category":"Experimentation & Scaling","url":"https://www.exp-platform.com/","difficulty":"intermediate","prerequisites":"hypothesis-testing, statistical-significance, basic-probability","topic_tags":"a-b-testing, online-experiments, causal-inference, tech-industry, experimentation-platform","summary":"Ronny Kohavi shares decades of practical wisdom from building and scaling experimentation platforms at Microsoft and Amazon. He covers common pitfalls, statistical best practices, and organizational challenges in running A/B tests at scale. Essential viewing for anyone implementing or improving online experimentation programs.","use_cases":"Setting up A/B testing infrastructure at your company and avoiding common statistical mistakes, Convincing leadership to invest in proper experimentation culture and tooling","audience":"Mid-DS, Senior-DS"},{"id":"talk-alexey-stysin:-auction-mechanism-design","type":"talk","name":"Alexey Stysin: Auction Mechanism Design","description":"Data Science Tech Lead at Topsort, former Yandex. 7+ years building VCG auctions, ML for click prediction, and revenue optimization for search ads.","category":"Market Design & Auctions","url":"https://www.youtube.com/@AlexeyStysin","difficulty":"intermediate","prerequisites":"microeconomics-game-theory, python-optimization, linear-programming","topic_tags":"auction-mechanisms, VCG-auctions, ad-auctions, revenue-optimization, talk","summary":"A technical talk on auction mechanism design by a practitioner with 7+ years of experience building VCG auctions at major tech companies. Covers the intersection of economic theory and practical implementation for search advertising revenue optimization. Provides insights into how auction theory translates to real-world ad serving systems.","use_cases":"Building auction systems for online advertising platforms, Optimizing revenue mechanisms for marketplace bidding","audience":"Mid-DS, Senior-DS"},{"id":"talk-casual-inference-podcast","type":"talk","name":"Casual Inference Podcast","description":"Lucy D'Agostino McGowan & Ellie Murray. Highly technical discussions on A/B testing, DAGs, and causal methods.","category":"Causal Inference & ML","url":"https://casualinfer.libsyn.com/","difficulty":"intermediate","prerequisites":"directed-acyclic-graphs, regression-analysis, randomized-controlled-trials","topic_tags":"causal-inference, A-B-testing, directed-acyclic-graphs, podcast, experimental-design","summary":"A technical podcast series hosted by Lucy D'Agostino McGowan and Ellie Murray covering advanced topics in causal inference methodology. Features deep discussions on A/B testing frameworks, DAG construction, and modern causal identification strategies for practitioners and researchers.","use_cases":"Learning advanced A/B testing methodologies while commuting or exercising, Staying current on causal inference research and hearing expert perspectives on complex identification problems","audience":"Mid-DS, Senior-DS"},{"id":"talk-econtalk","type":"talk","name":"EconTalk","description":"Russ Roberts. The gold standard for long-form economic interviews. John List, Hal Varian, and more.","category":"Strategy & Digital Platforms","url":"https://www.econtalk.org/","difficulty":"beginner","prerequisites":"basic-economics, microeconomics-principles","topic_tags":"economics-interviews, podcast, economic-thinking, strategy, digital-platforms","summary":"EconTalk is a long-form economics podcast hosted by Russ Roberts featuring in-depth conversations with leading economists and researchers. The show covers fundamental economic concepts, current research, and real-world applications through accessible interviews with experts like John List and Hal Varian. It's ideal for building economic intuition and understanding how economists think about complex problems.","use_cases":"Learning economic reasoning and mental models from leading practitioners, Understanding how economic principles apply to technology companies and digital markets","audience":"Curious-browser, Early-PhD"},{"id":"talk-not-so-standard-deviations","type":"talk","name":"Not So Standard Deviations","description":"Roger Peng (UT Austin) and Hilary Parker (Stitch Fix, Etsy). Statistics and data science bridging academia and industry. On indefinite hiatus (May 2025). 190 episode archive.","category":"Experimentation & Scaling","url":"https://nssdeviations.com/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"statistics, data-science, podcast, industry-academia, experimentation","summary":"A popular statistics and data science podcast featuring conversations between academic and industry perspectives. Covers practical data science topics, career advice, and bridges the gap between statistical theory and real-world application. Archive of 190 episodes provides comprehensive coverage of evolving data science practices.","use_cases":"Learning about data science career paths and industry practices while commuting, Understanding how statistical concepts apply in tech companies through expert discussions","audience":"Junior-DS, Curious-browser"},{"id":"talk-freakonomics-radio","type":"talk","name":"Freakonomics Radio","description":"Economics applied to everything. Great for economic intuition and learning to communicate data insights.","category":"Strategy & Digital Platforms","url":"https://freakonomics.com/podcasts/","difficulty":"beginner","prerequisites":"basic-economics-concepts, critical-thinking","topic_tags":"applied-economics, behavioral-economics, communication, podcast, intuition-building","summary":"Freakonomics Radio applies economic thinking to unexpected everyday topics, making complex economic concepts accessible through storytelling. The podcast helps listeners develop economic intuition and learn how to communicate data-driven insights to non-technical audiences. It's particularly valuable for understanding how economists approach problems and frame questions.","use_cases":"Learning to explain complex data findings to business stakeholders in compelling ways, Developing economic intuition before diving into technical econometric methods","audience":"Curious-browser, Junior-DS"},{"id":"talk-capitalisn't-podcast","type":"talk","name":"Capitalisn't Podcast","description":"Luigi Zingales, Stigler Center. Premier series on tech competition featuring Lina Khan, Carl Shapiro, Tim Wu.","category":"Antitrust & Competition","url":"https://www.capitalisnt.com/","difficulty":"beginner","prerequisites":"microeconomics-principles, market-structure-basics","topic_tags":"antitrust-policy, tech-competition, market-regulation, podcast-series, competition-economics","summary":"A podcast series from the University of Chicago's Stigler Center featuring discussions on antitrust and competition policy with leading experts. Hosted by Luigi Zingales, it covers major tech competition issues through accessible conversations with prominent figures like Lina Khan, Carl Shapiro, and Tim Wu. The series provides foundational understanding of competition economics and current policy debates in an interview format.","use_cases":"Learning foundational antitrust concepts while commuting or exercising, Staying current on competition policy debates affecting major tech platforms","audience":"Curious-browser, Early-PhD"},{"id":"talk-stigler-center","type":"talk","name":"Stigler Center","description":"Full YouTube archives. FTC Chair Lina Khan keynotes, Stigler Committee Report on digital platforms.","category":"Antitrust & Competition","url":"https://www.youtube.com/@StiglerCenter","difficulty":"intermediate","prerequisites":"microeconomics-theory, antitrust-law-basics","topic_tags":"antitrust-policy, digital-platforms, competition-economics, regulatory-analysis, video-lectures","summary":"The Stigler Center's YouTube archive contains comprehensive video content on antitrust and competition policy, featuring high-profile speakers like FTC Chair Lina Khan and presentations of the influential Stigler Committee Report on digital platforms. This collection provides accessible insights into current debates around tech regulation, market concentration, and competition policy from leading academics and policymakers.","use_cases":"Understanding current regulatory approaches to big tech platforms for academic research or policy analysis, Learning about antitrust economics and policy debates for professional development in competition consulting or government work","audience":"Curious-browser, Early-PhD"},{"id":"talk-the-mixtape-with-scott-cunningham","type":"talk","name":"The Mixtape with Scott Cunningham","description":"Causal inference and applied researcher careers. Features Susan Athey, Michael Luca, John List.","category":"Causal Inference & ML","url":"https://causalinf.substack.com/podcast","difficulty":"intermediate","prerequisites":"difference-in-differences, randomized-controlled-trials, regression-discontinuity","topic_tags":"causal-inference, applied-econometrics, podcast, career-advice, field-experiments","summary":"A podcast series featuring conversations with leading applied researchers like Susan Athey, Michael Luca, and John List about causal inference methods and research careers. Covers practical aspects of conducting rigorous empirical research in tech and economics settings. Provides insights into both methodological approaches and professional development for applied researchers.","use_cases":"Learning from top researchers about best practices in causal inference implementation, Getting career advice on transitioning from academia to tech research roles","audience":"Junior-DS, Mid-DS"},{"id":"talk-conversations-with-tyler","type":"talk","name":"Conversations with Tyler","description":"Tyler Cowen's long-form interviews. applied analytics episodes with Hal Varian, Marc Andreessen, and more.","category":"Strategy & Digital Platforms","url":"https://conversationswithtyler.com/","difficulty":"beginner","prerequisites":"basic-economics, podcast-listening","topic_tags":"economics-interviews, tech-strategy, digital-platforms, podcast-series, thought-leadership","summary":"Tyler Cowen's conversational podcast featuring in-depth interviews with leading economists and tech figures including Hal Varian and Marc Andreessen. The episodes explore strategic thinking, digital platform economics, and applied analytics through accessible long-form discussions. Ideal for gaining strategic perspective on how economics applies to technology and business decisions.","use_cases":"Understanding strategic thinking from tech leaders while commuting or exercising, Learning how prominent economists approach real-world tech problems and platform dynamics","audience":"Curious-browser, Junior-DS"},{"id":"talk-hbs-managing-the-future-of-work","type":"talk","name":"HBS Managing the Future of Work","description":"Bill Kerr, Joe Fuller. Erik Brynjolfsson on AI, gig economy series, and future of employment.","category":"AI & Labor","url":"https://www.hbs.edu/managing-the-future-of-work/podcast/","difficulty":"beginner","prerequisites":"basic-economics, labor-market-concepts","topic_tags":"artificial-intelligence, future-of-work, labor-economics, gig-economy, podcast","summary":"A podcast series from Harvard Business School featuring discussions with leading economists like Erik Brynjolfsson on how AI and digital platforms are reshaping employment and labor markets. The conversations cover the gig economy, automation impacts, and policy implications for the future workforce. Accessible to general audiences interested in understanding tech's impact on work.","use_cases":"Getting accessible expert perspectives on AI's impact on jobs for research background, Understanding labor market trends for strategic workforce planning decisions","audience":"Curious-browser, Junior-DS"},{"id":"talk-experimentation-masters","type":"talk","name":"Experimentation Masters","description":"Gavin Bryant (First Principles Ventures). Product experimentation at major tech companies. Guests: Lukas Vermeer (Booking.com), Aleksander Fabijan (Microsoft), Michael Luca (HBS).","category":"Experimentation & Scaling","url":"https://www.firstprinciples.ventures/experimentation-masters-podcast","difficulty":"intermediate","prerequisites":"A-B-testing, statistical-significance, experimental-design","topic_tags":"A-B-testing, experimentation-platforms, causal-inference, tech-industry, podcast","summary":"A podcast featuring experimentation leaders from Booking.com, Microsoft, and Harvard Business School discussing product experimentation practices at scale. Covers real-world challenges and solutions in running experiments at major tech companies. Valuable for practitioners looking to understand how experimentation works in production environments.","use_cases":"Learning how to scale experimentation programs from industry experts, Understanding common pitfalls and best practices in A/B testing at tech companies","audience":"Mid-DS, Senior-DS"},{"id":"talk-experiment-nation","type":"talk","name":"Experiment Nation","description":"Rommil Santiago (Optimizely). Conversion rate optimization and experimentation. 171+ episodes, top 10% most-followed on Spotify.","category":"Experimentation & Scaling","url":"https://experimentnation.com/","difficulty":"beginner","prerequisites":"a-b-testing-basics, conversion-rate-metrics","topic_tags":"conversion-rate-optimization, a-b-testing, product-experimentation, podcast-series","summary":"A popular podcast series hosted by Rommil Santiago from Optimizely covering conversion rate optimization and experimentation practices. With 171+ episodes, it features industry practitioners sharing real-world experiences, best practices, and lessons learned from running experiments at scale. The podcast serves as an accessible introduction to experimentation culture and methodologies for practitioners at all levels.","use_cases":"Learning experimentation best practices while commuting or during downtime, Staying updated on industry trends and hearing case studies from other companies' experimentation programs","audience":"Junior-DS, Mid-DS"},{"id":"talk-the-visible-hand","type":"talk","name":"The Visible Hand","description":"Jordi Blanes i Vidal (LSE). Deep dives into academic papers in organizational and labor economics. Walks through empirical methodology in detail. 100+ episodes.","category":"Causal Inference & ML","url":"https://www.thevisiblehand.uk/","difficulty":"intermediate","prerequisites":"econometrics-basics, regression-analysis, research-design","topic_tags":"organizational-economics, labor-economics, empirical-methods, podcast-series, academic-papers","summary":"A podcast series by Jordi Blanes i Vidal from LSE that provides detailed walkthroughs of academic papers in organizational and labor economics. Each episode breaks down empirical methodology and research design, making complex academic work accessible. With 100+ episodes, it's a comprehensive resource for understanding how rigorous empirical research is conducted in economics.","use_cases":"Learning how to design and execute empirical studies in organizational settings, Understanding methodology behind seminal papers in labor economics before implementing similar approaches","audience":"Early-PhD, Mid-DS"},{"id":"talk-practical-ai","type":"talk","name":"Practical AI","description":"Daniel Whitenack and Chris Benson. Applied AI implementation with exceptional causal inference episodes. Episode 220 with Paul H\u00fcnermund on Double ML and DiD.","category":"Causal Inference & ML","url":"https://practicalai.fm/","difficulty":"intermediate","prerequisites":"difference-in-differences, python-scikit-learn, linear-regression","topic_tags":"double-machine-learning, causal-inference, podcast, applied-econometrics, treatment-effects","summary":"Applied AI podcast with exceptional episodes on causal inference methods, featuring accessible discussions of cutting-edge econometric techniques. Episode 220 covers Double Machine Learning and Difference-in-Differences with expert Paul H\u00fcnermund. Perfect for data scientists wanting to bridge ML and causal inference in practice.","use_cases":"Learning how to implement Double ML for estimating treatment effects in A/B tests with high-dimensional controls, Understanding when to combine machine learning with difference-in-differences for policy evaluation","audience":"Junior-DS, Mid-DS"},{"id":"talk-the-pie-(uchicago)","type":"talk","name":"The Pie (UChicago)","description":"Becker Friedman Institute. Cutting-edge research on industrial organization, platforms, and competition economics with top Chicago economists.","category":"Strategy & Digital Platforms","url":"https://bfi.uchicago.edu/podcast/the-pie/","difficulty":"intermediate","prerequisites":"microeconomics-theory, regression-analysis, market-competition-concepts","topic_tags":"industrial-organization, platform-economics, competition-policy, chicago-school, economics-podcast","summary":"A podcast series from the University of Chicago's Becker Friedman Institute featuring leading economists discussing cutting-edge research in industrial organization, digital platforms, and competition economics. The content focuses on how modern markets operate, particularly in the digital economy, with insights from Chicago School economic thinking. Ideal for understanding theoretical frameworks and empirical approaches to studying market structure and competition policy.","use_cases":"Learning about platform market dynamics and two-sided markets for competitive strategy analysis, Understanding regulatory approaches to big tech and antitrust policy through academic research","audience":"Mid-DS, Senior-DS"},{"id":"talk-a16z-podcast","type":"talk","name":"a16z Podcast","description":"Andreessen Horowitz. VC perspective on marketplace economics, network effects, and market design. Prediction markets with Alex Tabarrok and Scott Duke Kominers.","category":"Strategy & Digital Platforms","url":"https://a16z.com/podcasts/","difficulty":"beginner","prerequisites":"basic-economics, market-fundamentals","topic_tags":"marketplace-economics, network-effects, prediction-markets, venture-capital, podcast","summary":"VC-focused podcast discussing marketplace economics, network effects, and market design from an investment perspective. Features discussions with economists Alex Tabarrok and Scott Duke Kominers on prediction markets and digital platform strategies. Provides practical insights on how economic principles apply to tech company valuations and business models.","use_cases":"Understanding how VCs evaluate marketplace startups and platform economics, Learning about prediction market mechanisms and their business applications","audience":"Curious-browser, Junior-DS"},{"id":"talk-odd-lots-(bloomberg)","type":"talk","name":"Odd Lots (Bloomberg)","description":"Joe Weisenthal and Tracy Alloway. Finance, markets, and economics. Strong coverage of monetary policy and macro trends. 10+ years running.","category":"Strategy & Digital Platforms","url":"https://www.bloomberg.com/oddlots","difficulty":"beginner","prerequisites":"macroeconomic-principles, financial-markets-basics","topic_tags":"monetary-policy, macroeconomics, financial-markets, podcast, strategy","summary":"Long-running Bloomberg podcast hosted by Joe Weisenthal and Tracy Alloway covering finance, markets, and economics with deep dives into monetary policy and macro trends. Accessible format makes complex economic concepts understandable for practitioners across experience levels. Over 10 years of archived episodes provide comprehensive coverage of major economic events and policy shifts.","use_cases":"Understanding how Federal Reserve policy decisions might impact tech company valuations and hiring, Getting expert commentary on macroeconomic trends that could affect platform business models","audience":"Curious-browser, Junior-DS"},{"id":"talk-impact-pricing","type":"talk","name":"Impact Pricing","description":"Mark Stiving, Ph.D. Pricing strategy, analytics, and revenue optimization. B2B focus with behavioral pricing insights. Weekly episodes.","category":"Pricing & Behavioral","url":"https://podcasts.apple.com/us/podcast/impact-pricing/id1449435549","difficulty":"beginner","prerequisites":"basic-economics, excel-formulas","topic_tags":"pricing-strategy, behavioral-economics, revenue-optimization, b2b-pricing, podcast","summary":"Weekly podcast by Mark Stiving covering pricing strategy, analytics, and revenue optimization with a focus on B2B markets. Combines traditional pricing theory with behavioral economics insights to help businesses set optimal prices. Accessible to beginners while providing actionable strategies for pricing decisions.","use_cases":"Product manager needs to price a new SaaS offering and wants to understand value-based pricing approaches, Business analyst tasked with optimizing subscription tiers and needs behavioral insights on customer price sensitivity","audience":"Junior-DS, Curious-browser"},{"id":"talk-pricing-heroes","type":"talk","name":"Pricing Heroes","description":"Competera. AI-driven retail pricing optimization, dynamic pricing, and competitive pricing strategies. Guests from major retailers.","category":"Pricing & Behavioral","url":"https://podcasts.apple.com/us/podcast/pricing-heroes/id1649346598","difficulty":"intermediate","prerequisites":"price-elasticity-modeling, A-B-testing, market-research-fundamentals","topic_tags":"dynamic-pricing, retail-optimization, competitive-intelligence, revenue-management, podcast","summary":"Pricing Heroes is a podcast series by Competera featuring discussions on AI-driven retail pricing optimization and dynamic pricing strategies. Industry practitioners from major retailers share insights on competitive pricing, market positioning, and revenue optimization techniques. The content bridges theoretical pricing concepts with real-world implementation challenges in retail environments.","use_cases":"Learning how major retailers implement dynamic pricing systems and handle competitive responses, Understanding best practices for pricing optimization from industry practitioners before launching your own pricing experiments","audience":"Mid-DS, Curious-browser"},{"id":"talk-retail-pricing-insights","type":"talk","name":"Retail Pricing Insights","description":"7Learnings. ML-driven pricing for retail. Guests from MediaMarkt Saturn, Deliveroo, and major retailers.","category":"Pricing & Behavioral","url":"https://7learnings.com/retail-pricing-insights-podcast/","difficulty":"intermediate","prerequisites":"python-scikit-learn, linear-regression, SQL-joins","topic_tags":"dynamic-pricing, retail-analytics, machine-learning, podcast, industry-case-studies","summary":"Industry practitioners from major retailers like MediaMarkt Saturn and Deliveroo discuss ML-driven pricing strategies and implementation challenges. The talk covers real-world pricing optimization techniques, competitive dynamics, and operational considerations for retail pricing systems.","use_cases":"Building automated pricing systems for e-commerce platforms, Understanding how major retailers implement dynamic pricing strategies","audience":"Mid-DS, Junior-DS"},{"id":"talk-super-data-science","type":"talk","name":"Super Data Science","description":"Jon Krohn. ML, AI, and data careers. 900+ episodes. Notable: Sean Taylor (Facebook/Lyft) on causal experimentation, Emre Kiciman (Microsoft) on DoWhy.","category":"Causal Inference & ML","url":"https://www.superdatascience.com/podcast","difficulty":"intermediate","prerequisites":"python-basics, statistical-inference, experimental-design","topic_tags":"causal-inference, experimentation, machine-learning, podcast, career-development","summary":"Long-running podcast series covering machine learning, AI, and data science careers with over 900 episodes. Features notable episodes on causal inference and experimentation methods from leading practitioners at major tech companies. Provides accessible discussions of advanced topics for data scientists looking to expand their knowledge.","use_cases":"Learning about causal inference methods while commuting or exercising, Staying updated on industry trends and career advice from experienced practitioners","audience":"Junior-DS, Mid-DS"},{"id":"talk-twiml-ai","type":"talk","name":"TWIML AI","description":"Sam Charrington. ML/AI research and applications. Susan Athey on ML in economics. Covers ML platforms at Netflix, Uber, Meta. Nearly 10M downloads.","category":"Causal Inference & ML","url":"https://twimlai.com/","difficulty":"intermediate","prerequisites":"python-scikit-learn, econometrics-basics, causal-inference-fundamentals","topic_tags":"machine-learning, causal-inference, podcast-series, industry-applications, economics","summary":"Popular ML/AI podcast featuring interviews with researchers and practitioners on applying machine learning to economic problems and business decisions. Covers real-world implementations at major tech companies like Netflix, Uber, and Meta, with episodes on causal inference methods for data scientists. Nearly 10 million downloads make it one of the most accessible resources for learning how ML intersects with economics.","use_cases":"Learning how major tech companies implement causal ML in production systems, Understanding practical applications of econometric methods in industry settings","audience":"Junior-DS, Mid-DS"},{"id":"talk-data-skeptic","type":"talk","name":"Data Skeptic","description":"Kyle Polich. Critical thinking approach to data science and ML. Organized in thematic seasons. Recommender Systems season in 2025.","category":"AI Economics & Labor","url":"https://dataskeptic.com/","difficulty":"intermediate","prerequisites":"python-basics, statistical-inference, machine-learning-fundamentals","topic_tags":"data-science-podcast, ml-methodology, critical-thinking, AI-economics, recommender-systems","summary":"Data Skeptic is a podcast hosted by Kyle Polich that applies critical thinking to data science and machine learning topics. The show is organized in thematic seasons covering different areas, with a recommender systems season planned for 2025. It's particularly valuable for practitioners who want to develop a more thoughtful, questioning approach to data science methods and claims.","use_cases":"Learning to critically evaluate ML papers and industry claims while commuting or exercising, Staying current on data science methodology and best practices through structured seasonal deep-dives","audience":"Junior-DS, Mid-DS"},{"id":"talk-dataframed-(datacamp)","type":"talk","name":"DataFramed (DataCamp)","description":"Adel Nehme and Richie Cotton. How AI and data change business. Guests: Emily Oster (Brown), Bilal Mahmoud (Duolingo, MIT Econ PhD) on A/B testing at scale.","category":"Experimentation & Scaling","url":"https://www.datacamp.com/podcast","difficulty":"intermediate","prerequisites":"A/B-testing-basics, statistical-significance, experimental-design","topic_tags":"A/B-testing, experimentation-at-scale, tech-industry, podcast, business-applications","summary":"A podcast discussion featuring Emily Oster and Bilal Mahmoud on implementing A/B testing at scale in tech companies. The conversation covers how data science and AI are transforming business decision-making, with practical insights from Duolingo's experimentation practices. Ideal for data scientists looking to understand real-world experimentation challenges and scaling strategies.","use_cases":"Learning how to design and run A/B tests for millions of users at tech companies, Understanding common pitfalls and best practices when scaling experimental programs","audience":"Mid-DS, Junior-DS"},{"id":"talk-macro-musings","type":"talk","name":"Macro Musings","description":"David Beckworth (Mercatus Center). Macroeconomic issues with technical depth. Features central bankers and academic researchers. Includes transcripts.","category":"Strategy & Digital Platforms","url":"https://www.mercatus.org/macro-musings","difficulty":"intermediate","prerequisites":"basic-macroeconomics, monetary-policy-frameworks, central-banking-concepts","topic_tags":"macroeconomics, monetary-policy, central-banking, podcast, economic-research","summary":"A podcast series hosted by David Beckworth from the Mercatus Center that explores macroeconomic issues with technical depth. Features interviews with central bankers, Federal Reserve officials, and academic researchers discussing current monetary policy, economic theory, and market conditions. Includes full transcripts making content searchable and accessible for research purposes.","use_cases":"Understanding current Federal Reserve policy decisions and their economic rationale, Learning about cutting-edge macroeconomic research and debates from leading practitioners","audience":"Senior-DS, Curious-browser"},{"id":"talk-economics,-applied-(hoover)","type":"talk","name":"Economics, Applied (Hoover)","description":"Steven J. Davis (Stanford, Economic Policy Uncertainty index). Translating research into actionable insights. Guests: Claudia Goldin, Austan Goolsbee.","category":"Strategy & Digital Platforms","url":"https://www.hoover.org/podcasts/economics-applied","difficulty":"beginner","prerequisites":"basic-economics, policy-analysis, data-interpretation","topic_tags":"economic-policy, applied-economics, policy-research, economic-uncertainty, podcast","summary":"A podcast series featuring Steven J. Davis discussing how to translate academic economic research into practical policy insights and business applications. Features conversations with leading economists like Claudia Goldin and Austan Goolsbee on real-world economic problems and solutions.","use_cases":"Learning how to communicate economic findings to non-technical stakeholders and policymakers, Understanding how academic economists approach policy questions and translate research into actionable recommendations","audience":"Curious-browser, Early-PhD"},{"id":"talk-planet-money-(npr)","type":"talk","name":"Planet Money (NPR)","description":"Sarah Gonzalez, Kenny Malone, Jeff Guo. Peabody Award-winning economic storytelling. Used in undergraduate economics courses.","category":"Strategy & Digital Platforms","url":"https://www.npr.org/podcasts/510289/planet-money","difficulty":"beginner","prerequisites":"microeconomics-principles, basic-market-concepts","topic_tags":"economics-storytelling, business-strategy, podcast-series, market-analysis, digital-platforms","summary":"Planet Money is NPR's Peabody Award-winning podcast that makes complex economic concepts accessible through engaging storytelling and real-world examples. The show is widely used in undergraduate economics courses to illustrate economic principles in action. It covers topics ranging from market dynamics and business strategy to behavioral economics and digital platform economics.","use_cases":"Learning economic concepts through narrative examples before diving into technical analysis, Understanding real-world business strategy cases to inform product and platform decisions","audience":"Curious-browser, Junior-DS"},{"id":"talk-the-brainy-business","type":"talk","name":"The Brainy Business","description":"Melina Palmer. Applying behavioral economics to marketing and business decisions. 500+ episodes on nudges, framing, and behavioral interventions.","category":"Pricing & Behavioral","url":"https://thebrainybusiness.com/","difficulty":"beginner","prerequisites":"basic-marketing-concepts, business-strategy-fundamentals","topic_tags":"behavioral-economics, marketing-psychology, nudge-theory, business-applications, podcast-series","summary":"A practical podcast series with 500+ episodes exploring how behavioral economics principles can be applied to marketing and business decisions. Melina Palmer breaks down concepts like nudges, framing effects, and behavioral interventions in an accessible way for business practitioners.","use_cases":"Learning how to apply behavioral nudges to improve conversion rates and customer decision-making, Understanding psychological pricing strategies and framing techniques for product launches","audience":"Curious-browser, Junior-DS"},{"id":"talk-jonathan.interviews:-data-science-careers-&-causal-inference","type":"talk","name":"Jonathan.Interviews: Data Science Careers & Causal Inference","description":"Senior data scientist with causal inference expertise. Practical tutorials on synthetic controls, event studies, Marketing Mix Models (Google Meridian), and data science career advice.","category":"Causal Inference & ML","url":"https://www.youtube.com/@data-science-interviews","difficulty":"intermediate","prerequisites":"python-pandas, basic-econometrics, regression-analysis","topic_tags":"causal-inference, synthetic-controls, marketing-mix-modeling, career-advice, video-tutorials","summary":"YouTube channel featuring practical tutorials on causal inference methods like synthetic controls and event studies, plus Marketing Mix Models including Google Meridian. Combines technical implementation guidance with data science career advice from a senior practitioner perspective.","use_cases":"Learning to implement causal inference methods for measuring marketing campaign effectiveness, Getting career guidance on transitioning to senior data science roles with causal inference focus","audience":"Junior-DS, Mid-DS"},{"id":"talk-causal-bandits-podcast-(alex-molak)","type":"talk","name":"Causal Bandits Podcast (Alex Molak)","description":"Causal Python channel. Deep-dive interviews on causal inference and causal AI with leading researchers: Judea Pearl, Julia Rohrer, Amit Sharma (DoWhy), Thomas Wiecki (PyMC).","category":"Causal Inference & ML","url":"https://www.youtube.com/@CausalPython","difficulty":"intermediate","prerequisites":"python-basics, regression-analysis, directed-acyclic-graphs","topic_tags":"causal-inference, podcast, interviews, python-causal-libraries, DoWhy","summary":"A podcast featuring deep-dive interviews with leading causal inference researchers including Judea Pearl, Julia Rohrer, and Amit Sharma. Covers both theoretical foundations and practical Python implementations of causal methods. Ideal for data scientists wanting to learn from experts about causal AI and inference techniques.","use_cases":"Learning causal inference concepts from leading researchers while commuting or exercising, Understanding how to apply causal methods in practice through expert interviews and case studies","audience":"Mid-DS, Curious-browser"},{"id":"talk-online-causal-inference-seminar","type":"talk","name":"Online Causal Inference Seminar","description":"Regular international causal inference research seminar. Features Susan Athey on Synthetic DiD, Jakob Runge on Tigramite, and leading researchers on cutting-edge methods.","category":"Causal Inference & ML","url":"https://www.youtube.com/@onlinecausalinferencesemin2364","difficulty":"advanced","prerequisites":"difference-in-differences, python-programming, causal-dag-theory","topic_tags":"synthetic-control, causal-inference, seminar-series, research-talks, tigramite","summary":"International research seminar featuring leading academics presenting cutting-edge causal inference methods and applications. Sessions include Susan Athey on Synthetic Difference-in-Differences and Jakob Runge on the Tigramite package for causal discovery. Provides access to the latest methodological advances directly from top researchers in the field.","use_cases":"Learning about new causal inference methods before they become mainstream, Understanding implementation details of advanced techniques like synthetic DiD from the original authors","audience":"Senior-DS, Early-PhD"},{"id":"talk-econ-ai-podcast","type":"talk","name":"Econ AI Podcast","description":"Interviews with scientists on cutting-edge business solutions. Guests include Matheus Facure (causal inference in fintech) and Vincent Martin (Meta) on researcher-engineers.","category":"Causal Inference & ML","url":"https://www.youtube.com/@econaipodcast","difficulty":"intermediate","prerequisites":"causal-inference-fundamentals, python-programming, experimental-design","topic_tags":"causal-inference, fintech, meta, business-applications, podcast","summary":"Interview podcast featuring scientists discussing cutting-edge applications of causal inference and ML in business contexts. Episodes cover real-world implementations at companies like Meta and fintech firms, bridging academic methods with industry practice.","use_cases":"Learning how causal inference is applied in fintech risk modeling and product analytics, Understanding the researcher-engineer role transition at major tech companies","audience":"Mid-DS, Senior-DS"},{"id":"talk-brady-neal:-causal-inference-course","type":"talk","name":"Brady Neal: Causal Inference Course","description":"Comprehensive causal inference video course. 16K subscribers. Guest lectures from Susan Athey, Alberto Abadie (Synthetic Controls), and Yoshua Bengio.","category":"Causal Inference & ML","url":"https://www.youtube.com/@BradyNealCausalInference","difficulty":"intermediate","prerequisites":"python-basics, linear-regression, probability-theory","topic_tags":"causal-inference, video-course, directed-acyclic-graphs, treatment-effects, observational-data","summary":"A comprehensive video course on causal inference methods taught by Brady Neal, featuring guest lectures from leading researchers like Susan Athey and Alberto Abadie. The course covers foundational concepts through advanced techniques, making causal inference accessible to data scientists and researchers. Ideal for practitioners who need to move beyond correlation to establish causation in their analysis.","use_cases":"Measuring the causal impact of a product feature launch on user engagement, Evaluating the effectiveness of a marketing campaign while controlling for confounding factors","audience":"Junior-DS, Mid-DS"},{"id":"talk-aki-vehtari:-bayesian-data-analysis","type":"talk","name":"Aki Vehtari: Bayesian Data Analysis","description":"Aalto University. BDA course lectures covering MCMC, HMC, model comparison, cross-validation (PSIS-LOO), and practical Bayesian workflow.","category":"Causal Inference & ML","url":"https://www.youtube.com/@aki_vehtari_aalto","difficulty":"intermediate","prerequisites":"probability-theory, linear-regression, python-programming","topic_tags":"bayesian-statistics, mcmc, model-validation, lecture-series, statistical-inference","summary":"Comprehensive university course on Bayesian data analysis by renowned expert Aki Vehtari, covering essential techniques like MCMC sampling, Hamiltonian Monte Carlo, and cross-validation methods. The lectures provide both theoretical foundations and practical workflow guidance for implementing Bayesian methods in real data analysis projects.","use_cases":"Learning rigorous approach to uncertainty quantification in A/B testing and experimentation, Implementing Bayesian models for product recommendation systems with proper model validation","audience":"Early-PhD, Mid-DS"},{"id":"talk-nber:-methods-lectures-&-feldstein-lectures","type":"talk","name":"NBER: Methods Lectures & Feldstein Lectures","description":"National Bureau of Economic Research. Methods lectures on causal inference (synthetic controls, RDD, DiD), Feldstein Lectures featuring Ben Bernanke, Gita Gopinath, and more.","category":"Causal Inference & ML","url":"https://www.youtube.com/@NBERvideos","difficulty":"intermediate","prerequisites":"regression-analysis, difference-in-differences, panel-data","topic_tags":"synthetic-control, regression-discontinuity, econometrics, video-lectures, academic-talks","summary":"NBER's methods lecture series covering foundational causal inference techniques like synthetic controls, regression discontinuity design, and difference-in-differences. Features high-quality academic presentations from leading economists explaining both theory and practical implementation of these methods.","use_cases":"Learning causal inference methods for impact evaluation of policy interventions, Understanding econometric techniques for product feature launches and A/B test analysis","audience":"Early-PhD, Mid-DS"},{"id":"talk-mad-seminar:-marketplace-algorithms-&-design","type":"talk","name":"MAD Seminar: Marketplace Algorithms & Design","description":"Preston McAfee, Ramesh Johari, and others. Recorded talks on pricing, experimentation, and mechanism design in two-sided markets.","category":"Market Design & Auctions","url":"https://www.youtube.com/channel/UCe9KREYNZuvgnDe0lQWi6Vw","difficulty":"intermediate","prerequisites":"microeconomic-theory, basic-statistics, auction-theory","topic_tags":"marketplace-design, auction-mechanisms, pricing-algorithms, two-sided-markets, video-lectures","summary":"A seminar series featuring leading researchers like Preston McAfee and Ramesh Johari discussing algorithmic approaches to marketplace design. Covers pricing strategies, experimental methods, and mechanism design for platforms like eBay, Google Ads, and ride-sharing services. Essential viewing for understanding how economic theory translates into real-world marketplace algorithms.","use_cases":"Designing pricing algorithms for a two-sided marketplace platform, Understanding auction mechanisms for ad placement systems","audience":"Mid-DS, Senior-DS"},{"id":"talk-mit-code:-conference-on-digital-experimentation","type":"talk","name":"MIT CODE: Conference on Digital Experimentation","description":"Talks from Meta, Google, Airbnb, Netflix researchers on A/B testing at scale and experimentation platforms.","category":"Experimentation & Scaling","url":"https://www.youtube.com/channel/UC8DqDLFZCni7Jkys3N3818w","difficulty":"intermediate","prerequisites":"hypothesis-testing, python-experimentation-libraries, SQL-aggregations","topic_tags":"ab-testing, experimentation-platforms, causal-inference, tech-industry, conference-talks","summary":"Conference talks from leading tech companies (Meta, Google, Airbnb, Netflix) sharing practical insights on running A/B tests at massive scale. Covers experimentation platform architecture, statistical methods for large-scale testing, and operational challenges. Essential viewing for practitioners implementing or improving experimentation capabilities at tech companies.","use_cases":"Building or improving A/B testing infrastructure at a growing tech company, Learning industry best practices for running experiments with millions of users","audience":"Mid-DS, Senior-DS"},{"id":"talk-statsig","type":"talk","name":"Statsig","description":"Experimentation platform tutorials, customer stories, and webinars on A/B testing, feature flags, and product analytics.","category":"Experimentation & Scaling","url":"https://www.youtube.com/@statsig_official","difficulty":"beginner","prerequisites":"basic-statistics, A/B-testing-fundamentals","topic_tags":"A/B-testing, experimentation-platform, feature-flags, product-analytics, video-tutorials","summary":"Statsig provides video tutorials and customer case studies on their experimentation platform for A/B testing and feature management. The content covers practical implementation of experiments, feature flag deployment, and product analytics workflows. These resources are designed to help teams learn best practices for running statistically rigorous experiments at scale.","use_cases":"Learning how to set up and run A/B tests using Statsig's platform, Understanding real-world experimentation challenges through customer success stories","audience":"Junior-DS, Mid-DS"},{"id":"talk-\u8bfe\u4ee3\u8868\u7acb\u6b63-(yuzheng-sun)","type":"talk","name":"\u8bfe\u4ee3\u8868\u7acb\u6b63 (Yuzheng Sun)","description":"Ex-Statsig Evangelist, ex-Tencent VP, PhD Cornell. Chinese-language content on data science, growth, A/B testing, and AI. 300K+ followers. Interviews top AI experts.","category":"Experimentation & Scaling","url":"https://www.youtube.com/@kedaibiao","difficulty":"intermediate","prerequisites":"a-b-testing-basics, statistical-significance, chinese-language","topic_tags":"experimentation, a-b-testing, growth-hacking, chinese-content, video-series","summary":"Chinese-language YouTube channel by former Statsig Evangelist and Tencent VP covering practical data science, A/B testing, and growth strategies. Features interviews with top AI experts and real-world case studies from major tech companies. Content bridges academic rigor with industry application for Chinese-speaking data professionals.","use_cases":"Learning A/B testing best practices from Chinese tech giants like Tencent, Understanding growth experimentation strategies used in Asian markets","audience":"Mid-DS, Junior-DS"},{"id":"talk-aea-webcasts","type":"talk","name":"AEA Webcasts","description":"American Economic Association. Includes Athey-Imbens ML and Econometrics course, plus sessions on LLMs for economics.","category":"Causal Inference & ML","url":"https://www.youtube.com/@AEA","difficulty":"intermediate","prerequisites":"regression-analysis, python-sklearn, experimental-design","topic_tags":"causal-inference, machine-learning, econometrics, video-lectures, AEA","summary":"American Economic Association's video lecture series featuring world-class economists presenting on cutting-edge topics. Includes the renowned Athey-Imbens course on machine learning and econometrics, plus recent sessions on LLMs applications in economics research.","use_cases":"Learning modern causal inference methods from leading academics like Athey and Imbens, Understanding how to apply LLMs and AI tools to economic research and analysis","audience":"Early-PhD, Mid-DS"},{"id":"talk-economics-of-ai","type":"talk","name":"Economics of AI","description":"NBER conference recordings on artificial intelligence and economics. Research presentations on AI labor markets, productivity, and automation.","category":"AI & Labor","url":"https://www.nber.org/programs-projects/projects-and-centers/8470-digital-economics-and-artificial-intelligence-2023-2025","difficulty":"intermediate","prerequisites":"microeconomics-theory, econometrics-basics, research-methods","topic_tags":"artificial-intelligence, labor-economics, productivity-analysis, automation, conference-talks","summary":"NBER conference recordings featuring leading economists presenting research on AI's impact on labor markets, productivity, and automation. These presentations cover cutting-edge empirical work and theoretical models examining how artificial intelligence transforms economic outcomes. Essential viewing for understanding the economic implications of AI adoption across industries.","use_cases":"Literature review for dissertation on AI's labor market effects, Background research for policy analysis on automation's economic impact","audience":"Early-PhD, Senior-DS"},{"id":"talk-causal-inference-(wager)","type":"talk","name":"Causal Inference (Wager)","description":"Stefan Wager's Stanford STATS 361 notes. Causal forests, HTE, and prescriptive policy learning \u2014 the exact tools used in tech companies.","category":"Monographs","url":"https://web.stanford.edu/~swager/stats361.pdf","difficulty":"intermediate","prerequisites":"randomized-experiments, regression-analysis, random-forests","topic_tags":"causal-inference, heterogeneous-treatment-effects, causal-forests, policy-learning, stanford-notes","summary":"Stefan Wager's comprehensive Stanford lecture notes covering modern causal inference methods including causal forests and heterogeneous treatment effects. These are the exact methodologies used by major tech companies for A/B testing, personalization, and policy optimization. The notes bridge theoretical foundations with practical implementation for estimating individualized treatment effects.","use_cases":"Personalizing product features by estimating individual user response to interface changes, Optimizing marketing spend by identifying which customer segments respond best to different campaign types","audience":"Mid-DS, Senior-DS"},{"id":"talk-advanced-data-analysis-(shalizi)","type":"talk","name":"Advanced Data Analysis (Shalizi)","description":"Cosma Shalizi's 600-page CMU manuscript. Geometry of regression, DAGs, heavy-tailed distributions. Mercilessly rigorous yet chatty.","category":"Monographs","url":"https://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/","difficulty":"advanced","prerequisites":"linear-algebra, probability-theory, causal-inference","topic_tags":"regression-analysis, causal-graphs, statistical-theory, data-analysis, heavy-tails","summary":"Cosma Shalizi's comprehensive 600-page manuscript covering advanced statistical methods including geometric approaches to regression, directed acyclic graphs for causal inference, and heavy-tailed distributions. Written with mathematical rigor but accessible explanations, it serves as both textbook and reference for sophisticated data analysis techniques. Essential reading for those seeking deep theoretical understanding of modern statistical methods.","use_cases":"Understanding the geometric intuition behind complex regression models when standard approaches fail, Learning rigorous causal inference methods using DAGs for observational studies","audience":"Early-PhD, Senior-DS"},{"id":"talk-patterns,-predictions,-and-actions","type":"talk","name":"Patterns, Predictions, and Actions","description":"Hardt & Recht's living book grounding ML in decision theory. Why models fail in the real world and how to think about prediction as action.","category":"Monographs","url":"https://mlstory.org/","difficulty":"intermediate","prerequisites":"supervised-learning, basic-statistics, model-evaluation","topic_tags":"decision-theory, model-deployment, causal-inference, ml-philosophy, prediction-systems","summary":"A comprehensive online book by Moritz Hardt and Benjamin Recht that bridges machine learning theory with real-world decision making. The authors examine why statistical models often fail when deployed and provide frameworks for thinking about prediction as fundamentally about taking actions. Essential reading for understanding the gap between model performance and business impact.","use_cases":"Understanding why your high-accuracy model performs poorly in production, Designing ML systems that account for feedback loops and strategic behavior","audience":"Mid-DS, Senior-DS"},{"id":"talk-geometric-deep-learning","type":"talk","name":"Geometric Deep Learning","description":"Bronstein et al.'s proto-book unifying CNNs, GNNs, and Transformers under symmetry and group theory. The GNN bible.","category":"Monographs","url":"https://arxiv.org/abs/2104.13478","difficulty":"advanced","prerequisites":"graph-neural-networks, group-theory, convolutional-neural-networks","topic_tags":"geometric-deep-learning, graph-neural-networks, symmetry, group-theory, neural-architectures","summary":"Bronstein et al.'s comprehensive framework unifying CNNs, GNNs, and Transformers through the lens of geometric principles and symmetry. This foundational text explains how different neural architectures emerge from imposing geometric constraints and invariances. Essential reading for understanding the mathematical foundations connecting major deep learning architectures.","use_cases":"Understanding mathematical connections between different neural network architectures, Designing new neural architectures based on geometric principles and symmetries","audience":"Senior-DS, Early-PhD"},{"id":"talk-probabilistic-modeling-case-studies","type":"talk","name":"Probabilistic Modeling Case Studies","description":"Michael Betancourt's Stan case studies. HMC geometry, divergences, hierarchical modeling \u2014 the Bayesian technical standard.","category":"Monographs","url":"https://betanalpha.github.io/writing/","difficulty":"advanced","prerequisites":"bayesian-inference, markov-chain-monte-carlo, stan-probabilistic-programming","topic_tags":"bayesian-modeling, hamiltonian-monte-carlo, hierarchical-models, stan, mcmc-diagnostics","summary":"Michael Betancourt's comprehensive Stan case studies covering advanced Bayesian modeling techniques including HMC geometry, divergence diagnostics, and hierarchical modeling. These represent the gold standard for technical Bayesian implementation, providing deep insights into proper MCMC methodology and Stan best practices. Essential reading for practitioners serious about rigorous probabilistic modeling.","use_cases":"debugging-mcmc-convergence-issues-and-understanding-divergence-warnings, implementing-complex-hierarchical-bayesian-models-with-proper-priors","audience":"Senior-DS, Early-PhD"},{"id":"talk-bandit-algorithms","type":"talk","name":"Bandit Algorithms","description":"Lattimore & Szepesv\u00e1ri's definitive reference. UCB, Thompson Sampling, Contextual Bandits \u2014 experimentation beyond A/B testing.","category":"Monographs","url":"https://tor-lattimore.com/downloads/book/book.pdf","difficulty":"advanced","prerequisites":"probability-theory, martingale-theory, regret-bounds","topic_tags":"bandit-algorithms, online-learning, thompson-sampling, contextual-bandits, experimentation","summary":"Comprehensive mathematical treatment of multi-armed bandit algorithms by leading researchers. Covers fundamental algorithms like UCB and Thompson Sampling, contextual bandits, and advanced topics with rigorous regret analysis. Essential reference for researchers and practitioners working on sequential decision-making and online experimentation beyond traditional A/B testing.","use_cases":"Dynamic pricing optimization where you need to learn optimal prices while serving customers, Personalized content recommendation systems that adapt in real-time to user preferences","audience":"Senior-DS, Early-PhD"},{"id":"talk-rl:-theory-and-algorithms","type":"talk","name":"RL: Theory and Algorithms","description":"Agarwal, Jiang, Kakade's working draft. Statistical learning theory of RL \u2014 'How many samples to learn this policy?'","category":"Monographs","url":"https://rltheorybook.github.io/","difficulty":"advanced","prerequisites":"markov-decision-processes, concentration-inequalities, policy-gradient-methods","topic_tags":"reinforcement-learning, statistical-learning-theory, sample-complexity, policy-optimization, theoretical-foundations","summary":"A comprehensive theoretical treatment of reinforcement learning from a statistical learning perspective by leading researchers. Focuses on fundamental questions of sample complexity - how much data is needed to learn effective policies with statistical guarantees. Provides rigorous mathematical foundations for understanding when and why RL algorithms work.","use_cases":"PhD student writing dissertation on RL theory needs sample complexity bounds for their algorithm, Senior researcher designing new RL method wants theoretical justification for data requirements","audience":"Early-PhD, Senior-DS"},{"id":"talk-causal-inference-and-ml-(imbens)","type":"talk","name":"Causal Inference and ML (Imbens)","description":"Guido Imbens' Nobel lectures. Matrix completion for synthetic controls, the rigorous foundation for tech metrics.","category":"Monographs","url":"https://www.nobelprize.org/uploads/2024/11/imbens-lecture.pdf","difficulty":"intermediate","prerequisites":"basic-regression, potential-outcomes-framework, python-scikit-learn","topic_tags":"causal-inference, synthetic-control, matrix-completion, econometrics, nobel-lecture","summary":"Nobel laureate Guido Imbens presents foundational lectures on causal inference methods, with emphasis on matrix completion techniques for synthetic control methods. These rigorous econometric foundations are essential for modern tech metrics and experimental design. The lectures bridge traditional econometrics with machine learning approaches to causal questions.","use_cases":"Evaluating impact of product launches using synthetic control methods, Building rigorous A/B testing frameworks with proper causal identification","audience":"Early-PhD, Mid-DS"},{"id":"talk-double-ml-(chernozhukov)","type":"talk","name":"Double ML (Chernozhukov)","description":"Belloni & Chernozhukov on Post-Double Selection Lasso. Use ML as controls while getting valid p-values.","category":"Monographs","url":"https://arxiv.org/abs/1608.00060","difficulty":"advanced","prerequisites":"lasso-regression, instrumental-variables, cross-validation","topic_tags":"double-ml, causal-inference, machine-learning, econometrics, post-selection","summary":"Double Machine Learning is a method that combines machine learning predictions with causal inference to estimate treatment effects while maintaining valid statistical inference. It uses cross-fitting and sample splitting to remove bias from regularized models like Lasso when estimating causal parameters. The approach allows economists to leverage high-dimensional controls without sacrificing the ability to conduct valid hypothesis tests.","use_cases":"Estimating treatment effects in high-dimensional observational data with many potential confounders, Running A/B tests with machine learning-based propensity score matching while preserving statistical validity","audience":"Senior-DS, Early-PhD"},{"id":"talk-econometrics-(hansen)","type":"talk","name":"Econometrics (Hansen)","description":"Bruce Hansen's modern reference. Asymptotics, cluster-robust SEs, panel data \u2014 the technical backbone.","category":"Monographs","url":"https://www.ssc.wisc.edu/~bhansen/econometrics/","difficulty":"advanced","prerequisites":"linear-regression, maximum-likelihood-estimation, matrix-algebra","topic_tags":"econometrics, asymptotics, panel-data, cluster-robust-inference, causal-inference","summary":"Bruce Hansen's comprehensive econometrics textbook covering modern theoretical foundations and practical methods. It provides rigorous treatment of asymptotic theory, robust standard errors, and panel data techniques essential for empirical research. The book serves as both a graduate-level reference and a bridge between theory and application in econometric analysis.","use_cases":"PhD student learning rigorous econometric theory for dissertation research, Senior researcher needing technical details on cluster-robust standard errors for publication","audience":"Early-PhD, Senior-DS"},{"id":"talk-microeconomic-theory-(rubinstein)","type":"talk","name":"Microeconomic Theory (Rubinstein)","description":"Ariel Rubinstein's free lecture notes. Game theory, rational choice, bargaining \u2014 for mechanism design work.","category":"Monographs","url":"https://arielrubinstein.tau.ac.il/books.html","difficulty":"intermediate","prerequisites":"calculus, linear-algebra, probability-theory","topic_tags":"game-theory, mechanism-design, bargaining-theory, rational-choice, microeconomics","summary":"Ariel Rubinstein's comprehensive lecture notes covering foundational microeconomic theory including game theory, rational choice, and bargaining models. Essential reading for understanding the theoretical foundations behind mechanism design and strategic interactions in markets. Widely used in economics PhD programs and by researchers working on auction design, platform economics, and strategic decision-making.","use_cases":"designing auction mechanisms for marketplace platforms, modeling strategic behavior in multi-sided markets and pricing","audience":"Early-PhD, Senior-DS"},{"id":"talk-market-design-(roth)","type":"talk","name":"Market Design (Roth)","description":"Alvin Roth's Nobel lecture on matching markets. Stability, unraveling \u2014 essential for marketplace analytics.","category":"Monographs","url":"https://www.nobelprize.org/uploads/2018/06/roth-lecture.pdf","difficulty":"intermediate","prerequisites":"game-theory, linear-programming, microeconomics","topic_tags":"market-design, matching-algorithms, two-sided-markets, mechanism-design, nobel-lecture","summary":"Alvin Roth's Nobel Prize lecture explaining how matching markets work when prices can't clear the market, focusing on stability and preventing unraveling. Essential reading for understanding two-sided marketplaces like dating apps, job matching, and kidney exchanges. Provides theoretical foundation with real-world applications that directly inform marketplace design decisions.","use_cases":"Designing matching algorithms for rideshare driver-rider pairing, Building stable matching systems for job marketplace platforms","audience":"Mid-DS, Senior-DS"},{"id":"talk-staff-engineer-(will-larson)","type":"talk","name":"Staff Engineer (Will Larson)","description":"Technical leadership, glue work, and navigating org complexity. Essential for senior ICs in tech.","category":"Monographs","url":"https://staffeng.com/book","difficulty":"intermediate","prerequisites":"software-engineering-fundamentals, technical-project-management, cross-functional-collaboration","topic_tags":"technical-leadership, staff-engineer, career-development, engineering-management, organizational-design","summary":"Will Larson's guide to the staff engineer role, covering technical leadership without direct management responsibilities. Essential reading for senior individual contributors navigating complex organizational dynamics and technical decision-making. Focuses on influence, systems thinking, and the 'glue work' that keeps engineering organizations functioning effectively.","use_cases":"Senior engineer transitioning to staff role seeking guidance on technical leadership and organizational influence, Mid-level engineer planning career advancement beyond senior IC roles in tech companies","audience":"Senior-DS, Mid-DS"},{"id":"talk-designing-data-intensive-applications","type":"talk","name":"Designing Data-Intensive Applications","description":"Martin Kleppmann's engineering bible. Stream vs batch, distributed systems, and data infrastructure.","category":"Monographs","url":"https://dataintensive.net/","difficulty":"intermediate","prerequisites":"SQL-joins, python-basics, distributed-computing-concepts","topic_tags":"distributed-systems, data-architecture, stream-processing, database-design, systems-engineering","summary":"Martin Kleppmann's comprehensive guide to building reliable, scalable, and maintainable data systems. The book covers fundamental concepts in distributed systems, data storage, and processing architectures that every data professional should understand. It bridges the gap between theoretical computer science and practical engineering challenges in modern data infrastructure.","use_cases":"Designing a real-time analytics pipeline that handles millions of events per day, Architecting a microservices system with consistent data across multiple databases","audience":"Junior-DS, Mid-DS"},{"id":"talk-aryma-labs","type":"talk","name":"Aryma Labs","description":"Data Science firm specializing in Marketing analytics. Features 'The Casual Causal Talk' series with causal inference experts (Matheus Facure, Stephan Kolassa) and 'The Marketing Mix - Unmixed' series on Marketing Mix Modeling.","category":"Causal Inference & ML","url":"https://www.youtube.com/@arymalabsmmm101","difficulty":"intermediate","prerequisites":"python-basics, regression-analysis, statistical-inference","topic_tags":"causal-inference, marketing-mix-modeling, youtube-series, applied-econometrics, business-analytics","summary":"Aryma Labs produces educational YouTube series on causal inference and marketing analytics for data practitioners. The content features expert discussions on causal methods and practical applications in marketing measurement, making advanced econometric concepts accessible through conversational formats.","use_cases":"Learning causal inference methods for A/B testing and observational studies, Understanding marketing mix modeling techniques for budget allocation decisions","audience":"Mid-DS, Junior-DS"},{"id":"talk-how-i-wrote-this","type":"talk","name":"How I Wrote This","description":"Marketing professors Brett Gordon and Karen Winterich interview authors of academic marketing papers to get the backstory of how their papers came to be. Topics include customer valuation, pricing, misinformation, and more.","category":"Causal Inference & ML","url":"https://open.spotify.com/show/3LrmMlwz4gh4dV3eVufXvV","difficulty":"beginner","prerequisites":"basic-econometrics, academic-research-methods","topic_tags":"academic-interviews, research-backstories, marketing-economics, methodology-discussion, podcast","summary":"A podcast where marketing professors interview academic authors to reveal the behind-the-scenes stories of how influential papers were conceived, developed, and published. Covers topics like customer valuation, pricing strategies, and misinformation research with insights into the research process itself. Valuable for understanding how academic ideas evolve from initial concepts to published work.","use_cases":"Learning about the research process and methodology choices from successful academic authors, Getting inspiration for thesis topics or research directions in marketing and economics","audience":"Early-PhD, Curious-browser"},{"id":"career-athey-&-luca:-economists-in-tech","type":"career","name":"Athey & Luca: Economists in Tech","description":"JEP article 'Economists (and Economics) in Tech Companies' - foundational reading on why tech hires economists. Amazon employs 150+ PhD economists. Focuses on causal inference, market design, incentives. Full PDF: https://gsb-faculty.stanford.edu/susan-athey/files/2022/04/economists_in_tech.pdf","category":"Why Tech","url":"https://www.aeaweb.org/articles?id=10.1257%2Fjep.33.1.209","difficulty":"beginner","prerequisites":"basic-economics, causal-inference-concepts","topic_tags":"tech-economics, career-guidance, market-design, causal-inference, academic-paper","summary":"Foundational JEP article explaining why major tech companies hire economists and what they do. Amazon employs 150+ PhD economists working on causal inference, market design, and incentive problems. Essential reading for understanding the intersection of economics and technology industry.","use_cases":"Understanding career opportunities for economists in tech companies, Learning about the role of economic methods in business strategy and product development","audience":"Early-PhD, Curious-browser"},{"id":"career-amazon-science-blog","type":"career","name":"Amazon Science Blog","description":"How Amazon's economics team works, research culture, and publications. Window into tech economist daily work.","category":"Why Tech","url":"https://www.amazon.science","difficulty":"beginner","prerequisites":"basic-economics, research-methods","topic_tags":"amazon, research-culture, career-guidance, tech-economics, industry-insights","summary":"Amazon Science Blog showcases how Amazon's economics team operates, their research culture, and published work. It provides insights into the daily work of tech economists at one of the world's largest companies. The blog serves as a window into industry research practices and career paths for economists in tech.","use_cases":"Understanding what economists do at major tech companies before applying for jobs, Learning about research priorities and methodologies used in industry settings","audience":"Early-PhD, Curious-browser"},{"id":"career-scarlet-chen:-econ-phd-to-tech","type":"career","name":"Scarlet Chen: Econ PhD to Tech","description":"Stanford PhD to Google/Shopify. Interview experiences at Google, Amazon, Facebook, Uber. 4-part comprehensive guide.","category":"Role Landscape","url":"https://scarlet-chen.medium.com/","difficulty":"beginner","prerequisites":"basic-economics, python-basics","topic_tags":"career-transition, interview-prep, econ-phd, tech-industry","summary":"A comprehensive 4-part guide from Stanford Economics PhD Scarlet Chen documenting her transition to tech roles at Google and Shopify. Includes detailed interview experiences and insights from applications to major tech companies including Google, Amazon, Facebook, and Uber. Provides practical advice for economics PhDs looking to break into the tech industry.","use_cases":"Economics PhD student preparing for tech industry job applications, Recent economics graduate looking for first-hand accounts of the PhD-to-tech transition process","audience":"Early-PhD, Curious-browser"},{"id":"career-ace-the-data-science-interview","type":"career","name":"Ace the Data Science Interview","description":"201 real questions from FAANG, startups, Wall Street. Industry-standard prep resource covering role expectations.","category":"Role Landscape","url":"https://www.acethedatascienceinterview.com/","difficulty":"beginner","prerequisites":"python-basics, statistics-fundamentals, SQL-queries","topic_tags":"interview-prep, career-development, data-science-roles, technical-questions, industry-practices","summary":"A comprehensive interview preparation guide featuring 201 real data science interview questions from top tech companies, financial firms, and startups. The resource covers technical concepts, coding challenges, and role-specific expectations across the industry. Essential reference for understanding what employers actually ask and how to structure effective responses.","use_cases":"Preparing for data science interviews at FAANG companies or major tech firms, Understanding industry expectations and common technical topics tested in DS roles","audience":"Junior-DS, Curious-browser"},{"id":"career-amazon-economist-careers","type":"career","name":"Amazon Economist Careers","description":"Dedicated Economist job family with RFCA (reduced-form), STRUC (structural), FMF (forecasting) tracks. Largest economist employer in tech.","category":"Company Lists","url":"https://www.amazon.jobs/en/landing_pages/economistjobs","difficulty":"beginner","prerequisites":"microeconomics-principles, econometrics-basics","topic_tags":"career-paths, amazon-jobs, economist-roles, tech-industry, job-search","summary":"Amazon operates the largest economist job family in tech with three specialized tracks: reduced-form causal inference (RFCA), structural modeling (STRUC), and forecasting/machine learning (FMF). The company offers dedicated economist titles and extensive PhD internship programs, making it a primary destination for economics PhDs entering tech.","use_cases":"PhD student exploring tech career options and understanding different economist role types, Early-career economist comparing Amazon's structure to other tech companies for job applications","audience":"Early-PhD, Curious-browser"},{"id":"career-google","type":"career","name":"Google","description":"Career portal","category":"Company Lists","url":"https://careers.google.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, tech-jobs, FAANG, economist-roles","summary":"Google's official career portal showcasing available positions including quantitative analyst, research scientist, and economist roles. The portal provides job descriptions, application processes, and insights into working at one of the world's largest tech companies. Essential resource for anyone exploring opportunities at Google or understanding their hiring requirements.","use_cases":"Searching for data science or economist positions at Google, Understanding job requirements and qualifications for FAANG companies","audience":"Junior-DS, Curious-browser"},{"id":"career-meta","type":"career","name":"Meta","description":"Career portal","category":"Company Lists","url":"https://www.metacareers.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"meta-careers, tech-jobs, data-science-hiring, economist-roles","summary":"Meta's career portal provides job listings and application information for data science, research, and economist positions at the company. This resource helps candidates understand role requirements, compensation, and hiring processes at one of the major tech companies. It serves as a gateway for exploring opportunities in tech economics and applied research.","use_cases":"Searching for data scientist or economist positions at Meta to transition into tech industry, Researching role requirements and qualifications needed for applied research positions at large tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-should-your-tech-firm-have-an-economist?","type":"career","name":"Should Your Tech Firm Have an Economist?","description":"Framework for economist roles: advising strategy, building products, evaluating impact, thought leadership. Five comparative advantages over data scientists.","category":"Team Types","url":"https://jedkolko.com/2016/02/01/should-your-tech-firm-have-an-economist/","difficulty":"beginner","prerequisites":"microeconomics-fundamentals, statistical-inference","topic_tags":"hiring-decisions, team-structure, economist-roles, data-science-teams, organizational-design","summary":"Framework for deciding whether tech companies should hire economists and how to structure their roles effectively. Outlines five key advantages economists bring compared to data scientists: causal inference expertise, strategic thinking, and policy analysis skills. Provides guidance for managers building cross-functional analytics teams.","use_cases":"Tech startup deciding between hiring an economist vs additional data scientist for their growth team, Established company evaluating whether to create a dedicated economist role for marketplace design and pricing strategy","audience":"Senior-DS, Curious-browser"},{"id":"career-wayfair-economics-group","type":"career","name":"Wayfair Economics Group","description":"~15 PhD economists from MIT, Harvard, Northwestern. Explicit 'Economist' title and intern positions. Strong for applied micro.","category":"Role Landscape","url":"https://www.aboutwayfair.com/careers/tech-blog","difficulty":"beginner","prerequisites":"microeconomics-basics, regression-analysis","topic_tags":"wayfair, economist-roles, company-profiles, applied-microeconomics, career-planning","summary":"Wayfair's Economics Group employs approximately 15 PhD economists from top universities like MIT, Harvard, and Northwestern with explicit 'Economist' job titles. The team focuses on applied microeconomics research and offers structured internship programs for economics students.","use_cases":"PhD economics student researching potential industry career paths and companies that value economics expertise, Academic economist considering transition to industry and looking for companies with strong economics teams","audience":"Early-PhD, Curious-browser"},{"id":"career-linkedin-economic-graph","type":"career","name":"LinkedIn Economic Graph","description":"Studies labor market dynamics using LinkedIn data. Chief Economist Karin Kimbrough. Public research team with policy impact.","category":"Role Landscape","url":"https://economicgraph.linkedin.com/","difficulty":"beginner","prerequisites":"basic-statistics, research-methods","topic_tags":"labor-economics, linkedin-data, economic-research, policy-analysis","summary":"LinkedIn's Economic Graph team conducts research on labor market trends using the platform's professional network data. Led by Chief Economist Karin Kimbrough, the team publishes studies on employment patterns, skills demand, and workforce mobility. Their research influences policy discussions and provides insights into real-time labor market dynamics.","use_cases":"Understanding which skills are in highest demand in your industry or region, Researching labor market trends for academic papers or policy recommendations","audience":"Early-PhD, Curious-browser"},{"id":"career-stripe-economics-of-ai-fellowship","type":"career","name":"Stripe Economics of AI Fellowship","description":"Chief Economist Ernie Tedeschi. $10K+ grants for academic economists. Partners with Stanford on research.","category":"Team Types","url":"https://stripe.events/fellowship","difficulty":"beginner","prerequisites":"research-proposal-writing, academic-cv","topic_tags":"fellowship, economics-research, AI-economics, funding, career","summary":"The Stripe Economics of AI Fellowship provides $10K+ grants to academic economists for research on AI's economic impacts. Led by Chief Economist Ernie Tedeschi and partnering with Stanford, it supports economists studying how AI transforms markets, labor, and economic systems. This fellowship offers both funding and mentorship opportunities for AI economics research.","use_cases":"PhD student researching AI's impact on labor markets needs funding and industry mentorship, Academic economist studying platform economics wants to collaborate with tech practitioners","audience":"Early-PhD, Curious-browser"},{"id":"career-salesforce-ai-economist","type":"career","name":"Salesforce AI Economist","description":"Unique project combining AI and economics for economic policy optimization. Publications at NeurIPS, ICML.","category":"Team Types","url":"https://www.salesforceairesearch.com/","difficulty":"intermediate","prerequisites":"reinforcement-learning, econometrics, deep-learning-frameworks","topic_tags":"AI-economics, reinforcement-learning, economic-policy, multi-agent-systems, Salesforce","summary":"Salesforce's AI Economist team develops reinforcement learning systems to optimize economic policies and taxation strategies. The project combines multi-agent simulation with economic theory to design fairer and more efficient policy mechanisms. Their work has been published at top ML conferences like NeurIPS and ICML, demonstrating novel applications of AI to economic problems.","use_cases":"Designing optimal tax policies using multi-agent reinforcement learning simulations, Building AI systems that can propose and evaluate economic policy interventions","audience":"Mid-DS, Senior-DS"},{"id":"career-pharma-heor-teams-overview","type":"career","name":"Pharma HEOR Teams Overview","description":"Biostatistics, VEO (Value Evidence Outcomes), RWE (Real-World Evidence) teams. 200+ statisticians at Lilly, Pfizer, Roche.","category":"Role Landscape","url":"https://business.optum.com/en/data-analytics/life-sciences/heor.html","difficulty":"beginner","prerequisites":"clinical-trials-basics, descriptive-statistics","topic_tags":"pharma, HEOR, biostatistics, career-paths, healthcare","summary":"Health Economics and Outcomes Research (HEOR) teams in pharmaceutical companies focus on demonstrating drug value through biostatistics, value evidence outcomes analysis, and real-world evidence generation. Major pharma companies like Lilly, Pfizer, and Roche employ hundreds of statisticians across these specialized roles. These teams bridge clinical research and business strategy by quantifying treatment effectiveness and economic impact.","use_cases":"Understanding career paths and team structures when transitioning from academia or other industries into pharmaceutical data science, Exploring alternative career options for statisticians and data scientists interested in healthcare applications beyond traditional tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-rose-tan:-tech-jobs-for-econ-phds","type":"career","name":"Rose Tan: Tech Jobs for Econ PhDs","description":"LinkedIn guide on navigating tech's job market. Networking tips, role types, expectations. Key advice: don't be first economist.","category":"PhD Transition","url":"https://www.linkedin.com/pulse/finding-tech-job-part-1-guide-econ-phds-some-useful-info-rose-tan","difficulty":"beginner","prerequisites":"economics-PhD, job-search-fundamentals","topic_tags":"career-transition, tech-jobs, networking, PhD-to-industry, job-market","summary":"Rose Tan's LinkedIn guide provides practical advice for economics PhDs entering the tech job market. Covers networking strategies, different role types, and setting realistic expectations for the transition. Emphasizes the importance of not being the first economist hired at a company.","use_cases":"Economics PhD student preparing for tech industry job applications, Recent economics graduate exploring career options beyond academia","audience":"Early-PhD, Curious-browser"},{"id":"career-key-advice:-title-vs-tasks","type":"career","name":"Key Advice: Title vs Tasks","description":"'Data Scientist', 'Economist', 'Applied Scientist' can involve similar work. Title matters less than team and tasks.","category":"PhD Transition","url":"https://scarlet-chen.medium.com/tech-industry-jobs-for-econ-phds-54a276dda80b","difficulty":"beginner","prerequisites":"PhD-experience, job-applications","topic_tags":"career-advice, job-titles, PhD-transition, industry-roles, data-science","summary":"Guidance for PhD graduates and career changers on how job titles like 'Data Scientist', 'Economist', and 'Applied Scientist' can involve overlapping responsibilities. Emphasizes evaluating opportunities based on actual work tasks and team dynamics rather than getting caught up in title distinctions.","use_cases":"PhD economist deciding between 'Data Scientist' and 'Applied Scientist' roles at different companies, Career changer comparing similar-sounding positions to find the best fit for their skills","audience":"Early-PhD, Curious-browser"},{"id":"career-nabe-tec-conference-&-job-fair","type":"career","name":"NABE TEC Conference & Job Fair","description":"Largest causal inference conference for tech economists (~800 participants). Free registration for job market PhDs. Amazon, Google, Netflix, Stripe recruit here. Resume deadline typically Sept-Oct. Essential networking event.","category":"Networking","url":"https://www.nabe.com/NABE/NABE/Events/TEC25/TEC2025.aspx","difficulty":"beginner","prerequisites":"causal-inference-basics, resume-writing","topic_tags":"job-market, causal-inference, tech-economics, networking, career-development","summary":"The NABE TEC Conference is the premier annual gathering for tech economists, featuring the latest research in causal inference and econometrics applied to technology companies. With 800+ participants from academia and industry, it serves as the primary recruiting venue for tech companies like Amazon, Google, Netflix, and Stripe. The event offers free registration for job market PhDs and includes both technical presentations and networking opportunities.","use_cases":"PhD student on the job market submitting resume to tech companies recruiting at the conference, Early career researcher networking with industry practitioners to learn about applied econometrics roles","audience":"Early-PhD, Curious-browser"},{"id":"career-economists-in-tech-linkedin-group","type":"career","name":"Economists in Tech LinkedIn Group","description":"The only dedicated online community for economics PhDs in tech. Functions as informal job board where members share openings, provide referrals, and discuss interview processes. Free to join.","category":"Networking","url":"https://www.linkedin.com/groups/13976497/","difficulty":"beginner","prerequisites":"linkedin-profile, economics-phd","topic_tags":"career-networking, job-search, economics-phd, tech-industry, professional-community","summary":"A specialized LinkedIn group connecting economics PhDs working in tech companies. Members share job opportunities, provide referrals, and discuss interview experiences in an informal community setting. Open to anyone with an economics background looking to break into or advance within the tech industry.","use_cases":"Economics PhD student looking for internship or full-time opportunities at tech companies, Experienced economist seeking referrals for senior data scientist positions at FAANG companies","audience":"Early-PhD, Curious-browser"},{"id":"career-mit-code-conference","type":"career","name":"MIT CODE Conference","description":"Premier academic conference for large-scale digital experimentation (Nov 14-15, Cambridge MA). Sponsored by Microsoft, Meta, Google with speakers from Netflix, Airbnb, Stripe, Lyft. Intimate size enables substantive networking.","category":"Networking","url":"https://ide.mit.edu/events/2025-conference-on-digital-experimentation-mit-codemit/","difficulty":"intermediate","prerequisites":"A/B-testing, experimental-design, statistical-inference","topic_tags":"experimentation, A/B-testing, conference, networking, digital-experiments","summary":"Premier academic conference focused on large-scale digital experimentation, bringing together industry practitioners from major tech companies and academic researchers. The intimate setting facilitates meaningful networking and knowledge sharing on cutting-edge experimental methods. Ideal for data scientists and researchers working on experimentation platforms and causal inference.","use_cases":"Mid-level data scientist at a startup wants to learn how Netflix and Airbnb approach large-scale A/B testing, Academic researcher seeking industry connections and real-world applications of experimental design methods","audience":"Mid-DS, Senior-DS"},{"id":"career-acm-ec-conference","type":"career","name":"ACM EC Conference","description":"Economics and Computation conference at Stanford (July 2025). Focus on mechanism design, auctions, market design. Student registration just $5 through SIGecom membership.","category":"Networking","url":"https://ec25.sigecom.org/","difficulty":"beginner","prerequisites":"microeconomics-theory, game-theory-basics","topic_tags":"conference, mechanism-design, auctions, market-design, academic-networking","summary":"Premier academic conference bringing together economists and computer scientists to present research on algorithmic game theory, mechanism design, and computational economics. Hosted at Stanford in July 2025 with heavily subsidized student registration through SIGecom membership. Ideal for PhD students and researchers wanting to network with leading academics in the intersection of economics and computation.","use_cases":"PhD student presenting thesis research on auction mechanisms to get feedback from top researchers, Academic researcher networking to find collaborators for computational market design projects","audience":"Early-PhD, Senior-DS"},{"id":"career-academic-economics-discord","type":"career","name":"Academic Economics Discord","description":"Active community of 8,400+ members for peer support and ongoing discussion. Useful for job market questions, interview prep, and connecting with others making the academia-to-tech transition.","category":"Networking","url":"https://discord.gg/en3rurA8ne","difficulty":"beginner","prerequisites":"academic-economics-background, job-search-basics","topic_tags":"discord-community, career-transition, job-market, academia-to-tech","summary":"A Discord server with over 8,400 academic economists providing peer support and career guidance. Members share job market experiences, interview tips, and advice for transitioning from academia to tech roles. The community offers real-time discussions and networking opportunities for economists at all career stages.","use_cases":"Getting feedback on tech job applications and interview preparation from peers who've made similar transitions, Finding mentorship and advice during the academic job market process or when considering leaving academia","audience":"Early-PhD, Curious-browser"},{"id":"career-aea-joe-listings","type":"career","name":"AEA JOE Listings","description":"Tech companies post here: Amazon, Google, Microsoft, Uber, Airbnb, Wayfair, Stripe. Most DS roles on LinkedIn instead.","category":"Job Boards","url":"https://www.aeaweb.org/joe/listings","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"job-boards, academic-careers, tech-recruiting, economist-jobs","summary":"The American Economic Association's Job Openings for Economists (JOE) listings where major tech companies like Amazon, Google, Microsoft, Uber, Airbnb, Wayfair, and Stripe post economist and research scientist positions. While most data science roles are found on LinkedIn, JOE remains the primary venue for academic-style research positions in tech companies.","use_cases":"PhD economist looking for research scientist roles at major tech companies, Academic researcher seeking industry transition opportunities with economics focus","audience":"Early-PhD, Senior-DS"},{"id":"career-stattrak-biostatistics-internships","type":"career","name":"StatTrak Biostatistics Internships","description":"ASA comprehensive list of pharma biostatistics internships with deadlines. Updated annually.","category":"Job Boards","url":"https://stattrak.amstat.org/2024/12/01/2025-internships/","difficulty":"beginner","prerequisites":"undergraduate-statistics, resume-writing","topic_tags":"biostatistics, pharma, internships, career-development, ASA","summary":"A comprehensive ASA-maintained list of pharmaceutical biostatistics internship opportunities with application deadlines and program details. This annually updated resource helps students find structured internship programs at major pharma companies. Essential for biostatistics students seeking industry experience and career entry points.","use_cases":"Biostatistics PhD student looking for summer internship opportunities at pharmaceutical companies, Master's student in statistics seeking hands-on experience in drug development and clinical trials","audience":"Early-PhD, Curious-browser"},{"id":"career-europeanhealtheconomics-jobs","type":"career","name":"EuropeanHealthEconomics Jobs","description":"HEOR job postings for pharma and consulting. European and global positions.","category":"Job Boards","url":"https://europeanhealtheconomics.com/job/heor/","difficulty":"beginner","prerequisites":"health-economics, econometrics-basics","topic_tags":"HEOR, health-economics, pharma-jobs, europe, career","summary":"Job board specializing in Health Economics and Outcomes Research (HEOR) positions across pharmaceutical companies and consulting firms. Features European and global opportunities for health economists at various career levels. Useful for finding roles that combine economic analysis with healthcare policy and pharmaceutical research.","use_cases":"PhD health economist seeking industry transition to pharma consulting, Experienced HEOR analyst looking for senior positions at European pharmaceutical companies","audience":"Junior-DS, Mid-DS"},{"id":"career-amazon","type":"career","name":"Amazon","description":"Career portal","category":"Company Lists","url":"https://www.amazon.jobs/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviewing","topic_tags":"career-portal, FAANG-jobs, economist-positions, tech-recruiting, PhD-careers","summary":"Amazon's career portal showcasing economist roles, PhD internships, and data science positions at one of the largest tech companies. The portal provides job listings, application processes, and insights into working as an economist or data scientist at Amazon. Essential resource for understanding FAANG-level expectations and opportunities in tech economics.","use_cases":"PhD student researching summer internship opportunities at major tech companies, Junior data scientist exploring economist-titled roles at Amazon","audience":"Early-PhD, Junior-DS"},{"id":"career-microsoft","type":"career","name":"Microsoft","description":"Career portal","category":"Company Lists","url":"https://careers.microsoft.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, tech-jobs, microsoft, recruiting","summary":"Microsoft's career portal showcasing job opportunities, internships, and company culture for tech professionals. The platform is particularly valuable for economists and data scientists seeking roles at major tech companies, offering insights into Microsoft's hiring processes and team structures. Features dedicated sections for PhD internships and research-oriented positions with economist job titles.","use_cases":"Searching for data scientist or economist positions at Microsoft with academic research components, Exploring PhD internship opportunities at a major tech company to gain industry experience","audience":"Early-PhD, Junior-DS"},{"id":"career-apple","type":"career","name":"Apple","description":"Career portal","category":"Company Lists","url":"https://jobs.apple.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, tech-jobs, FAANG, economist-roles","summary":"Apple's career portal for exploring job opportunities at one of the world's largest tech companies. The platform lists various roles including data science, economics, and research positions with economist-specific titles. Apple offers PhD internships and ML-focused roles across product teams and research divisions.","use_cases":"Searching for data scientist or economist positions at Apple to transition into Big Tech, Exploring PhD internship opportunities in machine learning and applied economics at a FAANG company","audience":"Junior-DS, Curious-browser"},{"id":"career-uber","type":"career","name":"Uber","description":"Career portal","category":"Company Lists","url":"https://www.uber.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, tech-jobs, marketplace-company, economist-roles, PhD-opportunities","summary":"Uber's career portal showcasing available positions at the ride-sharing and delivery marketplace company. The portal features economist roles, PhD internship programs, and various data science positions across different business units. It provides insights into Uber's hiring practices, team structures, and career development opportunities for tech economists.","use_cases":"Searching for economist or data scientist positions at a major marketplace company, Researching PhD internship opportunities in tech industry applications","audience":"Early-PhD, Junior-DS"},{"id":"career-lyft","type":"career","name":"Lyft","description":"Career portal","category":"Company Lists","url":"https://www.lyft.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, marketplace, PhD-internship, economist-roles, job-search","summary":"Lyft's career portal showcasing available positions for data scientists, economists, and researchers at the ride-sharing company. The portal features roles specifically for PhD-level economists and internship opportunities in marketplace analytics and pricing optimization. It provides insights into how economists contribute to real-world marketplace problems in the transportation industry.","use_cases":"PhD student seeking industry internships in marketplace economics, Data scientist looking for economist-titled roles at a major tech platform","audience":"Early-PhD, Junior-DS"},{"id":"career-wayfair","type":"career","name":"Wayfair","description":"Career portal","category":"Company Lists","url":"https://www.wayfair.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, marketplace, job-applications, economist-roles, internships","summary":"Wayfair's career portal showcasing economist positions and PhD internship opportunities at the home goods marketplace. The portal provides insights into data science and economics roles within e-commerce operations. Useful for understanding how economists contribute to pricing, demand forecasting, and marketplace dynamics at scale.","use_cases":"Exploring economist job opportunities at a major e-commerce company, Researching PhD internship programs in applied economics and data science","audience":"Early-PhD, Curious-browser"},{"id":"career-airbnb","type":"career","name":"Airbnb","description":"Career portal","category":"Company Lists","url":"https://careers.airbnb.com/","difficulty":"beginner","prerequisites":"undergraduate-economics, basic-statistics","topic_tags":"career-opportunities, marketplace-economics, industry-application, internship-programs","summary":"Airbnb's career portal showcases opportunities for economists and data scientists at one of the world's leading marketplace companies. The platform is known for heavy use of causal inference methods and offers PhD internship programs with economist job titles. It provides insight into how economic research is applied in tech industry settings.","use_cases":"PhD students seeking internships at tech companies that value economic research, Early career economists wanting to transition into industry roles at marketplace companies","audience":"Early-PhD, Curious-browser"},{"id":"career-doordash","type":"career","name":"DoorDash","description":"Career portal","category":"Company Lists","url":"https://careers.doordash.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"job-search, marketplace-company, career-opportunities, economist-roles, tech-industry","summary":"DoorDash career portal showcasing opportunities for economists and data scientists at the leading food delivery marketplace. The company actively recruits PhD economists and offers dedicated economist titles, making it a prime destination for academics transitioning to industry. Features internship programs, full-time positions, and detailed role descriptions across economic research and data science functions.","use_cases":"PhD economist seeking industry transition opportunities at a major marketplace company, Data scientist looking for roles at companies that value economic thinking and experimentation","audience":"Early-PhD, Junior-DS"},{"id":"career-instacart","type":"career","name":"Instacart","description":"Career portal","category":"Company Lists","url":"https://instacart.careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, marketplace, economist-jobs, PhD-internships, tech-careers","summary":"Instacart's career portal showcasing opportunities for economists and data scientists at the grocery delivery marketplace. Features roles with economist titles and PhD internship programs, highlighting their focus on pricing, marketplace dynamics, and economic research.","use_cases":"PhD student looking for economics internships at tech companies, Experienced economist seeking marketplace or pricing roles in industry","audience":"Early-PhD, Curious-browser"},{"id":"career-ebay","type":"career","name":"eBay","description":"Career portal","category":"Company Lists","url":"https://careers.ebayinc.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, job-search, marketplace, tech-jobs, internships","summary":"eBay's career portal showcasing open positions across data science, engineering, and research roles at the major e-commerce marketplace. Features entry-level positions, PhD internships, and experienced roles with detailed job descriptions and application processes. Provides insights into eBay's data-driven culture and technical challenges in marketplace optimization.","use_cases":"Finding data science internships or full-time positions at a major tech marketplace, Researching eBay's technical culture and data science problems before interviews","audience":"Junior-DS, Early-PhD"},{"id":"career-etsy","type":"career","name":"Etsy","description":"Career portal","category":"Company Lists","url":"https://careers.etsy.com/","difficulty":"beginner","prerequisites":"resume-writing, python-basics","topic_tags":"career-portal, marketplace, tech-jobs, phd-internship, data-science-careers","summary":"Etsy's career portal showcasing job opportunities at the online marketplace platform. The portal highlights roles in data science, research, and engineering, with particular emphasis on PhD-level internships and research positions. It provides insight into Etsy's tech culture and approach to data-driven marketplace optimization.","use_cases":"Finding data science internship opportunities at a marketplace company, Researching Etsy's technical culture and team structure before applying","audience":"Early-PhD, Junior-DS"},{"id":"career-linkedin","type":"career","name":"LinkedIn","description":"Career portal","category":"Company Lists","url":"https://careers.linkedin.com/","difficulty":"beginner","prerequisites":"web-scraping, job-search-strategy","topic_tags":"career-development, job-search, networking, tech-recruiting","summary":"LinkedIn is a professional networking platform and career portal widely used in tech for job searching, recruiting, and industry networking. Tech economists and data scientists use it to find positions, connect with peers, and showcase their work. The platform offers job listings, company insights, and professional networking opportunities specific to tech and economics roles.","use_cases":"Finding economist or data scientist positions at tech companies, Networking with other tech economists and building professional connections","audience":"Early-PhD, Junior-DS"},{"id":"career-spotify","type":"career","name":"Spotify","description":"Career portal","category":"Company Lists","url":"https://www.lifeatspotify.com/jobs/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, job-search, tech-companies, economist-roles, PhD-careers","summary":"Spotify's career portal showcasing open positions across data science, economics, and research roles. The company is known for being PhD-friendly and offering economist-titled positions, making it attractive for academic transitions. Features internship opportunities and emphasizes social media/music industry applications.","use_cases":"PhD economist looking for industry transition opportunities at a well-known tech company, Data scientist seeking roles that combine music/media domain expertise with economic analysis","audience":"Early-PhD, Curious-browser"},{"id":"career-netflix","type":"career","name":"Netflix","description":"Career portal","category":"Company Lists","url":"https://jobs.netflix.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"netflix-careers, tech-company-jobs, data-science-roles, economist-positions","summary":"Netflix's career portal showcasing available positions across their data science, economics, and research teams. The platform highlights roles that often prefer industry experience and offers internship opportunities for PhD candidates. Netflix is known for hiring economists with dedicated economist titles and competitive compensation packages.","use_cases":"Searching for data scientist or economist roles at a leading streaming company with strong quantitative culture, Exploring internship opportunities as a PhD student interested in tech industry applications","audience":"Junior-DS, Curious-browser"},{"id":"career-pinterest","type":"career","name":"Pinterest","description":"Career portal","category":"Company Lists","url":"https://www.pinterestcareers.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, tech-jobs, social-media, economist-roles","summary":"Pinterest's career portal showcasing job opportunities at the visual discovery platform. The company is known for hiring economists and PhD researchers, offering both full-time positions and internship programs. Pinterest provides opportunities to work on marketplace dynamics, user behavior analysis, and product economics.","use_cases":"Looking for economist or data scientist roles at a major social media platform, Exploring PhD-level research opportunities in tech industry","audience":"Early-PhD, Curious-browser"},{"id":"career-discord","type":"career","name":"Discord","description":"Career portal","category":"Company Lists","url":"https://discord.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, technical-interviewing","topic_tags":"career-development, tech-jobs, social-media, company-research","summary":"Discord's career portal provides job listings and company information for one of the largest gaming-focused communication platforms. The portal showcases opportunities in data science, engineering, and research roles at a company known for real-time messaging infrastructure and community analytics. Useful for understanding career paths at social media companies with complex user engagement challenges.","use_cases":"Finding data science roles at a major social media platform, Researching Discord's tech stack and data challenges before applying","audience":"Junior-DS, Mid-DS"},{"id":"career-snap","type":"career","name":"Snap","description":"Career portal","category":"Company Lists","url":"https://careers.snap.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, social-media, ML-jobs, PhD-internships, tech-recruiting","summary":"Snap's official career portal showcasing job opportunities at the social media and AR technology company. The portal features ML-focused roles and offers PhD internship programs for researchers. It provides insights into Snap's engineering culture and application process for data science and machine learning positions.","use_cases":"PhD students searching for ML internships at major social media companies, Data scientists looking to transition into AR/computer vision roles at Snap","audience":"Early-PhD, Junior-DS"},{"id":"career-stripe","type":"career","name":"Stripe","description":"Career portal","category":"Company Lists","url":"https://stripe.com/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, fintech, economist-roles, job-applications, phd-internships","summary":"Stripe's career portal showcasing opportunities for economists and data scientists at one of the world's leading fintech companies. The portal features economist-titled positions and PhD internship programs, making it particularly relevant for academics transitioning to industry. Stripe is known for hiring technical economists to work on payment systems, marketplace dynamics, and financial infrastructure.","use_cases":"PhD student looking for internship opportunities at a leading fintech company, Early career economist seeking economist-titled roles in the tech industry","audience":"Early-PhD, Curious-browser"},{"id":"career-paypal","type":"career","name":"PayPal","description":"Career portal","category":"Company Lists","url":"https://careers.paypal.com/","difficulty":"beginner","prerequisites":"resume-writing, basic-statistics, python-pandas","topic_tags":"career-opportunities, fintech-jobs, risk-analytics, PhD-internships, industry-transition","summary":"PayPal's career portal showcasing opportunities in financial technology, risk analytics, and data science roles. The company offers structured PhD internship programs and various technical positions for data scientists at different career levels. Known for its focus on payment systems, fraud detection, and machine learning applications in financial services.","use_cases":"PhD student looking for industry internships in fintech and risk modeling, Data scientist seeking roles in payment systems and fraud detection at a major tech company","audience":"Early-PhD, Junior-DS"},{"id":"career-robinhood","type":"career","name":"Robinhood","description":"Career portal","category":"Company Lists","url":"https://careers.robinhood.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, fintech, job-applications, company-research","summary":"Robinhood's career portal showcasing available positions at the popular commission-free trading platform. The company offers roles across data science, engineering, and research with opportunities to work on experimentation and financial product optimization. Features detailed job descriptions, company culture information, and application processes for tech roles in fintech.","use_cases":"Exploring data science opportunities at a high-growth fintech company, Researching Robinhood's tech culture and interview process before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-affirm","type":"career","name":"Affirm","description":"Career portal","category":"Company Lists","url":"https://www.affirm.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, fintech-jobs, credit-risk, company-research","summary":"Affirm's career portal showcasing opportunities at the buy-now-pay-later fintech company. The company focuses on point-of-sale lending and credit risk modeling with limited PhD-level research positions. Useful for understanding fintech career paths and company culture in consumer lending.","use_cases":"Researching fintech companies that work on credit risk and lending algorithms, Finding entry-level to mid-level data science positions in financial technology","audience":"Junior-DS, Mid-DS"},{"id":"career-block","type":"career","name":"Block","description":"Career portal","category":"Company Lists","url":"https://block.xyz/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, fintech, software-engineering, job-search, company-portal","summary":"Block's career portal showcases job opportunities at the fintech company, with a strong emphasis on software engineering roles. The portal provides insights into company culture, engineering practices, and available positions across Block's various products including Square and Cash App. Limited opportunities for PhD-level research roles, making it more suitable for software-focused career paths.","use_cases":"Software engineers looking for fintech opportunities at a major payments company, Data scientists seeking industry roles in financial technology and payment processing","audience":"Junior-DS, Curious-browser"},{"id":"career-adobe","type":"career","name":"Adobe","description":"Career portal","category":"Company Lists","url":"https://www.adobe.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, adobe, enterprise-jobs, tech-industry, internships","summary":"Adobe's career portal providing access to job opportunities at one of the largest enterprise software companies. The portal features positions across data science, research, engineering, and product teams, with strong PhD internship programs. Adobe offers opportunities to work on creative tools, digital marketing platforms, and document management solutions used by millions worldwide.","use_cases":"PhD students seeking summer internships at a major tech company with research opportunities, Data scientists looking for enterprise roles working on creative software and marketing analytics platforms","audience":"Early-PhD, Junior-DS"},{"id":"career-salesforce","type":"career","name":"Salesforce","description":"Career portal","category":"Company Lists","url":"https://careers.salesforce.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, enterprise-jobs, economist-roles, PhD-opportunities, AI-economics","summary":"Salesforce's career portal showcasing opportunities for economists and data scientists at one of the largest enterprise software companies. The portal features economist-titled positions and PhD internship programs, particularly in AI economics and enterprise analytics. It provides insight into how economists contribute to product strategy, pricing optimization, and market analysis in the enterprise software sector.","use_cases":"PhD student seeking summer internships at major tech companies with dedicated economist roles, Mid-career economist looking to transition from academia to enterprise software and AI-driven business strategy","audience":"Early-PhD, Curious-browser"},{"id":"career-databricks","type":"career","name":"Databricks","description":"Career portal","category":"Company Lists","url":"https://www.databricks.com/company/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-skills","topic_tags":"career-opportunities, tech-companies, job-search, enterprise-roles, economist-positions","summary":"Databricks career portal showcasing job opportunities at the unified analytics and AI platform company. Features roles welcoming economics PhDs and offers economist-titled positions across product, research, and data science teams. Includes internship programs and enterprise-focused positions for candidates with quantitative backgrounds.","use_cases":"Economics PhD seeking industry transition to tech company with strong data science culture, Data scientist looking for enterprise-focused role at company that values economic thinking","audience":"Early-PhD, Junior-DS"},{"id":"career-intuit","type":"career","name":"Intuit","description":"Career portal","category":"Company Lists","url":"https://www.intuit.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, fintech-jobs, economist-roles, PhD-opportunities, enterprise-careers","summary":"Intuit's career portal showcasing opportunities for economists, data scientists, and researchers at the financial technology company behind TurboTax, QuickBooks, and Mint. The portal features roles ranging from PhD internships to senior economist positions, emphasizing AI and machine learning applications in consumer finance. Ideal for exploring career paths in fintech and understanding how economic research translates to product impact.","use_cases":"PhD student researching fintech internship opportunities and economist career tracks, Data scientist exploring enterprise fintech roles and understanding Intuit's research culture","audience":"Early-PhD, Junior-DS"},{"id":"career-eli-lilly","type":"career","name":"Eli Lilly","description":"Career portal","category":"Company Lists","url":"https://careers.lilly.com/","difficulty":"beginner","prerequisites":"resume-writing, python-pandas, statistical-analysis","topic_tags":"pharma-careers, biostatistics-jobs, PhD-internships, healthcare-analytics, career-portal","summary":"Eli Lilly's career portal showcasing opportunities in pharmaceutical data science and biostatistics. The company offers roles ranging from PhD internships to senior researcher positions focused on drug development analytics. Particularly valuable for data scientists interested in healthcare applications and statistical modeling in clinical trials.","use_cases":"PhD student seeking summer internship in pharmaceutical biostatistics, Data scientist transitioning from tech to healthcare industry looking for relevant opportunities","audience":"Early-PhD, Junior-DS"},{"id":"career-pfizer","type":"career","name":"Pfizer","description":"Career portal","category":"Company Lists","url":"https://www.pfizer.com/about/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-applications","topic_tags":"pharma, biostatistics, career-portal, PhD-internship, industry-jobs","summary":"Pfizer's career portal provides job opportunities and internship programs in pharmaceutical research and development. The portal is particularly valuable for biostatisticians and data scientists interested in healthcare applications. It offers positions ranging from PhD internships to senior research roles in drug development and clinical trials.","use_cases":"Finding PhD internship opportunities in pharmaceutical biostatistics and clinical trial design, Exploring full-time data science positions in drug discovery and regulatory affairs","audience":"Early-PhD, Curious-browser"},{"id":"career-j&j","type":"career","name":"J&J","description":"Career portal","category":"Company Lists","url":"https://www.careers.jnj.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"pharma-careers, biostatistics-jobs, PhD-internships, industry-transition","summary":"Johnson & Johnson's career portal showcasing opportunities in pharmaceutical data science and biostatistics. Features PhD internship programs and full-time positions for statisticians and data scientists in healthcare innovation. Provides insight into one of the largest pharma companies' approach to recruiting quantitative talent.","use_cases":"PhD student seeking summer internship in pharmaceutical biostatistics, Academic researcher transitioning to industry data science role at major pharma company","audience":"Early-PhD, Curious-browser"},{"id":"career-moderna","type":"career","name":"Moderna","description":"Career portal","category":"Company Lists","url":"https://www.modernatx.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, pharma, biostatistics, job-search, internships","summary":"Moderna's career portal featuring opportunities in biostatistics, data science, and computational biology roles. Particularly valuable for those interested in pharmaceutical and biotech industry positions, with strong PhD internship programs and entry-level opportunities.","use_cases":"PhD student seeking biostatistics internship in pharmaceutical industry, Data scientist transitioning from tech to healthcare/pharma sector","audience":"Early-PhD, Junior-DS"},{"id":"career-roche","type":"career","name":"Roche","description":"Career portal","category":"Company Lists","url":"https://careers.roche.com/","difficulty":"beginner","prerequisites":"resume-writing, python-basics","topic_tags":"pharma-careers, biostatistics-jobs, PhD-internships, company-portal","summary":"Roche's career portal showcasing opportunities in pharmaceutical data science and biostatistics. The portal features internships, full-time positions, and PhD programs focused on drug development and clinical trials. Particularly valuable for data scientists interested in healthcare applications and regulatory environments.","use_cases":"PhD student seeking summer internship in pharmaceutical biostatistics, Junior data scientist exploring transition from tech to pharma industry","audience":"Early-PhD, Junior-DS"},{"id":"career-genentech","type":"career","name":"Genentech","description":"Career portal","category":"Company Lists","url":"https://www.gene.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"pharma-careers, biotech-jobs, industry-transition, HEOR, PhD-opportunities","summary":"Genentech's career portal showcasing opportunities in pharmaceutical and biotechnology research, with focus on health economics and outcomes research (HEOR) roles. The portal features positions for data scientists, researchers, and PhD-level scientists looking to transition from academia to industry. Includes internship programs specifically designed for PhD students and postdocs.","use_cases":"PhD student in economics or biostatistics looking for industry internship opportunities in pharmaceutical research, Data scientist seeking to transition from tech to biotech/pharma with focus on health outcomes analysis","audience":"Early-PhD, Junior-DS"},{"id":"career-optum","type":"career","name":"Optum","description":"Career portal","category":"Company Lists","url":"https://www.optum.com/en/careers.html","difficulty":"beginner","prerequisites":"resume-writing, healthcare-domain-knowledge","topic_tags":"career-opportunities, healthcare-economics, pharma-industry, internships","summary":"Optum is a major health services and innovation company that offers career opportunities for data scientists and economists in healthcare. The company provides roles in health economics and outcomes research (HEOR), analytics, and pharmaceutical consulting. They offer internship programs particularly suited for PhD students looking to transition into industry.","use_cases":"PhD student in economics or health policy seeking summer internship opportunities in healthcare industry, Data scientist looking to pivot from general tech into healthcare economics and pharmaceutical research","audience":"Early-PhD, Junior-DS"},{"id":"career-roblox","type":"career","name":"Roblox","description":"Career portal","category":"Company Lists","url":"https://careers.roblox.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, tech-economics, job-applications, roblox-careers","summary":"Roblox's career portal featuring opportunities for economists and data scientists in the gaming industry. The company actively recruits economics PhDs and offers internship programs with economist job titles. Known for being PhD-friendly and embracing economic methodologies in their data science work.","use_cases":"Economics PhD student looking for industry internships at gaming companies, Data scientist seeking economist-titled roles at tech companies that value economic training","audience":"Early-PhD, Junior-DS"},{"id":"career-openai","type":"career","name":"OpenAI","description":"Career portal","category":"Company Lists","url":"https://openai.com/careers/","difficulty":"beginner","prerequisites":"python-programming, statistical-inference","topic_tags":"careers, openai, job-applications, tech-companies, ai-research","summary":"OpenAI's career portal showcasing job opportunities at one of the leading AI research companies. The portal features roles spanning research, engineering, and applied AI positions that often require strong technical backgrounds. It serves as a gateway for tech economists and data scientists interested in working at the forefront of artificial intelligence development.","use_cases":"Exploring research scientist positions that combine economics and AI capabilities, Finding applied AI roles that leverage econometric skills in product development","audience":"Junior-DS, Mid-DS"},{"id":"career-anthropic","type":"career","name":"Anthropic","description":"Career portal","category":"Company Lists","url":"https://www.anthropic.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, python-basics","topic_tags":"career-portal, ai-safety, research-positions, machine-learning-jobs, anthropic-careers","summary":"Anthropic's career portal for AI safety and research positions at a leading AI company. Primarily targets researchers and engineers working on large language models and AI alignment. Known for having high bars and requiring strong networking or referrals rather than traditional internship pipelines.","use_cases":"Transitioning from academic research to industry AI safety roles, Finding senior research scientist positions focused on AI alignment and interpretability","audience":"Senior-DS, Curious-browser"},{"id":"career-notion","type":"career","name":"Notion","description":"Career portal","category":"Company Lists","url":"https://www.notion.so/careers/","difficulty":"beginner","prerequisites":"resume-writing, basic-networking","topic_tags":"career-portal, job-search, company-directory, internships, entry-level","summary":"Notion's career portal provides job listings and company information for early-career professionals in tech. The platform focuses on emerging opportunities including internships and entry-level positions with limited PhD-level roles. It serves as a gateway for students and new graduates to discover tech companies and available positions.","use_cases":"New computer science graduate searching for entry-level data science positions at tech companies, PhD student looking for summer internship opportunities in applied research roles","audience":"Junior-DS, Curious-browser"},{"id":"career-datalemur-sql","type":"career","name":"DataLemur SQL","description":"Free SQL practice with FAANG questions. Created by ex-Facebook authors of Ace the Data Science Interview.","category":"SQL & Data","url":"https://datalemur.com/","difficulty":"beginner","prerequisites":"basic-SQL, database-joins","topic_tags":"SQL-practice, interview-prep, FAANG-questions, data-querying, career-prep","summary":"DataLemur SQL is a free practice platform featuring real SQL interview questions from top tech companies like Facebook, Google, and Amazon. Created by ex-Facebook data scientists who authored a popular interview guide, it provides hands-on coding practice with company-specific problem sets. The platform is designed to help aspiring data professionals prepare for technical interviews at major tech companies.","use_cases":"Preparing for data science or analytics interviews at FAANG companies by practicing actual SQL questions, Learning industry-standard SQL patterns and problem-solving approaches used at top tech firms","audience":"Junior-DS, Curious-browser"},{"id":"career-stratascratch","type":"career","name":"StrataScratch","description":"Company-specific SQL filtering for Airbnb, Uber, Netflix. Real interview questions with solutions.","category":"SQL & Data","url":"https://www.stratascratch.com/","difficulty":"beginner","prerequisites":"SQL-basics, database-joins, SQL-window-functions","topic_tags":"SQL-practice, interview-prep, tech-companies, data-analysis, career-prep","summary":"StrataScratch provides real SQL interview questions from major tech companies like Airbnb, Uber, and Netflix with step-by-step solutions. It focuses on practical data filtering and analysis problems that mirror actual work scenarios at these companies. The platform is designed to help data professionals prepare for technical interviews while learning company-specific data patterns.","use_cases":"Preparing for data scientist or analyst interviews at FAANG companies, Learning how major tech companies structure their data problems and expect solutions","audience":"Junior-DS, Mid-DS"},{"id":"career-window-functions-practice","type":"career","name":"Window Functions Practice","description":"Interactive quizzes on ROW_NUMBER, RANK, LAG/LEAD. Consistently tested in interviews.","category":"SQL & Data","url":"https://www.windowfunctions.com/","difficulty":"beginner","prerequisites":"SQL-basics, SELECT-statements","topic_tags":"window-functions, SQL-practice, interview-prep, data-analysis, interactive-quiz","summary":"Interactive practice quizzes focusing on SQL window functions including ROW_NUMBER, RANK, and LAG/LEAD operations. Essential skill for data analysts and commonly tested in technical interviews. Provides hands-on experience with ranking, ordering, and accessing adjacent row data.","use_cases":"Preparing for data analyst or data scientist technical interviews, Learning to rank customers by purchase history or calculate running totals in business analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-interview-query","type":"career","name":"Interview Query","description":"Data science interview platform with SQL, Python, and ML questions. Take-home challenges included.","category":"SQL & Data","url":"https://www.interviewquery.com/","difficulty":"beginner","prerequisites":"python-basics, SQL-queries, pandas-dataframes","topic_tags":"interview-prep, SQL-practice, python-coding, data-science-jobs, technical-screening","summary":"Interview Query is a comprehensive platform designed to help data scientists prepare for technical interviews through practice problems in SQL, Python, and machine learning. The platform includes both quick coding challenges and realistic take-home assignments that mirror actual interview processes at tech companies. It's particularly valuable for practicing the specific types of questions and problem formats commonly encountered in data science interviews.","use_cases":"Preparing for data scientist interviews at tech companies by practicing SQL queries and Python coding problems, Completing mock take-home assignments to simulate real interview experiences and improve problem-solving skills","audience":"Junior-DS, Mid-DS"},{"id":"career-nick-singh's-40-stats-questions","type":"career","name":"Nick Singh's 40 Stats Questions","description":"Probability and statistics questions from FAANG and Wall Street. Bayesian puzzles and distributions.","category":"Stats & Probability","url":"https://www.nicksingh.com/posts/40-probability-statistics-data-science-interview-questions-asked-by-fang-wall-street","difficulty":"beginner","prerequisites":"basic-probability, combinatorics, bayes-theorem","topic_tags":"interview-prep, probability-puzzles, bayesian-inference, statistics-fundamentals, FAANG","summary":"A collection of 40 probability and statistics interview questions commonly asked at top tech companies (FAANG) and Wall Street firms. The questions focus on Bayesian reasoning, probability distributions, and statistical puzzles that test fundamental understanding. This resource helps candidates prepare for technical interviews and solidify their grasp of core statistical concepts.","use_cases":"preparing for data science interviews at tech companies, practicing probability puzzles for finance quantitative roles","audience":"Junior-DS, Curious-browser"},{"id":"career-statquest-with-josh-starmer","type":"career","name":"StatQuest with Josh Starmer","description":"Best resource for econ PhDs learning ML. Bias-variance, regularization, ensemble methods explained accessibly.","category":"ML Fundamentals","url":"https://www.youtube.com/@statquest","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"machine-learning, statistical-concepts, video-tutorials, regularization, ensemble-methods","summary":"StatQuest is a YouTube channel that explains machine learning concepts through visual animations and intuitive examples. Josh Starmer breaks down complex ML topics like bias-variance tradeoff, regularization, and ensemble methods into digestible explanations. Perfect for economists transitioning into data science who need to understand the statistical foundations behind ML algorithms.","use_cases":"Economics PhD student needs to understand random forests for their dissertation analysis, New data scientist at tech company wants to grasp regularization concepts before implementing models","audience":"Early-PhD, Junior-DS"},{"id":"career-trustworthy-online-controlled-experiments-(kohavi)","type":"career","name":"Trustworthy Online Controlled Experiments (Kohavi)","description":"The industry bible by Kohavi, Tang, Xu (Microsoft/LinkedIn/Google). Design, analysis, pitfalls of A/B testing at scale. Only 1/3 of well-designed experiments improve metrics. Free site: experimentguide.com","category":"Experimentation","url":"https://www.amazon.com/Trustworthy-Online-Controlled-Experiments-Practical/dp/1108724264","difficulty":"intermediate","prerequisites":"hypothesis-testing, statistical-significance, basic-probability","topic_tags":"a-b-testing, causal-inference, product-experimentation, statistical-methods, industry-guide","summary":"Comprehensive industry guide to designing and analyzing A/B tests at scale, covering common pitfalls and best practices from tech giants. Written by experimentation leaders at Microsoft, LinkedIn, and Google with real-world examples and statistical rigor. Essential reference for anyone running controlled experiments in product development.","use_cases":"Designing A/B tests for product features while avoiding common statistical mistakes, Building experimentation culture and processes at a tech company","audience":"Mid-DS, Senior-DS"},{"id":"career-understanding-cuped","type":"career","name":"Understanding CUPED","description":"Bridges CUPED to DiD and regression. Essential for industry A/B testing interviews.","category":"Experimentation","url":"https://towardsdatascience.com/understanding-cuped-a822523641af","difficulty":"intermediate","prerequisites":"A-B-testing, linear-regression, python-scipy","topic_tags":"CUPED, variance-reduction, A-B-testing, experimentation, causal-inference","summary":"CUPED (Controlled-experiment Using Pre-Experiment Data) is a variance reduction technique that uses pre-experiment data to reduce noise in A/B test results. It's widely used in tech companies to increase statistical power and reduce experiment runtime. The method connects to difference-in-differences and regression adjustment, making it essential knowledge for experimentation roles.","use_cases":"Reducing variance in conversion rate experiments by using historical user behavior, Shortening experiment duration for revenue metrics by controlling for pre-period spending","audience":"Junior-DS, Mid-DS"},{"id":"career-netflix:-quasi-experimentation","type":"career","name":"Netflix: Quasi Experimentation","description":"When A/B tests aren't feasible and how Netflix handles SUTVA violations.","category":"Experimentation","url":"https://netflixtechblog.com/quasi-experimentation-at-netflix-566b57d2e362","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference, regression-analysis","topic_tags":"quasi-experiments, SUTVA-violations, Netflix, causal-inference, experimentation","summary":"Netflix's approach to causal inference when randomized A/B tests aren't possible due to technical or business constraints. Covers methods for handling violations of SUTVA (Stable Unit Treatment Value Assumption) when user experiences are interconnected. Practical guidance for data scientists working on platform products where network effects matter.","use_cases":"Measuring impact of recommendation algorithm changes when users influence each other's content consumption, Evaluating product features that can't be randomized due to technical infrastructure limitations","audience":"Mid-DS, Senior-DS"},{"id":"career-yuan-meng's-causal-inference-in-data-science","type":"career","name":"Yuan Meng's Causal Inference in Data Science","description":"Most interview-relevant causal inference guide. Tech company case studies: switchback (DoorDash), DiD (Meta), synthetic control (Uber), RDD (DoorDash). By ML Engineer at DoorDash with Berkeley PhD.","category":"Causal Inference","url":"https://www.yuan-meng.com/posts/causality/causality/","difficulty":"intermediate","prerequisites":"python-pandas, basic-statistics, A-B-testing","topic_tags":"causal-inference, tech-interviews, case-studies, experimental-design, industry-applications","summary":"A practical guide to causal inference methods specifically tailored for tech industry applications and interviews. Covers key techniques like difference-in-differences, synthetic control, and RDD through real case studies from major tech companies. Written by a practitioner with both academic background and industry experience at DoorDash.","use_cases":"Preparing for data science interviews at tech companies focusing on causal inference questions, Learning how to apply causal methods to real business problems like measuring platform effects or policy changes","audience":"Junior-DS, Mid-DS"},{"id":"career-interview-prep:-causal-inference-(julie-zhang)","type":"career","name":"Interview Prep: Causal Inference (Julie Zhang)","description":"Explicit Q&A format with model answers. Covers RCTs, matching, IV, DiD, RDD. Each with specific interview questions and detailed responses.","category":"Causal Inference","url":"https://towardsdatascience.com/interview-preparation-causal-inference-44fbb8b0a5c6/","difficulty":"intermediate","prerequisites":"basic-statistics, regression-analysis, experimental-design","topic_tags":"interview-prep, causal-methods, econometrics, data-science-interviews","summary":"Structured Q&A format covering core causal inference methods with model interview responses. Covers randomized controlled trials, matching, instrumental variables, difference-in-differences, and regression discontinuity design. Designed specifically for data science and economics job interviews with detailed explanations of key concepts.","use_cases":"Preparing for data scientist interviews at tech companies focusing on causal methods, Economics PhD students practicing for industry interviews covering experimental design","audience":"Junior-DS, Early-PhD"},{"id":"career-causal-inference-interview-prep-guide-(bhattacherjee)","type":"career","name":"Causal Inference Interview Prep Guide (Bhattacherjee)","description":"Strategic framework for causal inference interviews. Key insight: first ask 'At what level was treatment administered?' Recommends Wooldridge chapters, Netflix/Uber blogs, Microsoft EconML.","category":"Causal Inference","url":"https://medium.com/@shreyabhattac/how-to-prepare-for-interviews-focused-on-causal-inference-modeling-and-online-experiments-aa1b5278ea69","difficulty":"intermediate","prerequisites":"linear-regression, python-basics, experimental-design","topic_tags":"interview-prep, causal-inference, study-guide, econometrics, career-advice","summary":"A strategic framework for preparing for causal inference interviews at tech companies. Provides a structured approach starting with identifying treatment administration levels and recommends specific resources including Wooldridge textbook chapters and industry blog posts. Particularly useful for data scientists transitioning into roles requiring causal reasoning skills.","use_cases":"Preparing for data scientist interviews at companies like Netflix, Uber, or Microsoft that emphasize causal inference, Structuring study plan for economists entering tech roles that require experimental design expertise","audience":"Junior-DS, Mid-DS"},{"id":"career-interviewdb-causal-inference-collection","type":"career","name":"InterviewDB Causal Inference Collection","description":"Largest dedicated causal inference question bank. 100+ questions on confounding, RCTs, PSM, DiD, RDD, DAGs, spillover effects, fixed effects, sensitivity analysis.","category":"Causal Inference","url":"https://www.interviewdb.com/causal-inference/","difficulty":"intermediate","prerequisites":"hypothesis-testing, regression-analysis, DAG-construction","topic_tags":"causal-inference, interview-prep, question-bank, econometrics, methodology","summary":"Comprehensive question bank with 100+ causal inference interview questions covering essential methods like confounding, RCTs, propensity score matching, and difference-in-differences. Designed for data scientists and researchers preparing for technical interviews or testing their understanding of causal methods. Questions span from fundamental concepts like DAGs to advanced topics like spillover effects and sensitivity analysis.","use_cases":"Preparing for data scientist interviews at tech companies focusing on causal inference expertise, Self-assessment and skill validation for researchers transitioning from observational to experimental methods","audience":"Mid-DS, Junior-DS"},{"id":"career-grabngoinfo:-causal-inference-interview-q&a","type":"career","name":"GrabNGoInfo: Causal Inference Interview Q&A","description":"Multimodal interview prep with video + blog. Covers DAGs, causal relationships, key terminology. Also offers 'Top 20 A/B Test Interview Questions'.","category":"Causal Inference","url":"https://grabngoinfo.com/","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design, causal-graphs","topic_tags":"interview-prep, causal-inference, DAGs, A/B-testing, video-tutorial","summary":"Interactive interview preparation resource combining video explanations and blog content focused on causal inference fundamentals. Covers essential concepts like directed acyclic graphs, causal relationships, and key terminology used in data science interviews. Also includes specialized A/B testing interview questions to help candidates prepare for practical experimental design discussions.","use_cases":"Preparing for data scientist interviews at tech companies with causal inference questions, Reviewing fundamental causal concepts before job interviews or performance reviews","audience":"Junior-DS, Mid-DS"},{"id":"career-emma-ding:-product-sense-guide","type":"career","name":"Emma Ding: Product Sense Guide","description":"Ultimate guide to business case interviews. AARRR framework, metrics, diagnostic approaches.","category":"Product Sense","url":"https://towardsdatascience.com/the-ultimate-guide-to-cracking-business-case-interviews-for-data-scientists-part-1-cb768c37edf4","difficulty":"beginner","prerequisites":"basic-statistics, business-fundamentals","topic_tags":"product-metrics, AARRR-framework, business-case-interviews, diagnostic-analysis, product-management","summary":"Comprehensive guide to product sense for business case interviews, focusing on the AARRR (Acquisition, Activation, Retention, Referral, Revenue) framework. Covers metrics design, diagnostic approaches, and structured thinking for product problems. Essential resource for data scientists transitioning into product-focused roles or preparing for tech interviews.","use_cases":"Preparing for product data scientist interviews at tech companies, Learning to design and interpret product metrics for A/B testing and feature launches","audience":"Junior-DS, Mid-DS"},{"id":"career-amplitude:-north-star-metrics","type":"career","name":"Amplitude: North Star Metrics","description":"Three games framework: Attention, Transaction, Productivity. Real examples from Facebook, Airbnb, Spotify.","category":"Product Sense","url":"https://amplitude.com/blog/north-star-metric","difficulty":"beginner","prerequisites":"basic-analytics, product-metrics","topic_tags":"north-star-metrics, product-strategy, kpi-frameworks, case-studies","summary":"Framework for identifying the single most important metric that captures core product value through three business model types: Attention, Transaction, and Productivity games. Uses real-world examples from major tech companies like Facebook, Airbnb, and Spotify to illustrate how different products define and measure their north star metrics.","use_cases":"Product manager needs to define primary success metric for new feature launch, Data scientist building executive dashboard and needs to identify most important KPI to highlight","audience":"Junior-DS, Mid-DS"},{"id":"career-datalemur-meta-ds-guide","type":"career","name":"DataLemur Meta DS Guide","description":"31 leaked Meta interview questions. Product sense and SQL focus.","category":"Product Sense","url":"https://datalemur.com/blog/meta-data-scientist-interview-guide","difficulty":"intermediate","prerequisites":"SQL-joins, product-metrics, A-B-testing","topic_tags":"interview-prep, product-sense, meta-facebook, sql-questions, data-science-interviews","summary":"A collection of 31 actual Meta/Facebook data science interview questions focusing on product sense and SQL skills. The guide provides real questions that have been asked in Meta interviews, helping candidates prepare for the specific types of problems and analytical thinking required at the company.","use_cases":"Preparing for Meta data science interviews, Learning product sense frameworks used at major tech companies","audience":"Junior-DS, Mid-DS"},{"id":"career-scarlet-ink:-amazon-lp-guide","type":"career","name":"Scarlet Ink: Amazon LP Guide","description":"Written by ex-Amazon Bar Raiser. Sent by recruiters to candidates. 100+ candidates credit it for getting hired.","category":"Behavioral","url":"https://www.scarletink.com/p/interviewing-at-amazon-leadership-principles","difficulty":"beginner","prerequisites":"behavioral-interviewing, resume-writing","topic_tags":"amazon-interview, leadership-principles, behavioral-questions, tech-recruiting, career-guide","summary":"A comprehensive guide to Amazon's Leadership Principles written by a former Bar Raiser who helped evaluate candidates. Provides frameworks and examples for answering behavioral questions using Amazon's specific evaluation criteria. Widely shared by recruiters and credited by 100+ candidates for successful Amazon interviews.","use_cases":"Preparing for Amazon software engineer or data scientist interviews, Understanding how to structure STAR method responses for Amazon's leadership principles","audience":"Junior-DS, Mid-DS"},{"id":"career-amazon-leadership-principles","type":"career","name":"Amazon Leadership Principles","description":"Official 16 principles with explanations. Customer Obsession, Ownership, Invent and Simplify, etc.","category":"Behavioral","url":"https://www.amazon.jobs/content/en/our-workplace/leadership-principles","difficulty":"beginner","prerequisites":"behavioral-interviewing, corporate-culture","topic_tags":"leadership-principles, behavioral-interviews, amazon-culture, career-development","summary":"Amazon's 16 official Leadership Principles that guide decision-making and behavior across the company, including Customer Obsession, Ownership, and Invent and Simplify. These principles are heavily used in Amazon's interview process and day-to-day operations. Essential reading for anyone interviewing at Amazon or wanting to understand their corporate culture.","use_cases":"Preparing for Amazon behavioral interviews and understanding expected responses, Learning corporate leadership frameworks to apply at other tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-interviewing.io-amazon-guide","type":"career","name":"Interviewing.io Amazon Guide","description":"Insights from 500+ mock Amazon behavioral interviews. STARI method with Action at 50-60%.","category":"Behavioral","url":"https://interviewing.io/guides/hiring-process/amazon","difficulty":"beginner","prerequisites":"basic-communication-skills, job-search-experience","topic_tags":"behavioral-interviews, STAR-method, Amazon-interviews, career-preparation, interview-coaching","summary":"A comprehensive guide based on analysis of 500+ mock Amazon behavioral interviews, focusing on the STARI method where the Action component should comprise 50-60% of your response. Provides data-driven insights into what works in Amazon's behavioral interview format. Essential preparation material for anyone interviewing at Amazon or other companies using similar behavioral interview techniques.","use_cases":"Preparing for Amazon behavioral interviews by learning the optimal structure and timing for STARI responses, Understanding common behavioral interview patterns and mistakes based on real interview data","audience":"Junior-DS, Curious-browser"},{"id":"career-igotanoffer:-google-behavioral","type":"career","name":"IGotAnOffer: Google Behavioral","description":"Googleyness traits: comfort with ambiguity, bias for action, intellectual humility.","category":"Behavioral","url":"https://igotanoffer.com/blogs/tech/google-behavioral-interview","difficulty":"beginner","prerequisites":"resume-writing, basic-interviewing-skills","topic_tags":"behavioral-interviews, google-interview, career-development, soft-skills, interview-preparation","summary":"Guide to Google's behavioral interview process focusing on core 'Googleyness' traits including comfort with ambiguity, bias for action, and intellectual humility. Helps candidates understand what Google looks for in behavioral responses and how to demonstrate these qualities effectively. Essential preparation for anyone interviewing at Google or similar tech companies.","use_cases":"Preparing for Google behavioral interview rounds, Understanding how to demonstrate soft skills valued by top tech companies","audience":"Junior-DS, Mid-DS"},{"id":"career-designing-machine-learning-systems","type":"career","name":"Designing Machine Learning Systems","description":"Essential ML system design book by Chip Huyen. Based on Stanford CS 329S.","category":"ML System Design","url":"https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/","difficulty":"intermediate","prerequisites":"python-scikit-learn, docker-containers, SQL-databases","topic_tags":"ml-systems, production-ml, system-design, mlops, engineering","summary":"Comprehensive guide to building production ML systems covering the full lifecycle from data engineering to model deployment and monitoring. Written by Chip Huyen based on Stanford's popular CS 329S course. Essential reading for anyone moving ML models from notebooks to real-world applications.","use_cases":"Designing recommendation systems at scale for e-commerce platforms, Building fraud detection pipelines that process millions of transactions daily","audience":"Junior-DS, Mid-DS"},{"id":"career-ml-system-design-interview-(alex-xu)","type":"career","name":"ML System Design Interview (Alex Xu)","description":"7-step framework with 10 detailed solutions: visual search, video recommendation, ad prediction.","category":"ML System Design","url":"https://www.amazon.com/Machine-Learning-System-Design-Interview/dp/1736049127","difficulty":"intermediate","prerequisites":"python-scikit-learn, system-architecture-basics, SQL-joins","topic_tags":"system-design, interview-preparation, ml-architecture, production-systems","summary":"A structured 7-step framework for tackling machine learning system design interviews with detailed walkthroughs of 10 real-world problems. Covers end-to-end system architecture from data ingestion to model serving for applications like visual search and recommendation systems. Essential preparation material for data scientists interviewing at tech companies.","use_cases":"Preparing for senior data scientist interviews at FAANG companies, Learning how to design scalable ML systems for production environments","audience":"Mid-DS, Senior-DS"},{"id":"career-ml-interviews-github","type":"career","name":"ML Interviews GitHub","description":"7.2k stars. Created by someone with offers from Meta, Google, Amazon, Apple for Applied Scientist.","category":"ML Fundamentals","url":"https://github.com/alirezadir/Machine-Learning-Interviews","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, probability-theory","topic_tags":"interview-prep, ml-fundamentals, applied-scientist, faang-interviews, github-resource","summary":"A comprehensive GitHub repository with 7.2k stars containing machine learning interview preparation materials, created by someone who received offers from top tech companies (Meta, Google, Amazon, Apple) for Applied Scientist roles. The resource covers fundamental ML concepts, coding problems, and interview strategies specifically tailored for applied scientist positions at major tech companies.","use_cases":"Preparing for Applied Scientist interviews at FAANG companies, Reviewing core ML concepts before technical interviews","audience":"Junior-DS, Early-PhD"},{"id":"career-chip-huyen-ml-interviews-book","type":"career","name":"Chip Huyen ML Interviews Book","description":"200+ knowledge questions organized by difficulty for ML fundamentals.","category":"ML Fundamentals","url":"https://huyenchip.com/ml-interviews-book/","difficulty":"beginner","prerequisites":"python-basics, linear-algebra, probability-theory","topic_tags":"interview-prep, ml-fundamentals, knowledge-questions, career-development, self-assessment","summary":"A comprehensive collection of 200+ machine learning interview questions organized by difficulty level, covering core ML concepts and fundamentals. Created by Chip Huyen, this resource helps practitioners test and strengthen their theoretical knowledge of machine learning. The questions span from basic concepts to more challenging problems, making it useful for both learning and interview preparation.","use_cases":"Preparing for machine learning engineer or data scientist job interviews, Self-assessment and identifying knowledge gaps in ML fundamentals","audience":"Junior-DS, Early-PhD"},{"id":"career-interview-query-take-homes","type":"career","name":"Interview Query Take-Homes","description":"23 real take-home challenges from Airbnb, Stripe, Uber, DoorDash, Amazon with solutions.","category":"Take-Home","url":"https://www.interviewquery.com/p/data-science-take-home-challenges","difficulty":"intermediate","prerequisites":"python-pandas, SQL-joins, statistical-hypothesis-testing","topic_tags":"interview-prep, data-science-interviews, take-home-assignments, case-studies, tech-companies","summary":"A curated collection of 23 authentic take-home data science challenges from top tech companies including Airbnb, Stripe, Uber, DoorDash, and Amazon, complete with detailed solutions. These real-world problems cover the types of analytical challenges candidates face during the interview process at major tech firms. The resource provides both the original problem statements and worked-through solutions to help prepare for similar interview scenarios.","use_cases":"Preparing for data science interviews at major tech companies by practicing with real challenge problems, Understanding what types of analytical problems and expectations exist at different tech firms","audience":"Junior-DS, Mid-DS"},{"id":"career-candor-salary-negotiation-guide","type":"career","name":"Candor Salary Negotiation Guide","description":"Complete framework for total compensation negotiation: base, equity valuation (public vs startup), signing bonuses, level negotiation. Harvard Career Services recommended. Helped one executive secure $5.4M more.","category":"Negotiation","url":"https://candor.co/guides/salary-negotiation","difficulty":"beginner","prerequisites":"basic-arithmetic, email-communication","topic_tags":"salary-negotiation, compensation-packages, career-guide, equity-valuation, total-compensation","summary":"A comprehensive framework for negotiating all components of tech compensation including base salary, equity valuation, signing bonuses, and job levels. Provides practical strategies and scripts for maximizing total compensation packages. Essential reading for anyone entering or advancing in tech roles.","use_cases":"New graduate preparing for first tech job offer negotiations, Experienced professional switching companies and evaluating competing offers","audience":"Junior-DS, Mid-DS"},{"id":"career-haseeb-qureshi:-ten-rules-for-negotiating","type":"career","name":"Haseeb Qureshi: Ten Rules for Negotiating","description":"Gold standard negotiation guide from ex-poker player who negotiated $250K at Airbnb for first tech job. Game-theory approach: information control, BATNA development, handling exploding offers.","category":"Negotiation","url":"https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/","difficulty":"beginner","prerequisites":"basic-communication, job-market-awareness","topic_tags":"salary-negotiation, job-offers, career-strategy, communication-tactics, compensation","summary":"Comprehensive negotiation framework from a former poker player who successfully negotiated a $250K offer at Airbnb for his first tech role. Uses game theory principles to teach information control, developing alternatives (BATNA), and handling pressure tactics like exploding offers. Essential reading for anyone entering or advancing in tech careers.","use_cases":"Negotiating initial job offer at a tech company, Discussing promotion or raise with current employer","audience":"Junior-DS, Curious-browser"},{"id":"career-levels.fyi-negotiation-guide","type":"career","name":"Levels.fyi Negotiation Guide","description":"From platform that helped negotiate $31M+ in raises. Covers total comp breakdown, equity at public vs private companies, leveling systems, location impact. Companion database has 75K+ verified data points.","category":"Negotiation","url":"https://www.levels.fyi/blog/ultimate-negotiation-guide.html","difficulty":"beginner","prerequisites":"basic-arithmetic, job-application-experience","topic_tags":"salary-negotiation, compensation-benchmarking, career-progression, equity-valuation","summary":"Comprehensive negotiation guide from Levels.fyi that breaks down total compensation structures, equity differences between public and private companies, and leveling systems across tech companies. Built on a database of 75K+ verified compensation data points, helping tech workers understand and negotiate their market value. Essential resource for anyone entering salary negotiations or evaluating job offers in tech.","use_cases":"Preparing for salary negotiation with current employer using market data, Evaluating competing job offers from different companies and stages","audience":"Junior-DS, Mid-DS"},{"id":"career-interviewing.io-negotiation-series","type":"career","name":"Interviewing.io Negotiation Series","description":"Word-for-word scripts from platform with 94% success rate and $50K average gain. Exposes recruiter psychology and information-extraction tactics. Includes Meta-specific playbook.","category":"Negotiation","url":"https://interviewing.io/blog/negotiate-salary-recruiter","difficulty":"beginner","prerequisites":"job-search-basics, salary-research","topic_tags":"salary-negotiation, tech-interviews, career-advancement, communication-scripts","summary":"Complete negotiation playbook with proven word-for-word scripts from a platform achieving 94% success rates and $50K average salary increases. Reveals recruiter psychology, information extraction tactics, and company-specific strategies including detailed Meta playbook.","use_cases":"Negotiating initial job offer at tech company, Requesting salary increase during performance review cycle","audience":"Junior-DS, Mid-DS"},{"id":"career-team-rora:-applied-scientist-negotiation","type":"career","name":"Team Rora: Applied Scientist Negotiation","description":"Only guide specifically for Applied Scientist roles. 400+ FAANG negotiations. Includes exact salary bands (Amazon L5: $170-220K base, $351-588K equity). Sign-ons can reach $100K+ with proper leverage.","category":"Negotiation","url":"https://www.teamrora.com/post/applied-scientist-salary-negotiation","difficulty":"beginner","prerequisites":"job-application-process, resume-writing, interview-preparation","topic_tags":"salary-negotiation, applied-scientist, FAANG, compensation, career-guide","summary":"Specialized negotiation guide for Applied Scientist positions at major tech companies, featuring over 400 FAANG salary negotiations. Provides concrete salary bands and strategies for maximizing compensation packages including base salary, equity, and sign-on bonuses.","use_cases":"Preparing for Applied Scientist offer negotiations at Amazon, Google, Meta, or other FAANG companies, Understanding market rates and compensation structures before salary discussions","audience":"Junior-DS, Mid-DS"},{"id":"career-hbr:-why-tech-hires-economists","type":"career","name":"HBR: Why Tech Hires Economists","description":"5 key areas: ads design, ROI estimation, marketplace incentives, causal inference, equilibrium effects.","category":"Role Landscape","url":"https://hbr.org/2019/02/why-tech-companies-hire-so-many-economists","difficulty":"beginner","prerequisites":"microeconomics-basics, basic-statistics","topic_tags":"tech-careers, economist-roles, industry-overview, HBR-article","summary":"Harvard Business Review article explaining why technology companies hire economists and the five key areas where they contribute value. Covers auction design, ROI measurement, marketplace design, causal inference, and understanding equilibrium effects in tech platforms. Provides an accessible overview for anyone considering or curious about economist roles in the tech industry.","use_cases":"PhD student exploring career options beyond academia, Tech professional wanting to understand what economists do at their company","audience":"Early-PhD, Curious-browser"},{"id":"career-evan's-industry-job-finding-advice","type":"career","name":"Evan's Industry Job Finding Advice","description":"Econ PhD who conducted 250+ interviews at Amazon shares job search strategy. Failed 2014 search (30 apps, 0 offers) \u2192 successful 2015 (100 apps, 35 interviews, Amazon offer). Covers networking, resume, behavioral interviews, technical prep.","category":"PhD Transition","url":"https://sites.google.com/view/themostdismalscientist/industry-job-finding-advice","difficulty":"beginner","prerequisites":"economics-PhD, basic-resume-writing","topic_tags":"job-search, PhD-transition, tech-industry, interview-prep, career-advice","summary":"An economics PhD's detailed job search strategy based on conducting 250+ interviews at Amazon and his own transition from academia to tech. Covers the complete process from failed attempts to successful placement, including networking tactics, resume optimization, and interview preparation. Provides insider perspective on what tech companies look for when hiring PhDs.","use_cases":"Economics PhD preparing to leave academia and enter tech industry, Recent PhD graduate struggling with initial job search rejections and needing strategic guidance","audience":"Early-PhD, Curious-browser"},{"id":"career-jed-kolko:-should-your-firm-have-an-economist?","type":"career","name":"Jed Kolko: Should Your Firm Have an Economist?","description":"Economists as public spokespeople and internal analysts at Indeed, Glassdoor, Zillow.","category":"Role Landscape","url":"https://www.linkedin.com/pulse/should-your-tech-firm-have-economist-jed-kolko","difficulty":"beginner","prerequisites":"basic-economics, business-communication","topic_tags":"tech-economist-roles, industry-career, public-relations, data-storytelling","summary":"Jed Kolko discusses the dual role of economists at major tech companies like Indeed, Glassdoor, and Zillow as both public-facing spokespeople and internal data analysts. He explains how economists contribute to companies through external thought leadership, media engagement, and internal strategic analysis. This perspective helps understand the career opportunities and value proposition for economists in the tech industry.","use_cases":"Understanding what economists actually do at tech companies before applying for roles, Making the business case to hire an economist for your startup or team","audience":"Early-PhD, Curious-browser"},{"id":"career-eugene-yan:-ds-vs-applied-vs-research-vs-mle","type":"career","name":"Eugene Yan: DS vs Applied vs Research vs MLE","description":"Clearest breakdown: DS\u2192documents, Applied Scientist\u2192ML systems, Research Scientist\u2192papers, MLE\u2192infrastructure.","category":"Role Landscape","url":"https://eugeneyan.com/writing/data-science-roles/","difficulty":"beginner","prerequisites":"basic-python, data-analysis-experience","topic_tags":"career-guidance, role-definitions, data-science-roles, career-transitions, job-market","summary":"Eugene Yan provides a clear framework distinguishing four key data roles: Data Scientists focus on analysis and documentation, Applied Scientists build ML systems, Research Scientists publish papers, and MLEs handle infrastructure. This breakdown helps clarify career paths and expectations across different data science positions.","use_cases":"Deciding which data science role to target when job searching or transitioning careers, Understanding team structure and responsibilities when hiring or organizing data teams","audience":"Junior-DS, Curious-browser"},{"id":"career-tds:-applied-vs-research-scientist","type":"career","name":"TDS: Applied vs Research Scientist","description":"Applied Scientists are 'same caliber as research scientists, but experts in implementing at scale.'","category":"Role Landscape","url":"https://towardsdatascience.com/whats-the-difference-between-a-data-scientist-research-scientist-and-an-applied-scientist-30c04190c1fa/","difficulty":"beginner","prerequisites":"basic-statistics, python-programming","topic_tags":"role-taxonomy, applied-scientist, career-guidance, research-vs-applied, data-science-roles","summary":"This article clarifies the distinction between Applied Scientists and Research Scientists in tech companies. Applied Scientists focus on implementing research at production scale while maintaining research-level expertise. It's essential reading for anyone navigating data science career paths in tech.","use_cases":"Deciding between applied scientist vs research scientist career tracks, Understanding role expectations when interviewing for scientist positions","audience":"Junior-DS, Curious-browser"},{"id":"career-neptune.ai:-mle-vs-data-scientist","type":"career","name":"Neptune.ai: MLE vs Data Scientist","description":"MLEs take models to production: optimization, MLOps, A/B testing, containerization, deployment.","category":"Role Landscape","url":"https://neptune.ai/blog/ml-engineer-vs-data-scientist","difficulty":"beginner","prerequisites":"python-scikit-learn, docker-containers, REST-APIs","topic_tags":"MLE, data-scientist, career-paths, MLOps, role-comparison","summary":"Compares Machine Learning Engineer and Data Scientist roles, focusing on how MLEs specialize in productionizing ML models. Covers key responsibilities like model optimization, deployment infrastructure, A/B testing frameworks, and containerization. Useful for understanding career paths and role distinctions in tech organizations.","use_cases":"Deciding between MLE and DS career tracks after completing a data science bootcamp, Understanding which role to hire when building an ML team that needs both research and production capabilities","audience":"Junior-DS, Curious-browser"},{"id":"career-365-data-science:-ds-vs-mle-skills","type":"career","name":"365 Data Science: DS vs MLE Skills","description":"ML requirements: 69.3% for DS vs 88.3% for MLE. AI: 21.2% for DS vs 60.4% for MLE.","category":"Role Landscape","url":"https://365datascience.com/career-advice/career-guides/data-scientist-vs-machine-learning-engineer/","difficulty":"beginner","prerequisites":"basic-statistics, job-market-awareness","topic_tags":"career-planning, skill-requirements, role-comparison, job-market, data-science-careers","summary":"Analysis comparing skill requirements between Data Scientist and Machine Learning Engineer roles based on job postings. Shows MLE positions require significantly more ML/AI skills (88.3% vs 69.3% for ML, 60.4% vs 21.2% for AI). Useful for career planning and understanding role distinctions in the data science job market.","use_cases":"Planning career transition from DS to MLE role and identifying skill gaps, Understanding which skills to prioritize when applying for different data roles","audience":"Junior-DS, Curious-browser"},{"id":"career-daliana-liu:-product-ds-vs-analyst","type":"career","name":"Daliana Liu: Product DS vs Analyst","description":"Product DS does predictive/prescriptive analysis with experiments; Analyst does descriptive dashboards.","category":"Role Landscape","url":"https://www.dalianaliu.blog/p/is-product-data-scientist-a-glorified","difficulty":"beginner","prerequisites":"SQL-basics, A-B-testing","topic_tags":"product-data-science, role-comparison, career-guidance, Google, analyst-vs-DS","summary":"Daliana Liu from Google explains the key differences between Product Data Scientists and Data Analysts. Product DS focuses on predictive and prescriptive analytics through experimentation, while Analysts primarily create descriptive dashboards and reports. This helps clarify career paths and role expectations in product organizations.","use_cases":"New graduate deciding between product analyst vs product DS roles, Current analyst considering transition to product data science","audience":"Junior-DS, Curious-browser"},{"id":"career-tds:-product-analytics-explained","type":"career","name":"TDS: Product Analytics Explained","description":"Product analysts provide timely insights; DS works on longer, in-depth projects.","category":"Role Landscape","url":"https://towardsdatascience.com/product-analysts-what-is-that-936978e5c215/","difficulty":"beginner","prerequisites":"SQL-basics, business-metrics","topic_tags":"product-analytics, role-taxonomy, career-guidance, analyst-vs-scientist, business-insights","summary":"This article explains the role of product analysts and how they differ from data scientists. Product analysts focus on providing quick, actionable insights to inform product decisions, while data scientists work on longer-term, more complex analytical projects. It's essential reading for understanding career paths in data roles.","use_cases":"Deciding between product analyst and data scientist career paths, Understanding team structure when hiring for analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-greg-rafferty:-hidden-career-ladder","type":"career","name":"Greg Rafferty: Hidden Career Ladder","description":"L3\u2192L4 reliable, L4\u2192L5 strategic (defining vs solving problems), L5\u2192L6 multiplier (scaling through others).","category":"Role Landscape","url":"https://towardsdatascience.com/the-hidden-career-ladder-of-data-science/","difficulty":"beginner","prerequisites":"performance-reviews, 1-on-1-meetings","topic_tags":"career-progression, tech-levels, leadership-skills, performance-management","summary":"Greg Rafferty breaks down the hidden expectations at each tech career level: L3\u2192L4 requires consistent reliable delivery, L4\u2192L5 demands strategic thinking and problem definition skills, while L5\u2192L6 focuses on multiplying impact through others. This framework helps data scientists understand what behaviors and mindsets are actually evaluated for promotions beyond just technical skills.","use_cases":"Preparing for promotion conversations with your manager by understanding level expectations, Self-assessing your current performance and identifying specific growth areas for advancement","audience":"Junior-DS, Mid-DS"},{"id":"career-data-science-leadership:-career-ladder","type":"career","name":"Data Science Leadership: Career Ladder","description":"Tasks (Junior) \u2192 Projects (Mid) \u2192 Products (Senior/Principal). Mental model progression.","category":"Role Landscape","url":"https://datascienceleadership.com/docs/people-management/career-ladder","difficulty":"beginner","prerequisites":"basic-data-analysis, project-management-basics","topic_tags":"career-progression, data-science-roles, leadership-development, skills-framework","summary":"Framework showing how data science careers progress from task-focused junior roles to project-owning mid-level positions to product-driving senior roles. Provides mental models for understanding responsibility scope and skill development at each career stage. Essential roadmap for planning career advancement in data science.","use_cases":"Junior data scientist planning next career moves and understanding what skills to develop, Manager designing career ladder framework and promotion criteria for data science team","audience":"Junior-DS, Mid-DS"},{"id":"career-design-gurus:-faang-levels-comparison","type":"career","name":"Design Gurus: FAANG Levels Comparison","description":"Meta E3-E10, Google L3-L10, Amazon SDE I-III. Senior (L5) is 'terminal level' where many plateau.","category":"Role Landscape","url":"https://www.designgurus.io/blog/understanding-faang-software-engineer-job-levels","difficulty":"beginner","prerequisites":"tech-industry-basics, job-search-fundamentals","topic_tags":"career-levels, FAANG, compensation, career-progression, tech-roles","summary":"A comprehensive comparison of career levels across major tech companies including Meta (E3-E10), Google (L3-L10), and Amazon (SDE I-III). Shows how roles map between companies and explains promotion trajectories, with L5/Senior being the 'terminal level' where many engineers plateau. Essential reference for understanding tech career progression and compensation bands.","use_cases":"Negotiating job offers across different FAANG companies by understanding equivalent levels, Planning career progression and setting realistic timeline expectations for promotions","audience":"Junior-DS, Curious-browser"},{"id":"career-what-is-data-science-at-lyft?","type":"career","name":"What is Data Science at Lyft?","description":"Maps the entire marketplace DS landscape: Marketplace team designs dispatch/pricing, Fleet team builds optimal pricing models. Shows how pricing pairs economics literature with econometrics.","category":"Team Types","url":"https://eng.lyft.com/what-is-data-science-at-lyft-4101a69be028","difficulty":"beginner","prerequisites":"basic-economics, python-pandas, SQL-basics","topic_tags":"marketplace-economics, pricing-models, team-structure, rideshare, career-guidance","summary":"Overview of data science roles and responsibilities at Lyft, covering how different teams approach marketplace problems. Shows how Marketplace teams handle dispatch and pricing algorithms while Fleet teams focus on supply-side optimization. Demonstrates the intersection of economic theory and practical implementation in a major tech platform.","use_cases":"Understanding career paths and team structures at rideshare companies, Learning how economic principles are applied in real marketplace platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-uber:-surge-pricing-moves-drivers","type":"career","name":"Uber: Surge Pricing Moves Drivers","description":"DiD analysis shows surge heatmap visibility explains 10-60% of driver self-positioning decisions.","category":"Team Types","url":"https://eng.uber.com/research/surge-pricing-moves-ubers-driver-partners/","difficulty":"intermediate","prerequisites":"difference-in-differences, python-pandas, statistical-significance-testing","topic_tags":"surge-pricing, driver-behavior, difference-in-differences, spatial-analysis, rideshare","summary":"This study uses difference-in-differences methodology to analyze how Uber's surge pricing heatmap affects driver positioning decisions. The research demonstrates that visual surge information accounts for 10-60% of drivers' self-positioning behavior, providing concrete evidence for how pricing signals influence supply allocation in rideshare markets.","use_cases":"Designing driver incentive systems and heat map interfaces for rideshare platforms, Evaluating the effectiveness of dynamic pricing visualization tools on supplier behavior","audience":"Mid-DS, Senior-DS"},{"id":"career-airbnb:-learning-market-dynamics-for-pricing","type":"career","name":"Airbnb: Learning Market Dynamics for Pricing","description":"ML + structural modeling for booking arrival processes and dynamic pricing policies.","category":"Team Types","url":"https://medium.com/airbnb-engineering/learning-market-dynamics-for-optimal-pricing-97cffbcc53e3","difficulty":"intermediate","prerequisites":"python-scikit-learn, econometric-modeling, time-series-analysis","topic_tags":"dynamic-pricing, structural-modeling, marketplace-economics, demand-forecasting, airbnb","summary":"This content explores how Airbnb combines machine learning with structural economic modeling to understand booking arrival processes and optimize dynamic pricing strategies. It demonstrates how tech companies integrate traditional econometric approaches with modern ML techniques to solve complex marketplace problems. The material covers both the technical implementation and strategic considerations for pricing in two-sided markets.","use_cases":"Building dynamic pricing systems for marketplace platforms with supply and demand fluctuations, Developing booking demand forecasting models that account for market structure and competitor behavior","audience":"Mid-DS, Senior-DS"},{"id":"career-amazon:-science-of-price-experiments","type":"career","name":"Amazon: Science of Price Experiments","description":"Crossover experiments, random-days, causal forests for non-discriminatory pricing. Can't show different prices.","category":"Team Types","url":"https://www.amazon.science/blog/the-science-of-price-experiments-in-the-amazon-store","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, causal-inference, random-forest","topic_tags":"pricing-experiments, causal-forests, crossover-design, non-discrimination, tech-industry","summary":"Amazon's approach to price experimentation using crossover designs, random-days methodology, and causal forests to test pricing strategies while maintaining non-discriminatory practices. These methods allow tech companies to experiment with pricing without showing different prices to different users simultaneously. The techniques are essential for large-scale platforms that need to balance revenue optimization with fairness constraints.","use_cases":"Testing promotional pricing strategies across different time periods without user discrimination, Evaluating dynamic pricing algorithms while complying with fair pricing regulations","audience":"Mid-DS, Senior-DS"},{"id":"career-lyft:-causal-forecasting","type":"career","name":"Lyft: Causal Forecasting","description":"DS builds causal models that are both predictive AND causally valid using experiments.","category":"Team Types","url":"https://eng.lyft.com/causal-forecasting-at-lyft-part-1-14cca6ff3d6d","difficulty":"intermediate","prerequisites":"causal-inference, experimental-design, python-scikit-learn","topic_tags":"causal-forecasting, lyft, team-structure, industry-practice, predictive-modeling","summary":"Lyft's data science team develops forecasting models that maintain both predictive accuracy and causal validity through experimental validation. This approach ensures that models can make reliable predictions while also identifying true causal relationships between variables. The methodology combines traditional forecasting techniques with rigorous experimental design to support business decision-making.","use_cases":"Predicting ride demand while understanding causal impact of pricing changes, Forecasting driver supply with ability to measure effects of incentive programs","audience":"Mid-DS, Senior-DS"},{"id":"career-dataroot-labs:-surge-pricing-algorithms","type":"career","name":"DataRoot Labs: Surge Pricing Algorithms","description":"Uber uses LSTM networks; Lyft implements Prime Time (200% increase) and Happy Hour (50% discount).","category":"Team Types","url":"https://datarootlabs.com/blog/uber-lift-gett-surge-pricing-algorithms","difficulty":"intermediate","prerequisites":"LSTM-neural-networks, python-tensorflow, demand-forecasting","topic_tags":"surge-pricing, rideshare-algorithms, dynamic-pricing, LSTM-networks, platform-economics","summary":"Analysis of surge pricing algorithms used by major rideshare companies, comparing Uber's LSTM-based approach with Lyft's Prime Time and Happy Hour pricing strategies. Provides insights into how tech platforms implement dynamic pricing to balance supply and demand in real-time marketplace environments.","use_cases":"Building dynamic pricing systems for marketplace platforms, Analyzing competitor pricing strategies in the sharing economy","audience":"Mid-DS, Junior-DS"},{"id":"career-beyond-winning:-spotify's-experiments-with-learning-framework","type":"career","name":"Beyond Winning: Spotify's Experiments with Learning Framework","description":"Learning rate (64%) exceeds win rate (12%) at mature products. Platform serves ~300 teams. Shows how experimentation platforms measure their own ROI.","category":"Team Types","url":"https://engineering.atspotify.com/2025/09/spotifys-experiments-with-learning-framework/","difficulty":"intermediate","prerequisites":"A-B-testing, statistical-significance, experiment-design","topic_tags":"experimentation-platforms, learning-metrics, spotify-case-study, ROI-measurement, product-experiments","summary":"Spotify's framework for measuring experimentation success beyond traditional win rates, focusing on learning outcomes and platform ROI. Shows how mature product teams can extract value from experiments even when most don't show statistically significant wins. Demonstrates methods for experimentation platforms to quantify their own business impact across hundreds of teams.","use_cases":"Building business case for experimentation platform investment by measuring learning value beyond statistical wins, Designing metrics framework for experimentation team to demonstrate ROI to leadership at scale","audience":"Mid-DS, Senior-DS"},{"id":"career-uber:-xp-experimentation-platform","type":"career","name":"Uber: XP Experimentation Platform","description":"1,000+ experiments at any time. Supports A/B/N tests, causal inference, multi-armed bandits.","category":"Experimentation","url":"https://www.uber.com/blog/xp/","difficulty":"intermediate","prerequisites":"A-B-testing, statistical-significance, python-experimentation","topic_tags":"experimentation-platform, A-B-testing, causal-inference, multi-armed-bandits, tech-industry","summary":"Uber's XP is a large-scale experimentation platform that manages over 1,000 concurrent experiments across the company. It supports A/B/N testing, causal inference methods, and multi-armed bandit algorithms for product optimization. The platform provides infrastructure for running statistically rigorous experiments at scale in a ride-sharing environment.","use_cases":"Setting up A/B tests for new driver incentive programs across different cities, Implementing multi-armed bandit algorithms to optimize dynamic pricing strategies in real-time","audience":"Mid-DS, Senior-DS"},{"id":"career-booking.com:-moving-fast-with-experiments","type":"career","name":"Booking.com: Moving Fast with Experiments","description":"Automated 'circuit breaker' monitors for errors and aborts releases within seconds.","category":"Experimentation","url":"https://medium.com/booking-com-development/moving-fast-breaking-things-and-fixing-them-as-quickly-as-possible-a6c16c5a1185","difficulty":"intermediate","prerequisites":"A-B-testing, statistical-significance, automated-monitoring","topic_tags":"automated-experimentation, circuit-breaker, release-monitoring, booking-case-study, fail-fast","summary":"Booking.com's automated circuit breaker system for A/B tests that monitors key metrics in real-time and automatically stops experiments when statistically significant negative effects are detected. This system allows the company to move faster with experimentation by reducing the risk of prolonged exposure to harmful variants. It's particularly valuable for high-traffic platforms where bad experiments can quickly impact millions of users.","use_cases":"Automatically stopping a checkout flow experiment that's causing conversion drops within minutes, Monitoring homepage redesign tests and killing variants that increase bounce rates before manual review","audience":"Mid-DS, Senior-DS"},{"id":"career-airbnb:-interleaving-experiments","type":"career","name":"Airbnb: Interleaving Experiments","description":"50x sensitivity improvement in search ranking by blending control/treatment for direct comparison.","category":"Experimentation","url":"https://airbnb.tech/data/beyond-a-b-test-speeding-up-airbnb-search-ranking-experimentation-through-interleaving/","difficulty":"intermediate","prerequisites":"a-b-testing, statistical-significance, python-scipy","topic_tags":"interleaving, search-ranking, airbnb, sensitivity-analysis, experimentation","summary":"Interleaving experiments blend control and treatment results in search rankings, allowing direct head-to-head comparison of algorithms. Airbnb achieved 50x sensitivity improvement by showing users results from both variants simultaneously rather than separate A/B buckets. This method is particularly powerful for search, recommendation, and ranking systems where traditional A/B tests lack statistical power.","use_cases":"Testing new search ranking algorithms with limited traffic by comparing click-through rates on interleaved results, Evaluating recommendation system changes when conversion events are rare and traditional A/B tests would take months","audience":"Mid-DS, Senior-DS"},{"id":"career-microsoft:-deep-dive-into-variance-reduction","type":"career","name":"Microsoft: Deep Dive Into Variance Reduction","description":"CUPED introduced 2013; effectively multiplies observed traffic for faster experiments.","category":"Experimentation","url":"https://www.microsoft.com/en-us/research/articles/deep-dive-into-variance-reduction/","difficulty":"intermediate","prerequisites":"A/B-testing, python-pandas, statistical-inference","topic_tags":"variance-reduction, A/B-testing, experimental-design, CUPED, Microsoft","summary":"CUPED (Controlled-experiment Using Pre-Experiment Data) is a variance reduction technique developed at Microsoft that uses pre-experiment user data to reduce noise in A/B test results. By controlling for pre-experiment behavior, it effectively increases statistical power, allowing experiments to detect smaller effects or reach significance faster. This method is widely adopted across tech companies for improving experiment sensitivity.","use_cases":"Reducing experiment runtime by 30-50% while maintaining statistical power for product feature tests, Detecting smaller conversion rate improvements in scenarios where traditional A/B tests would require prohibitively large sample sizes","audience":"Mid-DS, Senior-DS"},{"id":"career-nubank:-cuped-implementation","type":"career","name":"Nubank: CUPED Implementation","description":"40% of metric comparisons had variance reduced by 20%+ after implementing CUPED.","category":"Experimentation","url":"https://building.nubank.com/3-lessons-from-implementing-controlled-experiment-using-pre-experiment-data-cuped-at-nubank/","difficulty":"intermediate","prerequisites":"a-b-testing, variance-reduction, python-pandas","topic_tags":"CUPED, variance-reduction, experimentation, nubank, case-study","summary":"Nubank's implementation of CUPED (Controlled-experiment Using Pre-Experiment Data) for variance reduction in A/B tests. The case study shows how 40% of metric comparisons achieved 20%+ variance reduction, demonstrating practical application of this advanced experimentation technique. Provides real-world evidence of CUPED's effectiveness at scale in fintech.","use_cases":"Reducing noise in A/B tests with high-variance metrics like revenue or engagement, Improving statistical power for experiments in fintech or marketplace environments","audience":"Mid-DS, Senior-DS"},{"id":"career-matteo-courthoud:-cuped-technical-guide","type":"career","name":"Matteo Courthoud: CUPED Technical Guide","description":"CUPED used at Netflix, Booking, Meta, Uber, Airbnb, LinkedIn, DoorDash, Faire.","category":"Experimentation","url":"https://matteocourthoud.github.io/post/cuped/","difficulty":"intermediate","prerequisites":"A-B-testing, python-pandas, variance-reduction","topic_tags":"CUPED, experimentation, variance-reduction, A-B-testing, technical-guide","summary":"CUPED (Controlled-experiment Using Pre-Experiment Data) is a variance reduction technique that uses pre-experiment covariates to increase the statistical power of A/B tests. This technical guide covers implementation details for the method widely adopted by major tech companies like Netflix, Meta, and Uber. It provides practical guidance for data scientists looking to reduce experiment runtime and improve statistical sensitivity.","use_cases":"Reducing A/B test duration by improving statistical power through variance reduction, Implementing CUPED methodology at a tech company to match industry best practices","audience":"Mid-DS, Junior-DS"},{"id":"career-doordash:-switchback-experiment-analysis","type":"career","name":"DoorDash: Switchback Experiment Analysis","description":"Three-sided marketplace needs region-time randomization. Achieved 30% faster experimentation.","category":"Experimentation","url":"https://careersatdoordash.com/blog/experiment-rigor-for-switchback-experiment-analysis/","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, causal-inference, python-pandas","topic_tags":"switchback-experiments, marketplace-analysis, doordash, region-randomization, case-study","summary":"DoorDash's approach to running experiments in a three-sided marketplace (customers, drivers, merchants) using switchback designs with region-time randomization. The methodology addresses network effects and spillovers inherent in marketplace platforms, achieving significantly faster experiment cycles. Provides practical implementation details for similar marketplace experimentation challenges.","use_cases":"Running A/B tests in rideshare or delivery platforms where users interact within geographic regions, Designing experiments for marketplaces where treatment spillover between users makes traditional randomization ineffective","audience":"Mid-DS, Senior-DS"},{"id":"career-linkedin:-detecting-interference-in-a-b-tests","type":"career","name":"LinkedIn: Detecting Interference in A/B Tests","description":"A/B test of A/B tests comparing individual-level vs cluster-based randomization.","category":"Experimentation","url":"https://engineering.linkedin.com/blog/2019/06/detecting-interference--an-a-b-test-of-a-b-tests","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, statistical-hypothesis-testing, network-effects","topic_tags":"interference-detection, cluster-randomization, network-experiments, linkedin-research","summary":"LinkedIn's meta-experiment comparing individual-level versus cluster-based randomization to detect interference in A/B tests. This research demonstrates how to empirically measure spillover effects when treatment of one user affects outcomes for connected users. The methodology provides a practical framework for choosing appropriate randomization strategies in networked environments.","use_cases":"Social media platforms testing features where user interactions create spillover effects, Marketplace experiments where seller treatments affect buyer behavior through network connections","audience":"Mid-DS, Senior-DS"},{"id":"career-lyft:-marketplace-experimentation","type":"career","name":"Lyft: Marketplace Experimentation","description":"Interference-free treatment effect estimators for ridesharing marketplace.","category":"Experimentation","url":"https://eng.lyft.com/experimentation-in-a-ridesharing-marketplace-f75a9c4fcf01","difficulty":"advanced","prerequisites":"randomized-controlled-trials, causal-inference, network-effects","topic_tags":"marketplace-experimentation, interference-effects, two-sided-markets, causal-inference, ridesharing","summary":"Advanced methodology for running experiments in two-sided marketplaces where standard A/B testing fails due to network interference between riders and drivers. Lyft's approach handles spillover effects and provides unbiased treatment effect estimates in interconnected marketplace settings. Essential reading for data scientists working on platform experiments where participants influence each other.","use_cases":"Running pricing experiments in ridesharing without driver spillover effects, Testing matching algorithms in marketplaces while controlling for network interference","audience":"Senior-DS, Mid-DS"},{"id":"career-meta:-cluster-experimentation","type":"career","name":"Meta: Cluster Experimentation","description":"Even 1% cluster purity provides 3x improvement in reducing test interactions.","category":"Experimentation","url":"https://medium.com/@AnalyticsAtMeta/how-meta-tests-products-with-strong-network-effects-96003a056c2c","difficulty":"intermediate","prerequisites":"randomized-controlled-trials, statistical-significance, python-scipy","topic_tags":"cluster-experiments, a-b-testing, causal-inference, experimental-design, meta-research","summary":"Meta's research on cluster experimentation shows how grouping similar units can dramatically reduce interference between test and control groups. The study demonstrates that even minimal cluster purity (1% improvement) can triple the effectiveness of reducing interactions that bias experiment results. This is particularly valuable for large-scale platform experiments where user interactions can contaminate results.","use_cases":"Running A/B tests on social media platforms where users influence each other through network effects, Testing marketplace interventions where buyer-seller interactions could spread treatment effects across groups","audience":"Mid-DS, Senior-DS"},{"id":"career-uber-causalml-package","type":"career","name":"Uber CausalML Package","description":"Open-source uplift modeling and CATE estimation with meta-learners (S, T, X-learner).","category":"Experimentation","url":"https://github.com/uber/causalml","difficulty":"intermediate","prerequisites":"python-scikit-learn, randomized-controlled-trials, treatment-effect-estimation","topic_tags":"uplift-modeling, heterogeneous-treatment-effects, meta-learners, python-package, causal-inference","summary":"Uber's CausalML is an open-source Python package for uplift modeling and conditional average treatment effect (CATE) estimation. It implements meta-learning algorithms like S-learner, T-learner, and X-learner to identify heterogeneous treatment effects across different user segments. Data scientists use it to optimize personalized interventions and targeting strategies in experimentation.","use_cases":"Identifying which customer segments respond best to marketing campaigns or promotions, Personalizing product recommendations by estimating individual-level treatment effects from A/B tests","audience":"Mid-DS, Junior-DS"},{"id":"career-tinuiti:-ghost-ads-explained","type":"career","name":"Tinuiti: Ghost Ads Explained","description":"Google/Amazon 2017: log when ad would show but doesn't, creating cost-free control groups.","category":"Team Types","url":"https://tinuiti.com/blog/measurement/ghost-ads/","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference, digital-advertising","topic_tags":"ghost-ads, incrementality-testing, ad-attribution, control-groups, digital-marketing","summary":"Ghost ads is a method developed by Google and Amazon in 2017 to measure ad incrementality by logging when an ad would have been shown to a user but intentionally not displaying it, creating a cost-free control group. This approach allows advertisers to measure true causal impact by comparing users who saw ads versus those in the ghost ad control group. It's particularly valuable for measuring incremental lift without the cost of traditional holdout testing.","use_cases":"Measuring incremental sales lift from display advertising campaigns without paying for control group impressions, Evaluating the true effectiveness of retargeting campaigns by comparing ghost ad controls to exposed users","audience":"Mid-DS, Senior-DS"},{"id":"career-machine-learning-for-snapchat-ad-ranking","type":"career","name":"Machine Learning for Snapchat Ad Ranking","description":"End-to-end tour of ad systems: eligibility filtering, candidate generation, ML models, auction, feedback loop. Explains budget-split A/B testing for two-sided marketplaces.","category":"Team Types","url":"https://eng.snap.com/machine-learning-snap-ad-ranking","difficulty":"intermediate","prerequisites":"python-scikit-learn, A-B-testing, SQL-joins","topic_tags":"ad-ranking, two-sided-marketplaces, ML-systems, auction-mechanisms, budget-split-testing","summary":"Comprehensive walkthrough of Snapchat's ad ranking system covering the full pipeline from candidate generation through ML scoring to auction mechanics. Includes detailed explanation of budget-split A/B testing methodology specifically designed for two-sided marketplace experiments. Provides practical insights into production ML systems at scale with real-world implementation details.","use_cases":"Building or improving ad ranking systems at social media or marketplace companies, Designing A/B testing frameworks for platforms with both advertisers and users","audience":"Mid-DS, Junior-DS"},{"id":"career-remerge:-incrementality-tests-101","type":"career","name":"Remerge: Incrementality Tests 101","description":"Intent-to-treat vs PSA vs ghost ads vs ghost bids comparison for ad measurement.","category":"Team Types","url":"https://www.remerge.io/findings/blog-post/incrementality-tests-101-intent-to-treat-psa-ghost-ads-and-ghost-bids","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference, digital-advertising","topic_tags":"incrementality-testing, ad-measurement, causal-inference, digital-marketing, experimental-design","summary":"A comprehensive comparison of four major methods for measuring advertising incrementality: intent-to-treat, propensity score analysis, ghost ads, and ghost bids. This guide helps practitioners understand when and how to use each approach for measuring true causal impact of digital advertising campaigns.","use_cases":"Measuring the incremental lift of display advertising campaigns by comparing treatment and control groups, Evaluating the true ROI of programmatic advertising spend by isolating causal effects from correlation","audience":"Mid-DS, Junior-DS"},{"id":"career-meaningful-metrics:-how-data-sharpened-the-focus-of-product-teams","type":"career","name":"Meaningful Metrics: How Data Sharpened the Focus of Product Teams","description":"Markov model segments users into activity states, monitors transition probabilities. CURR identified as highest-leverage metric\u2014drove 4x DAU growth over 3 years.","category":"Team Types","url":"https://blog.duolingo.com/growth-model-duolingo/","difficulty":"intermediate","prerequisites":"markov-chains, user-segmentation, cohort-analysis","topic_tags":"markov-models, user-engagement, product-metrics, growth-strategy, duolingo","summary":"This case study demonstrates how Duolingo used Markov models to segment users into different activity states and track transition probabilities between them. The team identified CURR (Current User Retention Rate) as their highest-leverage metric, which ultimately drove 4x daily active user growth over three years through focused product team efforts.","use_cases":"Product team needs to identify which engagement metric to focus on for maximum user growth impact, Data team wants to model user behavior states and predict transitions between active/inactive periods","audience":"Mid-DS, Senior-DS"},{"id":"career-cxl:-growth-experimentation-culture","type":"career","name":"CXL: Growth Experimentation Culture","description":"Spotify: 75-80% of teams perform experimentation. Discover Weekly validated through experiments.","category":"Team Types","url":"https://cxl.com/blog/growth-experimentation-culture/","difficulty":"beginner","prerequisites":"A-B-testing, hypothesis-testing","topic_tags":"experimentation-culture, growth-teams, spotify-case-study, organizational-design","summary":"A case study examining how Spotify built a culture where 75-80% of teams regularly perform experimentation, including validation of major features like Discover Weekly. Shows how experimentation can become embedded in organizational processes and decision-making across product teams.","use_cases":"Building experimentation capabilities across multiple product teams in a tech organization, Learning how successful companies scale A/B testing culture beyond just growth teams","audience":"Mid-DS, Senior-DS"},{"id":"career-scaling-safety-and-civility-on-roblox","type":"career","name":"Scaling Safety and Civility on Roblox","description":"Moderates content for 71M daily users. 10% of FTEs + $100M+/year on safety. 53% reduction in abuse reports after real-time voice safety.","category":"Team Types","url":"https://corp.roblox.com/newsroom/2024/04/scaling-safety-civility-roblox","difficulty":"intermediate","prerequisites":"content-moderation, machine-learning-operations, A-B-testing","topic_tags":"trust-safety, content-moderation, platform-safety, real-time-systems, abuse-detection","summary":"Case study of Roblox's trust and safety operations, moderating content for 71 million daily users with 10% of workforce and $100M+ annual investment. Demonstrates real-world implementation of safety systems that achieved 53% reduction in abuse reports through real-time voice safety measures.","use_cases":"Understanding resource allocation and team structure for large-scale trust and safety operations, Learning about measuring impact and ROI of safety investments at consumer platforms","audience":"Mid-DS, Senior-DS"},{"id":"career-stripe:-similarity-clustering-for-fraud","type":"career","name":"Stripe: Similarity Clustering for Fraud","description":"Gradient-boosted trees predict account similarity, catching hundreds of fraudulent accounts weekly.","category":"Team Types","url":"https://stripe.com/blog/similarity-clustering","difficulty":"intermediate","prerequisites":"gradient-boosting, clustering-algorithms, feature-engineering","topic_tags":"fraud-detection, similarity-clustering, gradient-boosting, stripe, case-study","summary":"Stripe's fraud detection system uses gradient-boosted trees to identify similar accounts and catch fraudulent behavior at scale. The approach demonstrates how similarity clustering can be operationalized in production to automatically flag suspicious account patterns. This case study shows practical implementation of ML for fraud prevention in a high-stakes financial environment.","use_cases":"Building fraud detection systems for financial platforms, Implementing account similarity scoring for risk assessment","audience":"Mid-DS, Junior-DS"},{"id":"career-stripe:-ml-for-fraud-primer","type":"career","name":"Stripe: ML for Fraud Primer","description":"90% of cards have been seen before, providing rich behavioral data for fraud detection.","category":"Team Types","url":"https://stripe.com/guides/primer-on-machine-learning-for-fraud-protection","difficulty":"beginner","prerequisites":"supervised-learning, feature-engineering, data-preprocessing","topic_tags":"fraud-detection, behavioral-data, payment-systems, risk-modeling, fintech","summary":"A foundational guide to applying machine learning for fraud detection at Stripe, leveraging the fact that 90% of cards have historical transaction data. The primer covers how behavioral patterns and transaction history can be used to build effective fraud detection systems. Essential reading for data scientists entering fintech or payment processing roles.","use_cases":"Building fraud detection models for payment processors using transaction history, Developing behavioral scoring systems for financial risk assessment","audience":"Junior-DS, Curious-browser"},{"id":"career-lyft:-fleet-team-ds","type":"career","name":"Lyft: Fleet Team DS","description":"Setting rental rates, understanding price-demand relationships, fleet allocation through time series.","category":"Team Types","url":"https://eng.lyft.com/data-science-on-lyfts-fleet-team-141c594f656b","difficulty":"intermediate","prerequisites":"python-pandas, time-series-forecasting, price-elasticity-modeling","topic_tags":"fleet-management, pricing-optimization, time-series, marketplace-dynamics, demand-forecasting","summary":"Overview of data science work on Lyft's Fleet Team, focusing on rental car pricing strategies and allocation optimization. The role involves analyzing price-demand relationships to set optimal rental rates and using time series methods to forecast fleet needs across different markets and time periods. Critical for understanding how marketplace platforms balance supply and demand through dynamic pricing.","use_cases":"Determining optimal rental car prices during peak demand periods like holidays or events, Forecasting how many vehicles to allocate to different cities based on seasonal demand patterns","audience":"Mid-DS, Junior-DS"},{"id":"career-instacart-anytime:-a-data-science-paradigm","type":"career","name":"Instacart Anytime: A Data Science Paradigm","description":"Maps Shopper Staffing across Marketplace Forecasting, Supply Planning, Real-time Capacity. Shows how forecasts feed downstream decision systems.","category":"Team Types","url":"https://tech.instacart.com/instacart-anytime-a-data-science-paradigm-33eb25a5c32d","difficulty":"intermediate","prerequisites":"demand-forecasting, supply-chain-optimization, operations-research","topic_tags":"marketplace-design, demand-forecasting, supply-planning, real-time-systems, instacart","summary":"A comprehensive case study of Instacart's data science approach to shopper staffing, connecting marketplace forecasting to supply planning and real-time capacity management. Shows how predictive models feed into operational decision systems across the entire shopper lifecycle. Valuable for understanding how data science integrates across business functions in marketplace platforms.","use_cases":"Building integrated forecasting systems that connect demand prediction to workforce planning, Designing real-time capacity allocation systems for marketplace platforms","audience":"Mid-DS, Senior-DS"},{"id":"career-uber-orbit:-bayesian-time-series","type":"career","name":"Uber Orbit: Bayesian Time Series","description":"Open-source tool for KPI decomposition into trend, seasonality, and marketing effects.","category":"Team Types","url":"https://www.uber.com/blog/orbit/","difficulty":"intermediate","prerequisites":"python-statsmodels, bayesian-inference, time-series-decomposition","topic_tags":"bayesian-forecasting, kpi-decomposition, marketing-attribution, time-series, open-source-tools","summary":"Uber Orbit is an open-source Bayesian time series forecasting package that decomposes KPIs into interpretable components like trend, seasonality, and marketing effects. It's designed for data scientists who need to understand the drivers behind business metrics and make forecasts with uncertainty quantification. The tool is particularly valuable for marketing mix modeling and attribution analysis in tech companies.","use_cases":"Decomposing e-commerce revenue to measure impact of marketing campaigns vs seasonal trends, Forecasting app user growth while accounting for product launches and external events","audience":"Mid-DS, Senior-DS"},{"id":"career-uber:-lstm-for-extreme-events","type":"career","name":"Uber: LSTM for Extreme Events","description":"Neural networks handle NYE, concerts, and weather across 600+ cities.","category":"Team Types","url":"https://www.uber.com/blog/neural-networks/","difficulty":"intermediate","prerequisites":"python-tensorflow, time-series-analysis, feature-engineering","topic_tags":"lstm, demand-forecasting, neural-networks, time-series, extreme-events","summary":"Uber's approach to handling demand forecasting during extreme events like New Year's Eve, concerts, and severe weather using LSTM neural networks across their global platform. The system addresses the challenge of predicting demand spikes that traditional forecasting methods struggle with due to their irregular and context-dependent nature. This case study demonstrates how deep learning can be applied to real-world operational challenges at massive scale.","use_cases":"Predicting rideshare demand during major events or weather disruptions, Forecasting resource needs for logistics during irregular high-demand periods","audience":"Mid-DS, Senior-DS"},{"id":"career-uber-omphalos:-backtesting-infrastructure","type":"career","name":"Uber Omphalos: Backtesting Infrastructure","description":"Infrastructure for comparing forecasting models across millions of time series.","category":"Team Types","url":"https://www.uber.com/blog/omphalos/","difficulty":"intermediate","prerequisites":"time-series-forecasting, python-pandas, model-evaluation-metrics","topic_tags":"backtesting, forecasting-infrastructure, model-comparison, time-series, engineering","summary":"Uber's Omphalos is a scalable infrastructure system designed to backtest and compare forecasting models across millions of time series simultaneously. It enables data scientists to systematically evaluate model performance using standardized metrics and workflows. The platform streamlines the process of selecting optimal forecasting approaches for large-scale production systems.","use_cases":"Comparing ARIMA vs Prophet vs neural network models across all city-marketplace combinations for demand forecasting, Evaluating new feature engineering approaches against baseline models for driver supply prediction across different time horizons","audience":"Mid-DS, Senior-DS"},{"id":"career-meta:-how-ds-lead-and-drive-impact","type":"career","name":"Meta: How DS Lead and Drive Impact","description":"Fully embedded model: DS 1-to-1 with PMs, accountable for product outcomes.","category":"Role Landscape","url":"https://medium.com/@AnalyticsAtMeta/how-data-scientists-lead-and-drive-impact-at-meta-6b5b896821b2","difficulty":"intermediate","prerequisites":"product-analytics, stakeholder-management, A-B-testing","topic_tags":"data-science-leadership, product-management, organizational-design, tech-industry, career-growth","summary":"Meta's fully embedded data science model where DS professionals work 1-to-1 with product managers and are directly accountable for product outcomes. This structure integrates data scientists deeply into product decision-making rather than treating them as a separate support function. The model emphasizes ownership, impact measurement, and close collaboration with product teams.","use_cases":"Understanding how to structure DS teams for maximum product impact when designing organizational hierarchies, Preparing for DS leadership roles that require direct accountability for business metrics and product success","audience":"Mid-DS, Senior-DS"},{"id":"career-candor:-meta-ds-roles-guide","type":"career","name":"Candor: Meta DS Roles Guide","description":"Core Data Science is distinct R&D team developing novel methods, separate from embedded analytics.","category":"Role Landscape","url":"https://candor.co/articles/interview-prep/data-science-roles-at-facebook-what-they-are-and-how-to-get-one","difficulty":"beginner","prerequisites":"data-science-fundamentals, career-planning","topic_tags":"career-guidance, meta, data-science-roles, job-search, tech-companies","summary":"Guide explaining Meta's Core Data Science (CDS) team structure and roles, distinguishing between research-focused CDS positions and embedded analytics roles. Provides insights into Meta's unique organizational approach to data science career paths. Useful for understanding how major tech companies structure their data science organizations.","use_cases":"Preparing for Meta data science interviews and understanding role expectations, Comparing data science career paths at different types of tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-microsoft:-designing-ds-organization","type":"career","name":"Microsoft: Designing DS Organization","description":"Centralized DS for career paths with peers, scaled processes, end-to-end perspective.","category":"Role Landscape","url":"https://medium.com/data-science-at-microsoft/designing-a-data-science-organization-ab53a80b1d15","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"organizational-design, data-science-careers, team-structure, microsoft, centralized-analytics","summary":"Microsoft's approach to organizing data science teams through centralized structures that provide clear career progression, standardized processes, and comprehensive project ownership. This organizational model helps data scientists develop expertise while maintaining connection to business impact and peer learning opportunities.","use_cases":"Designing the structure of a new data science organization at a growing tech company, Restructuring an existing analytics team to improve career development and project outcomes","audience":"Senior-DS, Mid-DS"},{"id":"career-shanif-dhanani:-embedded-vs-centralized","type":"career","name":"Shanif Dhanani: Embedded vs Centralized","description":"Hybrid recommended: centralized management with embedded deployment.","category":"Role Landscape","url":"https://medium.com/@shanif/embedded-vs-centralized-data-science-teams-3035db6803b2","difficulty":"beginner","prerequisites":"team-management-basics, organizational-design","topic_tags":"data-science-organization, team-structure, management-strategy, embedded-teams, centralized-teams","summary":"Shanif Dhanani discusses the trade-offs between embedded and centralized data science team structures, recommending a hybrid approach. The model combines centralized management for consistency and career development with embedded deployment for domain expertise and stakeholder alignment. This framework helps organizations balance technical excellence with business impact.","use_cases":"Designing data science team structure for a growing tech company, Reorganizing existing DS teams to improve business alignment while maintaining technical standards","audience":"Mid-DS, Senior-DS"},{"id":"career-dbt-labs:-centralized-vs-decentralized","type":"career","name":"dbt Labs: Centralized vs Decentralized","description":"Most companies evolve through multiple organizational models as they scale.","category":"Role Landscape","url":"https://www.getdbt.com/data-teams/centralized-vs-decentralized/","difficulty":"beginner","prerequisites":"basic-management-concepts, organizational-design","topic_tags":"organizational-structure, scaling, team-management, data-teams, career-development","summary":"This content explores how data organizations at companies like dbt Labs transition between centralized and decentralized structures as they grow. It covers the trade-offs, timing, and practical considerations for different organizational models. Essential reading for understanding how data teams evolve and where career opportunities emerge at different company stages.","use_cases":"Deciding whether to join a centralized data science team or embedded analytics role, Planning career progression as your company's data organization restructures","audience":"Junior-DS, Mid-DS"},{"id":"career-stitch-fix-algorithms-tour","type":"career","name":"Stitch Fix Algorithms Tour","description":"Interactive visual tour of 10 algorithmic applications. Covers exploration vs exploitation, cold-start problems, human-in-the-loop stylist collaboration.","category":"Team Types","url":"https://algorithms-tour.stitchfix.com/","difficulty":"beginner","prerequisites":"basic-statistics, recommendation-systems-concepts","topic_tags":"recommendations, cold-start, exploration-exploitation, human-in-the-loop, interactive-tutorial","summary":"An interactive visual walkthrough of 10 real algorithmic applications used at Stitch Fix for personalized fashion recommendations. Covers key challenges like balancing exploration vs exploitation, solving cold-start problems for new customers, and integrating human stylists with algorithmic recommendations. Provides accessible introduction to applied recommendation systems in e-commerce.","use_cases":"Learning how recommendation algorithms work in practice at a major tech company, Understanding how to combine human expertise with algorithmic decision-making in product recommendations","audience":"Junior-DS, Curious-browser"},{"id":"career-netflix:-recommendations-research","type":"career","name":"Netflix: Recommendations Research","description":"80%+ of content discovered through recommendations, 20 years of refinement by hundreds of engineers.","category":"Team Types","url":"https://research.netflix.com/research-area/recommendations","difficulty":"beginner","prerequisites":"collaborative-filtering, matrix-factorization, A-B-testing","topic_tags":"recommendations, netflix, career-insights, team-structure, product-impact","summary":"Netflix's recommendation system drives 80%+ of content discovery on their platform, representing one of the most successful applied ML systems at scale. This content explores how Netflix's recommendations team operates, their research priorities, and career paths within recommendation systems. It provides insights into building and scaling recommendation systems that directly impact business metrics and user engagement.","use_cases":"Understanding how to structure a recommendations team and research priorities when building recommendation systems at scale, Learning about career progression and skill development paths for data scientists working on recommendation systems","audience":"Junior-DS, Curious-browser"},{"id":"career-athey-&-imbens:-ml-methods-for-economists","type":"career","name":"Athey & Imbens: ML Methods for Economists","description":"ML optimizes prediction; economics focuses on causal inference. Bridging both fields.","category":"ML Fundamentals","url":"https://www.annualreviews.org/doi/abs/10.1146/annurev-economics-080217-053433","difficulty":"intermediate","prerequisites":"basic-econometrics, supervised-learning, causal-inference","topic_tags":"machine-learning, causal-inference, econometrics, prediction-vs-causation, methodology","summary":"Athey and Imbens explore how machine learning methods can be integrated with economic research, highlighting the fundamental difference between ML's prediction focus and economics' causal inference goals. This foundational work shows how economists can leverage ML tools while maintaining rigorous causal identification. Essential reading for understanding when and how to apply ML methods in economic analysis.","use_cases":"Using regularized regression for high-dimensional treatment effect estimation, Applying tree-based methods to identify heterogeneous treatment effects in randomized experiments","audience":"Early-PhD, Mid-DS"},{"id":"career-susan-athey:-ml-short-course","type":"career","name":"Susan Athey: ML Short Course","description":"Free Stanford materials bridging ML and economics methods.","category":"ML Fundamentals","url":"https://www.gsb.stanford.edu/faculty-research/labs-initiatives/sil/research/methods/ai-machine-learning/short-course","difficulty":"beginner","prerequisites":"basic-python, linear-regression, probability-theory","topic_tags":"machine-learning, causal-inference, stanford-course, econometrics, applied-methods","summary":"Susan Athey's Stanford short course providing foundational materials that bridge machine learning techniques with economic methods and causal inference. The free course materials are designed for economists learning ML and data scientists wanting to understand economic applications. Covers key concepts like prediction vs. causal inference, treatment effect estimation, and ML methods for policy evaluation.","use_cases":"Learning how to apply ML methods for causal inference in tech product experiments, Understanding when to use prediction models vs. causal models for business decision-making","audience":"Early-PhD, Junior-DS"},{"id":"career-matt-sosna:-academia-to-data-science","type":"career","name":"Matt Sosna: Academia to Data Science","description":"Key gaps: implementing analysis results (not just generating), SWE for production, team vs personal output.","category":"PhD Transition","url":"https://towardsdatascience.com/transitioning-to-data-science-from-academia-93299602e4ba/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"career-transition, academia-to-industry, phd-skills, data-science-careers","summary":"Matt Sosna shares insights on transitioning from academia to data science, highlighting critical skill gaps that PhDs often face. He emphasizes the difference between generating analysis results versus implementing them in production systems, the importance of software engineering practices, and shifting from individual to team-based output metrics.","use_cases":"PhD student or postdoc preparing for industry data science interviews and wanting to understand what skills to develop, Recent PhD graduate in their first data science role struggling with production implementation and team collaboration","audience":"Early-PhD, Junior-DS"},{"id":"career-microsoft-experimentation-platform","type":"career","name":"Microsoft Experimentation Platform","description":"Technical and cultural challenges of A/B testing at scale. Companies run 20,000+ experiments/year.","category":"Experimentation","url":"https://exp-platform.com/","difficulty":"intermediate","prerequisites":"A-B-testing-fundamentals, statistical-significance, SQL-queries","topic_tags":"A-B-testing, experimentation-platform, infrastructure, microsoft, scale","summary":"Microsoft's approach to building and operating a large-scale experimentation platform that handles thousands of concurrent A/B tests. Covers technical infrastructure challenges like metric computation, statistical power, and data pipelines, plus organizational challenges like experiment governance and culture building. Essential reading for understanding how major tech companies operationalize experimentation at scale.","use_cases":"Building or scaling an experimentation platform at a tech company with thousands of experiments per year, Understanding organizational best practices for A/B testing governance and culture in large engineering teams","audience":"Mid-DS, Senior-DS"},{"id":"career-doing-data-science-at-uber","type":"career","name":"Doing Data Science at Uber","description":"Profile of hybrid DS/SWE role at Uber. Describes the expectations and work.","category":"Role Landscape","url":"https://www.uber.com/blog/data-science-engineering/","difficulty":"beginner","prerequisites":"python-programming, SQL-queries, basic-statistics","topic_tags":"uber, data-science-roles, tech-careers, role-expectations, industry-profile","summary":"This profile describes the hybrid data scientist/software engineer role at Uber, outlining daily responsibilities and expectations. It provides insight into how data science work is structured at a major tech platform company. The content helps readers understand the blend of technical analysis and engineering skills required in modern DS roles.","use_cases":"Evaluating whether to apply for a DS position at Uber or similar ride-sharing companies, Understanding what skills to develop for hybrid DS/SWE roles at tech platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-building-uber's-ds-platforms","type":"career","name":"Building Uber's DS Platforms","description":"Director-level perspective on democratizing data science at scale.","category":"Team Types","url":"https://www.uber.com/blog/building-ubers-data-science-platforms/","difficulty":"intermediate","prerequisites":"SQL-queries, python-jupyter, experimentation-design","topic_tags":"data-platforms, team-scaling, infrastructure, democratization, leadership","summary":"Director-level insights on building data science platforms that enable non-technical teams to access analytics and run experiments independently. Covers infrastructure decisions, tooling choices, and organizational strategies for scaling data science capabilities across large tech organizations. Provides strategic perspective on balancing self-service accessibility with data quality and governance.","use_cases":"Planning infrastructure roadmap for growing data science team, Deciding between build vs buy for internal analytics platforms","audience":"Mid-DS, Senior-DS"},{"id":"career-uber-data-science-workbench","type":"career","name":"Uber Data Science Workbench","description":"Platform used for pricing, safety, fraud detection. End-to-end DS workflow.","category":"Team Types","url":"https://www.uber.com/blog/dsw/","difficulty":"intermediate","prerequisites":"python-pandas, SQL-queries, AB-testing","topic_tags":"data-platform, workflow-tools, uber, experimentation, production-systems","summary":"Uber's internal data science platform that supports the full DS lifecycle from experimentation to production deployment. The platform handles critical business functions including dynamic pricing algorithms, safety monitoring systems, and fraud detection models. It provides integrated tools for data analysis, model development, and automated deployment at Uber's scale.","use_cases":"Building and deploying surge pricing models that adjust rates based on real-time supply and demand, Developing fraud detection systems that monitor transactions and flag suspicious rider or driver behavior","audience":"Mid-DS, Senior-DS"},{"id":"career-netflix-ds-and-engineering-team","type":"career","name":"Netflix DS and Engineering Team","description":"Team overview: data science at the center of Netflix's product decisions.","category":"Role Landscape","url":"https://jobs.netflix.com/teams/data-science-and-engineering","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"netflix, data-science-teams, tech-careers, team-structure, role-landscape","summary":"Overview of Netflix's data science and engineering team structure, highlighting how data science is positioned at the center of product decision-making. Provides insights into team organization, roles, and how data scientists collaborate with engineering teams at one of the world's leading streaming platforms.","use_cases":"Understanding how data science teams are structured at major tech companies when considering career moves, Learning about the intersection of data science and product decisions in streaming/entertainment industry","audience":"Junior-DS, Curious-browser"},{"id":"career-netflix:-experimentation-focus","type":"career","name":"Netflix: Experimentation Focus","description":"Experimentation is a major focus of data science across Netflix.","category":"Experimentation","url":"https://netflixtechblog.com/experimentation-is-a-major-focus-of-data-science-across-netflix-f67923f8e985","difficulty":"beginner","prerequisites":"a-b-testing, statistical-significance, python-pandas","topic_tags":"netflix-culture, experimentation-practice, data-science-careers, tech-industry, ab-testing","summary":"Netflix places experimentation at the core of its data science practice, using A/B tests and causal inference to drive product decisions. Data scientists at Netflix design and analyze experiments across streaming recommendations, user interface changes, and content optimization. This career-focused content explores how experimentation shapes the data science role and culture at one of tech's most data-driven companies.","use_cases":"Understanding how experimentation skills are valued at major tech companies, Learning about data science career paths focused on causal inference and experimentation","audience":"Junior-DS, Curious-browser"},{"id":"career-netflix-ml-systems-(metaflow)","type":"career","name":"Netflix ML Systems (Metaflow)","description":"Supporting diverse ML systems with the Metaflow ecosystem.","category":"Team Types","url":"https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d","difficulty":"intermediate","prerequisites":"python-programming, docker-containers, ML-model-deployment","topic_tags":"metaflow, ML-infrastructure, netflix-engineering, workflow-orchestration, production-ML","summary":"Netflix's Metaflow is an open-source framework for building and managing ML workflows at scale. It provides infrastructure for data scientists to prototype locally and seamlessly deploy to production without DevOps expertise. The ecosystem supports experiment tracking, versioning, and orchestration across diverse ML use cases.","use_cases":"Transitioning from ML prototypes to production systems without infrastructure overhead, Building reproducible ML pipelines that can run locally during development and scale to cloud resources","audience":"Mid-DS, Junior-DS"},{"id":"career-airbnb-data-university","type":"career","name":"Airbnb Data University","description":"Internal training program with 30+ classes democratizing data science.","category":"Role Landscape","url":"https://medium.com/airbnb-engineering/how-airbnb-democratizes-data-science-with-data-university-3eccc71e073a","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"data-science-training, corporate-education, airbnb, skills-development, internal-programs","summary":"Airbnb's internal Data University is a comprehensive training program featuring 30+ classes designed to democratize data science knowledge across the company. The program covers foundational to advanced topics, making data science accessible to employees regardless of their technical background. It represents a best practice in corporate data science education and workforce development.","use_cases":"Learning how tech companies structure internal data science training programs, Understanding corporate approaches to democratizing data literacy and analytical skills","audience":"Junior-DS, Curious-browser"},{"id":"career-meta:-building-ds-teams-at-scale","type":"career","name":"Meta: Building DS Teams at Scale","description":"Organizational structure for data science teams with impact at scale.","category":"Team Types","url":"https://engineering.fb.com/2018/06/12/core-infra/building-data-science-teams-to-have-an-impact-at-scale/","difficulty":"intermediate","prerequisites":"sql-joins, a-b-testing, python-data-analysis","topic_tags":"team-structure, organizational-design, data-science-management, scaling-teams, meta","summary":"Meta's approach to structuring data science teams for maximum impact across large-scale products and services. Covers organizational patterns, team composition, and governance structures that enable DS teams to operate effectively in fast-paced tech environments. Provides frameworks for scaling analytical capabilities while maintaining quality and alignment with business objectives.","use_cases":"Building your first data science team at a growing startup, Restructuring an existing analytics organization to improve cross-functional collaboration","audience":"Mid-DS, Senior-DS"},{"id":"career-google-research-careers","type":"career","name":"Google Research Careers","description":"Research environment with focus on product impact at Google.","category":"Role Landscape","url":"https://research.google/careers/","difficulty":"beginner","prerequisites":"python-programming, statistics-fundamentals","topic_tags":"google-research, tech-careers, research-roles, product-impact, industry-research","summary":"Google Research combines academic-style research with direct product applications across AI, machine learning, and computer science. Researchers work on both foundational problems and technologies that can be deployed in Google's products. The environment offers access to large-scale data and computing resources while maintaining publication freedom.","use_cases":"PhD considering transition from academia to industry research with product impact, Data scientist exploring research career paths at major tech companies","audience":"Early-PhD, Curious-browser"},{"id":"career-eppo-documentation","type":"career","name":"Eppo Documentation","description":"CUPED++ with post-stratification, Bayesian/frequentist approaches, sequential testing, clustered experiments, switchback experiments. Written by ex-Airbnb data scientists. Replaces Kohavi's A/B testing book.","category":"Experimentation","url":"https://docs.geteppo.com/","difficulty":"intermediate","prerequisites":"statistical-hypothesis-testing, python-pandas, experimental-design","topic_tags":"A-B-testing, CUPED, variance-reduction, sequential-testing, experiment-design","summary":"Comprehensive documentation covering advanced A/B testing methodologies including CUPED++ for variance reduction, post-stratification techniques, and sequential testing approaches. Written by experienced Airbnb data scientists, this resource provides both theoretical foundations and practical implementation guidance for modern experimentation. Serves as a contemporary replacement for traditional A/B testing textbooks with cutting-edge industry practices.","use_cases":"Reducing variance in product experiment measurements using historical user data, Implementing sequential testing to stop experiments early while controlling false discovery rates","audience":"Mid-DS, Senior-DS"},{"id":"career-statsig-docs-+-blog","type":"career","name":"Statsig Docs + Blog","description":"CUPED with math derivations, sequential testing (mSPRT), Bayesian experiments, winsorization, power analysis. Facebook-level statistical rigor. Free sample size calculators.","category":"Experimentation","url":"https://docs.statsig.com/","difficulty":"intermediate","prerequisites":"python-statistics, hypothesis-testing, A/B-test-fundamentals","topic_tags":"CUPED, sequential-testing, bayesian-experiments, power-analysis, variance-reduction","summary":"Statsig's documentation and blog provide comprehensive guides to advanced experimentation methods including CUPED for variance reduction, sequential testing with mSPRT, and Bayesian experimental design. The content includes mathematical derivations and practical implementation details used at Facebook scale. Features free calculators and tools for sample size planning and statistical power analysis.","use_cases":"Reducing experiment runtime by 30-50% using CUPED variance reduction techniques, Implementing sequential testing to stop experiments early when statistical significance is reached","audience":"Mid-DS, Senior-DS"},{"id":"career-netflix-tech-blog:-experimentation","type":"career","name":"Netflix Tech Blog: Experimentation","description":"Platform architecture, organizational culture, causal inference, contextual bandits. Real case studies from thousands of annual experiments. Covers cultural aspects missing from technical resources.","category":"Experimentation","url":"https://netflixtechblog.com/tagged/experimentation","difficulty":"intermediate","prerequisites":"a-b-testing, python-pandas, basic-statistics","topic_tags":"experimentation-platform, causal-inference, organizational-design, tech-industry, case-studies","summary":"Netflix's comprehensive guide to running experimentation at scale, covering both technical platform architecture and organizational culture. Provides real-world case studies from their thousands of annual experiments, including advanced topics like contextual bandits and causal inference applications. Uniquely focuses on the cultural and process aspects of experimentation that are often missing from purely technical resources.","use_cases":"Building experimentation infrastructure and processes at a tech company, Understanding how to scale A/B testing culture across engineering and product teams","audience":"Mid-DS, Senior-DS"},{"id":"career-khangich-machine-learning-interview","type":"career","name":"khangich/machine-learning-interview","description":"100+ curated questions: bias-variance, regularization, neural networks, backprop, CNNs, RNNs. 11.6k GitHub stars. Includes ML system design cases: YouTube recs, LinkedIn feed, ad CTR. Author received NVIDIA, Microsoft, Amazon offers.","category":"ML Fundamentals","url":"https://github.com/khangich/machine-learning-interview","difficulty":"intermediate","prerequisites":"supervised-learning-basics, gradient-descent, neural-network-fundamentals","topic_tags":"interview-prep, ml-fundamentals, system-design, faang-prep, technical-questions","summary":"A comprehensive collection of 100+ machine learning interview questions covering core concepts like bias-variance tradeoff, regularization, and deep learning architectures. The repository includes both theoretical questions and practical ML system design cases for major tech companies like YouTube recommendations and LinkedIn feed ranking.","use_cases":"Preparing for machine learning engineer or data scientist interviews at major tech companies, Self-assessment and knowledge gaps identification for mid-level ML practitioners","audience":"Junior-DS, Mid-DS"},{"id":"career-alirezadir-machine-learning-interviews","type":"career","name":"alirezadir/Machine-Learning-Interviews","description":"6 structured chapters: algorithms, ML coding, fundamentals, system design, behavioral. Updated 2025 with Agentic AI chapter. Author received offers from Meta, Google, Amazon, Apple. MIT licensed.","category":"ML Fundamentals","url":"https://github.com/alirezadir/Machine-Learning-Interviews","difficulty":"intermediate","prerequisites":"python-programming, supervised-learning-algorithms, basic-statistics","topic_tags":"interview-prep, ml-algorithms, system-design, coding-practice, behavioral-interviews","summary":"Comprehensive ML interview preparation guide with 6 structured chapters covering algorithms, coding, fundamentals, system design, and behavioral questions. Recently updated for 2025 with new Agentic AI content, authored by someone who successfully landed offers at major tech companies.","use_cases":"Preparing for machine learning engineer interviews at FAANG companies, Systematic review of ML concepts and coding skills before job transitions","audience":"Junior-DS, Mid-DS"},{"id":"career-chip-huyen's-ml-interviews-(free!)","type":"career","name":"Chip Huyen's ML Interviews (Free!)","description":"200+ questions across math, CS, ML workflows, algorithms. Difficulty tagged. 30 systems design questions. Companion answers at github.com/zafstojano/ml-interview-questions-and-answers. The book is FREE online.","category":"ML Fundamentals","url":"https://huyenchip.com/ml-interviews-book/","difficulty":"intermediate","prerequisites":"python-basics, linear-algebra, supervised-learning","topic_tags":"interview-prep, ml-fundamentals, systems-design, career-development, free-resource","summary":"Comprehensive collection of 200+ machine learning interview questions covering mathematical foundations, computer science concepts, ML workflows, and algorithms with difficulty ratings. Includes 30 systems design questions and is freely available online with companion answer repository on GitHub.","use_cases":"Preparing for ML engineer or data scientist job interviews at tech companies, Self-assessment and knowledge gap identification for ML practitioners transitioning roles","audience":"Junior-DS, Mid-DS"},{"id":"career-made-with-ml","type":"career","name":"Made With ML","description":"47 free lessons covering complete ML lifecycle: product design, data prep, feature engineering, training, serving, monitoring, CI/CD, testing. 30k GitHub stars. Includes working code from laptop to distributed cluster.","category":"ML System Design","url":"https://madewithml.com/courses/mlops/","difficulty":"intermediate","prerequisites":"python-programming, docker-containers, git-version-control","topic_tags":"MLOps, ML-lifecycle, production-ML, system-design, tutorial","summary":"Comprehensive free course covering the entire ML lifecycle from product design to production deployment and monitoring. Provides hands-on experience with industry-standard MLOps practices including CI/CD, testing, and scaling from local development to distributed systems. Popular resource with 30k GitHub stars offering practical code examples and best practices.","use_cases":"Junior DS learning to deploy first ML model to production, Mid-level DS setting up MLOps pipeline for A/B testing platform","audience":"Junior-DS, Mid-DS"},{"id":"career-eugene-yan's-blog-+-applied-ml","type":"career","name":"Eugene Yan's Blog + Applied ML","description":"Amazon Principal Applied Scientist. Deep articles on feature stores, real-time retrieval, ML testing. His applied-ml repo has 600+ curated papers from Netflix, Spotify, Pinterest. Co-authored 'A Year of Building with LLMs' (O'Reilly).","category":"ML System Design","url":"https://eugeneyan.com/start-here/","difficulty":"intermediate","prerequisites":"python-scikit-learn, A-B-testing, docker-containers","topic_tags":"ml-systems, feature-stores, real-time-ml, production-deployment, curated-papers","summary":"Eugene Yan's comprehensive blog and applied-ml repository containing 600+ curated papers from major tech companies on ML system design. Features deep dives into production ML topics like feature stores, real-time retrieval, and ML testing. Essential resource for understanding how Netflix, Spotify, and Pinterest implement ML at scale.","use_cases":"Building production ML pipelines at tech companies, Learning how to design feature stores and real-time recommendation systems","audience":"Mid-DS, Senior-DS"},{"id":"career-stanford-cs-329s-materials","type":"career","name":"Stanford CS 329S Materials","description":"Same author as Chip Huyen's book, same content. Free lecture notes: ML production, training data, feature engineering, deployment, monitoring. Guest tutorials from Made With ML, Stitch Fix. 24 final project demos on YouTube.","category":"ML System Design","url":"https://stanford-cs329s.github.io/syllabus.html","difficulty":"intermediate","prerequisites":"python-scikit-learn, docker-basics, model-evaluation-metrics","topic_tags":"ml-systems, model-deployment, production-ml, feature-engineering, ml-monitoring","summary":"Free Stanford course materials covering the full ML production pipeline from data processing to model monitoring. Created by Chip Huyen, these lecture notes provide practical guidance on feature engineering, model deployment, and system design with real-world examples from industry practitioners. Includes 24 student project demos showcasing end-to-end ML applications.","use_cases":"Learning how to deploy your first ML model to production at a tech company, Understanding best practices for monitoring ML models in production systems","audience":"Junior-DS, Mid-DS"},{"id":"career-hello-interview:-ml-system-design","type":"career","name":"Hello Interview: ML System Design","description":"6-step framework with timing recommendations. Free worked examples: Video Recommendations, Harmful Content Detection, Bot Detection. Written by former Meta and Amazon hiring managers.","category":"ML System Design","url":"https://www.hellointerview.com/learn/ml-system-design/in-a-hurry/introduction","difficulty":"intermediate","prerequisites":"python-scikit-learn, SQL-joins, distributed-computing-basics","topic_tags":"system-design, ml-interviews, scalable-ml, architecture, career-prep","summary":"A structured 6-step framework for tackling machine learning system design interviews, created by former FAANG hiring managers. Includes timing recommendations and three complete worked examples covering recommendation systems, content moderation, and fraud detection. Specifically designed to help candidates systematically approach complex ML architecture questions in technical interviews.","use_cases":"Preparing for senior data scientist or ML engineer interviews at major tech companies, Learning how to design production ML systems that handle millions of users","audience":"Mid-DS, Senior-DS"},{"id":"career-khangich:-ml-system-design-cases","type":"career","name":"khangich: ML System Design Cases","description":"6 complete ML system design cases: YouTube recommendations, LinkedIn feed ranking, ad click prediction, delivery time estimation, Airbnb search ranking. Links to source company engineering blogs.","category":"ML System Design","url":"https://github.com/khangich/machine-learning-interview#ml-system-design","difficulty":"intermediate","prerequisites":"supervised-learning, feature-engineering, system-architecture","topic_tags":"system-design, ml-engineering, case-studies, production-ml, tech-companies","summary":"Six real-world ML system design case studies from major tech companies including YouTube, LinkedIn, and Airbnb. Each case walks through the complete system architecture, feature engineering, model selection, and scaling decisions with links to original engineering blog posts. Perfect for understanding how ML systems work in production at scale.","use_cases":"Preparing for ML system design interviews at tech companies, Learning how to architect production ML systems by studying real implementations","audience":"Mid-DS, Junior-DS"},{"id":"career-alirezadir:-9-step-ml-design-formula","type":"career","name":"alirezadir: 9-Step ML Design Formula","description":"Structured 9-step formula: problem clarification, data requirements, ML objective, offline/online metrics, feature engineering, candidate generation \u2192 ranking \u2192 filters, training data, architecture, serving/deployment.","category":"ML System Design","url":"https://github.com/alirezadir/Machine-Learning-Interviews#ml-system-design","difficulty":"beginner","prerequisites":"python-scikit-learn, pandas-dataframes, supervised-learning","topic_tags":"ml-system-design, production-ml, framework, interview-prep, end-to-end-ml","summary":"A comprehensive 9-step framework for designing machine learning systems from problem definition to deployment. Covers the full ML lifecycle including data requirements, metrics selection, feature engineering, model architecture, and serving considerations. Particularly valuable for structuring ML system design interviews and real-world project planning.","use_cases":"Preparing for ML system design interviews at tech companies, Planning end-to-end ML projects from requirements gathering to production deployment","audience":"Junior-DS, Mid-DS"},{"id":"career-datalemur-(same-author-as-book!)","type":"career","name":"DataLemur (Same Author as Book!)","description":"100+ free practice questions: SQL, Python, statistics, ML, probability. Same author as 'Ace the Data Science Interview'. 60+ SQL from FAANG with solutions. Interactive PostgreSQL environment. Free 9-day crash course.","category":"SQL & Data","url":"https://datalemur.com","difficulty":"beginner","prerequisites":"basic-SQL, python-fundamentals","topic_tags":"interview-prep, SQL-practice, coding-challenges, career-development, interactive-learning","summary":"DataLemur provides 100+ free practice questions covering SQL, Python, statistics, ML, and probability, created by the author of 'Ace the Data Science Interview'. Features 60+ real SQL problems from FAANG companies with solutions in an interactive PostgreSQL environment. Includes a free 9-day crash course for structured learning.","use_cases":"Preparing for data science interviews at tech companies, Practicing SQL skills with real FAANG interview questions","audience":"Junior-DS, Early-PhD"},{"id":"career-rbhatia46-data-science-interview-resources","type":"career","name":"rbhatia46/Data-Science-Interview-Resources","description":"200+ curated links: probability/stats (40+ questions), SQL, ML algorithms, real case studies, FAANG-specific prep, deep learning (40+ questions), NLP (30+ questions), Spark (55+ questions), GenAI topics.","category":"SQL & Data","url":"https://github.com/rbhatia46/Data-Science-Interview-Resources","difficulty":"intermediate","prerequisites":"python-basics, SQL-queries, basic-statistics","topic_tags":"interview-prep, data-science-careers, technical-questions, coding-practice","summary":"A comprehensive collection of 200+ curated interview resources covering probability, statistics, SQL, machine learning, and system design questions. Specifically organized for data science roles at major tech companies including FAANG, with dedicated sections for deep learning, NLP, and big data technologies like Spark.","use_cases":"Preparing for data scientist interviews at tech companies, Reviewing foundational concepts before technical phone screens or onsite interviews","audience":"Junior-DS, Mid-DS"},{"id":"career-khanhnamle1994-cracking-the-data-science-interview","type":"career","name":"khanhnamle1994/cracking-the-data-science-interview","description":"Downloadable cheatsheets (SQL, stats, ML/DL), question bank with '150 Essential DS Questions' PDF, case studies, portfolio examples. Closest structural equivalent to the book. 4.4k GitHub stars.","category":"SQL & Data","url":"https://github.com/khanhnamle1994/cracking-the-data-science-interview","difficulty":"beginner","prerequisites":"python-basics, SQL-fundamentals, basic-statistics","topic_tags":"interview-prep, data-science-fundamentals, cheat-sheets, career-development","summary":"Comprehensive collection of downloadable cheatsheets covering SQL, statistics, and machine learning fundamentals, plus 150 essential data science interview questions with solutions. Created as a practical study guide for data science job interviews, featuring real case studies and portfolio examples. Popular GitHub repository with structured content designed to help candidates prepare systematically for technical interviews.","use_cases":"Preparing for data science job interviews and technical screens, Quick reference guide while studying core DS concepts and methods","audience":"Junior-DS, Early-PhD"},{"id":"career-harvard-gsas-resume-&-cover-letter-guide","type":"career","name":"Harvard GSAS Resume & Cover Letter Guide","description":"Gold-standard 24-page PDF with 9 resume examples from PhDs who landed BCG, Goldman, FAANG. CV-to-resume conversion with discipline-specific framing.","category":"Materials","url":"https://cdn-careerservices.fas.harvard.edu/wp-content/uploads/sites/161/2024/08/2024-GSAS_phd_resume_cover_letters-1.pdf","difficulty":"beginner","prerequisites":"academic-writing, PhD-research","topic_tags":"career-transition, resume-writing, PhD-jobs, consulting, tech-careers","summary":"Comprehensive Harvard guide showing how PhDs successfully converted academic CVs to industry resumes for top consulting, finance, and tech roles. Features 9 real resume examples with discipline-specific language and framing strategies that landed positions at BCG, Goldman Sachs, and FAANG companies.","use_cases":"PhD transitioning from academia to industry needing to reframe research experience for corporate recruiters, Postdoc applying to consulting or tech roles and struggling to translate academic achievements into business language","audience":"Early-PhD, Curious-browser"},{"id":"career-faang-recruiter's-guide-to-data-resumes","type":"career","name":"FAANG Recruiter's Guide to Data Resumes","description":"Former Microsoft/Amazon/Uber recruiter reveals 6-10 second resume scan process. Debunks ATS myths, shows before/after examples, networking strategies to bypass ATS.","category":"Materials","url":"https://thedatahustle.substack.com/p/from-rejection-to-offer-the-faang","difficulty":"beginner","prerequisites":"basic-word-processing, email-communication","topic_tags":"resume-writing, tech-recruiting, career-development, job-search, networking","summary":"A comprehensive guide from a former Big Tech recruiter explaining how resumes are actually evaluated in 6-10 seconds at major tech companies. Provides insider knowledge on what recruiters really look for, debunks common ATS myths, and includes before/after resume examples with networking strategies to increase visibility.","use_cases":"Preparing to apply for data science roles at major tech companies, Revising existing resume after getting few responses from tech job applications","audience":"Junior-DS, Curious-browser"},{"id":"career-justin-ellis:-academia-to-data-science","type":"career","name":"Justin Ellis: Academia to Data Science","description":"PhD astrophysicist to Principal Engineer. Ranks 3 portfolio project types by value, GitHub documentation best practices, learning industry lingo without deep expertise.","category":"Materials","url":"https://jellis18.github.io/post/2021-01-03-from-academia-to-data-science/","difficulty":"beginner","prerequisites":"basic-python, git-basics","topic_tags":"career-transition, portfolio-projects, github-documentation, academia-to-industry","summary":"A career transition guide from a PhD astrophysicist who became a Principal Engineer, focusing on practical advice for breaking into data science. Covers how to prioritize portfolio projects, create effective GitHub documentation, and navigate industry terminology without deep domain expertise.","use_cases":"PhD graduates transitioning from academia to industry data science roles, Recent graduates building their first data science portfolio and GitHub presence","audience":"Early-PhD, Junior-DS"},{"id":"career-github-for-data-science-job-seekers","type":"career","name":"GitHub for Data Science Job Seekers","description":"Only dedicated course on GitHub optimization for DS job seekers. Profile README, project resume construction, hiring manager perspective. Adopted by multiple university career centers.","category":"Materials","url":"https://www.linkedin.com/learning/github-for-data-science-job-seekers","difficulty":"beginner","prerequisites":"git-basics, basic-python","topic_tags":"github-portfolio, job-search, career-development, technical-resume","summary":"A specialized course focused on optimizing GitHub profiles and repositories specifically for data science job applications. Covers profile README construction, project presentation, and insights from hiring manager perspectives. Used by university career centers to help students build compelling technical portfolios.","use_cases":"Recent bootcamp graduate needs to showcase data science projects to potential employers, PhD transitioning to industry wants to present academic work in a way that appeals to tech hiring managers","audience":"Junior-DS, Early-PhD"},{"id":"career-yu-dong:-building-a-ds-portfolio","type":"career","name":"Yu Dong: Building a DS Portfolio","description":"6 years portfolio experience. Compares 5 platforms (personal site, GitHub, Kaggle, Medium, LinkedIn). Content strategy for technical tutorials, analysis reports, career journey docs.","category":"Materials","url":"https://yudong-94.github.io/personal-website/blog/DataSciencePortfolio/","difficulty":"beginner","prerequisites":"basic-data-analysis, git-version-control","topic_tags":"portfolio-building, career-development, data-science-platforms, personal-branding, technical-writing","summary":"Yu Dong shares 6 years of experience building data science portfolios across 5 major platforms. Provides practical comparison of personal websites, GitHub, Kaggle, Medium, and LinkedIn with specific content strategies for showcasing technical work and career progression.","use_cases":"Junior data scientist preparing for job applications needs to showcase projects effectively, Mid-career DS switching companies wants to demonstrate impact and technical skills online","audience":"Junior-DS, Mid-DS"},{"id":"career-evan-buntrock:-amazon-interviewer-perspective","type":"career","name":"Evan Buntrock: Amazon Interviewer Perspective","description":"Cornell PhD who conducted 250+ Amazon interviews (175 economist). Failed 2014 (30 apps, 0 offers), succeeded 2015 (100 apps, 35 interviews). Both sides of the interview table.","category":"PhD Transition","url":"https://sites.google.com/view/themostdismalscientist/industry-job-finding-advice","difficulty":"beginner","prerequisites":"PhD-coursework, basic-coding","topic_tags":"amazon-interviews, phd-transition, career-advice, tech-interviews, economist-hiring","summary":"Career insights from a Cornell PhD who experienced both sides of Amazon's hiring process, conducting 250+ interviews including 175 for economist roles. Covers the dramatic difference between his failed 2014 job search (30 applications, 0 offers) and successful 2015 search (100 applications, 35 interviews). Provides unique perspective on what Amazon looks for when hiring economists and data scientists.","use_cases":"PhD student preparing for tech industry job applications and interviews, Recent graduate who failed initial job search and wants to understand what went wrong","audience":"Early-PhD, Curious-browser"},{"id":"career-chris-nosko:-chicago-booth-to-uber-vp-(mixtape)","type":"career","name":"Chris Nosko: Chicago Booth to Uber VP (Mixtape)","description":"Harvard PhD to tenure-track at Chicago Booth to VP at Uber. How Pat Bajari recruited structural IO economists to Amazon, economist work at marketplace companies, managing career risk.","category":"PhD Transition","url":"https://causalinf.substack.com/p/s1e23-interview-with-chris-nosko","difficulty":"beginner","prerequisites":"economics-fundamentals, industry-knowledge","topic_tags":"career-transition, structural-io, marketplace-economics, academic-to-industry, leadership","summary":"Chris Nosko shares his career journey from Harvard economics PhD to tenured professor at Chicago Booth to VP at Uber. He discusses how economists like Pat Bajari built economics teams at major tech companies, the types of problems economists solve at marketplace companies, and strategies for managing career risk when transitioning between academia and industry.","use_cases":"PhD student considering industry vs academic career paths, Academic economist evaluating transition to tech company leadership","audience":"Early-PhD, Curious-browser"},{"id":"career-rose-tan:-my-journey-from-econ-phd-to-tech","type":"career","name":"Rose Tan: My Journey from Econ PhD to Tech","description":"Columbia PhD to LinkedIn Staff DS. Internship strategy (Quora for startup pace, Facebook for research), timeline, 'the big talk' with advisors, reverse interviewing teams. Founded Economists in Tech LinkedIn group.","category":"PhD Transition","url":"https://www.linkedin.com/pulse/my-journey-from-economics-phd-data-scientist-tech-rose-tan","difficulty":"beginner","prerequisites":"economics-phd-coursework, academic-research-experience","topic_tags":"career-transition, phd-to-industry, internship-strategy, tech-recruiting, career-advice","summary":"Rose Tan shares her transition journey from Columbia Economics PhD to Staff Data Scientist at LinkedIn. She covers strategic internship choices, timeline planning, and navigating advisor conversations during the industry transition. The post also discusses her founding of the Economists in Tech LinkedIn community.","use_cases":"Planning internship strategy to maximize both startup experience and research skills, Preparing for difficult conversations with academic advisors about industry career paths","audience":"Early-PhD, Curious-browser"},{"id":"career-zijing-zhu:-how-i-became-a-data-scientist","type":"career","name":"Zijing Zhu: How I Became a Data Scientist","description":"Honest narrative of 7 months job searching with constant rejections. Why she left academia, Python learning strategy, 8-week bootcamp experience. Has YouTube channel with day-in-the-life content.","category":"PhD Transition","url":"https://towardsdatascience.com/how-i-became-a-data-scientist-7f5b10606612","difficulty":"beginner","prerequisites":"basic-python, jupyter-notebooks","topic_tags":"career-transition, PhD-to-industry, bootcamp-experience, job-search-strategy, academic-exit","summary":"Personal account of a PhD's 7-month journey transitioning to data science, including bootcamp experience and job search challenges. Provides honest insights into leaving academia, learning Python, and navigating industry interviews. Valuable for understanding the realistic timeline and emotional aspects of career pivoting.","use_cases":"PhD students considering leaving academia for data science roles, Recent graduates planning their transition strategy and timeline expectations","audience":"Early-PhD, Curious-browser"},{"id":"career-susan-athey:-first-microsoft-chief-economist-(mixtape)","type":"career","name":"Susan Athey: First Microsoft Chief Economist (Mixtape)","description":"First female John Bates Clark Medal winner, pioneered tech economics with Hal Varian (Google). How CEO Steve Ballmer recruited her, taking two leaves from Harvard, the origin story of tech economists.","category":"PhD Transition","url":"https://causalinf.substack.com/p/interview-with-susan-athey-professor-48e","difficulty":"beginner","prerequisites":"economics-fundamentals, academic-career-basics","topic_tags":"career-transition, tech-economics, microsoft, interview, pioneer-story","summary":"Susan Athey shares her pioneering journey as Microsoft's first Chief Economist, recruited by Steve Ballmer while at Harvard. She discusses the early days of tech economics alongside Hal Varian at Google and her experience transitioning between academia and industry. This career story offers insights into how tech economics emerged as a field and the opportunities for economists in technology companies.","use_cases":"PhD economist considering industry transition to tech companies, Understanding the historical development and career paths in tech economics","audience":"Early-PhD, Curious-browser"},{"id":"career-interviewquery:-visa-sponsorship-for-ds-jobs","type":"career","name":"InterviewQuery: Visa Sponsorship for DS Jobs","description":"First-person account navigating H-1B lottery multiple times. Covers H-1B, L-1A/B, O-1, E-3, TN, EB green cards. Strategy: start at large companies for L-1B transfer eligibility.","category":"Visa","url":"https://www.interviewquery.com/p/visa-sponsorship-data-science","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"visa-sponsorship, immigration-law, career-guidance, international-students, job-market","summary":"A practical guide from someone who navigated the U.S. visa system multiple times as a data scientist. Covers different visa types (H-1B, L-1, O-1, etc.) and strategic career moves like starting at large companies to build eligibility for internal transfers.","use_cases":"International students planning their post-graduation job search strategy, Data scientists on temporary visas looking to transition to permanent residency","audience":"Junior-DS, Curious-browser"},{"id":"career-eb2niw.com:-diy-green-card-resource","type":"career","name":"EB2NIW.com: DIY Green Card Resource","description":"Perfect for PhD economists. Created by successful self-petitioners. Includes actual petition documents, Matter of Dhanasar framework, concurrent filing strategy. No employer sponsorship required.","category":"Visa","url":"https://www.eb2niw.com/","difficulty":"beginner","prerequisites":"academic-CV, publication-record","topic_tags":"immigration-law, self-petition, visa-process, career-transition","summary":"A comprehensive DIY guide for obtaining EB-2 National Interest Waiver green cards without employer sponsorship. Created by economists who successfully self-petitioned, featuring real petition documents and strategic guidance. Particularly valuable for PhD economists transitioning from academia to industry or seeking permanent residency independence.","use_cases":"PhD economist wanting to avoid H-1B lottery and employer dependency, Postdoc researcher planning transition to tech industry with visa security","audience":"Early-PhD, Curious-browser"},{"id":"career-h1bdata.info:-salary-&-sponsor-database","type":"career","name":"H1BData.info: Salary & Sponsor Database","description":"4.8M+ LCA records from 2013-2025. Search by company, job title, city, year. Pre-built searches for Google, Meta, Apple, Amazon, Microsoft, OpenAI, Nvidia. Critical for negotiation.","category":"Visa","url":"https://h1bdata.info/","difficulty":"beginner","prerequisites":"web-browser, salary-negotiation-basics","topic_tags":"H1B-visa, salary-benchmarking, tech-compensation, immigration-data","summary":"A comprehensive database of 4.8+ million Labor Condition Application (LCA) records spanning 2013-2025, providing salary and sponsorship data for H-1B visa holders. The platform allows searching by company, job title, location, and year, with pre-built searches for major tech companies. Essential for salary negotiation, immigration planning, and understanding compensation trends in the tech industry.","use_cases":"Negotiating salary offer by comparing against similar H-1B positions at target company, Researching which companies actively sponsor H-1B visas for specific roles and locations","audience":"Junior-DS, Curious-browser"},{"id":"career-built-in:-companies-that-sponsor-h-1b","type":"career","name":"Built In: Companies That Sponsor H-1B","description":"Updated 2025 list with approval numbers. Beyond FAANG: Stripe (100% approval), Databricks (300+ approvals), consulting firms. Includes 2025 policy changes and $100K fee update.","category":"Visa","url":"https://builtin.com/diversity-inclusion/companies-that-sponsor-h1b-visas","difficulty":"beginner","prerequisites":"job-search-basics, visa-fundamentals","topic_tags":"h1b-sponsorship, tech-companies, visa-policy, career-planning, immigration","summary":"Comprehensive 2025 list of technology companies that sponsor H-1B visas, including approval rates and numbers beyond traditional FAANG companies. Features updated policy changes and fee structures to help international talent identify potential employers. Essential resource for navigating the tech job market as an international candidate.","use_cases":"International student planning job search strategy and targeting companies with high H-1B approval rates, Career changer researching which tech companies actively sponsor visas for data science roles","audience":"Junior-DS, Curious-browser"},{"id":"career-uscis-h-1b-employer-data-hub","type":"career","name":"USCIS H-1B Employer Data Hub","description":"Official interactive tool. Query by fiscal year, employer, city, NAICS code. Shows approval AND denial rates by employer. Identifies smaller sponsors beyond big tech. Updated quarterly.","category":"Visa","url":"https://www.uscis.gov/tools/reports-and-studies/h-1b-employer-data-hub","difficulty":"beginner","prerequisites":"basic-data-filtering, government-form-terminology","topic_tags":"immigration-data, employer-analysis, government-database, labor-market, interactive-tool","summary":"Official USCIS interactive database for exploring H-1B visa petition data by employer, location, and industry. Shows both approval and denial rates, helping users identify sponsorship patterns beyond major tech companies. Updated quarterly with comprehensive employer statistics across all sectors.","use_cases":"Researching potential H-1B sponsoring employers when job searching, Analyzing labor market trends and employer hiring patterns for immigration policy research","audience":"Junior-DS, Curious-browser"},{"id":"career-intel","type":"career","name":"Intel","description":"Career portal","category":"Company Lists","url":"https://intel.wd1.myworkdayjobs.com/External","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, hardware-industry, economist-jobs, tech-careers, intel","summary":"Intel's career portal featuring job opportunities at one of the world's largest semiconductor and hardware companies. The portal includes economist positions and data science roles focused on market analysis, pricing strategy, and business intelligence. Particularly valuable for tech economists interested in hardware industry applications and semiconductor market dynamics.","use_cases":"Searching for economist or data scientist positions at a major hardware company, Researching career paths and job requirements in the semiconductor industry","audience":"Curious-browser, Junior-DS"},{"id":"career-ibm","type":"career","name":"IBM","description":"Career portal","category":"Company Lists","url":"https://www.ibm.com/careers/search","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, enterprise-jobs, tech-economist-roles","summary":"IBM's career portal showcasing job opportunities at one of the world's largest technology and consulting companies. The portal features positions across research, data science, economics, and consulting with emphasis on enterprise solutions and AI applications. Particularly relevant for economists seeking roles that blend technical skills with business strategy in large-scale corporate environments.","use_cases":"Searching for economist or data scientist positions at a major tech company with strong research culture, Exploring career paths that combine economics expertise with enterprise AI and consulting work","audience":"Junior-DS, Curious-browser"},{"id":"career-nvidia","type":"career","name":"NVIDIA","description":"Career portal","category":"Company Lists","url":"https://www.nvidia.com/en-us/about-nvidia/careers/","difficulty":"beginner","prerequisites":"resume-writing, technical-interviewing","topic_tags":"career-portal, hardware-industry, tech-jobs, research-careers","summary":"NVIDIA's career portal showcasing job opportunities at one of the world's leading GPU and AI hardware companies. The portal features roles spanning from research scientist positions to data science and engineering roles across AI, graphics, and autonomous systems. It provides insight into career paths at a major tech hardware company driving advances in machine learning infrastructure.","use_cases":"Exploring research scientist or data science roles at a leading AI hardware company, Understanding career opportunities in GPU computing and machine learning infrastructure","audience":"Junior-DS, Curious-browser"},{"id":"career-cisco","type":"career","name":"Cisco","description":"Career portal","category":"Company Lists","url":"https://jobs.cisco.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, enterprise-jobs, tech-careers, networking-company","summary":"Cisco's career portal provides job opportunities at one of the world's largest networking and enterprise technology companies. The portal offers positions across data science, analytics, engineering, and business roles within enterprise technology infrastructure. Tech economists can explore career paths in network analytics, enterprise data solutions, and technology consulting roles.","use_cases":"Finding data science roles focused on enterprise networking and infrastructure analytics, Exploring career opportunities in large-scale enterprise technology and business intelligence","audience":"Junior-DS, Mid-DS"},{"id":"career-qualcomm","type":"career","name":"Qualcomm","description":"Career portal","category":"Company Lists","url":"https://careers.qualcomm.com/","difficulty":"beginner","prerequisites":"resume-writing, technical-interviewing","topic_tags":"career-opportunities, hardware-company, tech-jobs, AI-roles, semiconductor","summary":"Qualcomm's career portal showcasing job opportunities at the leading semiconductor and wireless technology company. The company offers roles spanning hardware engineering, AI/ML research, software development, and data science positions. Tech economists can explore career paths in a company that sits at the intersection of hardware innovation and AI advancement.","use_cases":"Exploring hardware-focused data science roles that differ from typical software company positions, Researching career opportunities in semiconductor industry for economists interested in chip market dynamics","audience":"Junior-DS, Curious-browser"},{"id":"career-sap","type":"career","name":"SAP","description":"Career portal","category":"Company Lists","url":"https://jobs.sap.com/","difficulty":"beginner","prerequisites":"resume-writing, SQL-basics","topic_tags":"career-portal, enterprise-software, job-search, SAP-careers","summary":"SAP's official career portal provides job opportunities at one of the world's largest enterprise software companies. The platform lists positions across analytics, data science, engineering, and business roles within SAP's ecosystem of ERP and cloud solutions. Tech economists can explore career paths in enterprise analytics and B2B software economics.","use_cases":"Finding data science or analytics roles at a major enterprise software company, Exploring career opportunities in B2B SaaS and enterprise technology markets","audience":"Junior-DS, Curious-browser"},{"id":"career-zillow","type":"career","name":"Zillow","description":"Career portal","category":"Company Lists","url":"https://zillow.wd5.myworkdayjobs.com/Zillow_Group_External","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, job-listings, marketplace, real-estate","summary":"Zillow's career portal showcasing job opportunities at the real estate marketplace platform. The portal highlights roles for economists, data scientists, and researchers working on pricing models, market analysis, and platform optimization. Useful for understanding how tech economists apply their skills in the real estate technology sector.","use_cases":"Exploring economist and data science roles at a major real estate tech company, Understanding career paths and job requirements in marketplace economics","audience":"Junior-DS, Curious-browser"},{"id":"career-booking.com","type":"career","name":"Booking.com","description":"Career portal","category":"Company Lists","url":"https://careers.booking.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, booking-jobs, marketplace-careers, experimentation-roles, tech-jobs","summary":"Booking.com's career portal showcasing job opportunities at one of the world's largest online travel marketplaces. The company is known for its data-driven culture and extensive use of A/B testing and experimentation. This portal provides insights into roles in data science, product analytics, and tech positions at a leading marketplace platform.","use_cases":"Looking for data science or analytics roles at a major tech company known for experimentation, Researching career opportunities in the travel tech industry and marketplace business models","audience":"Junior-DS, Curious-browser"},{"id":"career-thumbtack","type":"career","name":"Thumbtack","description":"Career portal","category":"Company Lists","url":"https://careers.thumbtack.com/jobs","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, marketplace, job-search, tech-careers, economist-jobs","summary":"Thumbtack is a marketplace platform connecting service providers with customers, representing a notable tech company that hires economists and data scientists. Their career portal showcases opportunities for tech economists working on marketplace dynamics, pricing algorithms, and supply-demand matching. The company offers insights into how economists contribute to platform business models and two-sided market optimization.","use_cases":"Exploring economist job opportunities at marketplace companies, Understanding how economists work in platform business models","audience":"Junior-DS, Curious-browser"},{"id":"career-expedia-group","type":"career","name":"Expedia Group","description":"Career portal","category":"Company Lists","url":"https://careers.expediagroup.com/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, marketplace, internships, job-search, industry-portal","summary":"Expedia Group's career portal showcasing job opportunities at one of the world's largest online travel marketplace companies. The portal provides insights into roles spanning data science, engineering, product, and research positions across their travel technology ecosystem. Particularly valuable for those interested in marketplace dynamics, travel industry applications, and PhD internship opportunities.","use_cases":"PhD students seeking internship opportunities in travel tech and marketplace economics, Data scientists looking to transition into travel industry roles with marketplace exposure","audience":"Early-PhD, Junior-DS"},{"id":"career-opendoor","type":"career","name":"Opendoor","description":"Career portal","category":"Company Lists","url":"https://www.opendoor.com/careers","difficulty":"beginner","prerequisites":"basic-web-navigation, career-planning","topic_tags":"career-portal, real-estate-tech, marketplace, job-search, company-research","summary":"Opendoor's career portal provides job opportunities and company information for the real estate technology marketplace. It offers insights into working at a data-driven company that uses pricing algorithms and marketplace dynamics. Useful for understanding career paths in prop-tech and real estate analytics.","use_cases":"Researching data science roles at real estate technology companies, Learning about career opportunities in marketplace pricing and analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-redfin","type":"career","name":"Redfin","description":"Career portal","category":"Company Lists","url":"https://www.redfin.com/careers","difficulty":"beginner","prerequisites":"basic-web-navigation, resume-writing","topic_tags":"career-opportunities, real-estate-tech, job-portal, marketplace-companies","summary":"Redfin's career portal showcases job opportunities at the real estate technology company. It provides insights into roles across engineering, data science, product, and operations teams at a major marketplace platform. The portal is useful for understanding career paths and technical roles in real estate technology.","use_cases":"Exploring data science roles at a real estate marketplace company, Researching career opportunities in real estate technology sector","audience":"Junior-DS, Curious-browser"},{"id":"career-rover","type":"career","name":"Rover","description":"Career portal","category":"Company Lists","url":"https://www.rover.com/careers/search","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, job-search, marketplace, company-directory","summary":"Rover is a career portal and company directory focused on marketplace and search-ranking companies. It provides job listings, company information, and career resources for data science and tech economics roles. The platform helps professionals navigate opportunities in the marketplace technology sector.","use_cases":"Finding data science jobs at marketplace companies like Uber, Airbnb, or DoorDash, Researching company culture and interview processes at search and ranking focused tech firms","audience":"Junior-DS, Curious-browser"},{"id":"career-fiverr","type":"career","name":"Fiverr","description":"Career portal","category":"Company Lists","url":"https://www.fiverr.com/jobs","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, gig-economy, freelancing, marketplace-jobs","summary":"Fiverr is a global marketplace connecting freelancers with clients seeking digital services, from data analysis to web development. Tech professionals use it to find project-based work, build portfolios, or hire specialists for specific tasks. The platform operates on a gig economy model where services are offered at various price points starting from $5.","use_cases":"Junior data scientist looking to build experience by taking on small analytics projects while job searching, Mid-level researcher needing to quickly hire a specialist for data visualization or web scraping tasks","audience":"Junior-DS, Curious-browser"},{"id":"career-tiktok","type":"career","name":"TikTok","description":"Career portal","category":"Company Lists","url":"https://careers.tiktok.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, tech-jobs, social-media, application-portal","summary":"TikTok's career portal for exploring job opportunities at the social media platform. This is the main gateway for discovering open positions across data science, economics, engineering, and other tech roles at TikTok. Useful for understanding the company's hiring priorities and required skills in the tech-economics space.","use_cases":"Searching for data scientist or economist positions at TikTok, Researching TikTok's team structure and technical requirements before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-x-(twitter)","type":"career","name":"X (Twitter)","description":"Career portal","category":"Company Lists","url":"https://careers.twitter.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-development, job-search, social-media, tech-careers, networking","summary":"X (formerly Twitter) career portal providing job opportunities and career resources in the tech industry. It serves as a platform for discovering data science, engineering, and research positions at X while showcasing the company's work culture and employee experiences. The portal is useful for understanding X's hiring practices and connecting with current employees.","use_cases":"Researching X as a potential employer before applying to data scientist or research scientist roles, Networking with X employees to learn about team dynamics and project opportunities","audience":"Junior-DS, Curious-browser"},{"id":"career-reddit","type":"career","name":"Reddit","description":"Career portal","category":"Company Lists","url":"https://www.redditinc.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, job-search, tech-careers, social-media, networking","summary":"Reddit's career portal and job-related resources for tech professionals. Provides access to career advice, job postings, and community discussions about working in tech. Popular destination for learning about company culture, salary negotiations, and career transitions.","use_cases":"Research company culture and employee experiences before applying to tech roles, Get career advice and salary benchmarking from tech professionals in various subreddits","audience":"Junior-DS, Curious-browser"},{"id":"career-disney","type":"career","name":"Disney","description":"Career portal","category":"Company Lists","url":"https://www.disneycareers.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, disney, entertainment-industry, job-listings, tech-careers","summary":"Disney's career portal provides job opportunities across their entertainment, media, and technology divisions. Tech economists and data scientists can explore roles in streaming analytics, theme park optimization, content recommendation systems, and business intelligence. The portal offers insights into one of the world's largest entertainment conglomerates and their data-driven initiatives.","use_cases":"Seeking data science roles in entertainment and media industry, Researching career opportunities at a major streaming and content company","audience":"Junior-DS, Curious-browser"},{"id":"career-youtube","type":"career","name":"YouTube","description":"Career portal","category":"Company Lists","url":"https://careers.google.com/jobs/results/?company=YouTube","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-development, job-search, tech-careers, application-process","summary":"YouTube's career portal provides information about job opportunities, company culture, and application processes at one of the world's largest video platforms. It serves as a gateway for tech professionals interested in roles spanning data science, engineering, product management, and research at YouTube/Google. The portal typically includes job listings, employee testimonials, and insights into YouTube's technical challenges and business model.","use_cases":"Researching YouTube's data science roles and team structure before applying for a position, Understanding YouTube's technical stack and culture to prepare for interviews","audience":"Junior-DS, Curious-browser"},{"id":"career-twitch","type":"career","name":"Twitch","description":"Career portal","category":"Company Lists","url":"https://www.twitch.tv/jobs/careers/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, twitch, streaming-platform, tech-jobs, company-portal","summary":"Twitch's career portal showcasing job opportunities at the leading live streaming platform owned by Amazon. The portal provides insights into roles across data science, engineering, product, and content moderation teams working on recommendation systems, creator monetization, and community safety. Useful for understanding career paths in the streaming media and gaming industry.","use_cases":"Junior data scientists exploring opportunities in gaming and streaming platforms to work on recommendation algorithms and user engagement metrics, Curious browsers researching career opportunities at major streaming platforms to understand role requirements and company culture","audience":"Junior-DS, Curious-browser"},{"id":"career-two-sigma","type":"career","name":"Two Sigma","description":"Career portal","category":"Company Lists","url":"https://careers.twosigma.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"quantitative-trading, finance-careers, economist-roles, hedge-funds, career-portal","summary":"Two Sigma is a quantitative hedge fund that heavily recruits economists and data scientists for trading and research roles. Their career portal showcases opportunities for applying economic modeling and statistical methods to financial markets. The company is known for its data-driven culture and offers positions ranging from research scientist to quantitative analyst.","use_cases":"Exploring quantitative finance career paths after completing economics PhD, Finding economist-titled positions at top-tier financial firms","audience":"Early-PhD, Curious-browser"},{"id":"career-citadel","type":"career","name":"Citadel","description":"Career portal","category":"Company Lists","url":"https://www.citadel.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, trading-jobs, quant-finance, job-search","summary":"Citadel's career portal showcasing opportunities at one of the world's largest hedge funds. The portal provides information about quantitative research, trading, and technology roles that frequently hire economists and data scientists. Job seekers can explore positions that combine economic theory with practical financial markets application.","use_cases":"PhD economist looking for quantitative finance career transitions, Data scientist seeking high-paying roles in systematic trading firms","audience":"Junior-DS, Curious-browser"},{"id":"career-jane-street","type":"career","name":"Jane Street","description":"Career portal","category":"Company Lists","url":"https://www.janestreet.com/join-jane-street/","difficulty":"beginner","prerequisites":"undergraduate-math, programming-basics","topic_tags":"quantitative-trading, finance-careers, algorithmic-trading, market-making","summary":"Jane Street is a quantitative trading firm known for hiring top technical talent to build trading algorithms and market-making systems. The company offers career opportunities for researchers, engineers, and traders working on problems at the intersection of mathematics, computer science, and finance. Their career portal provides information about roles, interview processes, and the technical skills valued in quantitative finance.","use_cases":"Exploring quantitative finance career paths after completing a technical degree, Understanding what skills and experience Jane Street values when considering a transition from tech to finance","audience":"Curious-browser, Junior-DS"},{"id":"career-d.e.-shaw","type":"career","name":"D.E. Shaw","description":"Career portal","category":"Company Lists","url":"https://www.deshaw.com/careers","difficulty":"beginner","prerequisites":"basic-finance, probability-theory","topic_tags":"quantitative-trading, hedge-funds, career-portal, finance-jobs, algorithmic-trading","summary":"D.E. Shaw is a leading quantitative hedge fund known for systematic trading strategies and cutting-edge research. The career portal provides information about opportunities in quantitative research, software engineering, and trading roles. It's a premier destination for data scientists and researchers interested in applying mathematical and computational methods to financial markets.","use_cases":"Exploring quantitative finance career opportunities after completing a technical PhD, Researching top-tier hedge funds that value advanced analytics and systematic trading approaches","audience":"Curious-browser, Senior-DS"},{"id":"career-jump-trading","type":"career","name":"Jump Trading","description":"Career portal","category":"Company Lists","url":"https://www.jumptrading.com/careers","difficulty":"beginner","prerequisites":"finance-fundamentals, statistical-modeling","topic_tags":"high-frequency-trading, quantitative-finance, algorithmic-trading, career-opportunities","summary":"Jump Trading is a leading proprietary trading firm specializing in algorithmic and high-frequency trading across global financial markets. The company operates at the intersection of technology and finance, employing quantitative researchers, data scientists, and engineers to develop sophisticated trading strategies. They offer career opportunities for tech professionals interested in applying computational methods to financial markets.","use_cases":"Exploring career opportunities in quantitative trading and financial technology, Understanding the job market and skill requirements for data science roles in high-frequency trading","audience":"Junior-DS, Curious-browser"},{"id":"career-bridgewater","type":"career","name":"Bridgewater","description":"Career portal","category":"Company Lists","url":"https://www.bridgewater.com/working-at-bridgewater/job-openings","difficulty":"beginner","prerequisites":"resume-writing, financial-markets-basics","topic_tags":"career-portal, hedge-fund, macro-trading, job-applications","summary":"Career portal for Bridgewater Associates, the world's largest hedge fund known for its systematic macro trading strategies and data-driven investment approach. The portal provides information about job opportunities, company culture, and application processes for roles ranging from investment research to technology and operations. Particularly relevant for economists and data scientists interested in applying quantitative methods to global macro investing.","use_cases":"Exploring job opportunities at a leading systematic hedge fund that heavily employs economists and quantitative researchers, Researching company culture and application requirements for macro trading and investment research positions","audience":"Junior-DS, Curious-browser"},{"id":"career-coinbase","type":"career","name":"Coinbase","description":"Career portal","category":"Company Lists","url":"https://www.coinbase.com/careers/positions","difficulty":"beginner","prerequisites":"resume-writing, SQL-basics","topic_tags":"careers, fintech, job-search, cryptocurrency, applied-roles","summary":"Coinbase's career portal showcasing job opportunities at one of the largest cryptocurrency exchanges. The company offers roles for economists, applied scientists, and data scientists working on crypto markets, financial products, and user behavior analysis. Positions typically involve A/B testing, market analysis, and product optimization in the fintech space.","use_cases":"Looking for fintech roles that combine economics and data science at a major crypto company, Researching what skills and experience Coinbase values for applied scientist and economist positions","audience":"Junior-DS, Curious-browser"},{"id":"career-upstart","type":"career","name":"Upstart","description":"Career portal","category":"Company Lists","url":"https://careers.upstart.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, fintech-jobs, economics-careers, company-research","summary":"Upstart is a fintech company that uses machine learning for lending decisions and actively recruits economists and data scientists. The company is known for valuing economics training and statistical modeling skills. Their career portal provides opportunities for tech economists to apply quantitative methods to financial services.","use_cases":"Researching fintech companies that value economics backgrounds for job applications, Finding data science roles at companies that prioritize causal inference and econometric methods","audience":"Junior-DS, Curious-browser"},{"id":"career-capital-one","type":"career","name":"Capital One","description":"Career portal","category":"Company Lists","url":"https://www.capitalonecareers.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, fintech-jobs, economist-roles, industry-applications","summary":"Capital One's career portal showcases opportunities for economists and data scientists in financial technology. The company is known for hiring PhDs and offering roles with 'economist' titles, making it a key destination for tech economists entering industry. Their career page provides insights into how economic methods are applied in credit, risk, and product development.","use_cases":"Early PhD or recent graduate seeking first industry role in fintech, Experienced economist looking to transition from academia or other industries to financial technology","audience":"Early-PhD, Junior-DS"},{"id":"career-goldman-sachs","type":"career","name":"Goldman Sachs","description":"Career portal","category":"Company Lists","url":"https://www.goldmansachs.com/careers","difficulty":"beginner","prerequisites":"finance-fundamentals, economics-degree","topic_tags":"career-opportunities, fintech, investment-banking, economist-roles","summary":"Goldman Sachs career portal showcasing opportunities for economists and data scientists in investment banking and financial services. The portal highlights roles that leverage quantitative skills in areas like risk management, trading, and economic research. It serves as a gateway for PhD economists and data professionals seeking to transition into high-finance careers.","use_cases":"PhD economist exploring industry career paths outside academia, Data scientist researching fintech opportunities at top-tier investment banks","audience":"Early-PhD, Curious-browser"},{"id":"career-sofi","type":"career","name":"SoFi","description":"Career portal","category":"Company Lists","url":"https://www.sofi.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, fintech-jobs, job-applications, company-research","summary":"SoFi's career portal for exploring job opportunities at the financial technology company. The portal provides information about open positions, company culture, and application processes at SoFi. It's useful for job seekers interested in fintech roles and understanding SoFi's work environment.","use_cases":"Researching data science roles at SoFi before applying, Understanding SoFi's company culture and values for interview preparation","audience":"Junior-DS, Curious-browser"},{"id":"career-chainalysis","type":"career","name":"Chainalysis","description":"Career portal","category":"Company Lists","url":"https://www.chainalysis.com/careers/","difficulty":"beginner","prerequisites":"python-basics, SQL-fundamentals","topic_tags":"blockchain-analytics, fintech-careers, cryptocurrency, data-science-jobs, career-portal","summary":"Chainalysis is a leading blockchain analytics company that provides cryptocurrency investigation and compliance tools to government agencies and financial institutions. The company offers career opportunities for data scientists, analysts, and researchers working on cryptocurrency tracking, anti-money laundering, and blockchain forensics. Their career portal connects tech professionals with roles in the growing intersection of finance, compliance, and blockchain technology.","use_cases":"Finding data science roles focused on cryptocurrency analytics and blockchain investigation, Exploring career opportunities in fintech compliance and anti-money laundering technology","audience":"Junior-DS, Mid-DS"},{"id":"career-palantir","type":"career","name":"Palantir","description":"Career portal","category":"Company Lists","url":"https://www.palantir.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, enterprise-software, data-science-jobs, tech-careers","summary":"Palantir's career portal showcasing opportunities at the enterprise data analytics company. The portal provides insights into roles spanning data engineering, software development, and quantitative analysis at a company known for large-scale data integration and analytics platforms. Useful for understanding career paths in enterprise-focused data science and software engineering.","use_cases":"Exploring data science and engineering roles at a major enterprise software company, Understanding skill requirements and career progression in enterprise data analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-snowflake","type":"career","name":"Snowflake","description":"Career portal","category":"Company Lists","url":"https://careers.snowflake.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, job-search, enterprise-data, snowflake-careers","summary":"Snowflake's career portal showcasing job opportunities at the cloud data platform company. Lists technical roles across data engineering, analytics, and machine learning teams. Useful for understanding hiring requirements and career paths at a leading data infrastructure company.","use_cases":"Researching data engineering job requirements at cloud companies, Finding entry-level positions at enterprise data platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-servicenow","type":"career","name":"ServiceNow","description":"Career portal","category":"Company Lists","url":"https://www.servicenow.com/careers.html","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, enterprise-software, job-applications, servicenow, tech-careers","summary":"ServiceNow's career portal showcasing open positions at the enterprise cloud computing platform company. The company focuses on digital workflow automation and IT service management solutions. Job seekers can explore roles in data science, engineering, product, and research across ServiceNow's global offices.","use_cases":"Looking for data science or ML engineering roles at a major enterprise software company, Researching ServiceNow's team structure and technical requirements before applying","audience":"Junior-DS, Mid-DS"},{"id":"career-workday","type":"career","name":"Workday","description":"Career portal","category":"Company Lists","url":"https://www.workday.com/en-us/company/careers.html","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, enterprise-software, job-opportunities, tech-careers, workday-platform","summary":"Workday is a major enterprise software company specializing in human capital management and financial management applications. Tech economists and data scientists often encounter Workday both as a potential employer and as a platform whose HR/finance products they may analyze or integrate with. The company offers career opportunities across engineering, data science, product, and research roles.","use_cases":"Exploring job opportunities at a major enterprise software company with strong data and ML teams, Researching companies that build HR analytics and workforce planning products for case studies","audience":"Junior-DS, Curious-browser"},{"id":"career-datadog","type":"career","name":"Datadog","description":"Career portal","category":"Company Lists","url":"https://careers.datadoghq.com/","difficulty":"beginner","prerequisites":"resume-writing, python-basics","topic_tags":"careers, job-search, enterprise-monitoring, applied-science, company-portal","summary":"Datadog's career portal showcasing job opportunities at the cloud monitoring and analytics platform company. The portal features roles across engineering, data science, and applied research teams working on large-scale observability solutions. Particularly relevant for tech professionals interested in enterprise infrastructure, machine learning applications, and distributed systems.","use_cases":"Junior data scientists looking for applied ML roles at a high-growth enterprise software company, Mid-level engineers seeking positions in observability, monitoring, or cloud infrastructure teams","audience":"Junior-DS, Mid-DS"},{"id":"career-atlassian","type":"career","name":"Atlassian","description":"Career portal","category":"Company Lists","url":"https://www.atlassian.com/company/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, job-search, enterprise, company-portal","summary":"Atlassian's career portal showcasing available positions at the enterprise software company known for Jira, Confluence, and other collaboration tools. The portal provides insights into company culture, benefits, and specific role requirements for data scientists and economists interested in working at a major tech company. It's particularly valuable for understanding how large enterprise software companies structure their data teams and compensation.","use_cases":"Researching data science roles at enterprise software companies, Understanding compensation and career progression at Atlassian","audience":"Junior-DS, Mid-DS"},{"id":"career-cloudflare","type":"career","name":"Cloudflare","description":"Career portal","category":"Company Lists","url":"https://www.cloudflare.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, web-navigation","topic_tags":"career-opportunities, tech-jobs, company-research, job-applications, networking","summary":"Cloudflare's career portal showcases open positions at the global network and security company. The portal provides insight into roles spanning data science, engineering, product, and business functions at a major internet infrastructure provider. Job seekers can explore opportunities to work on large-scale distributed systems, cybersecurity, and performance optimization challenges.","use_cases":"Researching data scientist and analyst positions at a leading CDN and security company, Understanding career paths and technical requirements for roles in internet infrastructure","audience":"Junior-DS, Curious-browser"},{"id":"career-unitedhealth-group","type":"career","name":"UnitedHealth Group","description":"Career portal","category":"Company Lists","url":"https://careers.unitedhealthgroup.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"healthcare-industry, career-opportunities, job-search, health-economics, pharma-careers","summary":"UnitedHealth Group's career portal provides job opportunities and company information for one of the largest healthcare companies in the world. The portal is valuable for data scientists and economists interested in healthcare analytics, health economics research, and pharmaceutical industry roles. It offers insights into career paths within a major healthcare organization that heavily relies on data-driven decision making.","use_cases":"Junior data scientist looking for entry-level positions in healthcare analytics at a Fortune 500 company, Mid-level researcher seeking health economics roles with opportunities to work on population health and cost-effectiveness studies","audience":"Junior-DS, Curious-browser"},{"id":"career-cvs-health","type":"career","name":"CVS Health","description":"Career portal","category":"Company Lists","url":"https://jobs.cvshealth.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-opportunities, healthcare-analytics, pharma-jobs, company-portal","summary":"CVS Health's career portal showcasing analytics and data science opportunities within one of the largest healthcare companies. The portal provides insights into available roles, company culture, and application processes for tech positions in the pharmaceutical and healthcare analytics space. Useful for understanding career paths and requirements at a major healthcare technology employer.","use_cases":"Junior data scientist researching healthcare analytics roles and required qualifications at CVS Health, Career changer exploring opportunities to transition into pharmaceutical data science positions","audience":"Junior-DS, Curious-browser"},{"id":"career-elevance-health","type":"career","name":"Elevance Health","description":"Career portal","category":"Company Lists","url":"https://careers.elevancehealth.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"healthcare-economics, pharma-careers, job-portal, health-insurance, career-transition","summary":"Elevance Health's career portal provides job opportunities at one of the largest health insurance companies in the US. The portal is valuable for tech economists seeking roles in healthcare data analysis, actuarial science, and health economics research. It offers positions ranging from entry-level analyst roles to senior data science and economics positions in the healthcare sector.","use_cases":"Junior data scientist looking for first role in healthcare economics or insurance analytics, PhD economist seeking industry transition into health economics at a major payer organization","audience":"Junior-DS, Curious-browser"},{"id":"career-humana","type":"career","name":"Humana","description":"Career portal","category":"Company Lists","url":"https://careers.humana.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"careers, healthcare-tech, job-search, pharma, AI-ML","summary":"Humana's career portal showcasing job opportunities at the health insurance company known for integrating AI and machine learning into healthcare operations. The portal provides insights into roles spanning data science, analytics, and technology positions within the healthcare industry. Useful for understanding career paths and requirements at a major healthcare technology employer.","use_cases":"Exploring data science job opportunities in the healthcare insurance sector, Researching company culture and tech stack before applying to Humana positions","audience":"Junior-DS, Curious-browser"},{"id":"career-kaiser-permanente","type":"career","name":"Kaiser Permanente","description":"Career portal","category":"Company Lists","url":"https://divisionofresearch.kaiserpermanente.org/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"healthcare-careers, pharma-jobs, research-positions, career-portal, job-applications","summary":"Kaiser Permanente's career portal provides job opportunities in healthcare technology, data science, and research roles within one of the largest integrated healthcare systems. The portal offers positions ranging from entry-level analyst roles to senior research scientist positions in health economics, clinical data analysis, and population health management. It serves as a gateway for tech professionals looking to apply their skills in healthcare and pharmaceutical research.","use_cases":"Junior data scientist searching for entry-level healthcare analytics positions with training opportunities, PhD researcher looking for applied research roles in health economics or clinical outcomes analysis","audience":"Junior-DS, Early-PhD"},{"id":"career-iqvia","type":"career","name":"IQVIA","description":"Career portal","category":"Company Lists","url":"https://jobs.iqvia.com/","difficulty":"beginner","prerequisites":"resume-writing, healthcare-economics","topic_tags":"pharma-careers, HEOR-jobs, healthcare-analytics, industry-transition","summary":"IQVIA is a global healthcare data and analytics company offering career opportunities in pharmaceutical research, health economics outcomes research (HEOR), and data science. The career portal provides access to positions ranging from entry-level analyst roles to senior research positions in areas like real-world evidence, clinical trials, and market access. It's a key destination for economists and data scientists looking to transition into or advance within the pharmaceutical industry.","use_cases":"Academic health economist seeking industry transition to pharmaceutical consulting or HEOR roles, Data scientist looking for healthcare-focused positions involving real-world evidence analysis and clinical outcomes research","audience":"Junior-DS, Curious-browser"},{"id":"career-flatiron-health","type":"career","name":"Flatiron Health","description":"Career portal","category":"Company Lists","url":"https://flatiron.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, pharma, oncology, job-search, healthcare-data","summary":"Flatiron Health's career portal showcasing opportunities at a leading healthcare technology company focused on oncology research and real-world evidence. The company specializes in cancer data analytics and works with pharmaceutical companies and healthcare providers. Data scientists and researchers can explore roles involving clinical data analysis, drug development analytics, and healthcare outcomes research.","use_cases":"Junior data scientist looking for healthcare industry roles with real-world clinical data experience, PhD researcher transitioning from academia to industry pharma analytics positions","audience":"Junior-DS, Curious-browser"},{"id":"career-tempus","type":"career","name":"Tempus","description":"Career portal","category":"Company Lists","url":"https://tempus.wd5.myworkdayjobs.com/Tempus_Careers","difficulty":"beginner","prerequisites":"web-navigation, career-research","topic_tags":"career-portal, pharma-jobs, AI-medicine, company-directory, healthcare-tech","summary":"Tempus is a career portal focused on opportunities in pharmaceutical and AI-medicine companies. It serves as a curated directory for professionals seeking positions at the intersection of healthcare, artificial intelligence, and biotechnology. The platform helps job seekers discover companies working on cutting-edge medical AI applications.","use_cases":"Finding job opportunities at AI-driven pharmaceutical companies, Researching potential employers in the healthcare technology sector","audience":"Junior-DS, Curious-browser"},{"id":"career-veeva-systems","type":"career","name":"Veeva Systems","description":"Career portal","category":"Company Lists","url":"https://careers.veeva.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"pharma-careers, life-sciences, job-portal, company-research, biotech","summary":"Veeva Systems career portal showcasing opportunities at a leading cloud software company serving the life sciences industry. The portal provides job listings, company culture insights, and application processes for roles spanning data science, engineering, and business functions in pharmaceutical technology. Useful for understanding career paths and requirements in the pharma-tech sector.","use_cases":"Researching data science roles at pharmaceutical technology companies, Exploring career opportunities in life sciences software and cloud platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-amgen","type":"career","name":"Amgen","description":"Career portal","category":"Company Lists","url":"https://careers.amgen.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, pharma, HEOR, job-search, biotechnology","summary":"Amgen's career portal provides job opportunities at one of the world's largest biotechnology companies, particularly strong in health economics and outcomes research (HEOR) roles. The portal offers positions ranging from data science and biostatistics to market access and health economics. It's a key resource for professionals seeking to apply quantitative skills in pharmaceutical and biotechnology settings.","use_cases":"Junior data scientist looking for entry-level positions in pharmaceutical analytics and HEOR, Mid-career researcher seeking to transition from academia to industry biotech roles","audience":"Junior-DS, Curious-browser"},{"id":"career-abbvie","type":"career","name":"AbbVie","description":"Career portal","category":"Company Lists","url":"https://careers.abbvie.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, pharma-jobs, HEOR-positions, healthcare-economics","summary":"AbbVie's career portal provides job listings and information for positions at the pharmaceutical company. It serves as the primary gateway for data scientists and health economists seeking opportunities in healthcare and pharmaceutical research. The portal includes roles spanning clinical data analysis, health economics outcomes research, and biostatistics.","use_cases":"Finding data science positions focused on pharmaceutical research and drug development, Exploring HEOR analyst roles that combine healthcare economics with real-world evidence analysis","audience":"Junior-DS, Curious-browser"},{"id":"career-regeneron","type":"career","name":"Regeneron","description":"Career portal","category":"Company Lists","url":"https://careers.regeneron.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, pharma, HEOR, job-portal","summary":"Regeneron's career portal provides job listings and opportunities at the biotechnology company. The portal is particularly relevant for health economists and outcomes researchers (HEOR) looking for pharma industry positions. It offers insights into career paths, job requirements, and company culture in the biotech sector.","use_cases":"Looking for HEOR positions in pharmaceutical companies, Researching biotech career opportunities and salary ranges","audience":"Junior-DS, Curious-browser"},{"id":"career-bristol-myers-squibb","type":"career","name":"Bristol-Myers Squibb","description":"Career portal","category":"Company Lists","url":"https://careers.bms.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"pharma-careers, HEOR-jobs, career-portal, biotech-industry, healthcare-economics","summary":"Bristol-Myers Squibb's career portal provides job listings and company information for one of the world's largest pharmaceutical companies. The portal is particularly valuable for data scientists and economists interested in health economics and outcomes research (HEOR) roles. It offers insights into industry career paths, required skills, and compensation structures in pharmaceutical data science.","use_cases":"Researching HEOR data scientist positions and required qualifications at major pharma companies, Benchmarking pharmaceutical industry job requirements against current skillset for career planning","audience":"Junior-DS, Curious-browser"},{"id":"career-gilead-sciences","type":"career","name":"Gilead Sciences","description":"Career portal","category":"Company Lists","url":"https://www.gilead.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, pharma-jobs, HEOR-careers, biotech-employment","summary":"Gilead Sciences career portal providing job opportunities at a major pharmaceutical company focused on antiviral drugs and treatments. The portal lists positions across R&D, data science, health economics outcomes research (HEOR), and other functions. Useful for exploring pharma industry career paths and understanding role requirements at a leading biotech company.","use_cases":"Junior DS exploring data science roles in pharmaceutical industry, HEOR researcher looking for industry positions at major biotech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-google-deepmind","type":"career","name":"Google DeepMind","description":"Career portal","category":"Company Lists","url":"https://deepmind.google/careers/","difficulty":"beginner","prerequisites":"python-programming, machine-learning-fundamentals","topic_tags":"careers, AI-research, deep-learning, hiring","summary":"Google DeepMind's career portal showcasing job opportunities at one of the world's leading AI research labs. The portal provides information about research positions, applied AI roles, and engineering positions that combine cutting-edge AI research with real-world applications. Particularly relevant for those interested in reinforcement learning, large language models, and AI safety research.","use_cases":"PhD looking for AI research positions that welcome economics backgrounds, Senior DS exploring transition from industry to AI research lab","audience":"Early-PhD, Senior-DS"},{"id":"career-scale-ai","type":"career","name":"Scale AI","description":"Career portal","category":"Company Lists","url":"https://scale.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, AI-companies, job-listings, tech-careers, data-science-jobs","summary":"Scale AI's career portal showcasing open positions at one of the leading AI data infrastructure companies. The portal provides insight into roles, requirements, and company culture at a major AI platform that serves enterprise clients. Useful for understanding career trajectories and skill requirements in the AI/ML industry.","use_cases":"Researching data science roles at AI-focused companies to understand required skills and career paths, Exploring job opportunities at Scale AI or similar AI infrastructure companies","audience":"Junior-DS, Curious-browser"},{"id":"career-cohere","type":"career","name":"Cohere","description":"Career portal","category":"Company Lists","url":"https://jobs.ashbyhq.com/cohere","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"AI-careers, job-search, company-portal, tech-jobs, research-careers","summary":"Cohere's career portal showcasing job opportunities at the AI research company. Features positions in machine learning research, engineering, and product development at one of the leading language model companies. Useful for understanding career paths and requirements in commercial AI research.","use_cases":"Exploring AI research career opportunities at a leading language model company, Understanding job requirements and skills needed for commercial NLP roles","audience":"Junior-DS, Curious-browser"},{"id":"career-perplexity-ai","type":"career","name":"Perplexity AI","description":"Career portal","category":"Company Lists","url":"https://www.perplexity.ai/hub/careers","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"careers, AI-companies, job-search, tech-industry","summary":"Perplexity AI's career portal showcasing open positions at the AI search company. Provides job listings, company culture information, and application processes for roles in AI research, engineering, and business functions. Useful for tech professionals interested in working at cutting-edge AI search companies.","use_cases":"Finding AI researcher or ML engineer positions at Perplexity, Learning about career opportunities in AI-powered search technology","audience":"Junior-DS, Curious-browser"},{"id":"career-weights-&-biases","type":"career","name":"Weights & Biases","description":"Career portal","category":"Company Lists","url":"https://wandb.ai/site/careers/","difficulty":"beginner","prerequisites":"python-basics, jupyter-notebooks","topic_tags":"career-opportunities, AI-companies, job-search, machine-learning-roles, data-science-careers","summary":"Weights & Biases career portal showcases job opportunities at a leading MLOps and experiment tracking company. The portal features roles across engineering, data science, and research positions focused on machine learning infrastructure and tooling. It provides insights into working at a fast-growing AI company that serves major tech organizations.","use_cases":"Finding ML engineering or data science roles at a company specializing in experiment tracking and model management, Exploring career opportunities in the MLOps space and learning about industry-leading ML infrastructure work","audience":"Junior-DS, Mid-DS"},{"id":"career-hugging-face","type":"career","name":"Hugging Face","description":"Career portal","category":"Company Lists","url":"https://apply.workable.com/huggingface/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, AI-jobs, open-source, job-portal, tech-hiring","summary":"Hugging Face's career portal showcasing job opportunities at the leading open-source AI company. The portal provides insights into roles spanning machine learning engineering, research, developer relations, and product development at a company known for democratizing AI through open-source tools and models. It serves as both a direct application channel and a window into career paths in the modern AI/ML industry.","use_cases":"Exploring career opportunities at a prominent AI company known for transformers and open-source ML tools, Understanding role requirements and career progression paths in the AI/ML industry","audience":"Junior-DS, Curious-browser"},{"id":"career-ai21-labs","type":"career","name":"AI21 Labs","description":"Career portal","category":"Company Lists","url":"https://www.ai21.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, AI-research, job-search, NLP, company-portal","summary":"AI21 Labs is a leading AI research company focused on natural language processing and large language models. Their career portal provides opportunities for researchers, engineers, and data scientists to work on cutting-edge AI technologies. The company offers roles spanning research, product development, and applied AI across various experience levels.","use_cases":"Looking for research positions at AI companies specializing in large language models, Exploring career opportunities in natural language processing and generative AI","audience":"Curious-browser, Junior-DS"},{"id":"career-valve","type":"career","name":"Valve","description":"Career portal","category":"Company Lists","url":"https://www.valvesoftware.com/en/jobs","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"valve-corporation, gaming-industry, economist-careers, tech-jobs","summary":"Career portal for Valve Corporation, the gaming company behind Steam, Half-Life, and Portal. Valve is known for its flat organizational structure and hiring economists for marketplace design and game economy analysis. The portal provides information about open positions, company culture, and application processes.","use_cases":"Exploring economist opportunities in gaming industry and digital marketplaces, Researching Valve's unique flat management structure and work culture","audience":"Curious-browser, Junior-DS"},{"id":"career-riot-games","type":"career","name":"Riot Games","description":"Career portal","category":"Company Lists","url":"https://www.riotgames.com/en/work-with-us/jobs","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviewing","topic_tags":"career-opportunities, gaming-industry, job-portal, economy-design, company-research","summary":"Riot Games' career portal showcasing job opportunities at the gaming company behind League of Legends and other popular titles. The portal is particularly valuable for those interested in economy design roles and understanding how gaming companies structure their data science and economics teams. It provides insights into the skills and experience gaming companies value for tech-econ positions.","use_cases":"Researching economy designer positions at gaming companies to understand required qualifications, Exploring career transitions from traditional data science into gaming industry economics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-zynga","type":"career","name":"Zynga","description":"Career portal","category":"Company Lists","url":"https://www.zynga.com/jobs/careers/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"gaming-industry, tech-careers, company-research, game-economics, career-portal","summary":"Zynga's career portal provides insights into opportunities at one of the leading mobile gaming companies. The portal showcases roles specifically relevant to game economists and data scientists working in the gaming industry. It offers a window into how economics and data science are applied in free-to-play mobile game development and monetization.","use_cases":"Researching career opportunities in gaming economics and understanding what skills are valued at major game companies, Learning about the intersection of economics and game design through job descriptions and company culture information","audience":"Junior-DS, Curious-browser"},{"id":"career-playtika","type":"career","name":"Playtika","description":"Career portal","category":"Company Lists","url":"https://www.playtika.com/careers/","difficulty":"beginner","prerequisites":"basic-resume-writing, tech-industry-knowledge","topic_tags":"career-portal, gaming-industry, job-search, company-research","summary":"Playtika's career portal provides job opportunities and company information for one of the leading mobile gaming companies. The portal offers insights into roles for data scientists, economists, and analysts working on game monetization, player behavior, and product optimization. It's a valuable resource for understanding career paths in gaming economics and the skills valued by top gaming companies.","use_cases":"Researching data science and economist roles at gaming companies to understand required skills and compensation, Exploring career opportunities in game analytics and learning about Playtika's approach to data-driven game development","audience":"Junior-DS, Curious-browser"},{"id":"career-epic-games","type":"career","name":"Epic Games","description":"Career portal","category":"Company Lists","url":"https://www.epicgames.com/site/en-US/careers/jobs","difficulty":"beginner","prerequisites":"resume-writing, basic-interviewing","topic_tags":"career-opportunities, gaming-industry, tech-jobs, job-search","summary":"Epic Games career portal showcasing job opportunities at the creator of Fortnite and Unreal Engine. The company operates at the intersection of gaming, metaverse development, and cutting-edge graphics technology. Offers positions ranging from data science and analytics to game development and platform engineering.","use_cases":"Exploring data science opportunities in the gaming industry, Finding roles in metaverse and virtual world development","audience":"Junior-DS, Curious-browser"},{"id":"career-activision-blizzard","type":"career","name":"Activision Blizzard","description":"Career portal","category":"Company Lists","url":"https://careers.activisionblizzard.com/","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"gaming-industry, career-opportunities, tech-jobs, game-economics, company-research","summary":"Career portal for Activision Blizzard, one of the largest gaming companies known for franchises like Call of Duty, World of Warcraft, and Candy Crush. This resource provides job listings and company information for data scientists, economists, and researchers interested in gaming industry careers. Useful for understanding career paths in game analytics, player behavior research, and gaming economics.","use_cases":"Exploring data science career opportunities in the gaming industry, Researching company culture and roles at major gaming companies","audience":"Junior-DS, Curious-browser"},{"id":"career-electronic-arts","type":"career","name":"Electronic Arts","description":"Career portal","category":"Company Lists","url":"https://www.ea.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"gaming-careers, tech-jobs, company-research, game-economics, career-portal","summary":"Electronic Arts career portal providing job opportunities and company information for one of the world's largest gaming companies. Offers insights into roles spanning game development, data science, economics, and business operations within the gaming industry. Useful for understanding career paths and requirements in game economics and tech roles at major gaming studios.","use_cases":"Exploring data science and analyst positions in the gaming industry, Researching career opportunities in game economics and monetization teams","audience":"Junior-DS, Curious-browser"},{"id":"career-supercell","type":"career","name":"Supercell","description":"Career portal","category":"Company Lists","url":"https://supercell.com/en/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"gaming-industry, career-opportunities, mobile-games, tech-jobs, company-portal","summary":"Supercell's career portal provides job opportunities at the Finnish mobile gaming company behind Clash of Clans, Clash Royale, and other popular games. The portal showcases data science, analytics, and product roles within the gaming industry. It offers insights into working at a leading mobile gaming company with a unique culture and data-driven approach to game development.","use_cases":"Data scientists looking for roles in the gaming industry to apply statistical methods to player behavior and game monetization, Recent graduates exploring career opportunities at innovative tech companies with strong analytical cultures","audience":"Junior-DS, Curious-browser"},{"id":"career-take-two-interactive","type":"career","name":"Take-Two Interactive","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/taketwo/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"gaming-careers, tech-jobs, career-portal, take-two, job-applications","summary":"Take-Two Interactive's career portal showcases job opportunities at one of the largest gaming companies, known for franchises like Grand Theft Auto and NBA 2K. The portal provides insight into roles spanning game development, data science, analytics, and business operations in the gaming industry. It serves as a window into career paths and skill requirements at a major gaming publisher.","use_cases":"Exploring data science and analytics roles in the gaming industry, Understanding skill requirements and career progression at major gaming companies","audience":"Junior-DS, Curious-browser"},{"id":"career-delta-air-lines","type":"career","name":"Delta Air Lines","description":"Career portal","category":"Company Lists","url":"https://delta.dejobs.org/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, airline-industry, travel-sector, job-search, corporate-careers","summary":"Delta Air Lines career portal for job opportunities at one of the major U.S. airlines. Early career data scientists and economists can explore entry-level positions in revenue management, operations research, and customer analytics. The portal provides insight into how airlines apply data science to optimize pricing, routes, and customer experience.","use_cases":"Looking for entry-level data science roles in the airline/travel industry, Researching how major airlines structure their analytics and economics teams","audience":"Junior-DS, Curious-browser"},{"id":"career-united-airlines","type":"career","name":"United Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.united.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, airline-industry, corporate-jobs, transportation, aviation","summary":"United Airlines' career portal showcasing job opportunities across the airline industry including data science, economics, operations research, and analytics roles. The portal provides insights into how a major airline leverages data professionals for pricing, route optimization, customer analytics, and operational efficiency. It's valuable for understanding career paths in the transportation sector and seeing real-world applications of economic and data science methods in aviation.","use_cases":"Exploring data science career opportunities in the airline/transportation industry, Understanding how airlines structure their analytics and economics teams","audience":"Junior-DS, Curious-browser"},{"id":"career-southwest-airlines","type":"career","name":"Southwest Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.southwestair.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, airline-industry, job-opportunities, transportation-economics","summary":"Southwest Airlines' career portal provides job opportunities at one of the largest low-cost carriers in the United States. The portal offers positions across various functions including data science, analytics, operations research, and business intelligence roles that focus on airline economics and optimization. It serves as a gateway for tech economists interested in transportation industry applications.","use_cases":"Searching for data science positions in the airline industry with focus on pricing and revenue optimization, Exploring career opportunities that combine transportation economics with operational analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-american-airlines","type":"career","name":"American Airlines","description":"Career portal","category":"Company Lists","url":"https://jobs.aa.com/","difficulty":"beginner","prerequisites":"resume-writing, SQL-basics","topic_tags":"careers, airline-industry, job-applications, transportation","summary":"American Airlines career portal featuring data science, analytics, and technology positions within the airline industry. Provides insights into opportunities at one of the world's largest airlines for tech professionals interested in transportation, operations research, and customer analytics. Useful for understanding industry-specific applications of data science in aviation.","use_cases":"Finding data science roles in airline operations and revenue management, Exploring tech career opportunities in the transportation industry","audience":"Junior-DS, Curious-browser"},{"id":"career-fedex","type":"career","name":"FedEx","description":"Career portal","category":"Company Lists","url":"https://careers.fedex.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, transportation-industry, corporate-careers","summary":"FedEx's career portal provides job opportunities across their global logistics and transportation network. The portal offers positions ranging from data science and analytics roles to operations research and economics positions within one of the world's largest shipping companies. It serves as a gateway for tech professionals interested in applying quantitative skills to supply chain optimization and logistics challenges.","use_cases":"Recent PhD looking for industry economist positions at major logistics companies, Data scientist seeking opportunities to work on supply chain optimization and route planning algorithms","audience":"Junior-DS, Curious-browser"},{"id":"career-waymo","type":"career","name":"Waymo","description":"Career portal","category":"Company Lists","url":"https://careers.withwaymo.com/jobs/search","difficulty":"beginner","prerequisites":"resume-writing, python-pandas, A-B-testing","topic_tags":"careers, autonomous-vehicles, self-driving, waymo, tech-jobs","summary":"Waymo's career portal showcasing job opportunities at the leading autonomous vehicle company. Junior and mid-level data scientists can explore roles in machine learning, robotics, and transportation technology. The portal provides insights into working on cutting-edge self-driving car technology and the skills needed for autonomous vehicle development.","use_cases":"Junior DS looking for ML roles in autonomous vehicles and robotics, Mid DS wanting to transition from traditional tech to transportation and mobility","audience":"Junior-DS, Mid-DS"},{"id":"career-zoox","type":"career","name":"Zoox","description":"Career portal","category":"Company Lists","url":"https://jobs.lever.co/zoox","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, autonomous-vehicles, job-search, mobility, tech-companies","summary":"Zoox is an autonomous vehicle company owned by Amazon that develops fully self-driving robotaxis. Their career portal provides opportunities for tech economists, data scientists, and researchers working on transportation economics, demand forecasting, and mobility optimization. The company offers roles spanning from product analytics to research positions focused on the economics of autonomous transportation systems.","use_cases":"Finding data science roles focused on transportation and mobility economics at a cutting-edge autonomous vehicle company, Exploring career opportunities in the intersection of economics, AI, and urban transportation systems","audience":"Junior-DS, Curious-browser"},{"id":"career-aurora-innovation","type":"career","name":"Aurora Innovation","description":"Career portal","category":"Company Lists","url":"https://boards.greenhouse.io/aurorainnovation","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, autonomous-vehicles, job-opportunities, tech-companies","summary":"Aurora Innovation's career portal showcasing job opportunities at the autonomous vehicle technology company. The portal provides insights into roles across engineering, data science, economics, and operations at a leading self-driving car company. Useful for understanding career paths and skill requirements in the autonomous vehicle industry.","use_cases":"Junior data scientist exploring career opportunities in autonomous vehicle companies, Economics PhD student researching potential industry positions in transportation technology","audience":"Junior-DS, Curious-browser"},{"id":"career-walmart","type":"career","name":"Walmart","description":"Career portal","category":"Company Lists","url":"https://careers.walmart.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"walmart, retail-economics, career-opportunities, economist-jobs","summary":"Walmart's career portal showcasing economist positions and opportunities within one of the world's largest retailers. The company maintains dedicated economist teams working on pricing, supply chain optimization, and market analysis. This resource helps job seekers understand Walmart's economist roles and application processes.","use_cases":"Exploring economist job opportunities at a major retail corporation, Understanding how economists contribute to retail operations and strategy","audience":"Junior-DS, Curious-browser"},{"id":"career-starbucks","type":"career","name":"Starbucks","description":"Career portal","category":"Company Lists","url":"https://careers.starbucks.com","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, retail-jobs, economist-positions, job-applications","summary":"Starbucks' career portal for exploring job opportunities at the global coffee retail chain. The portal includes economist-titled positions and data science roles within their corporate functions. Useful for understanding how large retail companies structure their analytical teams and compensation.","use_cases":"Researching economist job opportunities at major retail corporations, Understanding career progression paths from academia to retail industry analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-nike","type":"career","name":"Nike","description":"Career portal","category":"Company Lists","url":"https://jobs.nike.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, retail-industry, job-applications, PhD-careers","summary":"Nike's career portal showcasing opportunities at one of the world's largest athletic apparel and footwear companies. The portal features positions across analytics, data science, and research roles, with many positions preferring PhD qualifications. Useful for understanding how major retail companies structure their data teams and what skills they prioritize.","use_cases":"Researching data science career paths at major retail companies, Understanding skill requirements and team structures at consumer brands","audience":"Early-PhD, Curious-browser"},{"id":"career-the-home-depot","type":"career","name":"The Home Depot","description":"Career portal","category":"Company Lists","url":"https://careers.homedepot.com/","difficulty":"beginner","prerequisites":"resume-writing, basic-statistics","topic_tags":"retail-analytics, career-opportunities, data-science-jobs, home-depot, corporate-careers","summary":"The Home Depot's career portal showcases data science and analytics opportunities at one of the world's largest home improvement retailers. The portal provides insights into roles spanning customer analytics, supply chain optimization, and retail forecasting. It serves as a resource for understanding how analytics drives business decisions in the retail sector.","use_cases":"Exploring entry-level data analyst positions at a major retailer, Understanding analytics career paths in brick-and-mortar retail companies","audience":"Junior-DS, Curious-browser"},{"id":"career-procter-&-gamble","type":"career","name":"Procter & Gamble","description":"Career portal","category":"Company Lists","url":"https://www.pgcareers.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, retail-industry, PhD-careers, corporate-jobs, consumer-goods","summary":"Procter & Gamble's career portal showcasing opportunities at one of the world's largest consumer goods companies. The company offers structured PhD programs and data science roles across brand management, market research, and operations analytics. P&G is known for rigorous analytical training and strong career development pathways.","use_cases":"Exploring corporate data science opportunities in consumer goods and retail analytics, Researching PhD-friendly companies with structured training programs and mentorship","audience":"Early-PhD, Junior-DS"},{"id":"career-nvidia-1","type":"career","name":"NVIDIA","description":"Career portal","category":"Company Lists","url":"https://www.nvidia.com/en-us/about-nvidia/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, NVIDIA, tech-jobs, hardware-industry, AI-companies","summary":"NVIDIA's career portal showcasing job opportunities at the leading GPU and AI hardware company. Features roles across engineering, research, data science, and business functions at a company central to the AI revolution. Provides insights into working at one of the most valuable tech companies driving modern AI infrastructure.","use_cases":"Exploring job opportunities in AI hardware and GPU computing industry, Researching career paths and role requirements at a leading tech company","audience":"Junior-DS, Curious-browser"},{"id":"career-amd","type":"career","name":"AMD","description":"Career portal","category":"Company Lists","url":"https://careers.amd.com/","difficulty":"beginner","prerequisites":"resume-writing, technical-interviewing","topic_tags":"careers, hardware, semiconductor, job-portal, tech-companies","summary":"AMD's career portal provides job listings and company information for one of the world's leading semiconductor and processor companies. The portal offers opportunities across engineering, data science, research, and business roles in hardware and chip design. It's particularly valuable for tech economists interested in hardware industry career paths and compensation benchmarking.","use_cases":"Exploring data science and analytics roles in the semiconductor industry, Researching hardware company compensation and job requirements for industry analysis","audience":"Junior-DS, Curious-browser"},{"id":"career-intel-1","type":"career","name":"Intel","description":"Career portal","category":"Company Lists","url":"https://www.intel.com/content/www/us/en/jobs/jobs-at-intel.html","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-opportunities, hardware-industry, tech-jobs, semiconductor, career-portal","summary":"Intel's career portal showcasing job opportunities at one of the world's largest semiconductor companies. The portal provides insights into roles across hardware engineering, data science, research, and business functions at Intel. Useful for understanding career paths and technical requirements in the semiconductor industry.","use_cases":"Exploring data science and engineering roles at a major hardware company, Understanding skill requirements and career progression in semiconductor industry","audience":"Junior-DS, Curious-browser"},{"id":"career-qualcomm-1","type":"career","name":"Qualcomm","description":"Career portal","category":"Company Lists","url":"https://careers.qualcomm.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, hardware, mobile, job-applications, tech-careers","summary":"Qualcomm's career portal provides job listings and application opportunities at the mobile chipset and wireless technology company. The portal offers positions across engineering, data science, research, and business functions focused on mobile hardware and telecommunications. Job seekers can explore roles in RF engineering, signal processing, product management, and data analytics within the mobile technology ecosystem.","use_cases":"Applying for data scientist positions focusing on mobile device analytics and wireless network optimization, Exploring hardware engineering roles in chipset design and mobile processor development","audience":"Junior-DS, Curious-browser"},{"id":"career-broadcom","type":"career","name":"Broadcom","description":"Career portal","category":"Company Lists","url":"https://www.broadcom.com/company/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, hardware-jobs, semiconductor-industry, tech-careers, broadcom","summary":"Broadcom's career portal for exploring job opportunities at one of the world's largest semiconductor and infrastructure software companies. The portal provides insights into roles spanning data science, engineering, and business analytics within the hardware industry. Useful for understanding career paths and skill requirements in the semiconductor sector.","use_cases":"Exploring data science and analytics roles at a major semiconductor company, Researching hardware industry career opportunities and compensation benchmarks","audience":"Junior-DS, Curious-browser"},{"id":"career-texas-instruments","type":"career","name":"Texas Instruments","description":"Career portal","category":"Company Lists","url":"https://careers.ti.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, hardware-jobs, semiconductor-industry, tech-careers","summary":"Texas Instruments career portal providing job opportunities in semiconductor and hardware technology. The portal offers positions ranging from data science and analytics roles to hardware engineering positions. Tech economists can explore career paths in the semiconductor industry and understand compensation structures at major hardware companies.","use_cases":"Exploring data science opportunities in the semiconductor industry, Researching career transitions from software to hardware companies","audience":"Junior-DS, Curious-browser"},{"id":"career-micron","type":"career","name":"Micron","description":"Career portal","category":"Company Lists","url":"https://www.micron.com/careers","difficulty":"beginner","prerequisites":"resume-writing, technical-interviewing","topic_tags":"careers, hardware, memory-technology, semiconductor","summary":"Micron's career portal provides job opportunities at one of the world's largest memory and storage technology companies. The portal features positions in data science, engineering, research, and business roles across semiconductor and memory technology development. Tech economists can explore career paths in hardware-focused data analysis and technology research.","use_cases":"Finding data science roles in semiconductor manufacturing and memory technology, Exploring research positions in hardware performance analysis and optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-arm","type":"career","name":"ARM","description":"Career portal","category":"Company Lists","url":"https://careers.arm.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, hardware, semiconductor, tech-jobs, company-research","summary":"ARM's career portal provides job opportunities and company information for one of the world's leading semiconductor and processor design companies. The portal offers insights into roles spanning chip design, software engineering, and hardware development across ARM's global operations. It's valuable for understanding career paths in the semiconductor industry and ARM's specific technical focus areas.","use_cases":"Researching hardware engineering career opportunities at a leading chip design company, Understanding skill requirements and career progression paths in semiconductor industry","audience":"Curious-browser, Junior-DS"},{"id":"career-tsmc","type":"career","name":"TSMC","description":"Career portal","category":"Company Lists","url":"https://www.tsmc.com/english/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, semiconductor-jobs, hardware-careers, tech-recruiting, foundry-industry","summary":"TSMC's career portal provides job opportunities at the world's largest semiconductor foundry. The platform offers positions ranging from process engineering and R&D to supply chain and business operations roles. Tech professionals can explore career paths in advanced chip manufacturing and semiconductor technology development.","use_cases":"Hardware engineer looking for process development roles in semiconductor manufacturing, Recent graduate seeking entry-level positions in chip design or fab operations","audience":"Junior-DS, Curious-browser"},{"id":"career-applied-materials","type":"career","name":"Applied Materials","description":"Career portal","category":"Company Lists","url":"https://www.appliedmaterials.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, hardware, semiconductor, job-portal, materials-science","summary":"Applied Materials is a major semiconductor equipment and materials company with career opportunities in tech hardware, engineering, and data science roles. The career portal provides job listings for positions ranging from R&D engineers to data scientists working on manufacturing optimization and process control. It's particularly relevant for tech economists interested in hardware industry career paths and semiconductor market dynamics.","use_cases":"Exploring career opportunities in semiconductor equipment manufacturing and hardware tech, Researching salary benchmarks and job requirements for hardware-focused data science roles","audience":"Junior-DS, Curious-browser"},{"id":"career-spotify-1","type":"career","name":"Spotify","description":"Career portal","category":"Company Lists","url":"https://www.lifeatspotify.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, tech-company, europe-jobs, experimentation-roles","summary":"Spotify's career portal showcasing job opportunities at the Swedish music streaming giant. The company is known for hiring economists and data scientists for experimentation, causal inference, and product analytics roles. Particularly relevant for those interested in European tech positions with strong emphasis on A/B testing and user behavior analysis.","use_cases":"Looking for economist or data scientist positions at a European tech company with strong experimentation culture, Researching career opportunities at companies that value causal inference and behavioral economics expertise","audience":"Junior-DS, Curious-browser"},{"id":"career-klarna","type":"career","name":"Klarna","description":"Career portal","category":"Company Lists","url":"https://www.klarna.com/careers/","difficulty":"beginner","prerequisites":"basic-SQL, python-fundamentals","topic_tags":"career-opportunities, fintech-jobs, european-companies, klarna-careers","summary":"Klarna's career portal showcasing job opportunities at the Swedish fintech company. The portal provides insights into roles in data science, engineering, and product development at one of Europe's leading buy-now-pay-later platforms. Useful for understanding career paths and technical requirements at a major fintech unicorn.","use_cases":"Junior data scientist researching fintech career opportunities in Europe, Mid-career professional exploring roles at a leading payment technology company","audience":"Junior-DS, Curious-browser"},{"id":"career-revolut","type":"career","name":"Revolut","description":"Career portal","category":"Company Lists","url":"https://www.revolut.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, fintech-jobs, europe-tech, company-research","summary":"Revolut's career portal showcasing job opportunities at the European fintech unicorn. Features roles across data science, engineering, product, and business functions with details on company culture and benefits. Useful for understanding career paths and requirements at a leading digital banking platform.","use_cases":"Researching data science job opportunities at European fintech companies, Understanding skill requirements and career progression at fast-growing tech startups","audience":"Junior-DS, Curious-browser"},{"id":"career-wise","type":"career","name":"Wise","description":"Career portal","category":"Company Lists","url":"https://www.wise.jobs/","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing, interview-preparation","topic_tags":"career-portal, fintech-jobs, europe-opportunities, company-directory","summary":"Wise's career portal showcasing available positions at the international money transfer and fintech company. The portal targets tech professionals interested in working for a European fintech scale-up with strong engineering culture. It provides job listings, company culture information, and application processes for data science, engineering, and product roles.","use_cases":"Junior data scientist looking for first fintech role in London or European offices, Mid-level engineer exploring opportunities at established European fintech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-adyen","type":"career","name":"Adyen","description":"Career portal","category":"Company Lists","url":"https://careers.adyen.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, fintech-jobs, netherlands-careers, european-tech, company-recruitment","summary":"Adyen's career portal showcasing job opportunities at the Dutch fintech payment processing company. The portal provides insights into company culture, available positions, and application processes for tech roles in Europe. Useful for understanding career paths and requirements at a major European fintech player.","use_cases":"Researching data science job opportunities at European fintech companies, Understanding hiring requirements and company culture at payment processing firms","audience":"Junior-DS, Curious-browser"},{"id":"career-n26","type":"career","name":"N26","description":"Career portal","category":"Company Lists","url":"https://n26.com/en/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, fintech-jobs, europe-careers, company-research","summary":"N26's career portal showcasing job opportunities at the German digital banking and fintech company. The portal provides insights into company culture, available positions, and application processes for one of Europe's leading neobanks. Useful for understanding fintech career paths and company expectations in the European market.","use_cases":"Researching fintech career opportunities and company culture at a major European digital bank, Understanding job requirements and skills needed for data science roles in the financial technology sector","audience":"Junior-DS, Curious-browser"},{"id":"career-delivery-hero","type":"career","name":"Delivery Hero","description":"Career portal","category":"Company Lists","url":"https://careers.deliveryhero.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, delivery-hero, europe-jobs, marketplace-company, tech-careers","summary":"Delivery Hero's career portal showcasing job opportunities at the European food delivery marketplace company. Features open positions across engineering, data science, product, and business roles primarily in Berlin and other European locations. Provides insights into company culture, benefits, and application processes for tech professionals interested in the on-demand delivery sector.","use_cases":"Junior data scientists seeking entry-level positions at a major European marketplace platform, Mid-career professionals exploring opportunities in the food delivery and logistics technology space","audience":"Junior-DS, Curious-browser"},{"id":"career-zalando","type":"career","name":"Zalando","description":"Career portal","category":"Company Lists","url":"https://jobs.zalando.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, european-tech, marketplace-jobs, job-search, zalando","summary":"Zalando's career portal showcasing job opportunities at one of Europe's largest online fashion marketplaces. The platform offers insights into roles across data science, engineering, product, and business functions at their Berlin headquarters and other European locations. Provides valuable perspective on career paths and skill requirements at a major European tech company.","use_cases":"Exploring data science and tech roles at a major European marketplace company, Understanding skill requirements and career progression opportunities in European e-commerce","audience":"Junior-DS, Curious-browser"},{"id":"career-blablacar","type":"career","name":"BlaBlaCar","description":"Career portal","category":"Company Lists","url":"https://www.blablacar.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, european-tech, marketplace-companies, job-search, france","summary":"BlaBlaCar's career portal showcasing open positions at Europe's leading carpooling marketplace platform. The company offers opportunities across data science, engineering, product, and business roles in their French headquarters and international offices. This resource helps tech professionals explore career paths at a major European marketplace unicorn.","use_cases":"Researching data science job opportunities at European marketplace companies, Exploring career paths and role requirements at a major French tech unicorn","audience":"Junior-DS, Curious-browser"},{"id":"career-bolt","type":"career","name":"Bolt","description":"Career portal","category":"Company Lists","url":"https://bolt.eu/en/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, job-search, european-marketplace, estonia, company-research","summary":"Bolt is a European mobility and delivery platform company headquartered in Estonia, operating ride-hailing, food delivery, and micro-mobility services across multiple markets. The career portal provides information about job opportunities at one of Europe's prominent tech unicorns. It serves as a resource for understanding career paths and opportunities within the European tech ecosystem.","use_cases":"Researching job opportunities at European tech companies in the mobility/marketplace sector, Understanding career progression and roles available at a major Estonian unicorn company","audience":"Junior-DS, Curious-browser"},{"id":"career-supercell-1","type":"career","name":"Supercell","description":"Career portal","category":"Company Lists","url":"https://supercell.com/en/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, gaming-industry, finland-jobs, tech-careers","summary":"Supercell's career portal showcasing job opportunities at the Finnish mobile gaming company behind Clash of Clans and Clash Royale. The portal provides insights into their company culture, open positions, and application process for data science and analytics roles in the gaming industry. Useful for understanding how a leading European gaming company structures their data teams and what skills they value.","use_cases":"Researching gaming industry career opportunities in Finland, Understanding data science roles at mobile gaming companies","audience":"Junior-DS, Curious-browser"},{"id":"career-king","type":"career","name":"King","description":"Career portal","category":"Company Lists","url":"https://careers.king.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, gaming-industry, europe-jobs, sweden-companies, tech-careers","summary":"King is a major mobile gaming company based in Sweden, best known for Candy Crush Saga and other popular mobile games. The company offers career opportunities across data science, analytics, game development, and business roles throughout Europe. Their career portal provides insights into working at a leading gaming company with significant user data and engagement challenges.","use_cases":"Exploring data science career opportunities in the European gaming industry, Researching company culture and roles at a major mobile gaming platform","audience":"Junior-DS, Curious-browser"},{"id":"career-mistral-ai","type":"career","name":"Mistral AI","description":"Career portal","category":"Company Lists","url":"https://mistral.ai/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, mistral-ai, llm-companies, europe-tech, ai-jobs","summary":"Mistral AI's career portal showcasing open positions at the French AI company specializing in large language models. The portal provides job listings, company culture information, and application processes for roles in AI research, engineering, and business functions. It serves as the primary gateway for professionals seeking to join one of Europe's leading LLM companies.","use_cases":"Junior DS looking for ML engineering roles at European AI startups, Senior researchers seeking positions at cutting-edge LLM companies","audience":"Junior-DS, Senior-DS"},{"id":"career-upwork","type":"career","name":"Upwork","description":"Career portal","category":"Company Lists","url":"https://careers.upwork.com/","difficulty":"beginner","prerequisites":"basic-resume-writing, portfolio-development","topic_tags":"freelance-marketplace, remote-work, career-platform, gig-economy","summary":"Upwork is a major online freelancing platform connecting businesses with independent contractors across various fields including data science, analytics, and tech roles. It serves as a marketplace where professionals can find project-based work, build client relationships, and develop freelance careers. The platform is particularly useful for data scientists and researchers looking to transition to consulting or supplement their income with contract work.","use_cases":"Junior DS looking to gain experience through small data analysis projects while job searching, Senior researcher wanting to monetize expertise through consulting on machine learning implementations","audience":"Junior-DS, Curious-browser"},{"id":"career-toptal","type":"career","name":"Toptal","description":"Career portal","category":"Company Lists","url":"https://www.toptal.com/careers","difficulty":"beginner","prerequisites":"portfolio-building, client-communication","topic_tags":"freelance-marketplace, career-platform, remote-work, consulting","summary":"Toptal is a freelance marketplace connecting businesses with top-tier tech talent, including data scientists and economists. The platform serves as a career portal for experienced professionals seeking high-quality freelance and contract opportunities. It emphasizes rigorous screening processes to maintain a selective network of elite freelancers.","use_cases":"Finding high-paying freelance data science projects while between full-time roles, Building a consulting practice by accessing enterprise clients seeking specialized economic analysis","audience":"Mid-DS, Senior-DS"},{"id":"career-instawork","type":"career","name":"Instawork","description":"Career portal","category":"Company Lists","url":"https://www.instawork.com/careers","difficulty":"beginner","prerequisites":"mobile-app-development, marketplace-economics","topic_tags":"career-portal, gig-economy, marketplace-platform, staffing-solutions, on-demand-work","summary":"Instawork is a marketplace platform connecting businesses with hourly workers for on-demand staffing needs. The company operates in the gig economy space, using ML to match workers with job opportunities in real-time. Tech economists study Instawork as an example of how digital platforms transform labor markets and employment relationships.","use_cases":"Analyzing platform economics and two-sided marketplace dynamics in the gig economy, Studying ML applications in workforce matching and demand forecasting for staffing","audience":"Curious-browser, Junior-DS"},{"id":"career-wonolo","type":"career","name":"Wonolo","description":"Career portal","category":"Company Lists","url":"https://www.wonolo.com/careers","difficulty":"beginner","prerequisites":"basic-networking, job-search-fundamentals","topic_tags":"career-portal, marketplace-companies, tech-jobs, ML-careers, staffing-platforms","summary":"Wonolo is a marketplace platform that connects businesses with temporary workers for on-demand staffing needs. The company uses ML algorithms for matching workers to jobs and optimizing workforce allocation. Tech professionals can explore career opportunities at a company operating in the gig economy space with data science applications.","use_cases":"Researching ML applications in workforce marketplace platforms, Exploring career opportunities at companies using algorithmic matching systems","audience":"Junior-DS, Curious-browser"},{"id":"career-taskrabbit","type":"career","name":"TaskRabbit","description":"Career portal","category":"Company Lists","url":"https://www.taskrabbit.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"job-search, marketplace-economics, gig-economy, career-portal","summary":"TaskRabbit is a marketplace platform connecting freelancers with local service tasks, representing a key case study in gig economy dynamics. The career portal provides insights into platform work opportunities and marketplace labor economics. Tech economists study TaskRabbit to understand two-sided markets, pricing mechanisms, and labor platform design.","use_cases":"Analyzing gig economy labor markets and platform economics, Exploring alternative career paths in the sharing economy","audience":"Junior-DS, Curious-browser"},{"id":"career-care.com","type":"career","name":"Care.com","description":"Career portal","category":"Company Lists","url":"https://www.care.com/careers","difficulty":"beginner","prerequisites":"basic-economics, market-research","topic_tags":"marketplace-economics, platform-business, two-sided-markets, services-industry, company-analysis","summary":"Care.com is a two-sided marketplace connecting families with caregivers for childcare, senior care, and other services. As a prominent example of platform economics, it demonstrates pricing strategies, matching algorithms, and trust mechanisms in service marketplaces. Tech economists study Care.com to understand network effects, transaction costs, and regulatory challenges in care services.","use_cases":"Analyzing marketplace pricing models and commission structures in service platforms, Studying trust and safety mechanisms in two-sided markets with high-stakes transactions","audience":"Curious-browser, Junior-DS"},{"id":"career-catalant","type":"career","name":"Catalant","description":"Career portal","category":"Company Lists","url":"https://www.catalant.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, marketplace-jobs, consulting-careers, B2B-opportunities","summary":"Catalant is a career portal and marketplace connecting professionals with consulting and B2B opportunities. The platform serves as a bridge between talented individuals and companies seeking specialized expertise. It's particularly useful for those looking to transition into consulting roles or find project-based work in the B2B space.","use_cases":"Finding freelance consulting opportunities while transitioning between full-time roles, Exploring B2B marketplace career paths and understanding industry requirements","audience":"Junior-DS, Curious-browser"},{"id":"career-faire","type":"career","name":"Faire","description":"Career portal","category":"Company Lists","url":"https://www.faire.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, marketplace, B2B-pricing, job-opportunities, company-research","summary":"Faire is a B2B marketplace connecting retailers with wholesale brands, known for its data-driven pricing and marketplace economics. The company offers various tech roles focusing on marketplace optimization, pricing algorithms, and B2B platform development. Tech economists can explore opportunities in experimentation, pricing strategy, and marketplace design at this growing unicorn.","use_cases":"Researching companies that work on marketplace pricing and B2B economics problems, Finding job opportunities at tech companies focused on data-driven marketplace optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-flexport","type":"career","name":"Flexport","description":"Career portal","category":"Company Lists","url":"https://www.flexport.com/careers","difficulty":"beginner","prerequisites":"python-pandas, SQL-queries","topic_tags":"careers, logistics, marketplace, data-science-jobs, company-research","summary":"Flexport is a logistics and supply chain technology company that operates a digital freight forwarding platform. The company heavily uses data science and analytics for optimizing supply chain operations, demand forecasting, and marketplace dynamics. Their career portal showcases opportunities for data scientists working on logistics optimization, causal inference problems, and marketplace economics.","use_cases":"Researching data science career opportunities at logistics and marketplace companies, Understanding how tech companies apply data science to supply chain and logistics problems","audience":"Junior-DS, Curious-browser"},{"id":"career-goat-group","type":"career","name":"GOAT Group","description":"Career portal","category":"Company Lists","url":"https://www.goat.com/careers","difficulty":"beginner","prerequisites":"job-search-fundamentals, resume-writing","topic_tags":"career-portal, marketplace-companies, job-search, tech-careers","summary":"GOAT Group is a career portal that aggregates opportunities at marketplace and pricing-focused companies, particularly those in the resale space. It serves as a curated job board for tech professionals looking to work at companies dealing with marketplace dynamics, pricing algorithms, and resale platforms. The portal helps job seekers identify relevant opportunities in the growing marketplace economy sector.","use_cases":"Finding data science roles at companies like eBay, Poshmark, or other resale platforms, Exploring career opportunities specifically in marketplace pricing and economics teams","audience":"Junior-DS, Curious-browser"},{"id":"career-stockx","type":"career","name":"StockX","description":"Career portal","category":"Company Lists","url":"https://careers.stockx.com/","difficulty":"beginner","prerequisites":"basic-web-navigation, career-research-methods","topic_tags":"career-portal, marketplace-jobs, pricing-roles, resale-industry, company-careers","summary":"StockX is a sneaker and streetwear marketplace that operates as a stock market for consumer goods, using dynamic pricing algorithms and authentication processes. The company offers career opportunities for data scientists and economists interested in marketplace dynamics, pricing optimization, and consumer behavior analysis. Their platform provides real-time market data and pricing transparency in the resale market.","use_cases":"Finding data science roles at marketplace companies focused on pricing and authentication, Researching career opportunities in companies that use economic principles for consumer goods trading","audience":"Junior-DS, Curious-browser"},{"id":"career-poshmark","type":"career","name":"Poshmark","description":"Career portal","category":"Company Lists","url":"https://poshmark.com/careers","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-opportunities, marketplace-jobs, resale-platform, job-portal","summary":"Poshmark's career portal provides job listings and opportunities at the social marketplace platform focused on fashion resale. The portal targets candidates interested in working at a tech company that operates in the fashion, e-commerce, and social commerce space. Job seekers can explore roles across engineering, data science, product, marketing, and other functions at this marketplace unicorn.","use_cases":"Job searching for positions at marketplace or e-commerce companies, Researching career opportunities in the fashion-tech or resale industry","audience":"Curious-browser, Junior-DS"},{"id":"career-thredup","type":"career","name":"ThredUp","description":"Career portal","category":"Company Lists","url":"https://careers.thredup.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, marketplace, e-commerce, resale, company-research","summary":"ThredUp is an online marketplace for secondhand clothing and fashion resale. Data scientists and economists can explore career opportunities at this marketplace company while studying their business model of circular economy and consumer behavior. The company offers roles in data science, analytics, and research focused on pricing optimization, recommendation systems, and marketplace dynamics.","use_cases":"Exploring data science career opportunities at marketplace companies, Researching companies in the circular economy and resale space for job applications","audience":"Junior-DS, Curious-browser"},{"id":"career-mercari","type":"career","name":"Mercari","description":"Career portal","category":"Company Lists","url":"https://careers.mercari.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, marketplace-jobs, japan-tech, asia-opportunities, resale-platform","summary":"Mercari is a leading Japanese peer-to-peer marketplace company offering career opportunities in tech roles across Asia. The career portal provides access to positions in data science, engineering, product, and research at one of Japan's most successful resale platforms. Ideal for tech professionals interested in marketplace economics, international experience, and Asian tech markets.","use_cases":"Exploring data science opportunities at Asian marketplace companies, Seeking international tech roles in the Japanese market","audience":"Junior-DS, Curious-browser"},{"id":"career-the-realreal","type":"career","name":"The RealReal","description":"Career portal","category":"Company Lists","url":"https://careers.therealreal.com/","difficulty":"beginner","prerequisites":"basic-statistics, excel-or-spreadsheets","topic_tags":"career-opportunities, marketplace-economics, luxury-resale, pricing-strategies, e-commerce","summary":"The RealReal is a luxury consignment marketplace that offers career opportunities in data science, economics, and analytics roles. The company focuses on authentication, pricing, and marketplace dynamics in the luxury resale market. Their career portal provides insights into roles involving pricing algorithms, demand forecasting, and marketplace optimization.","use_cases":"Looking for entry-level data science positions at marketplace companies, Researching career paths in luxury retail and resale economics","audience":"Junior-DS, Curious-browser"},{"id":"career-reverb","type":"career","name":"Reverb","description":"Career portal","category":"Company Lists","url":"https://reverb.com/page/jobs","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, marketplace, job-search, company-directory","summary":"Reverb is a career portal focused on marketplace companies, providing job listings and company information with emphasis on causal inference roles. It serves as a curated directory for data science and research positions at marketplace and platform companies. The portal helps connect candidates with companies that value rigorous analytical approaches.","use_cases":"Finding data science roles at marketplace companies like Uber, Airbnb, or DoorDash, Researching company culture and technical requirements before applying to platform economy jobs","audience":"Junior-DS, Curious-browser"},{"id":"career-offerup","type":"career","name":"OfferUp","description":"Career portal","category":"Company Lists","url":"https://offerup.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, marketplace, local-commerce, job-opportunities, tech-careers","summary":"OfferUp is a local marketplace company's career portal showcasing job opportunities at a peer-to-peer commerce platform. The portal provides insights into roles at a company focused on connecting local buyers and sellers through mobile technology. It offers perspectives on working in the local marketplace and mobile commerce space.","use_cases":"Exploring job opportunities at marketplace companies to understand required skills and compensation, Researching company culture and technical stack at local commerce platforms before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-costar-group","type":"career","name":"CoStar Group","description":"Career portal","category":"Company Lists","url":"https://www.costargroup.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, real-estate, marketplace, job-portal, economist-roles","summary":"CoStar Group is a leading commercial real estate information and analytics company that regularly hires economists and data scientists. Their career portal showcases opportunities for tech economists working on real estate market analysis, pricing models, and property valuation algorithms. The company offers roles spanning from junior analyst positions to senior economist roles focused on market research and predictive modeling.","use_cases":"Finding economist positions at a major real estate technology company, Exploring career opportunities in real estate analytics and market modeling","audience":"Junior-DS, Curious-browser"},{"id":"career-angi","type":"career","name":"Angi","description":"Career portal","category":"Company Lists","url":"https://www.angi.com/landing/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, marketplace-companies, economist-roles, tech-careers","summary":"Angi's career portal provides job opportunities and career information for tech economists and data scientists at a major marketplace company. The portal showcases economist-titled positions and career paths within the services marketplace industry. It serves as a gateway for exploring career opportunities at companies operating in the home services sector.","use_cases":"Exploring economist job openings at marketplace companies, Researching career paths and role expectations at Angi","audience":"Junior-DS, Curious-browser"},{"id":"career-cargurus","type":"career","name":"CarGurus","description":"Career portal","category":"Company Lists","url":"https://careers.cargurus.com/","difficulty":"beginner","prerequisites":"python-pandas, web-scraping, SQL-basics","topic_tags":"automotive-marketplace, pricing-models, company-careers, tech-jobs, data-science-roles","summary":"CarGurus is a leading automotive marketplace that uses data science and machine learning for vehicle pricing, market analysis, and consumer recommendations. The company offers career opportunities for data scientists, engineers, and analysts working on marketplace dynamics, pricing algorithms, and consumer behavior analysis. Their career portal provides insights into roles involving automotive data, marketplace optimization, and recommendation systems.","use_cases":"Finding data science roles at automotive marketplace companies, Learning about career paths in marketplace pricing and recommendation systems","audience":"Junior-DS, Curious-browser"},{"id":"career-cars.com","type":"career","name":"Cars.com","description":"Career portal","category":"Company Lists","url":"https://www.cars.com/careers/","difficulty":"beginner","prerequisites":"web-scraping, python-requests","topic_tags":"career-portal, automotive-marketplace, job-search, company-research","summary":"Cars.com is a major automotive marketplace and the career portal section provides job opportunities within the company. Tech economists and data scientists can explore career opportunities at a leading automotive platform company. The portal offers insights into working at a company that operates in the intersection of automotive retail and digital marketplace economics.","use_cases":"Researching career opportunities at automotive marketplace companies, Understanding organizational structure and roles at Cars.com for competitive analysis","audience":"Curious-browser, Junior-DS"},{"id":"career-carvana","type":"career","name":"Carvana","description":"Career portal","category":"Company Lists","url":"https://www.carvana.com/careers/jobs","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-opportunities, automotive-industry, marketplace-economics, job-portal","summary":"Carvana's career portal provides job opportunities at the online car marketplace company. It's useful for data scientists and economists interested in marketplace dynamics, automotive industry analytics, and e-commerce operations. The portal offers insights into roles involving pricing algorithms, demand forecasting, and customer behavior analysis in the used car market.","use_cases":"Finding data science roles focused on automotive marketplace economics and pricing optimization, Exploring career opportunities in e-commerce platforms with complex logistics and inventory management","audience":"Junior-DS, Curious-browser"},{"id":"career-truecar","type":"career","name":"TrueCar","description":"Career portal","category":"Company Lists","url":"https://www.truecar.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, marketplace, automotive, job-search, company-research","summary":"TrueCar's career portal showcasing job opportunities at the online automotive marketplace company. The portal provides insights into company culture, available positions, and application processes for roles in data science, engineering, product, and business functions. Useful for understanding how marketplace companies structure their teams and what skills they prioritize.","use_cases":"Researching data science career opportunities at marketplace companies in the automotive sector, Understanding team structures and role requirements at TrueCar to prepare for interviews or similar companies","audience":"Junior-DS, Curious-browser"},{"id":"career-turo","type":"career","name":"Turo","description":"Career portal","category":"Company Lists","url":"https://turo.com/us/en/careers","difficulty":"beginner","prerequisites":"basic-economics, market-research-methods","topic_tags":"career-opportunities, marketplace-economics, pricing-strategy, automotive-industry, company-research","summary":"Turo is a peer-to-peer car sharing marketplace that operates as the 'Airbnb for cars,' connecting car owners with renters. The company offers career opportunities for tech economists interested in marketplace dynamics, pricing algorithms, and sharing economy business models. Their platform presents interesting challenges around dynamic pricing, supply-demand matching, and trust mechanisms in two-sided markets.","use_cases":"Researching career opportunities at marketplace companies focused on pricing and economics, Understanding business models and economic challenges in the peer-to-peer automotive rental space","audience":"Junior-DS, Curious-browser"},{"id":"career-houzz","type":"career","name":"Houzz","description":"Career portal","category":"Company Lists","url":"https://www.houzz.com/jobs","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, marketplace, home-improvement, job-listings, company-research","summary":"Houzz is a home improvement and design marketplace company that operates career portals for job seekers interested in the home design, renovation, and e-commerce space. The platform connects homeowners with home improvement professionals and sells home goods, making it relevant for data scientists interested in marketplace dynamics, recommendation systems, and two-sided market economics. Their career page provides insights into roles at a major home-focused marketplace platform.","use_cases":"Researching data science opportunities at marketplace companies focused on home improvement, Understanding career paths and role requirements at a two-sided platform connecting consumers with service providers","audience":"Junior-DS, Curious-browser"},{"id":"career-spothero","type":"career","name":"SpotHero","description":"Career portal","category":"Company Lists","url":"https://spothero.com/careers","difficulty":"beginner","prerequisites":"basic-economics, marketplace-concepts","topic_tags":"marketplace, pricing, parking, career-opportunities, company-research","summary":"SpotHero is a marketplace platform that connects drivers with parking spot owners, using dynamic pricing algorithms and location-based optimization. The company offers career opportunities for data scientists and economists working on pricing strategies, demand forecasting, and marketplace optimization. This resource provides insights into tech roles at a parking marketplace company.","use_cases":"Researching career opportunities at marketplace companies focused on urban mobility, Understanding business models and data science applications in parking/transportation startups","audience":"Junior-DS, Curious-browser"},{"id":"career-nextdoor","type":"career","name":"Nextdoor","description":"Career portal","category":"Company Lists","url":"https://about.nextdoor.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, tech-companies, marketplace, local-networks","summary":"Nextdoor's career portal provides job opportunities at a leading neighborhood-focused social networking platform. The company specializes in hyperlocal marketplace and community features, offering roles in data science, engineering, and product development. Tech professionals can explore positions working with location-based data, recommendation systems, and community engagement metrics.","use_cases":"Searching for data science roles at a social networking company focused on local communities, Exploring career opportunities in marketplace and recommendation algorithm development","audience":"Junior-DS, Curious-browser"},{"id":"career-hopper","type":"career","name":"Hopper","description":"Career portal","category":"Company Lists","url":"https://www.hopper.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"job-search, career-portal, travel-industry, economist-roles, marketplace-jobs","summary":"Hopper is a career portal focused on travel industry opportunities, particularly for roles with economist titles. It serves as a marketplace connecting job seekers with travel-tech companies looking for analytical talent. The platform specializes in economics and data science positions within the travel and transportation sector.","use_cases":"Finding economist or data scientist roles at travel companies like Airbnb, Uber, or booking platforms, Exploring career opportunities that combine economics expertise with travel industry applications","audience":"Junior-DS, Curious-browser"},{"id":"career-tripadvisor","type":"career","name":"Tripadvisor","description":"Career portal","category":"Company Lists","url":"https://careers.tripadvisor.com/","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-opportunities, marketplace-company, travel-industry, job-portal","summary":"Tripadvisor's career portal showcasing job opportunities at one of the world's largest travel marketplace companies. Provides insights into roles across data science, engineering, product, and business functions within the travel and hospitality tech sector. Useful for understanding career paths and requirements at a major marketplace platform company.","use_cases":"Exploring data science career opportunities at travel marketplace companies, Understanding skill requirements and role expectations at Tripadvisor","audience":"Junior-DS, Curious-browser"},{"id":"career-just-eat-takeaway","type":"career","name":"Just Eat Takeaway","description":"Career portal","category":"Company Lists","url":"https://careers.justeattakeaway.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, food-delivery, marketplace-jobs, europe-tech, company-careers","summary":"Just Eat Takeaway's career portal showcasing available positions at one of Europe's largest food delivery platforms. The portal provides insights into roles across data science, engineering, product, and operations within the marketplace ecosystem. Useful for understanding career paths and skill requirements at major European tech companies.","use_cases":"Researching data science career opportunities at European marketplace companies, Understanding skill requirements and job descriptions for food delivery platform roles","audience":"Junior-DS, Curious-browser"},{"id":"career-grubhub","type":"career","name":"Grubhub","description":"Career portal","category":"Company Lists","url":"https://www.grubhub.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, marketplace, food-delivery, company-research","summary":"Grubhub's career portal provides job listings and company information for the food delivery marketplace. It's useful for data scientists and economists interested in working on marketplace dynamics, demand forecasting, and logistics optimization problems. The portal offers insight into role requirements and company culture at a major tech platform.","use_cases":"Researching data science roles at marketplace companies, Understanding tech job requirements in food delivery industry","audience":"Junior-DS, Curious-browser"},{"id":"career-gopuff","type":"career","name":"Gopuff","description":"Career portal","category":"Company Lists","url":"https://gopuff.com/go/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-applications, marketplace-company, delivery-tech, gopuff","summary":"Gopuff's career portal showcasing job opportunities at the instant delivery marketplace company. Lists current openings across data science, engineering, operations, and business roles at a major tech logistics company. Useful for understanding career paths and requirements in the delivery/marketplace tech sector.","use_cases":"Exploring data science roles at delivery marketplace companies, Researching job requirements and career progression at Gopuff","audience":"Junior-DS, Curious-browser"},{"id":"career-goodrx","type":"career","name":"GoodRx","description":"Career portal","category":"Company Lists","url":"https://www.goodrx.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, healthcare-tech, marketplace-companies, job-search","summary":"GoodRx's career portal provides job opportunities at a leading healthcare marketplace company that focuses on prescription drug pricing transparency. The company offers roles across data science, engineering, product, and business functions for professionals interested in healthcare technology. This resource is valuable for understanding career paths in healthcare tech and marketplace business models.","use_cases":"Exploring data science roles at healthcare technology companies, Researching career opportunities in marketplace pricing and economics","audience":"Junior-DS, Curious-browser"},{"id":"career-zocdoc","type":"career","name":"Zocdoc","description":"Career portal","category":"Company Lists","url":"https://www.zocdoc.com/about/careers-list","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, marketplace, healthcare-tech, job-opportunities, company-research","summary":"Zocdoc's career portal provides job opportunities at a leading healthcare marketplace platform. The company connects patients with healthcare providers through technology, offering roles in data science, engineering, product, and business functions. This resource is valuable for understanding career paths in healthcare technology and marketplace business models.","use_cases":"Exploring data science roles at healthcare technology companies, Researching marketplace business models and team structures for career transitions","audience":"Junior-DS, Curious-browser"},{"id":"career-teladoc","type":"career","name":"Teladoc","description":"Career portal","category":"Company Lists","url":"https://www.teladochealth.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, telemedicine, healthcare-tech, job-opportunities","summary":"Teladoc's career portal showcasing job opportunities at a leading telemedicine and virtual healthcare platform. The company operates digital health marketplaces connecting patients with healthcare providers remotely. Tech economists can explore roles in data science, product analytics, and marketplace optimization within the rapidly growing telehealth industry.","use_cases":"Exploring data science career opportunities in healthcare technology and telemedicine platforms, Researching company culture and tech stack at a major digital health marketplace before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-hims-&-hers","type":"career","name":"Hims & Hers","description":"Career portal","category":"Company Lists","url":"https://www.hims.com/careers-professionals","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"healthcare-marketplace, career-opportunities, company-research, digital-health, tech-careers","summary":"Career portal for Hims & Hers, a direct-to-consumer telehealth and wellness company operating a digital marketplace for health products and services. The portal provides information about job opportunities, company culture, and career paths within the digital healthcare space. Useful for data scientists and researchers interested in healthcare technology, marketplace dynamics, and consumer health analytics roles.","use_cases":"Exploring data science career opportunities in digital health and telehealth marketplaces, Researching company culture and team structure when considering healthcare technology roles","audience":"Junior-DS, Curious-browser"},{"id":"career-maven-clinic","type":"career","name":"Maven Clinic","description":"Career portal","category":"Company Lists","url":"https://www.mavenclinic.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, healthcare-tech, job-opportunities, marketplace-careers","summary":"Maven Clinic is a digital health platform specializing in women's and family health services. Their career portal showcases opportunities for data scientists and tech professionals in the healthcare marketplace space. The company offers insights into working with health outcome metrics, patient engagement analytics, and healthcare product development.","use_cases":"Exploring data science roles in digital health companies, Understanding career paths in healthcare technology and marketplace analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-included-health","type":"career","name":"Included Health","description":"Career portal","category":"Company Lists","url":"https://www.includedhealth.com/careers/tech-jobs","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, healthcare-tech, job-opportunities, company-research","summary":"Included Health is a healthcare technology company that provides virtual care and navigation services. Their career portal offers job opportunities for data scientists, engineers, and other tech professionals interested in applying their skills to healthcare problems. The portal provides insights into the company's mission, culture, and available positions across various technical disciplines.","use_cases":"Data scientist looking for healthcare tech opportunities to apply ML to patient outcomes, Recent graduate researching companies that combine technology with meaningful social impact","audience":"Junior-DS, Curious-browser"},{"id":"career-deliveroo","type":"career","name":"Deliveroo","description":"Career portal","category":"Company Lists","url":"https://careers.deliveroo.co.uk/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, job-applications, marketplace-economics, food-delivery, europe","summary":"Deliveroo's career portal showcasing job opportunities at the UK-based food delivery marketplace. The company offers economist and data scientist roles focused on marketplace dynamics, pricing optimization, and platform economics. Useful for understanding how tech companies in the gig economy structure their analytics teams.","use_cases":"Exploring economist roles at European marketplace companies, Researching job requirements and skills needed for food delivery platform analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-glovo","type":"career","name":"Glovo","description":"Career portal","category":"Company Lists","url":"https://jobs.glovoapp.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, marketplace-jobs, food-delivery, europe-opportunities","summary":"Glovo is a European on-demand delivery marketplace headquartered in Spain that connects customers with local businesses for food and goods delivery. The career portal provides job opportunities across various functions including data science, engineering, product, and operations roles. Tech economists can explore positions in a high-growth marketplace environment with rich transactional data and multi-sided platform dynamics.","use_cases":"Finding data science or analytics roles at a European marketplace company, Exploring career opportunities in the on-demand delivery industry","audience":"Junior-DS, Curious-browser"},{"id":"career-back-market","type":"career","name":"Back Market","description":"Career portal","category":"Company Lists","url":"https://www.backmarket.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-opportunities, marketplace-jobs, europe-tech, circular-economy, refurbished-electronics","summary":"Back Market is a leading European marketplace for refurbished electronics, offering career opportunities in a fast-growing circular economy company. The company operates across multiple markets and provides roles spanning data science, engineering, product, and business functions. Tech professionals can find positions working on marketplace optimization, recommendation systems, supply chain analytics, and sustainability metrics.","use_cases":"Junior data scientists seeking marketplace experience in European tech ecosystem, Mid-level professionals wanting to work on sustainability-focused tech problems in circular economy","audience":"Junior-DS, Mid-DS"},{"id":"career-vinted","type":"career","name":"Vinted","description":"Career portal","category":"Company Lists","url":"https://careers.vinted.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, marketplace-economics, european-tech, job-opportunities","summary":"Vinted is a Lithuanian-based marketplace platform focused on second-hand fashion and resale economics. The company's career portal provides opportunities for tech economists and data scientists interested in marketplace dynamics, consumer behavior, and circular economy models. It's particularly relevant for those interested in European tech companies and sustainable commerce platforms.","use_cases":"Exploring career opportunities at a leading European marketplace company, Researching company culture and roles at a circular economy tech platform","audience":"Curious-browser, Junior-DS"},{"id":"career-vestiaire-collective","type":"career","name":"Vestiaire Collective","description":"Career portal","category":"Company Lists","url":"https://careers.vestiairecollective.com/","difficulty":"beginner","prerequisites":"job-application-basics, resume-writing","topic_tags":"career-opportunities, marketplace-companies, european-tech, job-portal, fashion-tech","summary":"Vestiaire Collective is a French luxury fashion resale marketplace that operates globally, connecting buyers and sellers of pre-owned designer items. The company offers career opportunities for data scientists and economists working on marketplace dynamics, pricing algorithms, and consumer behavior analysis. Their career portal provides insights into working at a European tech company focused on circular economy and sustainable fashion.","use_cases":"Exploring data science opportunities at European marketplace companies, Researching career paths in fashion-tech and circular economy platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-grab","type":"career","name":"Grab","description":"Career portal","category":"Company Lists","url":"https://grab.careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, asia-tech, marketplace-jobs, singapore-careers","summary":"Grab's career portal provides job opportunities at Southeast Asia's leading super-app company. The portal offers positions across data science, engineering, product, and business functions within Grab's ride-hailing, food delivery, and fintech ecosystem. It serves as a gateway for tech professionals seeking roles in Asia's rapidly growing digital economy.","use_cases":"Data scientists looking for marketplace or two-sided platform experience in Southeast Asian markets, Tech professionals wanting to transition into fintech, mobility, or super-app business models","audience":"Junior-DS, Curious-browser"},{"id":"career-goto-group","type":"career","name":"GoTo Group","description":"Career portal","category":"Company Lists","url":"https://career.gojek.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, tech-jobs, southeast-asia, marketplace-companies","summary":"GoTo Group's career portal showcasing job opportunities at one of Southeast Asia's largest technology companies. The portal provides insights into roles across their super-app ecosystem including Gojek, Tokopedia, and other marketplace platforms. Useful for understanding career paths and compensation structures at major Asian tech companies.","use_cases":"Researching job opportunities at Southeast Asian marketplace companies, Understanding organizational structure and role types at super-app platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-shopee","type":"career","name":"Shopee","description":"Career portal","category":"Company Lists","url":"https://careers.shopee.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-opportunities, e-commerce, asia-pacific, job-portal","summary":"Shopee's career portal showcasing job opportunities at one of Southeast Asia's largest e-commerce platforms. The portal provides insights into roles across data science, engineering, product, and business functions at a major marketplace company. Useful for understanding career paths and requirements at leading Asian tech companies.","use_cases":"Exploring data science opportunities at major Southeast Asian e-commerce companies, Researching career requirements and growth paths in Asian tech marketplace industry","audience":"Junior-DS, Curious-browser"},{"id":"career-coupang","type":"career","name":"Coupang","description":"Career portal","category":"Company Lists","url":"https://www.coupang.jobs/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, e-commerce-jobs, asia-tech, marketplace-careers, korea-jobs","summary":"Coupang is South Korea's largest e-commerce platform, often called the 'Amazon of Korea,' offering career opportunities in tech, data science, and operations. The company provides roles across engineering, analytics, and business functions in a fast-growing Asian marketplace environment. Tech professionals can explore positions in machine learning, data engineering, and product analytics at one of Asia's most prominent e-commerce companies.","use_cases":"Exploring data science career opportunities at major Asian e-commerce companies, Researching tech job markets in South Korea and Asia-Pacific region","audience":"Junior-DS, Mid-DS"},{"id":"career-flipkart","type":"career","name":"Flipkart","description":"Career portal","category":"Company Lists","url":"https://www.flipkartcareers.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, e-commerce, india-jobs, marketplace-careers, tech-jobs","summary":"Flipkart's career portal provides job opportunities at one of India's largest e-commerce platforms. The portal offers positions across data science, engineering, product management, and business roles within the marketplace ecosystem. It serves as an entry point for tech professionals looking to work in India's rapidly growing e-commerce sector.","use_cases":"Applying for data scientist roles at major Indian e-commerce companies, Exploring career opportunities in Asian marketplace platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-swiggy","type":"career","name":"Swiggy","description":"Career portal","category":"Company Lists","url":"https://careers.swiggy.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, food-delivery, marketplace, india, job-portal","summary":"Swiggy is India's leading food delivery platform and major tech employer in the marketplace economy. Their career portal showcases opportunities in data science, engineering, and product roles within the food-tech ecosystem. This resource is valuable for understanding career paths and skill requirements at leading Asian marketplace companies.","use_cases":"Researching data science roles at major Indian tech companies, Understanding skill requirements and career progression at marketplace platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-zomato","type":"career","name":"Zomato","description":"Career portal","category":"Company Lists","url":"https://www.zomato.com/careers","difficulty":"beginner","prerequisites":"basic-web-navigation, career-planning","topic_tags":"career-opportunities, food-tech, marketplace-economics, india-market, tech-jobs","summary":"Zomato's career portal showcasing job opportunities at one of India's leading food delivery and restaurant discovery platforms. The portal provides insights into roles across data science, engineering, product, and business functions at a major Asian marketplace company. Useful for understanding career paths and skill requirements in the food-tech sector.","use_cases":"Exploring data science job opportunities at Indian food-tech companies, Researching skill requirements and career paths in marketplace platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-mercado-libre","type":"career","name":"Mercado Libre","description":"Career portal","category":"Company Lists","url":"https://careers-meli.mercadolibre.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, job-search, latin-america, e-commerce, marketplace","summary":"Mercado Libre is Latin America's largest e-commerce and fintech company, offering data science and tech roles across Argentina, Brazil, Mexico and other LatAm markets. The career portal provides opportunities for analysts, data scientists, engineers, and researchers working on marketplace optimization, payments, logistics, and machine learning systems. It's particularly valuable for those interested in emerging market dynamics and large-scale platform economics.","use_cases":"Junior data scientists seeking entry-level positions at a major Latin American tech company, Researchers interested in marketplace economics and payment systems in emerging markets","audience":"Junior-DS, Curious-browser"},{"id":"career-rappi","type":"career","name":"Rappi","description":"Career portal","category":"Company Lists","url":"https://rappi.wd12.myworkdayjobs.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, marketplace-jobs, latam-tech, super-app, colombia","summary":"Rappi is a Colombian super-app company that operates across Latin America, offering on-demand delivery services and marketplace solutions. As one of LatAm's major tech unicorns, Rappi provides career opportunities for data scientists, engineers, and analysts working on marketplace dynamics, logistics optimization, and platform economics. The company is known for its data-driven approach to expansion and operations across multiple verticals.","use_cases":"Finding data science roles at Latin American tech companies, Exploring career opportunities in marketplace and super-app platforms","audience":"Junior-DS, Mid-DS"},{"id":"career-alibaba","type":"career","name":"Alibaba","description":"Career portal","category":"Company Lists","url":"https://careers.alibaba.com/","difficulty":"beginner","prerequisites":"resume-writing, basic-mandarin","topic_tags":"career-portal, china-tech, e-commerce-jobs, asia-opportunities","summary":"Career portal for Alibaba Group, one of China's largest e-commerce and cloud computing companies. Provides job listings, company information, and application processes for roles across their ecosystem including Taobao, Tmall, and Alibaba Cloud. Useful for tech professionals interested in Asia-Pacific market opportunities and Chinese tech industry experience.","use_cases":"Researching data science career opportunities at major Chinese tech companies, Understanding Alibaba's business structure and job requirements before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-match-group","type":"career","name":"Match Group","description":"Career portal","category":"Company Lists","url":"https://join.matchgroupcareers.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, dating-marketplace, tech-jobs, company-careers","summary":"Match Group's career portal provides job opportunities at the company behind dating platforms like Tinder, Hinge, and OkCupid. The portal offers roles across data science, engineering, product, and research teams working on marketplace dynamics, recommendation systems, and user matching algorithms. This is particularly relevant for tech economists interested in two-sided markets and behavioral economics applications.","use_cases":"Data scientists seeking roles in marketplace economics and matching algorithms at dating platforms, Researchers interested in applying behavioral economics and network effects in consumer tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-bumble","type":"career","name":"Bumble","description":"Career portal","category":"Company Lists","url":"https://team.bumble.com/","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, dating-industry, job-search, economist-roles, company-research","summary":"Bumble's career portal showcasing job opportunities at the dating app company. Lists economist and data science positions along with company culture information. Useful for understanding how tech companies in the dating space structure their economics and analytics teams.","use_cases":"Researching economist job opportunities at dating/social media companies, Understanding how dating apps structure their economics and data science teams","audience":"Junior-DS, Curious-browser"},{"id":"career-hinge","type":"career","name":"Hinge","description":"Career portal","category":"Company Lists","url":"https://hinge.co/careers","difficulty":"beginner","prerequisites":"product-analytics, SQL-basics","topic_tags":"dating-apps, tech-careers, product-companies, job-search","summary":"Career portal for Hinge, the popular dating app company known for its relationship-focused approach and data-driven product development. Provides information about job opportunities, company culture, and roles in product, engineering, data science, and marketing teams. Useful for understanding how a major consumer tech company approaches matching algorithms, user engagement, and growth metrics.","use_cases":"Research data science roles at consumer tech companies focusing on recommendation systems, Understand career paths in product analytics for dating/social apps","audience":"Junior-DS, Curious-browser"},{"id":"career-grindr","type":"career","name":"Grindr","description":"Career portal","category":"Company Lists","url":"https://www.grindr.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, dating-app, tech-jobs, company-research","summary":"Grindr's career portal showcasing job opportunities at the popular dating app company. This resource helps tech professionals explore roles at a consumer-facing social platform with unique data science and product challenges. Useful for understanding career paths in the dating app industry and social network companies.","use_cases":"Researching data scientist positions at consumer social apps, Exploring career opportunities in the dating app industry","audience":"Junior-DS, Curious-browser"},{"id":"career-warner-bros.-discovery","type":"career","name":"Warner Bros. Discovery","description":"Career portal","category":"Company Lists","url":"https://careers.wbd.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, streaming-industry, media-jobs, data-science-careers","summary":"Warner Bros. Discovery's career portal showcasing job opportunities at the media and streaming conglomerate. This resource helps data scientists and researchers explore roles in entertainment analytics, content optimization, and streaming platform development. The portal provides insights into how tech roles support major media operations and content strategy.","use_cases":"Data scientists looking for roles in streaming analytics and content recommendation systems, Researchers interested in transitioning from academia to entertainment industry applications","audience":"Junior-DS, Curious-browser"},{"id":"career-nbcuniversal-peacock","type":"career","name":"NBCUniversal/Peacock","description":"Career portal","category":"Company Lists","url":"https://www.nbcunicareers.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, streaming-media, job-opportunities, tech-careers","summary":"NBCUniversal/Peacock's career portal showcasing job opportunities at the streaming media company. This platform provides insights into roles across data science, engineering, content analytics, and media technology at one of the major streaming services. Useful for understanding career paths and job requirements in the streaming media industry.","use_cases":"Exploring data science and analytics roles at a major streaming platform, Researching career opportunities in media technology and content recommendation systems","audience":"Junior-DS, Curious-browser"},{"id":"career-roku","type":"career","name":"Roku","description":"Career portal","category":"Company Lists","url":"https://www.weareroku.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, streaming-industry, job-portal, tech-jobs","summary":"Roku's career portal showcases job opportunities at the streaming platform company, with roles spanning data science, economics, engineering, and business functions. The portal provides insights into Roku's workplace culture, benefits, and hiring process for professionals interested in the streaming media industry. It serves as a gateway for tech economists and data scientists to explore career paths in connected TV and advertising technology.","use_cases":"Researching data scientist positions at streaming companies to understand required skills and compensation, Exploring economist roles in ad-tech and connected TV platforms for career transition planning","audience":"Junior-DS, Curious-browser"},{"id":"career-vimeo","type":"career","name":"Vimeo","description":"Career portal","category":"Company Lists","url":"https://vimeo.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, streaming-jobs, video-technology, company-research","summary":"Vimeo's career portal showcasing job opportunities at the video streaming and hosting platform. Lists current openings across engineering, data science, product, and other roles at Vimeo. Useful for understanding role requirements and company culture in the video technology space.","use_cases":"Researching data science positions at video streaming companies, Understanding skill requirements for roles in video technology industry","audience":"Junior-DS, Curious-browser"},{"id":"career-fubotv","type":"career","name":"FuboTV","description":"Career portal","category":"Company Lists","url":"https://careers.fubo.tv/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, streaming-industry, sports-tech, job-search","summary":"FuboTV's career portal showcasing job opportunities at the sports-focused streaming platform. This resource provides insights into roles at a tech company specializing in live sports streaming and entertainment technology. Useful for understanding career paths in the streaming media industry and sports technology sector.","use_cases":"Exploring data science roles at streaming media companies, Researching sports technology industry career opportunities","audience":"Junior-DS, Curious-browser"},{"id":"career-dazn","type":"career","name":"DAZN","description":"Career portal","category":"Company Lists","url":"https://careers.dazn.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, streaming-industry, sports-analytics, european-market","summary":"DAZN is a global sports streaming platform that offers career opportunities across data science, engineering, and analytics roles. The company focuses on sports content delivery and user experience optimization, making it relevant for professionals interested in media technology and sports analytics. Their career portal provides access to positions in multiple European markets and other global locations.","use_cases":"Finding data science roles at a sports streaming company, Exploring career opportunities in European tech companies focused on media and entertainment","audience":"Junior-DS, Curious-browser"},{"id":"career-audible","type":"career","name":"Audible","description":"Career portal","category":"Company Lists","url":"https://www.audiblecareers.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, audio-streaming, job-opportunities, economist-roles","summary":"Audible's career portal showcasing job opportunities at the Amazon-owned audiobook and podcast platform. The portal features economist positions and other roles within their data science and research teams. Tech economists can explore opportunities in audio content recommendation systems, pricing strategies, and marketplace economics.","use_cases":"Finding economist or data scientist positions at a major audio streaming platform, Researching career opportunities in digital content and entertainment economics","audience":"Junior-DS, Curious-browser"},{"id":"career-siriusxm-pandora","type":"career","name":"SiriusXM/Pandora","description":"Career portal","category":"Company Lists","url":"https://careers.siriusxm.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, audio-streaming, music-tech, job-opportunities","summary":"SiriusXM/Pandora's career portal showcasing job opportunities at one of the largest audio entertainment companies. Features roles in data science, economics, product analytics, and engineering focused on personalization, recommendation systems, and audio content optimization. Provides insight into how tech economists work in the music and audio streaming industry.","use_cases":"Exploring data science career opportunities in the music/audio streaming industry, Researching company culture and technical challenges at SiriusXM/Pandora before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-iheartmedia","type":"career","name":"iHeartMedia","description":"Career portal","category":"Company Lists","url":"https://www.iheartmedia.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, audio-industry, media-company, job-opportunities","summary":"iHeartMedia's career portal provides job opportunities at one of the largest audio and podcast companies in the world. The platform offers positions across data science, engineering, product, and business roles within the digital audio and podcast ecosystem. This is valuable for tech professionals interested in working with audio data, recommendation systems, and large-scale media platforms.","use_cases":"Finding data science roles focused on audio analytics and podcast recommendation algorithms, Exploring product management opportunities in digital audio and streaming platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-soundcloud","type":"career","name":"SoundCloud","description":"Career portal","category":"Company Lists","url":"https://careers.soundcloud.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, audio-streaming, music-technology, job-listings","summary":"SoundCloud's career portal showcasing job opportunities at the audio streaming and music sharing platform. The portal provides insights into roles in audio engineering, recommendation systems, content moderation, and music technology. Useful for understanding career paths in audio-focused tech companies and the intersection of music and data science.","use_cases":"Exploring data science roles focused on audio processing and music recommendation algorithms, Learning about career opportunities in music streaming platforms and audio technology companies","audience":"Junior-DS, Curious-browser"},{"id":"career-scopely","type":"career","name":"Scopely","description":"Career portal","category":"Company Lists","url":"https://www.scopely.com/en/join-us","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, gaming-industry, mobile-games, job-applications, tech-careers","summary":"Scopely is a mobile gaming company's career portal featuring job opportunities in data science, analytics, and engineering roles within the gaming industry. The portal provides insights into working at a major mobile game publisher and developer. It serves as a gateway for tech professionals interested in applying data skills to gaming and entertainment.","use_cases":"Exploring data science career opportunities in the gaming industry, Researching company culture and role requirements at mobile gaming companies","audience":"Junior-DS, Curious-browser"},{"id":"career-draftkings","type":"career","name":"DraftKings","description":"Career portal","category":"Company Lists","url":"https://careers.draftkings.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, gaming-industry, sports-betting, economist-jobs, job-search","summary":"DraftKings career portal featuring job opportunities at the daily fantasy sports and sports betting company. The portal showcases economist, data scientist, and analytics roles within the gaming industry. Provides insights into working at a major sports betting technology company.","use_cases":"Exploring economist and data science career opportunities in the gaming/sports betting industry, Researching company culture and job requirements at DraftKings before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-zoom","type":"career","name":"Zoom","description":"Career portal","category":"Company Lists","url":"https://careers.zoom.us/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-applications, tech-careers, remote-work","summary":"Zoom's career portal provides job opportunities at the video communications company. The portal lists open positions across engineering, data science, product, and business functions with options for remote and hybrid work arrangements.","use_cases":"Searching for data science or engineering roles at a major tech communication platform, Exploring remote work opportunities at an established video conferencing company","audience":"Junior-DS, Curious-browser"},{"id":"career-slack","type":"career","name":"Slack","description":"Career portal","category":"Company Lists","url":"https://slack.com/careers","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, job-search, company-research, tech-careers","summary":"Slack's career portal provides information about job opportunities, company culture, and application processes at the workplace communication platform. It serves as a resource for tech professionals interested in roles at Slack across engineering, data science, product, and other functions. The portal includes job listings, team information, and insights into Slack's work environment and values.","use_cases":"Researching data scientist positions at Slack to understand role requirements and team structure, Learning about Slack's engineering culture and remote work policies before applying for technical roles","audience":"Junior-DS, Curious-browser"},{"id":"career-notion-1","type":"career","name":"Notion","description":"Career portal","category":"Company Lists","url":"https://www.notion.com/careers","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, job-search, professional-development, tech-careers, productivity-tools","summary":"Notion's career portal provides resources and templates for job searching, career planning, and professional development in tech. It offers structured frameworks for tracking applications, organizing interview preparation, and managing career goals. The platform is particularly useful for those seeking systematic approaches to career advancement.","use_cases":"Organizing job applications and tracking interview progress across multiple tech companies, Creating a structured career development plan with goal tracking and skill gap analysis","audience":"Junior-DS, Curious-browser"},{"id":"career-figma","type":"career","name":"Figma","description":"Career portal","category":"Company Lists","url":"https://www.figma.com/careers/","difficulty":"beginner","prerequisites":"portfolio-creation, design-systems","topic_tags":"career-resources, design-tools, product-design, user-interface, job-opportunities","summary":"Figma's career portal provides job opportunities at the leading collaborative design platform company. The portal showcases roles in product design, engineering, research, and business functions at a company known for revolutionizing design workflows. Ideal for professionals interested in joining a design-forward tech company that values collaboration and user experience.","use_cases":"Exploring design and product roles at a cutting-edge design tool company, Finding engineering positions at a company with strong design culture and collaborative values","audience":"Curious-browser, Junior-DS"},{"id":"career-clubhouse","type":"career","name":"Clubhouse","description":"Career portal","category":"Company Lists","url":"https://www.clubhouse.com/jobs","difficulty":"beginner","prerequisites":"networking-fundamentals, career-planning","topic_tags":"career-development, networking, audio-social, job-search","summary":"Clubhouse is an audio-based social networking platform that became popular for professional networking and industry discussions. Tech professionals use it to join conversations about data science, AI, and tech careers. The platform offers opportunities to learn from industry experts and build professional connections through live audio discussions.","use_cases":"Joining data science career advice rooms to learn about industry trends and job opportunities, Participating in tech company culture discussions to research potential employers before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-patreon","type":"career","name":"Patreon","description":"Career portal","category":"Company Lists","url":"https://www.patreon.com/careers","difficulty":"beginner","prerequisites":"basic-web-navigation, resume-writing","topic_tags":"career-portal, creator-economy, job-search, company-research","summary":"Patreon's career portal showcasing job opportunities at the creator economy platform. The portal provides insights into company culture, values, and open positions for technologists interested in subscription-based creator monetization. Useful for understanding how a leading creator economy company structures its technical teams and product development.","use_cases":"Researching Patreon as a potential employer in the creator economy space, Understanding technical roles and skills needed at subscription platform companies","audience":"Junior-DS, Curious-browser"},{"id":"career-substack","type":"career","name":"Substack","description":"Career portal","category":"Company Lists","url":"https://substack.com/jobs","difficulty":"beginner","prerequisites":"email-marketing, content-creation","topic_tags":"newsletter-platforms, creator-economy, content-monetization, career-transition, writing-careers","summary":"Substack is a newsletter platform that enables writers to build paid subscriber audiences and monetize their content. Many data scientists and researchers use it to transition from traditional tech roles to independent creator careers. The platform provides tools for publishing, audience building, and subscription management.","use_cases":"Data scientist wants to start a paid newsletter about ML techniques and industry insights, Researcher looking to monetize their expertise by creating educational content for practitioners","audience":"Curious-browser, Mid-DS"},{"id":"career-quora","type":"career","name":"Quora","description":"Career portal","category":"Company Lists","url":"https://www.quora.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-development, job-search, tech-companies, professional-networking","summary":"Quora is a question-and-answer platform that serves as a career resource portal for tech professionals. Users can find insights about company cultures, interview processes, and career advancement at various tech companies. The platform aggregates real employee experiences and industry expert advice for job seekers and career changers.","use_cases":"Researching company culture and interview processes before applying to tech roles, Getting advice on career transitions from academia to industry data science positions","audience":"Junior-DS, Curious-browser"},{"id":"career-yelp","type":"career","name":"Yelp","description":"Career portal","category":"Company Lists","url":"https://www.yelp.careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, tech-careers, company-research","summary":"Yelp's career portal provides job opportunities at the local business review platform company. It offers positions across engineering, data science, product, and business roles for professionals interested in working with local business data and recommendation systems. The portal includes information about company culture, benefits, and application processes.","use_cases":"Researching data science roles at a company known for recommendation algorithms and local business analytics, Exploring career opportunities at a tech company that works with review data and local search problems","audience":"Junior-DS, Curious-browser"},{"id":"career-tencent","type":"career","name":"Tencent","description":"Career portal","category":"Company Lists","url":"https://careers.tencent.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, tencent, china-tech, job-applications, super-app","summary":"Career portal for Tencent, one of China's largest technology companies known for WeChat and gaming platforms. Provides job listings and application processes for data science, engineering, and research positions within Tencent's ecosystem. Useful for understanding career opportunities at major Chinese tech firms and super-app business models.","use_cases":"Applying for data scientist positions at Tencent's various business units, Researching career paths and requirements at major Chinese tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-bilibili","type":"career","name":"Bilibili","description":"Career portal","category":"Company Lists","url":"https://www.bilibili.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, china-tech, video-streaming, job-opportunities, asia-market","summary":"Bilibili's career portal provides job opportunities at one of China's leading video streaming and entertainment platforms. The portal offers insights into working at a major Chinese tech company that serves hundreds of millions of users with video content, gaming, and live streaming services. It's particularly valuable for understanding career paths in the Chinese tech ecosystem and video platform industry.","use_cases":"Researching job opportunities at Chinese video streaming companies, Understanding career requirements and culture at major Asian tech platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-xiaohongshu","type":"career","name":"Xiaohongshu","description":"Career portal","category":"Company Lists","url":"https://job.xiaohongshu.com/","difficulty":"beginner","prerequisites":"web-scraping, company-research-methods","topic_tags":"career-opportunities, chinese-tech, social-commerce, company-research","summary":"Xiaohongshu is a major Chinese social commerce platform combining social media with e-commerce, often called 'China's Instagram meets Pinterest.' This career portal provides information about job opportunities, company culture, and hiring practices at one of China's fastest-growing tech companies. It's valuable for understanding career paths in Chinese social commerce and the intersection of content creation with retail technology.","use_cases":"Researching career opportunities at Chinese social commerce companies, Understanding hiring practices and job requirements in Asian tech markets","audience":"Junior-DS, Curious-browser"},{"id":"career-line","type":"career","name":"LINE","description":"Career portal","category":"Company Lists","url":"https://careers.linecorp.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, tech-jobs, asia-companies, messaging-industry, job-applications","summary":"Career portal for LINE, a major Japanese messaging and technology company with operations across Asia. Provides information about job opportunities, company culture, and application processes at one of Asia's leading tech platforms. Useful for understanding career paths and opportunities in Asian tech markets.","use_cases":"Researching job opportunities at major Asian messaging platforms, Understanding career progression and roles available at LINE's various subsidiaries","audience":"Junior-DS, Curious-browser"},{"id":"career-rakuten","type":"career","name":"Rakuten","description":"Career portal","category":"Company Lists","url":"https://japan-job-en.rakuten.careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, e-commerce, japan, tech-jobs, rakuten","summary":"Rakuten's career portal provides job opportunities at one of Japan's largest e-commerce and fintech companies. The portal offers positions across data science, engineering, and business roles in Tokyo and globally. It serves as a gateway for tech professionals interested in working at a major Asian tech company with international reach.","use_cases":"Exploring data science positions at major Japanese e-commerce companies, Finding tech roles with international exposure in Asian markets","audience":"Junior-DS, Mid-DS"},{"id":"career-kakao","type":"career","name":"Kakao","description":"Career portal","category":"Company Lists","url":"https://careers.kakao.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, korea-tech, messaging-industry, job-search, asia-market","summary":"Kakao's career portal for exploring job opportunities at one of South Korea's largest tech companies, known for KakaoTalk messaging app and diverse digital services. The portal provides insights into roles across product, engineering, data science, and business functions at a major Asian tech platform. Useful for understanding career paths and company culture at Korean tech giants.","use_cases":"Data scientist researching career opportunities at major Asian tech companies, Recent graduate exploring international tech job markets in Korea","audience":"Junior-DS, Curious-browser"},{"id":"career-naver","type":"career","name":"NAVER","description":"Career portal","category":"Company Lists","url":"https://recruit.navercorp.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, naver, korea-tech, job-search, asia-opportunities","summary":"NAVER's career portal showcases job opportunities at South Korea's leading tech company, known for search, messaging, and digital services. The portal provides insights into roles in engineering, data science, product management, and research at one of Asia's major tech employers. It's valuable for understanding career paths and requirements at a dominant Korean tech platform.","use_cases":"Exploring data science and engineering opportunities at major Korean tech companies, Researching career requirements and company culture before applying to NAVER positions","audience":"Junior-DS, Curious-browser"},{"id":"career-sea-group","type":"career","name":"Sea Group","description":"Career portal","category":"Company Lists","url":"https://career.sea.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-opportunities, sea-group, singapore-tech, gaming-industry, asia-tech-jobs","summary":"Sea Group's career portal showcases job opportunities at one of Southeast Asia's largest technology conglomerates, known for Shopee, Garena, and SeaMoney. The company offers roles spanning e-commerce, gaming, fintech, and data science across multiple Asian markets. This portal provides insight into career paths at a major regional tech player with significant growth and scale.","use_cases":"Exploring data science and analytics roles at a major Southeast Asian tech company, Researching career opportunities in Asian gaming and e-commerce markets","audience":"Junior-DS, Curious-browser"},{"id":"career-viber","type":"career","name":"Viber","description":"Career portal","category":"Company Lists","url":"https://www.viber.com/en/careers/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-opportunities, tech-jobs, europe-tech, messaging-apps, israel-tech","summary":"Viber's career portal showcasing open positions at the popular messaging platform. The company, based in Israel with European operations, offers opportunities across engineering, data science, product, and business roles. Useful for exploring career paths in the messaging and communications technology sector.","use_cases":"Exploring data science roles at European messaging companies, Researching career opportunities in Israeli tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-smartnews","type":"career","name":"SmartNews","description":"Career portal","category":"Company Lists","url":"https://about.smartnews.com/en/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, news-industry, job-portal, tech-companies, ML-careers","summary":"SmartNews career portal providing job opportunities at the AI-powered news aggregation company. Features roles in machine learning, data science, and engineering positions. Useful for understanding career paths and requirements at a major news-tech company.","use_cases":"Exploring ML engineering roles at a content recommendation company, Researching career opportunities in news-tech industry","audience":"Junior-DS, Curious-browser"},{"id":"career-newsbreak","type":"career","name":"NewsBreak","description":"Career portal","category":"Company Lists","url":"https://careers.newsbreak.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, news-media, job-listings, company-research, causal-inference","summary":"NewsBreak is a career portal for the news and media technology company. It provides job opportunities and career information for data scientists and researchers interested in working at a company that applies causal inference methods to news recommendation and content optimization.","use_cases":"Searching for data science positions at a news media company that uses causal inference, Researching NewsBreak's tech culture and data science practices before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-buzzfeed","type":"career","name":"BuzzFeed","description":"Career portal","category":"Company Lists","url":"https://www.buzzfeed.com/about/jobs","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, media-jobs, company-research, job-applications","summary":"BuzzFeed's career portal showcasing open positions at the digital media company. Provides insights into roles spanning data science, engineering, content creation, and business operations at a major online media platform. Useful for understanding career paths and job requirements in the digital media industry.","use_cases":"Researching data science roles at media companies to understand required skills and responsibilities, Exploring career opportunities in content analytics and audience measurement at digital publishers","audience":"Junior-DS, Curious-browser"},{"id":"career-vox-media","type":"career","name":"Vox Media","description":"Career portal","category":"Company Lists","url":"https://www.voxmedia.com/pages/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, media-company, job-listings, vox-media, content-creation","summary":"Vox Media's career portal showcases job opportunities at one of the largest digital media companies, known for brands like Vox, The Verge, and SB Nation. This portal is valuable for data scientists and analysts interested in media, content analytics, and audience measurement roles. It provides insights into how major media companies structure their data teams and what skills they prioritize.","use_cases":"Exploring data science opportunities in digital media and content companies, Understanding job requirements and team structures at major media organizations","audience":"Junior-DS, Curious-browser"},{"id":"career-taboola","type":"career","name":"Taboola","description":"Career portal","category":"Company Lists","url":"https://www.taboola.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, content-recommendation, ads, job-search","summary":"Taboola is a content recommendation and native advertising platform that operates globally. The company offers career opportunities for data scientists, engineers, and researchers working on recommendation systems, machine learning, and advertising technology. Their career portal provides access to roles involving large-scale content optimization and personalization algorithms.","use_cases":"Finding data science roles at a major recommendation engine company, Exploring career opportunities in native advertising and content discovery platforms","audience":"Junior-DS, Mid-DS"},{"id":"career-outbrain","type":"career","name":"Outbrain","description":"Career portal","category":"Company Lists","url":"https://www.outbrain.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, content-recommendation, ads, job-search","summary":"Outbrain is a content recommendation platform that also maintains a career portal for job opportunities. The company specializes in native advertising and content discovery technology, making it relevant for data scientists interested in recommendation systems and ad tech. Their career page provides insights into roles at a major content recommendation company.","use_cases":"Exploring job opportunities at a content recommendation company, Understanding career paths in ad tech and recommendation systems","audience":"Junior-DS, Curious-browser"},{"id":"career-espn","type":"career","name":"ESPN","description":"Career portal","category":"Company Lists","url":"https://jobs.disneycareers.com/espn","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, sports-tech, media-jobs, streaming-analytics","summary":"ESPN's career portal provides access to job opportunities at one of the world's largest sports media and streaming companies. The portal showcases roles across data science, analytics, engineering, and product teams working on sports content, streaming platforms, and fan engagement. It's particularly valuable for tech professionals interested in applying data skills to sports media and entertainment.","use_cases":"Finding data scientist positions focused on sports analytics and fan behavior modeling, Exploring streaming technology and content recommendation roles at a major media company","audience":"Junior-DS, Curious-browser"},{"id":"career-nubank","type":"career","name":"Nubank","description":"Career portal","category":"Company Lists","url":"https://international.nubank.com.br/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, fintech, latin-america, job-search","summary":"Nubank is Brazil's largest digital bank and a major fintech employer in Latin America. The career portal provides information about job opportunities, company culture, and hiring processes at one of the region's most prominent tech companies. It's particularly valuable for data scientists and economists interested in fintech roles in emerging markets.","use_cases":"Exploring fintech career opportunities in Brazil and Latin America, Researching company culture and values before applying to digital banking roles","audience":"Junior-DS, Curious-browser"},{"id":"career-haus","type":"career","name":"Haus","description":"Career portal","category":"Company Lists","url":"https://www.haus.io/careers","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design","topic_tags":"career-portal, mmm, incrementality, causal-inference, job-search","summary":"Haus is a career portal focused on connecting data scientists and economists with companies specializing in marketing mix modeling, incrementality testing, and causal inference. The platform aggregates job opportunities from companies that value quantitative marketing measurement and econometric approaches. It serves as a specialized job board for professionals with expertise in experimental design and causal methods.","use_cases":"Finding data science roles at companies that prioritize causal inference and experimental rigor, Discovering career opportunities in marketing measurement and incrementality testing","audience":"Junior-DS, Mid-DS"},{"id":"career-recast","type":"career","name":"Recast","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/recast","difficulty":"beginner","prerequisites":"basic-statistics, A-B-testing-concepts","topic_tags":"career-portal, data-science-jobs, economist-roles, incrementality-testing, bayesian-methods","summary":"Recast is a career portal specializing in data science and economist roles at tech companies. The platform connects candidates with positions focused on causal inference, experimentation, and quantitative analysis. It's particularly valuable for those seeking roles involving MMM, incrementality testing, and Bayesian methods.","use_cases":"Finding economist or senior data scientist positions at tech companies focused on causal inference, Exploring career opportunities in marketing measurement and incrementality testing teams","audience":"Junior-DS, Mid-DS"},{"id":"career-incrmntal","type":"career","name":"INCRMNTAL","description":"Career portal","category":"Company Lists","url":"https://www.incrmntal.com/careers","difficulty":"beginner","prerequisites":"marketing-fundamentals, basic-statistics","topic_tags":"career-portal, incrementality-testing, marketing-measurement, job-listings","summary":"INCRMNTAL is a career portal focused on companies and roles in marketing measurement and incrementality testing. It serves as a curated resource for professionals looking to work on causal inference problems in tech and marketing. The platform connects job seekers with companies that prioritize rigorous measurement of marketing effectiveness.","use_cases":"Finding job opportunities at companies that specialize in marketing mix modeling and incrementality testing, Exploring career paths in marketing measurement and causal inference within the tech industry","audience":"Junior-DS, Curious-browser"},{"id":"career-northbeam","type":"career","name":"Northbeam","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/northbeam","difficulty":"beginner","prerequisites":"marketing-fundamentals, basic-analytics","topic_tags":"career-portal, mmm, attribution, marketing-analytics, job-search","summary":"Northbeam is a marketing measurement and attribution company that provides a career portal for job opportunities. The portal connects professionals interested in marketing mix modeling (MMM) and attribution analysis with relevant career opportunities. It serves as a resource for those looking to work in the marketing analytics and measurement space.","use_cases":"Finding job opportunities in marketing measurement and attribution companies, Exploring career paths in marketing mix modeling and incrementality testing","audience":"Junior-DS, Curious-browser"},{"id":"career-liftlab","type":"career","name":"LiftLab","description":"Career portal","category":"Company Lists","url":"https://liftlab.com/careers-2/","difficulty":"beginner","prerequisites":"resume-writing, basic-statistics","topic_tags":"career-portal, job-search, tech-careers, economist-jobs, company-directory","summary":"LiftLab is a career portal specifically designed for tech economists and data scientists. It provides job listings, company information, and career guidance for professionals working at the intersection of economics and technology. The platform helps connect economists with tech companies that value econometric expertise.","use_cases":"Finding economist roles at tech companies like Meta, Uber, or Netflix, Researching which companies hire economists for causal inference and experimentation work","audience":"Junior-DS, Curious-browser"},{"id":"career-paramark","type":"career","name":"Paramark","description":"Career portal","category":"Company Lists","url":"https://paramark.com/careers","difficulty":"beginner","prerequisites":"basic-statistics, marketing-fundamentals","topic_tags":"career-portal, mmm, incrementality, company-directory, job-search","summary":"Paramark is a career portal focused on marketing measurement and incrementality roles. It serves as a company directory for professionals seeking positions in MMM, incrementality testing, and related analytics fields. The platform connects job seekers with companies working on marketing effectiveness measurement.","use_cases":"Finding job opportunities at companies specializing in marketing mix modeling and incrementality measurement, Researching which companies are actively hiring for MMM and incrementality roles to target applications","audience":"Junior-DS, Curious-browser"},{"id":"career-measured","type":"career","name":"Measured","description":"Career portal","category":"Company Lists","url":"https://www.measured.com/careers/","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design","topic_tags":"careers, job-search, tech-economics, data-science-roles, mmm","summary":"Measured is a career portal focused on connecting data science and analytics professionals with opportunities in the tech industry. The platform specializes in roles related to experimentation, causal inference, and measurement - particularly relevant for economists and data scientists working on product analytics, marketing mix modeling, and growth measurement. It serves as a curated job board for technical roles that require strong analytical and statistical skills.","use_cases":"Junior data scientist looking for their first role at a tech company with focus on experimentation and causal analysis, PhD economist transitioning to industry seeking positions in product analytics or marketing measurement teams","audience":"Junior-DS, Curious-browser"},{"id":"career-triple-whale","type":"career","name":"Triple Whale","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/triplewhale","difficulty":"beginner","prerequisites":"basic-marketing-concepts, business-analytics-fundamentals","topic_tags":"career-portal, mmm, ecommerce, marketing-analytics, job-opportunities","summary":"Triple Whale is a career portal for professionals in the ecommerce and marketing mix modeling (MMM) space. It connects job seekers with companies specializing in attribution, analytics, and measurement solutions for online retail businesses. The platform serves as a gateway for careers in the growing field of ecommerce data science and marketing technology.","use_cases":"Finding job opportunities at companies that specialize in MMM and attribution modeling for ecommerce brands, Exploring career paths in marketing analytics and measurement at direct-to-consumer companies","audience":"Junior-DS, Curious-browser"},{"id":"career-rockerbox","type":"career","name":"Rockerbox","description":"Career portal","category":"Company Lists","url":"https://www.rockerbox.com/careers","difficulty":"beginner","prerequisites":"digital-marketing-basics, SQL-queries","topic_tags":"marketing-mix-modeling, attribution-analytics, adtech-careers, measurement-jobs","summary":"Rockerbox is a marketing measurement and attribution company that provides career opportunities in marketing analytics, incrementality testing, and media mix modeling. The company focuses on helping brands understand the true impact of their marketing investments across channels. Their career portal showcases roles for data scientists and analysts working on cutting-edge measurement methodologies.","use_cases":"Finding job opportunities at companies specializing in marketing measurement and attribution analytics, Exploring career paths in adtech and marketing analytics at a company known for incrementality testing","audience":"Junior-DS, Curious-browser"},{"id":"career-moloco","type":"career","name":"Moloco","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/moloco","difficulty":"beginner","prerequisites":"resume-writing, basic-interviewing","topic_tags":"careers, ad-tech, mobile-advertising, job-portal, tech-companies","summary":"Moloco is a machine learning company specializing in mobile advertising and programmatic auction platforms. Their career portal showcases opportunities for data scientists and engineers working on real-time bidding, recommendation systems, and large-scale ML infrastructure. The company focuses on performance advertising using advanced ML techniques for mobile app monetization.","use_cases":"Finding data science roles at a mobile ad-tech company with strong ML focus, Exploring career opportunities in programmatic advertising and auction mechanisms","audience":"Junior-DS, Curious-browser"},{"id":"career-criteo","type":"career","name":"Criteo","description":"Career portal","category":"Company Lists","url":"https://careers.criteo.com/en/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, ad-tech, rtb, auction-theory, job-search","summary":"Criteo's career portal for tech economist and data science positions at a leading ad-tech company specializing in real-time bidding and auction mechanisms. The company is known for hiring economists to work on pricing, auction design, and marketplace optimization. Offers opportunities to apply auction theory and causal inference methods to large-scale advertising problems.","use_cases":"Finding economist roles at major ad-tech companies, Exploring career paths in real-time bidding and auction design","audience":"Junior-DS, Curious-browser"},{"id":"career-the-trade-desk","type":"career","name":"The Trade Desk","description":"Career portal","category":"Company Lists","url":"https://careers.thetradedesk.com/jobs","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis","topic_tags":"career-opportunities, ad-tech, programmatic-advertising, auction-theory","summary":"The Trade Desk is a leading demand-side platform (DSP) in programmatic advertising that uses real-time bidding and auction mechanisms to buy digital ad inventory. The company offers career opportunities for data scientists and economists working on bidding algorithms, attribution modeling, and market optimization. Their career portal showcases roles that combine auction theory, machine learning, and large-scale data processing in the ad-tech ecosystem.","use_cases":"Exploring career opportunities at a major ad-tech company specializing in programmatic advertising, Understanding how auction theory and data science are applied in real-time bidding platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-topsort","type":"career","name":"Topsort","description":"Career portal","category":"Company Lists","url":"https://wellfound.com/company/topsort/jobs","difficulty":"beginner","prerequisites":"basic-economics, job-search-fundamentals","topic_tags":"careers, ad-tech, auction-theory, retail-media, job-portal","summary":"Topsort is a career portal focused on opportunities in ad-tech, auction mechanisms, and retail media companies. The platform connects economists and data scientists with roles that leverage auction theory and economic modeling in digital advertising. It's particularly valuable for those seeking positions that combine economics expertise with technology applications.","use_cases":"Finding economist roles at ad-tech companies that work on auction design and bidding algorithms, Discovering retail media positions that require understanding of two-sided markets and pricing mechanisms","audience":"Junior-DS, Curious-browser"},{"id":"career-liveramp","type":"career","name":"LiveRamp","description":"Career portal","category":"Company Lists","url":"https://liveramp.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, ad-tech, measurement, job-search, data-identity","summary":"LiveRamp's career portal showcasing opportunities at a leading data connectivity platform specializing in identity resolution and measurement solutions. The company focuses on helping businesses connect customer data across digital touchpoints while maintaining privacy compliance. Offers roles spanning data science, engineering, product, and business functions in the ad-tech and marketing technology space.","use_cases":"Data scientists looking for roles in identity resolution, audience segmentation, or marketing measurement at a established ad-tech company, Early career professionals seeking entry-level positions in data connectivity, privacy-focused advertising technology, or customer data platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-skai","type":"career","name":"Skai","description":"Career portal","category":"Company Lists","url":"https://skai.io/company/careers/data-science/","difficulty":"beginner","prerequisites":"basic-statistics, online-advertising-concepts","topic_tags":"career-portal, ad-tech, bid-optimization, job-search, company-profiles","summary":"Skai is a career portal providing information about companies in the ad-tech space, particularly those focused on bid optimization and programmatic advertising. The platform helps job seekers explore career opportunities at companies working on digital advertising technologies. It serves as a curated directory for understanding the ad-tech ecosystem and identifying potential employers.","use_cases":"Finding ad-tech companies to apply to when transitioning from general data science to advertising technology, Researching company profiles and tech stacks before interviewing for bid optimization or programmatic advertising roles","audience":"Junior-DS, Curious-browser"},{"id":"career-pacvue","type":"career","name":"Pacvue","description":"Career portal","category":"Company Lists","url":"https://pacvue.com/about/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, ad-tech, retail-media, job-portal, company-research","summary":"Pacvue is a career portal for opportunities at a retail media and advertising technology company. The platform provides job listings and company information for data scientists and analysts interested in the retail media space. It serves as a gateway for understanding career paths in programmatic advertising and e-commerce analytics.","use_cases":"Data scientists exploring career opportunities in retail media and ad-tech companies, Recent graduates researching companies that work with Amazon advertising and retail analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-kevel","type":"career","name":"Kevel","description":"Career portal","category":"Company Lists","url":"https://www.kevel.com/careers","difficulty":"beginner","prerequisites":"basic-networking, web-development-fundamentals","topic_tags":"career-portal, ad-tech, company-directory, job-search, advertising-technology","summary":"Kevel is a career portal focused on advertising technology companies and platforms. It serves as a directory for professionals seeking opportunities in the ad-tech industry. The platform connects job seekers with companies building advertising infrastructure, demand-side platforms, and programmatic advertising solutions.","use_cases":"Finding job opportunities at ad-tech companies when transitioning from other industries, Researching potential employers in the advertising technology space before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-launchdarkly","type":"career","name":"LaunchDarkly","description":"Career portal","category":"Company Lists","url":"https://launchdarkly.com/careers/","difficulty":"beginner","prerequisites":"A-B-testing-basics, basic-statistics","topic_tags":"feature-flags, experimentation, career-opportunities, tech-companies","summary":"LaunchDarkly is a feature flag and experimentation platform company that helps organizations safely deploy code and run experiments. The company offers career opportunities for data scientists and engineers interested in working on experimentation infrastructure and statistical methodology. Their career portal provides insight into roles focused on building tools that enable safe feature rollouts and sophisticated A/B testing capabilities.","use_cases":"Finding job opportunities at a company specializing in experimentation and feature flag technology, Exploring career paths in companies that build infrastructure for A/B testing and gradual feature rollouts","audience":"Junior-DS, Mid-DS"},{"id":"career-eppo","type":"career","name":"Eppo","description":"Career portal","category":"Company Lists","url":"https://www.geteppo.com/careers","difficulty":"beginner","prerequisites":"statistics-fundamentals, hypothesis-testing","topic_tags":"career-portal, experimentation-jobs, causal-inference-careers, ab-testing-companies","summary":"Eppo is a career portal focused on experimentation and causal inference roles. It serves as a gateway for data scientists and economists to find positions at companies that prioritize rigorous A/B testing and statistical methods. The platform connects talent with organizations that value experimental design and causal reasoning skills.","use_cases":"Finding your first A/B testing role after learning experimental design, Transitioning from academic economics to industry experimentation positions","audience":"Junior-DS, Curious-browser"},{"id":"career-growthbook","type":"career","name":"GrowthBook","description":"Career portal","category":"Company Lists","url":"https://www.growthbook.io/careers","difficulty":"beginner","prerequisites":"a-b-testing-basics, statistical-significance","topic_tags":"career-opportunities, experimentation-companies, ab-testing-jobs, tech-careers, data-science-roles","summary":"GrowthBook is a career portal focused on experimentation and A/B testing roles in the tech industry. It connects data scientists and analysts with companies that prioritize experiment-driven growth and statistical rigor. The platform helps professionals find positions where they can apply statistical methods and experimentation frameworks in real-world business contexts.","use_cases":"Finding data science roles at companies with strong experimentation cultures, Discovering career opportunities specifically focused on A/B testing and causal inference","audience":"Junior-DS, Mid-DS"},{"id":"career-statsig","type":"career","name":"Statsig","description":"Career portal","category":"Company Lists","url":"https://www.statsig.com/careers","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design","topic_tags":"career-portal, experimentation, a-b-testing, job-search, tech-careers","summary":"Statsig is a career portal for professionals interested in experimentation and A/B testing roles. It provides job listings, career guidance, and resources for data scientists and product analysts working in experimental design. The platform connects talent with companies that prioritize data-driven decision making through controlled experiments.","use_cases":"Finding A/B testing or experimentation roles at tech companies, Exploring career paths in product analytics and experimental design","audience":"Junior-DS, Mid-DS"},{"id":"career-absmartly","type":"career","name":"ABsmartly","description":"Career portal","category":"Company Lists","url":"https://absmartly.com/about","difficulty":"beginner","prerequisites":"A-B-testing-basics, statistical-significance","topic_tags":"career, experimentation, sequential-testing, job-search","summary":"ABsmartly is a career portal focused on experimentation and sequential testing roles in the tech industry. The platform connects data scientists and researchers with companies that specialize in A/B testing, causal inference, and experimental design. It serves as a specialized job board for professionals seeking roles in experimentation-focused teams.","use_cases":"Finding data scientist positions at companies with strong experimentation cultures, Discovering career opportunities specifically in A/B testing and causal inference teams","audience":"Junior-DS, Mid-DS"},{"id":"career-optimizely","type":"career","name":"Optimizely","description":"Career portal","category":"Company Lists","url":"https://careers.optimizely.com/","difficulty":"beginner","prerequisites":"basic-statistics, experiment-design","topic_tags":"careers, experimentation, a-b-testing, job-search, tech-companies","summary":"Optimizely's career portal showcasing job opportunities at a leading experimentation platform company. Provides insights into roles focused on A/B testing, product optimization, and data-driven decision making. Useful for understanding career paths in the experimentation and optimization space.","use_cases":"Finding job opportunities at experimentation-focused tech companies, Understanding required skills and career progression in A/B testing roles","audience":"Junior-DS, Curious-browser"},{"id":"career-split","type":"career","name":"Split","description":"Career portal","category":"Company Lists","url":"https://www.split.io/careers","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design","topic_tags":"experimentation, feature-flags, career, company-directory","summary":"Split is a feature management and experimentation platform that enables teams to deploy code safely and measure impact through feature flags and A/B testing. The career portal provides job opportunities at a company specializing in experimentation infrastructure and data-driven product development. Ideal for data scientists and engineers interested in working on large-scale experimentation platforms.","use_cases":"Finding jobs at companies focused on experimentation and feature management, Exploring career opportunities in A/B testing platform development","audience":"Junior-DS, Mid-DS"},{"id":"career-vwo","type":"career","name":"VWO","description":"Career portal","category":"Company Lists","url":"https://wingify.com/careers/","difficulty":"beginner","prerequisites":"web-browsing, resume-writing","topic_tags":"career-portal, experimentation, bayesian, job-search, company-research","summary":"VWO is a career portal providing job listings and company information in the experimentation and analytics space. It serves as a resource for data professionals seeking positions at companies that use experimentation platforms and Bayesian methods. The portal helps candidates discover opportunities at organizations focused on A/B testing and conversion optimization.","use_cases":"Finding data science jobs at companies using experimentation platforms, Researching career paths in A/B testing and conversion optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-kameleoon","type":"career","name":"Kameleoon","description":"Career portal","category":"Company Lists","url":"https://career.kameleoon.com/en/jobs","difficulty":"beginner","prerequisites":"basic-statistics, web-analytics","topic_tags":"career-opportunities, experimentation-jobs, ai-roles, company-portal","summary":"Kameleoon is a career portal for a company that specializes in experimentation and AI-powered testing platforms. It provides job listings and career opportunities for data scientists and researchers interested in working on A/B testing, personalization, and AI-driven experimentation tools. The portal serves as a gateway for professionals looking to join teams focused on conversion optimization and digital experimentation.","use_cases":"Finding job opportunities at companies specializing in A/B testing and experimentation platforms, Exploring career paths in AI-powered experimentation and optimization roles","audience":"Junior-DS, Curious-browser"},{"id":"career-zilliant","type":"career","name":"Zilliant","description":"Career portal","category":"Company Lists","url":"https://zilliant.applytojob.com/apply","difficulty":"beginner","prerequisites":"basic-economics, pricing-fundamentals","topic_tags":"pricing-optimization, b2b-economics, career-opportunities, price-elasticity, revenue-management","summary":"Zilliant is a leading B2B pricing optimization company that helps businesses maximize revenue through advanced pricing analytics and machine learning. The company frequently hires economists, data scientists, and pricing analysts to work on price elasticity modeling, demand forecasting, and revenue optimization problems. Their career portal showcases opportunities to apply economic theory to real-world pricing challenges in various industries.","use_cases":"Finding economist or data scientist roles focused on pricing and revenue optimization, Exploring career opportunities at a company that applies economic principles to B2B pricing problems","audience":"Junior-DS, Curious-browser"},{"id":"career-pros-holdings","type":"career","name":"PROS Holdings","description":"Career portal","category":"Company Lists","url":"https://pros.wd5.myworkdayjobs.com/PROS_Careers","difficulty":"beginner","prerequisites":"basic-economics, business-analytics","topic_tags":"careers, pricing, revenue-management, company-profiles, job-search","summary":"PROS Holdings is a software company specializing in AI-powered pricing and revenue management solutions. They serve industries like airlines, hotels, and manufacturing with dynamic pricing optimization tools. Their career portal showcases opportunities for data scientists and economists working on pricing algorithms and revenue optimization.","use_cases":"Exploring career opportunities at companies focused on pricing and revenue optimization, Researching potential employers that work on dynamic pricing problems in travel and retail","audience":"Junior-DS, Curious-browser"},{"id":"career-vendavo","type":"career","name":"Vendavo","description":"Career portal","category":"Company Lists","url":"https://www.vendavo.com/careers/","difficulty":"beginner","prerequisites":"basic-economics, pricing-theory","topic_tags":"pricing-strategy, revenue-optimization, tech-careers, economist-roles, SaaS-pricing","summary":"Vendavo is a B2B pricing software company that helps enterprises optimize pricing and margin strategies through AI and analytics. The company frequently hires economists and data scientists to work on pricing algorithms, market analysis, and revenue optimization problems. Their career portal showcases opportunities for quantitative professionals to apply economic theory to real-world pricing challenges.","use_cases":"Finding economist or pricing analyst roles at a tech company focused on B2B pricing solutions, Exploring career opportunities that combine economic theory with practical pricing strategy implementation","audience":"Junior-DS, Curious-browser"},{"id":"career-competera","type":"career","name":"Competera","description":"Career portal","category":"Company Lists","url":"https://competera.ai/company/careers","difficulty":"beginner","prerequisites":"basic-economics, business-fundamentals","topic_tags":"career-opportunities, pricing-analytics, demand-forecasting, company-research","summary":"Competera is a pricing optimization and competitive intelligence company that helps retailers and brands make data-driven pricing decisions. The career portal showcases opportunities for tech economists and data scientists to work on pricing algorithms, demand forecasting, and competitive analysis. It's a useful resource for understanding career paths in pricing analytics and retail tech.","use_cases":"Exploring career opportunities at companies specializing in pricing optimization and retail analytics, Researching what skills and backgrounds are valued in pricing analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-pricefx","type":"career","name":"Pricefx","description":"Career portal","category":"Company Lists","url":"https://www.pricefx.com/careers","difficulty":"beginner","prerequisites":"basic-economics, business-fundamentals","topic_tags":"pricing, dynamic-pricing, career-opportunities, company-jobs","summary":"Pricefx is a cloud-based pricing software company that provides dynamic pricing solutions and optimization tools for enterprises. The career portal showcases job opportunities for data scientists, pricing analysts, and software engineers working on pricing algorithms and revenue optimization. It's a good resource for understanding career paths in the pricing technology sector.","use_cases":"Exploring job opportunities at pricing software companies, Understanding career requirements for pricing analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-intelligence-node","type":"career","name":"Intelligence Node","description":"Career portal","category":"Company Lists","url":"https://www.intelligencenode.com/about-us/","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, pricing-jobs, market-dynamics-careers, company-directory","summary":"Intelligence Node is a career portal for a company specializing in pricing intelligence and market dynamics analytics. The portal provides job opportunities for data scientists and analysts interested in retail pricing, competitive intelligence, and market research roles. It's particularly relevant for those looking to apply data science skills in e-commerce and pricing strategy contexts.","use_cases":"Finding data science jobs focused on pricing analytics and competitive intelligence, Exploring career opportunities in retail market dynamics and e-commerce optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-perfect-price","type":"career","name":"Perfect Price","description":"Career portal","category":"Company Lists","url":"https://wellfound.com/company/perfect-price","difficulty":"beginner","prerequisites":"basic-economics, market-research","topic_tags":"pricing, dynamic-pricing, career-portal, company-lists, job-search","summary":"Perfect Price is a career portal focused on pricing-related opportunities in the tech industry. It serves as a curated job board for professionals interested in pricing strategy, dynamic pricing, and revenue optimization roles. The platform connects job seekers with companies that prioritize sophisticated pricing methodologies.","use_cases":"Finding pricing analyst or revenue optimization roles at tech companies, Discovering companies that heavily invest in dynamic pricing and algorithmic pricing strategies","audience":"Junior-DS, Curious-browser"},{"id":"career-omnia-retail","type":"career","name":"Omnia Retail","description":"Career portal","category":"Company Lists","url":"https://jobs.omniaretail.com/","difficulty":"beginner","prerequisites":"basic-economics, market-research","topic_tags":"pricing, competitive-pricing, careers, retail-tech, company-directory","summary":"Omnia Retail is a pricing technology company that provides competitive pricing and dynamic pricing solutions for e-commerce and retail businesses. Their career portal offers opportunities for tech economists, data scientists, and pricing analysts to work on pricing algorithms and market intelligence systems. This is valuable for understanding career paths in the pricing technology sector.","use_cases":"Exploring career opportunities in pricing technology and dynamic pricing companies, Understanding what skills and roles exist at retail tech companies focused on competitive intelligence","audience":"Junior-DS, Curious-browser"},{"id":"career-pendo","type":"career","name":"Pendo","description":"Career portal","category":"Company Lists","url":"https://www.pendo.io/careers/","difficulty":"beginner","prerequisites":"product-management-basics, web-analytics","topic_tags":"product-analytics, experimentation, career-opportunities, company-research, job-search","summary":"Pendo is a product analytics company that provides digital experience platforms and product usage insights. They offer career opportunities for professionals interested in product analytics, experimentation, and customer experience roles. Their career portal showcases positions spanning data science, product management, and analytics engineering.","use_cases":"Exploring career opportunities at a leading product analytics company, Researching companies that specialize in experimentation and product optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-contentsquare","type":"career","name":"Contentsquare","description":"Career portal","category":"Company Lists","url":"https://contentsquare.com/careers/","difficulty":"beginner","prerequisites":"basic-analytics, web-metrics","topic_tags":"product-analytics, journey-analytics, career-opportunities, company-jobs, user-experience","summary":"Contentsquare is a digital experience analytics platform that helps companies understand user behavior on websites and mobile apps. The company specializes in product analytics and customer journey optimization, making it relevant for data scientists working in e-commerce and digital product teams. Their career portal provides opportunities for analysts and data scientists interested in user experience and conversion optimization.","use_cases":"Finding job opportunities at a company specializing in digital analytics and user behavior analysis, Exploring career paths in product analytics and customer journey optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-amplitude","type":"career","name":"Amplitude","description":"Career portal","category":"Company Lists","url":"https://amplitude.com/careers","difficulty":"beginner","prerequisites":"product-analytics-basics, SQL-queries","topic_tags":"product-analytics, experimentation, career-opportunities, job-search, company-portal","summary":"Amplitude's career portal showcasing job opportunities at the product analytics and experimentation platform company. The portal targets data professionals interested in working on large-scale user behavior analysis, A/B testing infrastructure, and product intelligence tools. Ideal for exploring roles that combine technical skills with product impact measurement.","use_cases":"Finding product analytics roles at a leading experimentation platform, Exploring career opportunities in companies that specialize in user behavior measurement","audience":"Junior-DS, Mid-DS"},{"id":"career-quantum-metric","type":"career","name":"Quantum Metric","description":"Career portal","category":"Company Lists","url":"https://www.quantummetric.com/careers","difficulty":"beginner","prerequisites":"product-management-basics, web-analytics-fundamentals","topic_tags":"product-analytics, career-opportunities, pattern-detection, digital-analytics, user-behavior","summary":"Quantum Metric is a digital intelligence platform company that provides real-time customer experience analytics and insights. The company focuses on helping businesses understand user behavior patterns and optimize digital experiences through advanced analytics. Their career portal offers opportunities for data scientists and analysts interested in product analytics and customer journey optimization.","use_cases":"Finding data science roles focused on product analytics and user experience optimization, Exploring career opportunities at companies specializing in real-time behavioral analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-posthog","type":"career","name":"PostHog","description":"Career portal","category":"Company Lists","url":"https://posthog.com/careers","difficulty":"beginner","prerequisites":"product-management-basics, sql-queries","topic_tags":"product-analytics, feature-flags, career-opportunities, jobs, startup-careers","summary":"PostHog's career portal showcasing job opportunities at the open-source product analytics company. The company specializes in product analytics, feature flags, session replay, and experimentation tools for tech companies. This portal provides insight into roles at a fast-growing analytics startup and the skills they value.","use_cases":"Finding product analytics or data science roles at a modern tech company, Learning about career paths and skills needed at analytics-focused startups","audience":"Junior-DS, Curious-browser"},{"id":"career-mixpanel","type":"career","name":"Mixpanel","description":"Career portal","category":"Company Lists","url":"https://mixpanel.com/jobs/","difficulty":"beginner","prerequisites":"sql-basics, basic-statistics","topic_tags":"product-analytics, event-tracking, user-behavior, career-opportunities","summary":"Mixpanel is a product analytics platform that helps companies track user interactions and behavior through event-based data collection. The company offers career opportunities for data scientists and analysts interested in product analytics, user engagement measurement, and behavioral data analysis. Their platform is widely used by tech companies to understand user journeys and optimize product experiences.","use_cases":"Finding product analyst roles at a company specializing in event-based analytics, Exploring career paths in product analytics and user behavior measurement","audience":"Junior-DS, Curious-browser"},{"id":"career-glassbox","type":"career","name":"Glassbox","description":"Career portal","category":"Company Lists","url":"https://www.glassbox.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, product-analytics, enterprise, job-search, company-research","summary":"Glassbox is a career portal that helps professionals explore opportunities in product analytics and enterprise companies. It provides insights into company cultures, roles, and career paths for data professionals. The platform serves as a resource for understanding the landscape of analytics-focused organizations.","use_cases":"Researching product analytics companies before applying for data science positions, Exploring career paths and company cultures in enterprise analytics organizations","audience":"Junior-DS, Curious-browser"},{"id":"career-fullstory","type":"career","name":"FullStory","description":"Career portal","category":"Company Lists","url":"https://www.fullstory.com/careers/","difficulty":"beginner","prerequisites":"google-analytics, basic-web-analytics","topic_tags":"product-analytics, behavioral-insights, career-opportunities, user-experience, web-analytics","summary":"FullStory is a digital experience analytics company that provides session replay and behavioral analytics tools. The career portal showcases job opportunities for data scientists and analysts interested in product analytics and user behavior research. It's particularly relevant for professionals looking to work with cutting-edge behavioral data and user experience optimization.","use_cases":"Finding data science roles focused on product analytics and user behavior, Exploring career paths in digital experience analytics and session replay technology","audience":"Junior-DS, Mid-DS"},{"id":"career-hightouch","type":"career","name":"Hightouch","description":"Career portal","category":"Company Lists","url":"https://hightouch.com/careers","difficulty":"beginner","prerequisites":"sql-basics, data-modeling","topic_tags":"careers, data-infrastructure, cdp, company-jobs","summary":"Hightouch is a reverse ETL and customer data platform company that helps businesses sync data from warehouses to operational tools. Their career portal showcases opportunities in data engineering, product, and go-to-market roles at a fast-growing data infrastructure startup. This resource is valuable for understanding career paths in the modern data stack ecosystem.","use_cases":"Exploring job opportunities at a leading reverse ETL company, Understanding career progression in data infrastructure startups","audience":"Junior-DS, Curious-browser"},{"id":"career-dbt-labs","type":"career","name":"dbt Labs","description":"Career portal","category":"Company Lists","url":"https://www.getdbt.com/about-us/careers","difficulty":"beginner","prerequisites":"SQL-basics, data-modeling","topic_tags":"careers, data-infrastructure, analytics-engineering, dbt, job-opportunities","summary":"dbt Labs is a leading analytics engineering company that created the popular dbt (data build tool) framework for transforming data in warehouses. Their career portal showcases opportunities in data infrastructure, analytics engineering, and related technical roles. The company is at the forefront of the modern data stack movement and offers positions for both technical and business roles.","use_cases":"Finding analytics engineering positions at a company pioneering the field, Exploring career opportunities in data infrastructure and modern data tooling","audience":"Junior-DS, Mid-DS"},{"id":"career-fivetran","type":"career","name":"Fivetran","description":"Career portal","category":"Company Lists","url":"https://www.fivetran.com/careers","difficulty":"beginner","prerequisites":"SQL-basics, data-pipelines","topic_tags":"data-infrastructure, etl, career-opportunities, data-engineering, jobs","summary":"Fivetran is a leading data integration platform that automates ETL processes for enterprises. Their career portal showcases opportunities in data engineering, infrastructure, and related technical roles. This is valuable for data professionals interested in working at a major data infrastructure company or understanding career paths in the ETL/data integration space.","use_cases":"Exploring data engineering career opportunities at a major ETL platform company, Understanding job requirements and skills needed for roles in data infrastructure and integration","audience":"Junior-DS, Mid-DS"},{"id":"career-rudderstack","type":"career","name":"RudderStack","description":"Career portal","category":"Company Lists","url":"https://www.rudderstack.com/careers/","difficulty":"beginner","prerequisites":"SQL-basics, data-warehousing-concepts","topic_tags":"data-infrastructure, cdp, career, company-profiles, job-search","summary":"RudderStack is a customer data platform (CDP) company that provides open-source infrastructure for collecting, transforming, and routing customer data. Their career portal offers opportunities for data engineers and infrastructure professionals to work on modern data stack technologies. It's particularly relevant for those interested in real-time data pipelines and privacy-focused customer analytics.","use_cases":"Finding data engineering roles at a modern CDP company, Exploring career opportunities in customer data infrastructure and real-time analytics","audience":"Junior-DS, Mid-DS"},{"id":"career-census","type":"career","name":"Census","description":"Career portal","category":"Company Lists","url":"https://www.getcensus.com/careers","difficulty":"beginner","prerequisites":"SQL-basics, data-warehousing-concepts","topic_tags":"reverse-etl, data-infrastructure, career-opportunities, census-platform, data-activation","summary":"Census is a leading reverse ETL platform that helps companies sync data from warehouses to business tools. Their career portal showcases opportunities in data infrastructure, engineering, and go-to-market roles at a fast-growing data activation company. It's valuable for understanding career paths in modern data infrastructure and the reverse ETL space.","use_cases":"Exploring career opportunities at a cutting-edge data infrastructure company, Learning about job requirements and skills needed in the reverse ETL/data activation industry","audience":"Junior-DS, Curious-browser"},{"id":"career-airbyte","type":"career","name":"Airbyte","description":"Career portal","category":"Company Lists","url":"https://airbyte.com/company/careers","difficulty":"beginner","prerequisites":"SQL-basics, data-pipelines","topic_tags":"careers, data-infrastructure, etl, open-source, job-search","summary":"Airbyte is an open-source data integration platform that helps companies move data between various sources and destinations. Their career portal showcases opportunities to work on data infrastructure, ETL systems, and open-source projects. This is valuable for data professionals interested in joining a fast-growing data infrastructure company.","use_cases":"Finding job opportunities at a leading open-source data integration company, Learning about career paths in data infrastructure and ETL engineering","audience":"Junior-DS, Mid-DS"},{"id":"career-qlik","type":"career","name":"Qlik","description":"Career portal","category":"Company Lists","url":"https://www.qlik.com/us/company/careers","difficulty":"beginner","prerequisites":"SQL-basics, data-visualization","topic_tags":"career-portal, data-infrastructure, bi-tools, job-search, qlik-careers","summary":"Qlik's career portal showcasing job opportunities at the business intelligence and data analytics company. The portal provides insights into roles across data infrastructure, BI development, and AI/ML teams. Useful for understanding career paths and skill requirements at a major data visualization company.","use_cases":"Exploring data analyst or BI developer positions at Qlik, Researching company culture and technical requirements for data infrastructure roles","audience":"Junior-DS, Curious-browser"},{"id":"career-matillion","type":"career","name":"Matillion","description":"Career portal","category":"Company Lists","url":"https://www.matillion.com/careers","difficulty":"beginner","prerequisites":"basic-sql, data-warehousing-concepts","topic_tags":"career-portal, data-infrastructure, etl-jobs, cloud-computing, data-engineering","summary":"Matillion's career portal showcasing opportunities in cloud-native data transformation and ETL infrastructure. The company specializes in data pipeline automation and AI-powered transformation tools for modern data stacks. Ideal for exploring roles in data engineering, platform development, and enterprise data solutions.","use_cases":"Finding data engineering positions at a leading ETL platform company, Exploring career paths in cloud data infrastructure and transformation tools","audience":"Junior-DS, Curious-browser"},{"id":"career-6sense","type":"career","name":"6sense","description":"Career portal","category":"Company Lists","url":"https://6sense.com/about-us/careers/join-us/","difficulty":"beginner","prerequisites":"sales-funnel-analysis, CRM-systems","topic_tags":"career-opportunities, b2b-saas, revenue-operations, predictive-analytics, sales-technology","summary":"6sense is a B2B revenue intelligence platform that uses predictive analytics and intent data to identify potential customers and optimize sales processes. The company offers career opportunities for data scientists and analysts interested in working with large-scale B2B data, machine learning models for lead scoring, and revenue operations. Their career portal showcases roles spanning data engineering, predictive modeling, and customer analytics in the sales technology space.","use_cases":"Exploring data science career opportunities at a revenue intelligence company, Understanding job requirements for predictive modeling roles in B2B SaaS","audience":"Junior-DS, Curious-browser"},{"id":"career-gong","type":"career","name":"Gong","description":"Career portal","category":"Company Lists","url":"https://www.gong.io/careers","difficulty":"beginner","prerequisites":"basic-networking, linkedin-research","topic_tags":"career-opportunities, revenue-intelligence, tech-companies, job-search","summary":"Gong is a revenue intelligence platform that uses AI to analyze sales conversations and forecast deal outcomes. The company offers career opportunities for data scientists and ML engineers working on NLP, conversation analytics, and sales forecasting problems. Their career portal provides insights into roles involving large-scale audio processing, predictive modeling, and business intelligence.","use_cases":"Exploring data science roles at a fast-growing B2B SaaS company, Understanding career paths in revenue operations and sales analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-outreach","type":"career","name":"Outreach","description":"Career portal","category":"Company Lists","url":"https://www.outreach.io/company/working-at-outreach","difficulty":"beginner","prerequisites":"resume-writing, networking-basics","topic_tags":"career-development, job-search, tech-economics, professional-networking, industry-connections","summary":"A career portal focused on outreach opportunities and professional development in tech economics. Provides resources for building industry connections, finding job opportunities, and advancing careers in data science and tech economic research. Includes company lists and revenue intelligence insights to help professionals identify potential employers and career paths.","use_cases":"Recent graduate looking to identify tech companies with strong data science teams for job applications, Mid-career professional seeking to transition into tech economics roles and needing industry contacts","audience":"Junior-DS, Curious-browser"},{"id":"career-zoominfo","type":"career","name":"ZoomInfo","description":"Career portal","category":"Company Lists","url":"https://www.zoominfo.com/careers","difficulty":"beginner","prerequisites":"web-scraping, data-cleaning","topic_tags":"b2b-data, lead-generation, sales-intelligence, company-research, contact-databases","summary":"ZoomInfo is a B2B intelligence platform providing company and contact databases for sales and marketing teams. It offers detailed firmographic data, technographic insights, and intent signals to help identify prospects and understand market opportunities. The platform serves as a comprehensive resource for business development and competitive analysis.","use_cases":"Building targeted prospect lists for B2B sales outreach campaigns, Researching potential employers and understanding company tech stacks for job applications","audience":"Junior-DS, Curious-browser"},{"id":"career-people.ai","type":"career","name":"People.ai","description":"Career portal","category":"Company Lists","url":"https://www.people.ai/about-us/careers","difficulty":"beginner","prerequisites":"basic-sales-concepts, CRM-systems","topic_tags":"revenue-intelligence, activity-modeling, career-portal, sales-tech, company-directory","summary":"People.ai is a revenue intelligence platform that uses AI to analyze sales activities and optimize revenue operations. The career portal provides job opportunities for professionals interested in working on sales analytics, activity modeling, and revenue optimization technologies. It's particularly relevant for data scientists looking to apply ML techniques to sales and revenue problems.","use_cases":"Finding job opportunities in revenue intelligence and sales analytics, Researching career paths in sales tech and activity modeling roles","audience":"Junior-DS, Curious-browser"},{"id":"career-clari","type":"career","name":"Clari","description":"Career portal","category":"Company Lists","url":"https://www.clari.com/careers/","difficulty":"beginner","prerequisites":"sales-operations, CRM-systems","topic_tags":"revenue-intelligence, sales-forecasting, career-opportunities, company-research","summary":"Clari is a revenue intelligence platform that helps companies forecast sales and optimize revenue operations. The career portal provides job opportunities for data scientists and analysts interested in working on predictive sales models and revenue optimization problems. It's particularly relevant for those looking to apply data science in B2B sales and forecasting contexts.","use_cases":"Finding data science roles focused on sales forecasting and revenue prediction, Researching career opportunities at companies specializing in revenue intelligence technology","audience":"Junior-DS, Mid-DS"},{"id":"career-salesloft","type":"career","name":"Salesloft","description":"Career portal","category":"Company Lists","url":"https://www.salesloft.com/careers","difficulty":"beginner","prerequisites":"basic-CRM-knowledge, sales-funnel-concepts","topic_tags":"sales-careers, revenue-operations, sales-tech, career-portal, job-search","summary":"Salesloft is a sales engagement platform that provides career opportunities in revenue intelligence and sales technology. Their career portal connects job seekers with roles in sales operations, data science, and revenue analytics at a leading sales automation company. The platform offers insights into working at the intersection of sales and technology.","use_cases":"Finding data science roles focused on sales analytics and revenue optimization, Exploring career opportunities in sales operations and revenue intelligence","audience":"Junior-DS, Curious-browser"},{"id":"career-zuora","type":"career","name":"Zuora","description":"Career portal","category":"Company Lists","url":"https://www.zuora.com/careers/","difficulty":"beginner","prerequisites":"basic-finance, subscription-metrics","topic_tags":"subscription-business, churn-prediction, ltv, careers, fintech","summary":"Zuora is a leading subscription management platform company that pioneered the subscription economy business model. Their career portal offers opportunities for data scientists and analysts to work on subscription metrics, churn prediction, and customer lifetime value problems. The company provides extensive experience with recurring revenue analytics and subscription-based machine learning challenges.","use_cases":"Finding data science roles focused on subscription business models and recurring revenue analytics, Exploring career opportunities at a company known for subscription economy expertise and SaaS metrics","audience":"Junior-DS, Curious-browser"},{"id":"career-pandadoc","type":"career","name":"PandaDoc","description":"Career portal","category":"Company Lists","url":"https://www.pandadoc.com/careers/","difficulty":"beginner","prerequisites":"basic-web-navigation, career-planning-fundamentals","topic_tags":"career-portal, job-search, company-research, subscription-business, quote-to-cash","summary":"PandaDoc is a document automation and e-signature platform that also maintains a career portal for job opportunities. The company operates in the subscription business model space, focusing on quote-to-conversion optimization for sales teams. Their career section provides insights into roles at a growing SaaS company specializing in document workflow solutions.","use_cases":"Researching job opportunities at document automation companies, Understanding career paths in subscription-based SaaS businesses","audience":"Junior-DS, Curious-browser"},{"id":"career-recurly","type":"career","name":"Recurly","description":"Career portal","category":"Company Lists","url":"https://recurly.com/careers/","difficulty":"beginner","prerequisites":"basic-finance, subscription-metrics","topic_tags":"careers, subscription-business, fintech, saas, revenue-optimization","summary":"Recurly is a subscription management platform that helps businesses handle recurring billing, revenue recognition, and churn reduction. The company offers career opportunities for data scientists and analysts working on subscription economics, pricing optimization, and customer lifecycle modeling. Their career portal provides insight into roles focused on subscription analytics and revenue intelligence.","use_cases":"Finding data science roles at a subscription-focused fintech company, Exploring career opportunities in subscription billing and dunning optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-connectwise","type":"career","name":"ConnectWise","description":"Career portal","category":"Company Lists","url":"https://www.connectwise.com/company/careers/","difficulty":"beginner","prerequisites":"basic-networking, job-search-fundamentals","topic_tags":"career-portal, tech-companies, job-listings, ConnectWise","summary":"ConnectWise is a technology company specializing in business automation software for managed service providers (MSPs) and technology solution providers. Their career portal provides job opportunities across engineering, data science, product, and business roles within the tech services industry. The platform offers insights into working at a B2B software company focused on subscription-based business models.","use_cases":"Exploring job opportunities at a B2B SaaS company specializing in MSP software solutions, Researching career paths and role requirements at technology companies serving business clients","audience":"Junior-DS, Curious-browser"},{"id":"career-chargebee","type":"career","name":"Chargebee","description":"Career portal","category":"Company Lists","url":"https://jobs.chargebee.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, subscription-business, payment-systems, job-portal, company-research","summary":"Chargebee's career portal provides job opportunities at a leading subscription billing and revenue management platform. The company serves SaaS businesses and subscription-based companies worldwide, making it relevant for data scientists interested in subscription analytics, payment optimization, and revenue forecasting. Career seekers can explore roles in data science, analytics, and engineering within the subscription economy ecosystem.","use_cases":"Applying for data scientist positions focused on subscription metrics and churn analysis, Researching career opportunities in payment optimization and billing analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-maxio","type":"career","name":"Maxio","description":"Career portal","category":"Company Lists","url":"https://www.maxio.com/careers","difficulty":"beginner","prerequisites":"excel-basics, saas-fundamentals","topic_tags":"career-portal, saas-metrics, subscription-business, job-search, company-research","summary":"Maxio is a career portal focused on subscription and SaaS companies. It provides job listings and company information specifically for professionals interested in the subscription economy and SaaS metrics space. The platform helps job seekers connect with companies that use subscription-based business models.","use_cases":"Finding data science jobs at SaaS companies that focus on subscription metrics and churn analysis, Researching subscription-based companies to understand their business models before applying for analyst positions","audience":"Junior-DS, Curious-browser"},{"id":"career-dealhub","type":"career","name":"DealHub","description":"Career portal","category":"Company Lists","url":"https://dealhub.io/careers/","difficulty":"beginner","prerequisites":"basic-web-navigation, resume-writing","topic_tags":"career-portal, job-search, cpq-industry, sales-technology, tech-careers","summary":"DealHub is a career portal for a company specializing in CPQ (Configure, Price, Quote) and deal velocity software solutions. It provides job opportunities and career information for those interested in working in the sales technology and revenue operations space. The platform likely features roles in data science, engineering, and business functions focused on optimizing sales processes.","use_cases":"Finding data science roles at a CPQ/sales tech company, Exploring career opportunities in deal velocity and revenue optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-cvs-health-1","type":"career","name":"CVS Health","description":"Career portal","category":"Company Lists","url":"https://jobs.cvshealth.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, pharmacy-economics, healthcare-analytics, job-search","summary":"CVS Health's career portal showcasing economist and data science positions at one of the largest pharmacy and healthcare companies. The portal features roles in pricing, health economics, and analytics within the retail pharmacy and healthcare services sectors. Useful for understanding career paths and requirements in healthcare economics.","use_cases":"Finding economist positions in the pharmacy and healthcare industry, Researching job requirements and qualifications for healthcare analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-kroger-(84.51\u00b0)","type":"career","name":"Kroger (84.51\u00b0)","description":"Career portal","category":"Company Lists","url":"https://www.8451.com/careers","difficulty":"beginner","prerequisites":"SQL-basics, python-pandas","topic_tags":"career-opportunities, retail-analytics, grocery-industry, data-science-jobs","summary":"84.51\u00b0 is Kroger's data science and analytics subsidiary that focuses on customer personalization, pricing optimization, and supply chain analytics in the grocery retail space. They offer career opportunities for data scientists and analysts working on large-scale consumer behavior problems. The company is known for applying advanced analytics to grocery retail challenges including demand forecasting, promotional effectiveness, and customer segmentation.","use_cases":"Finding data science job opportunities in retail/grocery industry, Learning about career paths in applied analytics at large consumer companies","audience":"Junior-DS, Curious-browser"},{"id":"career-pepsico","type":"career","name":"PepsiCo","description":"Career portal","category":"Company Lists","url":"https://www.pepsicojobs.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, cpg-industry, pricing-jobs, rgm-roles, corporate-careers","summary":"PepsiCo's career portal showcasing data science and analytics opportunities at one of the world's largest consumer packaged goods companies. The portal features roles in revenue growth management, pricing analytics, and consumer insights across PepsiCo's global brands. It provides job seekers with information about the company's data-driven culture and career development opportunities in CPG analytics.","use_cases":"Finding data science roles focused on pricing and revenue optimization in the CPG industry, Exploring career paths in consumer analytics at a Fortune 500 company with global reach","audience":"Junior-DS, Curious-browser"},{"id":"career-colgate-palmolive","type":"career","name":"Colgate-Palmolive","description":"Career portal","category":"Company Lists","url":"https://jobs.colgate.com/","difficulty":"beginner","prerequisites":"undergraduate-economics, basic-statistics","topic_tags":"cpg, career-portal, industry-jobs, pricing-analytics, consumer-goods","summary":"Colgate-Palmolive's career portal showcasing opportunities in consumer packaged goods (CPG) analytics and pricing strategy. The company is known for advanced revenue growth management (RGM) and price elasticity modeling work. This portal provides insight into industry career paths for data scientists interested in consumer behavior and pricing optimization.","use_cases":"Junior data scientist exploring CPG industry career opportunities and required skills, Economics PhD student researching companies that apply price elasticity models in practice","audience":"Junior-DS, Curious-browser"},{"id":"career-target","type":"career","name":"Target","description":"Career portal","category":"Company Lists","url":"https://corporate.target.com/careers","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, job-search, retail-tech, corporate-careers, merchandising","summary":"Target's career portal provides information about job opportunities at one of the largest retail corporations in the US. The portal showcases roles across merchandising, supply chain, data science, and technology teams. It's particularly valuable for understanding how traditional retail companies are integrating data science and analytics into their operations.","use_cases":"Junior data scientist looking for retail industry opportunities with strong analytics culture, Recent graduate exploring corporate career paths in merchandising and supply chain optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-nordstrom","type":"career","name":"Nordstrom","description":"Career portal","category":"Company Lists","url":"https://careers.nordstrom.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, retail-analytics, job-portal, department-store, experimentation","summary":"Nordstrom's career portal showcasing job opportunities at the major department store retailer. The company is known for leveraging data science and experimentation in retail operations, merchandising, and customer experience optimization. Useful for exploring career paths in retail analytics and e-commerce data science.","use_cases":"Finding data science roles in retail/e-commerce industry, Researching company culture and tech stack before applying to Nordstrom","audience":"Junior-DS, Curious-browser"},{"id":"career-macy's","type":"career","name":"Macy's","description":"Career portal","category":"Company Lists","url":"https://www.macysinc.com/work-with-us/careers/","difficulty":"beginner","prerequisites":"basic-economics, business-fundamentals","topic_tags":"career-opportunities, retail-industry, department-store, pricing-strategy, corporate-jobs","summary":"Macy's career portal provides information about job opportunities at one of America's largest department store chains. The portal is particularly relevant for tech economists interested in retail analytics, pricing strategy, and consumer behavior roles. It offers insights into how traditional retailers are adapting their business models and data practices in the digital economy.","use_cases":"Exploring data science and analytics roles in traditional retail companies, Researching career paths in pricing and revenue optimization at established department stores","audience":"Junior-DS, Curious-browser"},{"id":"career-lowe's","type":"career","name":"Lowe's","description":"Career portal","category":"Company Lists","url":"https://talent.lowes.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, home-improvement, retail-analytics, job-portal, econ-preferred","summary":"Lowe's career portal showcasing job opportunities at the home improvement retail chain. The company actively recruits economists and data scientists for roles in pricing, demand forecasting, and customer analytics. Particularly valuable for those interested in retail economics and supply chain optimization.","use_cases":"Applying for economist or data scientist roles at a major retailer with complex pricing and inventory challenges, Researching career paths in retail analytics and home improvement market analysis","audience":"Junior-DS, Curious-browser"},{"id":"career-best-buy","type":"career","name":"Best Buy","description":"Career portal","category":"Company Lists","url":"https://jobs.bestbuy.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, electronics-retail, job-portal, tech-jobs, corporate","summary":"Best Buy's career portal showcasing job opportunities at one of the largest electronics retailers in North America. The company offers positions across technology, data science, e-commerce, and retail operations with significant focus on digital transformation and personalization initiatives. Useful for understanding how traditional retailers are investing in tech talent and data-driven capabilities.","use_cases":"Exploring data science roles in retail and e-commerce personalization, Understanding career paths at large technology-forward retailers","audience":"Junior-DS, Curious-browser"},{"id":"career-kohl's","type":"career","name":"Kohl's","description":"Career portal","category":"Company Lists","url":"https://careers.kohls.com/","difficulty":"beginner","prerequisites":"basic-statistics, excel-proficiency","topic_tags":"career-opportunities, retail-analytics, department-store, pricing-analytics, job-portal","summary":"Kohl's career portal showcasing opportunities in retail analytics and data science at one of America's largest department store chains. The company offers roles in pricing optimization, customer analytics, and merchandising analysis. Ideal for data scientists interested in applying quantitative methods to retail operations and consumer behavior.","use_cases":"Junior data scientist seeking entry-level position in retail analytics and pricing optimization, Career changer exploring opportunities to apply analytical skills in department store operations and merchandising","audience":"Junior-DS, Curious-browser"},{"id":"career-albertsons","type":"career","name":"Albertsons","description":"Career portal","category":"Company Lists","url":"https://www.albertsons.com/careers.html","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, grocery-retail, data-science-jobs, demand-forecasting","summary":"Albertsons career portal providing job opportunities at one of the largest grocery retail chains in the US. The company offers data science and analytics roles focused on demand forecasting, pricing optimization, and customer analytics. Relevant for tech economists interested in retail operations and supply chain analytics.","use_cases":"Finding data scientist positions specializing in grocery retail and demand forecasting, Exploring career opportunities in supply chain analytics at a major retailer","audience":"Junior-DS, Mid-DS"},{"id":"career-walgreens","type":"career","name":"Walgreens","description":"Career portal","category":"Company Lists","url":"https://jobs.walgreens.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, pharmacy, healthcare-jobs, industry-opportunities","summary":"Walgreens career portal providing job opportunities at one of the largest pharmacy chains in the US. Relevant for tech economists interested in healthcare, retail analytics, and real-world evidence roles. Offers positions in data science, analytics, and research within the pharmacy and healthcare sector.","use_cases":"Finding data science roles focused on healthcare and pharmacy analytics, Exploring career opportunities in real-world evidence and healthcare outcomes research","audience":"Junior-DS, Mid-DS"},{"id":"career-costco","type":"career","name":"Costco","description":"Career portal","category":"Company Lists","url":"https://careers.costco.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-applications, retail-analytics, warehouse-operations, corporate-careers","summary":"Costco's career portal provides job opportunities at the membership-based warehouse club retailer. The portal offers positions ranging from data science and analytics roles to operations and corporate functions. Tech economists and data professionals can explore opportunities in retail analytics, supply chain optimization, and membership data analysis.","use_cases":"Applying for data scientist positions focused on retail analytics and customer behavior analysis, Exploring corporate strategy roles that leverage economic analysis for warehouse operations and pricing","audience":"Junior-DS, Curious-browser"},{"id":"career-chewy","type":"career","name":"Chewy","description":"Career portal","category":"Company Lists","url":"https://careers.chewy.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, ecommerce, job-search, tech-companies, pet-industry","summary":"Chewy is a major e-commerce company specializing in pet products and subscription services, offering various data science and analytics career opportunities. The company provides a career portal for tech professionals interested in working in the pet industry vertical. Data scientists and analysts can find roles focused on recommendation systems, customer analytics, and supply chain optimization.","use_cases":"Looking for data science roles at pet-focused e-commerce companies, Researching career opportunities in subscription-based business models","audience":"Junior-DS, Curious-browser"},{"id":"career-fanatics","type":"career","name":"Fanatics","description":"Career portal","category":"Company Lists","url":"https://www.fanaticsinc.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, ecommerce, sports-tech, job-search, company-research","summary":"Fanatics is a major sports merchandise and collectibles ecommerce company with significant data science and technology operations. This career portal provides information about job opportunities, company culture, and technical roles at Fanatics. It serves as a resource for data scientists and engineers interested in sports technology and ecommerce analytics.","use_cases":"Researching Fanatics as a potential employer in sports tech and ecommerce analytics, Understanding career paths and technical roles available at major sports merchandise companies","audience":"Junior-DS, Curious-browser"},{"id":"career-shein","type":"career","name":"Shein","description":"Career portal","category":"Company Lists","url":"https://careers.shein.com/","difficulty":"beginner","prerequisites":"basic-research-skills, web-navigation","topic_tags":"career-opportunities, fast-fashion, ecommerce, company-research","summary":"Shein's career portal provides job listings and company information for one of the world's largest fast-fashion e-commerce platforms. The portal offers insights into roles spanning data science, engineering, marketing, and operations at a rapidly scaling global retailer. It's useful for understanding career paths in fast-fashion tech and the types of skills valued at major e-commerce companies.","use_cases":"Researching data science roles at major e-commerce companies in the fast-fashion industry, Understanding skill requirements and career progression at rapidly scaling retail tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-temu","type":"career","name":"Temu","description":"Career portal","category":"Company Lists","url":"https://www.temu.com/careers.html","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"job-search, marketplace-careers, ecommerce-jobs, tech-recruiting, career-portal","summary":"Temu's career portal for exploring job opportunities at the marketplace and ecommerce platform. The portal provides information about company culture, open positions, and application processes for tech roles. Useful for understanding career paths and opportunities in the rapidly growing online marketplace sector.","use_cases":"Researching data science roles at major ecommerce platforms, Understanding career progression opportunities in marketplace tech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-trader-joe's","type":"career","name":"Trader Joe's","description":"Career portal","category":"Company Lists","url":"https://traderjoes.avature.net/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, grocery-retail, job-portal, company-research, employment","summary":"Trader Joe's career portal provides job listings and company information for positions at the popular grocery chain. The portal offers insights into company culture, benefits, and available roles across stores, distribution centers, and corporate offices. It's useful for understanding retail industry employment practices and compensation structures.","use_cases":"Researching retail industry job market and compensation benchmarks, Exploring career opportunities in grocery/retail operations and supply chain","audience":"Curious-browser, Junior-DS"},{"id":"career-lululemon","type":"career","name":"Lululemon","description":"Career portal","category":"Company Lists","url":"https://careers.lululemon.com/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, apparel-industry, experimentation, econ-phd","summary":"Lululemon's career portal showcasing opportunities at the athletic apparel company known for data-driven decision making and experimentation culture. The company frequently seeks economics PhDs and data scientists for roles in pricing, product analytics, and customer insights. Career seekers can explore positions that combine retail domain expertise with quantitative analysis.","use_cases":"Looking for data science roles in retail/apparel industry with strong experimentation focus, Economics PhD seeking industry transition opportunities at companies that value academic rigor","audience":"Curious-browser, Junior-DS"},{"id":"career-gap-inc","type":"career","name":"Gap Inc","description":"Career portal","category":"Company Lists","url":"https://www.gapinc.com/en-us/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, retail-analytics, apparel-industry, job-opportunities","summary":"Gap Inc's career portal showcasing data science and analytics opportunities within one of the world's largest apparel retailers. The portal provides insights into how tech economists work in retail forecasting, inventory optimization, and consumer behavior analysis. Useful for understanding industry applications of economic methods in fashion and retail.","use_cases":"Exploring data science career paths in retail and consumer goods companies, Understanding how forecasting and demand planning work in apparel industry","audience":"Junior-DS, Curious-browser"},{"id":"career-h&m","type":"career","name":"H&M","description":"Career portal","category":"Company Lists","url":"https://career.hm.com/","difficulty":"beginner","prerequisites":"basic-statistics, excel-or-python","topic_tags":"career-opportunities, retail-analytics, fashion-tech, supply-chain","summary":"H&M's career portal showcasing opportunities in retail analytics, demand forecasting, and supply chain optimization. The company offers roles spanning data science, economics, and operations research in the fast fashion industry. Provides insight into how large retailers apply quantitative methods to inventory management and consumer behavior analysis.","use_cases":"Exploring data science career paths in retail and fashion industry, Understanding how fast fashion companies structure their analytics teams","audience":"Junior-DS, Curious-browser"},{"id":"career-adidas","type":"career","name":"Adidas","description":"Career portal","category":"Company Lists","url":"https://careers.adidas-group.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, apparel-industry, pricing-optimization, job-opportunities","summary":"Adidas career portal providing job opportunities at the global sportswear company. Particularly relevant for tech economists interested in roles involving pricing optimization and retail analytics in the apparel industry. Offers entry points into applied economics work in consumer goods.","use_cases":"Finding pricing analyst or data scientist roles in retail/apparel industry, Exploring career opportunities that combine economics with consumer product strategy","audience":"Junior-DS, Curious-browser"},{"id":"career-kering","type":"career","name":"Kering","description":"Career portal","category":"Company Lists","url":"https://www.kering.com/en/talent/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, luxury-industry, data-jobs, company-research","summary":"Kering's career portal showcasing data science and analytics opportunities at luxury brands like Gucci, Saint Laurent, and Bottega Veneta. The portal provides insights into data intelligence roles within the luxury fashion industry. Tech professionals can explore positions ranging from customer analytics to supply chain optimization at one of the world's leading luxury conglomerates.","use_cases":"Researching data science career opportunities in luxury retail and fashion industry, Understanding how luxury brands like Gucci and Saint Laurent structure their data teams and requirements","audience":"Junior-DS, Curious-browser"},{"id":"career-ralph-lauren","type":"career","name":"Ralph Lauren","description":"Career portal","category":"Company Lists","url":"https://careers.ralphlauren.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, apparel-industry, data-jobs, company-research","summary":"Ralph Lauren's career portal provides job opportunities and company information for data science and analytics roles within the luxury apparel industry. The portal offers insights into the company's data lab initiatives and technical career paths. It serves as a resource for understanding how data science is applied in fashion retail and brand management.","use_cases":"Researching data science opportunities in fashion and retail companies, Understanding career progression and role requirements at luxury apparel brands","audience":"Junior-DS, Curious-browser"},{"id":"career-pvh","type":"career","name":"PVH","description":"Career portal","category":"Company Lists","url":"https://careers.pvh.com/","difficulty":"beginner","prerequisites":"web-navigation, job-search-basics","topic_tags":"career-portal, fashion-retail, corporate-jobs, apparel-industry","summary":"PVH is a career portal for one of the world's largest apparel companies, owning brands like Calvin Klein and Tommy Hilfiger. Tech economists and data scientists can explore opportunities in retail analytics, supply chain optimization, and consumer behavior analysis within the fashion industry. The portal provides insights into data-driven roles at a major consumer goods corporation.","use_cases":"Exploring data science career opportunities in fashion retail and consumer goods, Researching company culture and tech roles at a major apparel corporation","audience":"Junior-DS, Curious-browser"},{"id":"career-vf-corporation","type":"career","name":"VF Corporation","description":"Career portal","category":"Company Lists","url":"https://www.vfc.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, apparel-industry, corporate-jobs","summary":"VF Corporation's career portal provides job opportunities at one of the world's largest apparel companies, home to brands like Vans, The North Face, and Timberland. The portal offers positions across various functions including data science, analytics, marketing, and operations. Tech economists can explore roles that combine consumer behavior analysis, supply chain optimization, and retail analytics.","use_cases":"Finding data science or analytics roles in the consumer goods and apparel industry, Exploring corporate career opportunities at a Fortune 500 company with diverse brand portfolio","audience":"Junior-DS, Curious-browser"},{"id":"career-under-armour","type":"career","name":"Under Armour","description":"Career portal","category":"Company Lists","url":"https://careers.underarmour.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, athletic-apparel, sports-tech, job-portal, company-profiles","summary":"Under Armour's career portal for exploring job opportunities at the athletic apparel and sports technology company. The portal provides insights into company culture, available positions, and application processes for data science and analytics roles in the sports industry. Useful for understanding how tech roles operate within consumer goods and athletic performance companies.","use_cases":"Researching data science opportunities in the athletic apparel industry, Understanding how consumer brands structure their analytics and technology teams","audience":"Junior-DS, Curious-browser"},{"id":"career-lvmh","type":"career","name":"LVMH","description":"Career portal","category":"Company Lists","url":"https://www.lvmh.com/en/join-us/our-job-offers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, luxury-brands, job-opportunities, data-careers, company-research","summary":"LVMH's career portal showcasing data science and analytics opportunities at the world's largest luxury goods conglomerate. The portal provides insights into how data drives decision-making across luxury brands like Louis Vuitton, Mo\u00ebt & Chandon, and Hennessy. It's valuable for understanding career paths and data applications in the luxury retail sector.","use_cases":"Researching data science roles at luxury brands and understanding industry-specific analytics challenges, Exploring career transitions from tech companies to luxury retail and consumer goods","audience":"Junior-DS, Curious-browser"},{"id":"career-inditex-(zara)","type":"career","name":"Inditex (Zara)","description":"Career portal","category":"Company Lists","url":"https://www.inditexcareers.com/","difficulty":"beginner","prerequisites":"resume-writing, industry-research","topic_tags":"career-opportunities, retail-analytics, fashion-tech, company-research","summary":"Inditex is the parent company of Zara and other fast-fashion brands, known for sophisticated supply chain optimization and data-driven inventory management. Their career portal offers opportunities in retail analytics, demand forecasting, and operations research. Tech economists study Inditex as a prime example of how data science drives competitive advantage in fast fashion.","use_cases":"Researching career opportunities in retail analytics and supply chain optimization at a data-driven fashion company, Studying Inditex's business model and data science applications for academic research on digital transformation in retail","audience":"Junior-DS, Curious-browser"},{"id":"career-unilever","type":"career","name":"Unilever","description":"Career portal","category":"Company Lists","url":"https://careers.unilever.com/","difficulty":"beginner","prerequisites":"statistics-basics, experimental-design","topic_tags":"career-opportunities, cpg-industry, data-science-jobs, causal-inference, bayesian-methods","summary":"Unilever's career portal showcasing data science and analytics opportunities at one of the world's largest consumer packaged goods companies. The company is known for applying advanced causal inference and Bayesian methods to marketing mix modeling, pricing optimization, and consumer behavior analysis. Offers roles spanning from entry-level analyst positions to senior data scientist roles working on brand portfolio optimization.","use_cases":"Finding data science roles that apply causal inference to marketing and consumer goods, Exploring career paths in CPG industry that utilize Bayesian statistical methods","audience":"Junior-DS, Curious-browser"},{"id":"career-nestl\u00e9","type":"career","name":"Nestl\u00e9","description":"Career portal","category":"Company Lists","url":"https://www.nestle.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, cpg, commercial-analytics, job-applications, corporate-careers","summary":"Nestl\u00e9's corporate career portal showcasing data science and analytics opportunities at one of the world's largest consumer packaged goods companies. The portal provides insights into commercial analytics roles, company culture, and application processes for tech professionals interested in CPG industry applications. Offers exposure to how global brands leverage data science for consumer insights, supply chain optimization, and market research.","use_cases":"Junior data scientists exploring career opportunities in consumer packaged goods industry and commercial analytics roles, Career changers researching how established CPG companies structure their data teams and what skills they prioritize","audience":"Junior-DS, Curious-browser"},{"id":"career-coca-cola","type":"career","name":"Coca-Cola","description":"Career portal","category":"Company Lists","url":"https://www.coca-colacompany.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, cpg-industry, coca-cola, job-applications, corporate-careers","summary":"Coca-Cola's official career portal for exploring job opportunities at one of the world's largest consumer packaged goods companies. The site features data science, analytics, marketing, and business roles across global markets. Useful for understanding career paths and job requirements in the CPG industry.","use_cases":"Searching for data scientist or analyst positions at a major CPG company, Researching career requirements and job descriptions in consumer goods industry","audience":"Junior-DS, Curious-browser"},{"id":"career-kraft-heinz","type":"career","name":"Kraft Heinz","description":"Career portal","category":"Company Lists","url":"https://careers.kraftheinz.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, cpg-industry, food-manufacturing, corporate-jobs, revenue-management","summary":"Kraft Heinz career portal for job opportunities at the consumer packaged goods giant. The company offers roles spanning data science, revenue growth management, supply chain, and marketing analytics. Ideal entry point for data professionals interested in applying analytics to food industry challenges like pricing optimization and demand forecasting.","use_cases":"Junior data scientist seeking first industry role in CPG with established analytics infrastructure, Mid-career analyst looking to transition into revenue growth management at a Fortune 500 food company","audience":"Junior-DS, Mid-DS"},{"id":"career-general-mills","type":"career","name":"General Mills","description":"Career portal","category":"Company Lists","url":"https://careers.generalmills.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, cpg-industry, data-science-jobs, corporate-careers","summary":"General Mills career portal featuring data science and analytics opportunities at a major consumer packaged goods company. The portal showcases roles in marketing mix modeling, optimization, and consumer insights within the CPG industry. Provides insight into how large consumer brands structure their analytics teams and apply data science to product marketing and operations.","use_cases":"Exploring data science career opportunities in the consumer packaged goods industry, Understanding how CPG companies like General Mills structure their analytics and data science roles","audience":"Junior-DS, Curious-browser"},{"id":"career-kimberly-clark","type":"career","name":"Kimberly-Clark","description":"Career portal","category":"Company Lists","url":"https://careers.kimberly-clark.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, cpg-industry, ai-first-companies, job-opportunities, corporate-careers","summary":"Kimberly-Clark's career portal showcasing opportunities at the consumer packaged goods company known for brands like Kleenex and Huggies. The portal highlights their AI-first transformation and data science roles across product development, supply chain optimization, and consumer insights. Useful for exploring how traditional CPG companies are integrating modern analytics and machine learning into their operations.","use_cases":"Exploring data science career opportunities at established CPG companies transitioning to AI-first operations, Understanding how traditional consumer goods companies structure their analytics and technology teams","audience":"Junior-DS, Curious-browser"},{"id":"career-clorox","type":"career","name":"Clorox","description":"Career portal","category":"Company Lists","url":"https://www.thecloroxcompany.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"career-portal, cpg-industry, marketing-analytics, job-search","summary":"Clorox's career portal showcasing data science and marketing analytics opportunities at a major consumer packaged goods company. The portal provides insights into CPG industry data roles, company culture, and application processes. Useful for understanding how data science is applied in traditional consumer goods companies.","use_cases":"Exploring data science career opportunities in the CPG industry, Understanding marketing analytics roles at established consumer brands","audience":"Junior-DS, Curious-browser"},{"id":"career-mondel\u0113z","type":"career","name":"Mondel\u0113z","description":"Career portal","category":"Company Lists","url":"https://www.mondelezinternational.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, cpg-industry, pricing-strategy, corporate-jobs","summary":"Mondel\u0113z International's career portal providing job opportunities at the global snacking company. The portal offers positions across various functions including data science, pricing, and product management roles. Particularly relevant for tech economists interested in consumer packaged goods (CPG) industry applications of pricing and pack architecture optimization.","use_cases":"Searching for data science roles in CPG industry with focus on pricing optimization, Exploring corporate career paths in pack architecture and revenue management","audience":"Junior-DS, Curious-browser"},{"id":"career-mars","type":"career","name":"Mars","description":"Career portal","category":"Company Lists","url":"https://careers.mars.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, cpg-jobs, analytics-careers, company-directory","summary":"Mars is a career portal focused on consumer packaged goods (CPG) companies and analytics roles. It provides job listings, company information, and career resources for professionals looking to work in the CPG industry with data science and analytics positions. The portal serves as a curated directory for CPG-focused career opportunities.","use_cases":"Finding analytics roles at CPG companies like P&G, Unilever, or Nestle, Researching CPG industry employers and their data science team structures","audience":"Junior-DS, Curious-browser"},{"id":"career-kenvue","type":"career","name":"Kenvue","description":"Career portal","category":"Company Lists","url":"https://jobs.kenvue.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"careers, cpg-industry, corporate-jobs, kenvue, operations-research","summary":"Kenvue is a consumer health company spun off from Johnson & Johnson, focusing on everyday health brands like Band-Aid, Tylenol, and Listerine. The career portal provides job opportunities for data scientists and operations researchers in CPG analytics, supply chain optimization, and consumer insights. Tech economists can find roles applying quantitative methods to consumer behavior analysis and business operations.","use_cases":"Junior data scientist looking for entry-level positions in consumer packaged goods industry, Operations research professional seeking roles in supply chain analytics and demand forecasting at a major CPG company","audience":"Junior-DS, Curious-browser"},{"id":"career-church-&-dwight","type":"career","name":"Church & Dwight","description":"Career portal","category":"Company Lists","url":"https://careers.churchdwight.com/","difficulty":"beginner","prerequisites":"web-browsing, basic-economics","topic_tags":"career-portal, cpg-industry, corporate-jobs, pricing-roles, job-search","summary":"Church & Dwight's career portal showcasing job opportunities at the consumer packaged goods company known for brands like Arm & Hammer. The portal provides insights into pricing analyst, data scientist, and market research roles within the CPG industry. Useful for understanding career paths and compensation structures in consumer goods companies.","use_cases":"Researching CPG industry career opportunities and salary benchmarks, Identifying companies that hire pricing analysts and revenue optimization roles","audience":"Junior-DS, Curious-browser"},{"id":"career-l'or\u00e9al","type":"career","name":"L'Or\u00e9al","description":"Career portal","category":"Company Lists","url":"https://careers.loreal.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"career-portal, beauty-industry, corporate-jobs, bi-analytics, data-careers","summary":"L'Or\u00e9al's career portal showcasing opportunities at the global beauty company, with particular emphasis on business intelligence and analytics roles. The portal provides insight into data science positions within the consumer goods and beauty industry. Useful for understanding how traditional corporations structure their analytics teams and career progression paths.","use_cases":"Junior data scientists exploring opportunities in consumer goods companies, Mid-career professionals researching L'Or\u00e9al's analytics organization structure and role requirements","audience":"Junior-DS, Mid-DS"},{"id":"career-est\u00e9e-lauder","type":"career","name":"Est\u00e9e Lauder","description":"Career portal","category":"Company Lists","url":"https://www.elcompanies.com/en/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, beauty-industry, consumer-goods, job-applications, company-research","summary":"Est\u00e9e Lauder's career portal provides job opportunities and company information for one of the world's largest beauty and cosmetics companies. The portal serves as a gateway for tech professionals interested in consumer goods analytics, e-commerce optimization, and beauty industry data science roles. It offers insights into how a traditional consumer brand approaches digital transformation and data-driven decision making.","use_cases":"Researching data science opportunities in the beauty/consumer goods industry, Understanding how traditional retail companies structure their tech and analytics teams","audience":"Junior-DS, Curious-browser"},{"id":"career-ulta-beauty","type":"career","name":"Ulta Beauty","description":"Career portal","category":"Company Lists","url":"https://careers.ulta.com/","difficulty":"beginner","prerequisites":"python-pandas, SQL-basics","topic_tags":"career-opportunities, beauty-industry, retail-analytics, company-research","summary":"Ulta Beauty's career portal showcasing data science and analytics opportunities at one of the largest beauty retailers in the US. The company is known for its extensive loyalty program and personalized customer experiences, making it relevant for those interested in retail analytics and recommendation systems. Provides insight into how beauty companies approach data-driven decision making.","use_cases":"Researching career opportunities at beauty/retail companies that heavily use customer analytics and personalization, Understanding how major retailers structure their data science teams and what skills they prioritize","audience":"Junior-DS, Curious-browser"},{"id":"career-sephora","type":"career","name":"Sephora","description":"Career portal","category":"Company Lists","url":"https://jobs.sephora.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"beauty-industry, career-opportunities, tech-roles, retail-analytics, crm-jobs","summary":"Sephora's career portal showcasing data science, analytics, and tech opportunities at the global beauty retailer. The company offers roles spanning customer analytics, marketing mix modeling, recommendation systems, and CRM optimization. This resource helps tech professionals understand career paths in beauty retail and the data challenges unique to cosmetics e-commerce.","use_cases":"Finding data science jobs focused on beauty industry applications and customer personalization, Researching career opportunities at companies that heavily use marketing mix modeling and CRM analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-coty","type":"career","name":"Coty","description":"Career portal","category":"Company Lists","url":"https://careers.coty.com/","difficulty":"beginner","prerequisites":"excel-spreadsheets, basic-statistics","topic_tags":"career-resources, beauty-industry, pricing-analytics, company-research, job-search","summary":"Coty is a career portal focusing on beauty industry opportunities with emphasis on pricing analytics roles. The platform provides company listings and career resources specifically tailored to beauty and consumer goods sectors. It serves as a gateway for professionals seeking positions that combine beauty industry knowledge with analytical skills.","use_cases":"Finding pricing analyst positions at beauty companies like L'Oreal or Unilever, Researching beauty industry employers before applying for data science roles in consumer goods","audience":"Junior-DS, Curious-browser"},{"id":"career-ikea","type":"career","name":"IKEA","description":"Career portal","category":"Company Lists","url":"https://jobs.ikea.com/en","difficulty":"beginner","prerequisites":"basic-job-search, resume-writing","topic_tags":"career-portal, furniture-industry, retail-tech, corporate-jobs, demand-sensing","summary":"IKEA's career portal showcasing opportunities at the global furniture retailer known for its data-driven approach to demand sensing and AI applications. The company offers roles spanning retail analytics, supply chain optimization, and customer experience teams. Tech economists can explore positions that combine furniture industry expertise with modern data science techniques.","use_cases":"Finding data science roles in retail/furniture industry with focus on demand forecasting, Exploring corporate positions that blend traditional retail with AI and demand sensing technologies","audience":"Junior-DS, Curious-browser"},{"id":"career-williams-sonoma","type":"career","name":"Williams-Sonoma","description":"Career portal","category":"Company Lists","url":"https://careers.williams-sonomainc.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, retail-jobs, corporate-careers, furniture, pottery-barn","summary":"Williams-Sonoma's career portal provides job opportunities across their retail brands including Pottery Barn, West Elm, and Williams Sonoma. The portal offers positions in data science, analytics, technology, and business roles within the home furnishings and retail sector. It serves as a gateway for professionals seeking to apply quantitative skills in retail analytics and e-commerce.","use_cases":"Finding data science roles at major retail companies with strong e-commerce presence, Exploring career opportunities in retail analytics and consumer behavior research","audience":"Junior-DS, Curious-browser"},{"id":"career-rh","type":"career","name":"RH","description":"Career portal","category":"Company Lists","url":"https://rh.com/careers","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-development, job-search, company-research, furniture-industry, luxury-brands","summary":"RH (formerly Restoration Hardware) is a luxury home furnishings company that operates as both a retailer and design platform. This career portal provides information about opportunities at RH for data scientists and analysts interested in retail analytics, customer experience optimization, and luxury market research. The resource covers RH's data-driven approach to inventory management, customer segmentation, and omnichannel retail strategy.","use_cases":"Researching RH as a potential employer for retail analytics roles, Understanding luxury retail business models for case study preparation","audience":"Junior-DS, Curious-browser"},{"id":"career-beyond-inc","type":"career","name":"Beyond Inc","description":"Career portal","category":"Company Lists","url":"https://corporate.beyond.com/corporate/careers","difficulty":"beginner","prerequisites":"web-browsing, job-search-basics","topic_tags":"career-portal, ecommerce-jobs, overstock-careers, tech-recruiting, company-research","summary":"Beyond Inc's career portal provides job listings and company information for the ecommerce company (formerly Overstock.com). Early career professionals and job seekers can explore opportunities in data science, analytics, and tech roles at this established online retail company. The portal offers insights into company culture, benefits, and specific role requirements.","use_cases":"Researching data scientist positions at ecommerce companies, Learning about Beyond Inc's tech stack and culture before applying","audience":"Junior-DS, Curious-browser"},{"id":"career-petco","type":"career","name":"Petco","description":"Career portal","category":"Company Lists","url":"https://careers.petco.com/","difficulty":"beginner","prerequisites":"basic-web-navigation, job-search-fundamentals","topic_tags":"career-opportunities, pet-industry, company-research, job-portal","summary":"Petco's career portal provides job listings and company information for one of the largest pet retail chains in the US. The portal offers insights into data science, analytics, and tech roles within the pet industry ecosystem. It's useful for understanding how retail companies structure their data teams and what skills they prioritize.","use_cases":"Researching data science career opportunities in retail/pet industry, Understanding skill requirements and team structures at large retail companies","audience":"Junior-DS, Curious-browser"},{"id":"career-o'reilly-auto-parts","type":"career","name":"O'Reilly Auto Parts","description":"Career portal","category":"Company Lists","url":"https://careers.oreillyauto.com/","difficulty":"beginner","prerequisites":"basic-statistics, supply-chain-fundamentals","topic_tags":"careers, auto-industry, inventory-optimization, retail-analytics","summary":"O'Reilly Auto Parts career portal provides job opportunities at one of the largest automotive aftermarket retailers in North America. The company offers data science and analytics roles focused on inventory optimization, demand forecasting, and supply chain analytics across thousands of retail locations. Tech economists can explore career paths in retail operations research and automotive industry analytics.","use_cases":"Finding data science roles in automotive retail and inventory management, Exploring career opportunities in supply chain optimization at scale","audience":"Junior-DS, Curious-browser"},{"id":"career-tractor-supply","type":"career","name":"Tractor Supply","description":"Career portal","category":"Company Lists","url":"https://www.tractorsupply.careers/","difficulty":"beginner","prerequisites":"basic-resume-writing, job-search-strategies","topic_tags":"career-portal, retail-jobs, company-research, job-applications, rural-lifestyle","summary":"Tractor Supply Company's career portal for exploring job opportunities at the rural lifestyle retailer. The portal provides insights into company culture, available positions, and application processes for data science and analytics roles within the retail sector. Useful for understanding how data science applies in specialty retail environments focused on agricultural and rural communities.","use_cases":"Researching data science opportunities in retail companies that serve rural markets, Understanding career paths and requirements for analytics roles in specialty retail chains","audience":"Junior-DS, Curious-browser"},{"id":"career-dick's-sporting-goods","type":"career","name":"Dick's Sporting Goods","description":"Career portal","category":"Company Lists","url":"https://www.dickssportinggoods.jobs/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, sporting-goods, job-opportunities, company-research","summary":"Dick's Sporting Goods career portal provides job listings and company information for the major sporting goods retailer. This resource is useful for data scientists and analysts interested in retail, sports analytics, or e-commerce roles. The portal offers insights into career opportunities within the sporting goods industry.","use_cases":"Researching data science career opportunities in retail sporting goods companies, Exploring job openings for analysts interested in sports merchandise and customer analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-autozone","type":"career","name":"AutoZone","description":"Career portal","category":"Company Lists","url":"https://careers.autozone.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, automotive-retail, job-portal, store-operations, career-development","summary":"AutoZone's career portal provides job opportunities at the automotive parts retailer, focusing on store operations, management, and corporate roles. The portal offers insights into career paths in automotive retail, store development, and data-driven merchandising roles. It's useful for understanding how traditional retail companies structure their data and analytics teams.","use_cases":"Finding data analyst or business intelligence roles in automotive retail industry, Researching career progression paths from store operations to corporate analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"career-gamestop","type":"career","name":"GameStop","description":"Career portal","category":"Company Lists","url":"https://careers.gamestop.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, gaming-industry, retail-analytics, trade-pricing","summary":"GameStop's career portal provides job opportunities at the gaming retail company known for trade-in pricing strategies and retail analytics. The portal offers positions ranging from data analysis roles to business strategy positions within the gaming and retail sector. It's particularly relevant for those interested in applying tech-econ skills to gaming industry challenges and retail optimization.","use_cases":"Finding data science roles focused on trade-in pricing optimization and inventory management, Exploring career opportunities in gaming retail analytics and customer behavior modeling","audience":"Junior-DS, Curious-browser"},{"id":"career-petsmart","type":"career","name":"PetSmart","description":"Career portal","category":"Company Lists","url":"https://careers.petsmart.com/","difficulty":"beginner","prerequisites":"basic-sql, customer-analytics","topic_tags":"career-opportunities, pet-industry, retail-analytics, customer-lifetime-value","summary":"PetSmart's career portal showcasing opportunities in data science and analytics roles within the pet retail industry. The company offers positions focused on customer lifetime value analysis, pricing strategy, and retail optimization. Ideal for data professionals interested in applying analytics to pet retail and e-commerce.","use_cases":"Finding data science roles in retail industry with focus on CLV and pricing, Exploring career opportunities in pet industry analytics and customer behavior","audience":"Junior-DS, Curious-browser"},{"id":"career-tjx-companies","type":"career","name":"TJX Companies","description":"Career portal","category":"Company Lists","url":"https://jobs.tjx.com/","difficulty":"beginner","prerequisites":"basic-statistics, excel-or-spreadsheets","topic_tags":"careers, retail-analytics, off-price-retail, demand-forecasting, job-opportunities","summary":"TJX Companies career portal showcasing opportunities at the world's leading off-price retailer of apparel and home goods. The company operates TJ Maxx, Marshalls, HomeGoods, and international brands, offering roles in demand forecasting, inventory optimization, and retail analytics. Career seekers can explore data science positions focused on merchandise planning, pricing strategies, and supply chain analytics in the unique off-price retail environment.","use_cases":"Finding data science roles specializing in retail demand forecasting and inventory management, Exploring career opportunities in off-price retail analytics and merchandise optimization","audience":"Junior-DS, Curious-browser"},{"id":"career-ross-stores","type":"career","name":"Ross Stores","description":"Career portal","category":"Company Lists","url":"https://jobs.rossstores.com/","difficulty":"beginner","prerequisites":"basic-web-navigation, resume-writing","topic_tags":"career-opportunities, retail-analytics, off-price-retail, job-portal","summary":"Ross Stores career portal provides job opportunities at one of the largest off-price retail chains in the US. The company offers positions in retail analytics, supply chain optimization, and data science roles focused on merchandise planning and inventory management. This is particularly relevant for data scientists interested in retail economics and off-price business models.","use_cases":"Looking for entry-level or experienced data science positions in retail industry, Researching career opportunities in off-price retail and supply chain analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-burlington","type":"career","name":"Burlington","description":"Career portal","category":"Company Lists","url":"https://www.burlington.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, retail-analytics, off-price-retail, company-research, job-search","summary":"Burlington is a major off-price retailer offering career opportunities in data science, analytics, and business intelligence roles. The company focuses on customer insights and pricing analytics to optimize inventory and merchandising decisions. This career portal provides information about data-driven roles at Burlington and insights into retail analytics work.","use_cases":"Researching data science career opportunities in retail industry, Understanding how off-price retailers use analytics for merchandising decisions","audience":"Junior-DS, Curious-browser"},{"id":"career-dollar-general","type":"career","name":"Dollar General","description":"Career portal","category":"Company Lists","url":"https://careers.dollargeneral.com/","difficulty":"beginner","prerequisites":"basic-statistics, retail-analytics","topic_tags":"career-opportunities, retail-tech, dollar-general, company-research","summary":"Career portal for Dollar General, a major discount retail chain that has increasingly invested in AI and optimization technologies. This resource provides information about job opportunities at a company known for applying data science to supply chain management, pricing optimization, and store operations. Useful for understanding how traditional retail companies are incorporating modern analytics roles.","use_cases":"Researching data science career opportunities at retail companies, Understanding how discount retailers apply AI and optimization in their business operations","audience":"Junior-DS, Curious-browser"},{"id":"career-dollar-tree","type":"career","name":"Dollar Tree","description":"Career portal","category":"Company Lists","url":"https://careers.dollartree.com/","difficulty":"beginner","prerequisites":"basic-economics, market-research","topic_tags":"career-opportunities, retail-economics, discount-retail, pricing-strategy","summary":"Dollar Tree's career portal showcasing opportunities at one of the largest discount retail chains in North America. The company operates over 15,000 stores with a unique $1.25 fixed-price model, making it a valuable case study for economists studying pricing strategies and retail market dynamics. Career opportunities span retail operations, supply chain, data analysis, and corporate strategy roles.","use_cases":"Exploring career opportunities in discount retail economics and pricing strategy roles, Researching Dollar Tree as a case study for fixed-price retail business models","audience":"Curious-browser, Junior-DS"},{"id":"career-five-below","type":"career","name":"Five Below","description":"Career portal","category":"Company Lists","url":"https://careers.fivebelow.com/","difficulty":"beginner","prerequisites":"job-search-fundamentals, resume-writing","topic_tags":"career-portal, retail-jobs, company-research, job-applications, value-retail","summary":"Five Below is a value-retail company career portal for exploring job opportunities at the discount merchandise chain. The portal provides information about company culture, available positions, and application processes across retail, corporate, and analytics roles. It serves as a resource for understanding career paths and opportunities within the value retail sector.","use_cases":"Researching retail analytics positions at value-oriented companies, Exploring corporate career opportunities in discount retail chains","audience":"Junior-DS, Curious-browser"},{"id":"career-jpmorgan-chase","type":"career","name":"JPMorgan Chase","description":"Career portal","category":"Company Lists","url":"https://www.jpmorganchase.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, finance, banking, job-search, economist-roles","summary":"JPMorgan Chase's career portal provides job listings and application information for roles at one of the largest investment banks. The portal includes economist positions, data science roles, and quantitative analyst opportunities across their various divisions. It serves as the primary gateway for exploring career opportunities in financial services and understanding the bank's hiring requirements.","use_cases":"Searching for economist or data scientist positions at a major financial institution, Researching career paths and job requirements in investment banking and financial services","audience":"Junior-DS, Curious-browser"},{"id":"career-wells-fargo","type":"career","name":"Wells Fargo","description":"Career portal","category":"Company Lists","url":"https://www.wellsfargojobs.com","difficulty":"beginner","prerequisites":"resume-writing, SQL-basics","topic_tags":"banking-careers, economist-jobs, finance-industry, job-portal","summary":"Wells Fargo's career portal showcasing economist and data science opportunities at one of the largest US banks. The portal provides job listings, company culture information, and application processes for quantitative roles in financial services. Useful for understanding career paths and requirements in traditional banking economics.","use_cases":"Researching economist job requirements and salary ranges at major banks, Finding entry-level data science positions in financial services","audience":"Junior-DS, Curious-browser"},{"id":"career-citi","type":"career","name":"Citi","description":"Career portal","category":"Company Lists","url":"https://jobs.citi.com","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"banking-careers, financial-services, economist-jobs, career-portal","summary":"Citigroup's career portal featuring job opportunities in financial services, including economist and data science roles. The portal provides access to positions across global markets, risk management, and quantitative analysis teams. Useful for understanding career paths and job requirements at a major financial institution.","use_cases":"Exploring economist job opportunities at a major investment bank, Understanding skill requirements and career progression in financial services","audience":"Junior-DS, Curious-browser"},{"id":"career-bank-of-america","type":"career","name":"Bank of America","description":"Career portal","category":"Company Lists","url":"https://careers.bankofamerica.com","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, banking, economist-jobs, corporate-careers","summary":"Bank of America's career portal featuring job opportunities for economists and data scientists in the financial services sector. The portal provides access to positions across various divisions including risk management, economic research, and quantitative analysis. Useful for understanding career paths and job requirements at major financial institutions.","use_cases":"Exploring economist and data scientist roles at a major bank to understand required skills and career progression, Researching job descriptions to identify what technical skills are valued in financial services","audience":"Junior-DS, Curious-browser"},{"id":"career-morgan-stanley","type":"career","name":"Morgan Stanley","description":"Career portal","category":"Company Lists","url":"https://www.morganstanley.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, finance-jobs, economist-positions, banking-careers","summary":"Morgan Stanley's career portal provides job listings and recruitment information for the global investment bank. The portal is particularly relevant for economists and data scientists interested in finance roles, offering positions in research, quantitative analysis, and strategic planning. It serves as a gateway for tech-savvy professionals looking to transition into financial services.","use_cases":"Junior DS exploring finance career opportunities at major investment banks, Economics PhD seeking industry research positions in financial markets","audience":"Junior-DS, Curious-browser"},{"id":"career-pnc","type":"career","name":"PNC","description":"Career portal","category":"Company Lists","url":"https://careers.pnc.com","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-opportunities, banking-sector, economist-jobs, finance-careers","summary":"PNC is a major regional bank that regularly hires economists and data scientists for roles in risk management, economic research, and analytics. The career portal provides information about open positions, company culture, and application processes at one of the largest financial institutions in the US.","use_cases":"Searching for economist positions at major banks and financial institutions, Researching career opportunities in applied economics within the banking sector","audience":"Junior-DS, Curious-browser"},{"id":"career-truist","type":"career","name":"Truist","description":"Career portal","category":"Company Lists","url":"https://careers.truist.com/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"banking, career-portal, economist-jobs, financial-services, job-listings","summary":"Truist is a major U.S. bank that employs economists and data scientists across various divisions including risk management, consumer analytics, and economic research. Their career portal provides access to economist, data scientist, and quantitative analyst positions within the financial services industry. The bank offers opportunities to work on problems like credit risk modeling, customer segmentation, and macroeconomic forecasting.","use_cases":"Finding economist or data scientist positions at a major financial institution, Exploring career opportunities in banking and financial services analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-ally-financial","type":"career","name":"Ally Financial","description":"Career portal","category":"Company Lists","url":"https://ally.avature.net/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, financial-services, job-listings, economist-positions, banking","summary":"Ally Financial's career portal showcasing available positions at the digital banking company. The portal includes economist-titled roles and other data science positions within financial services. It provides job seekers with direct access to opportunities at a major fintech employer.","use_cases":"Recent economics PhD looking for economist positions in banking and financial services, Data scientist seeking to transition into fintech industry roles","audience":"Junior-DS, Curious-browser"},{"id":"career-mastercard","type":"career","name":"Mastercard","description":"Career portal","category":"Company Lists","url":"https://careers.mastercard.com","difficulty":"beginner","prerequisites":"resume-writing, economics-fundamentals","topic_tags":"career-portal, payments, fintech, economist-jobs","summary":"Mastercard's career portal showcasing job opportunities for economists and data scientists in the payments and fintech industry. The portal provides insights into roles, responsibilities, and career paths at one of the world's largest payment processing companies. It serves as a gateway for professionals interested in applying economic analysis to payments, consumer behavior, and financial technology.","use_cases":"Junior economist exploring career opportunities in fintech and payments industry, Data scientist researching company culture and role requirements before applying to Mastercard","audience":"Junior-DS, Curious-browser"},{"id":"career-visa","type":"career","name":"Visa","description":"Career portal","category":"Company Lists","url":"https://corporate.visa.com/en/careers.html","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, payments, fintech, job-search, economist-roles","summary":"Visa's career portal showcasing open positions and opportunities at one of the world's largest payment processing companies. The portal is particularly relevant for economists and data scientists interested in fintech, payments research, and consumer behavior analysis. It provides insight into how traditional financial services companies structure their economics and data science teams.","use_cases":"Exploring economist and data scientist job opportunities at a major payments company, Researching career paths and role requirements in the fintech payments industry","audience":"Junior-DS, Curious-browser"},{"id":"career-american-express","type":"career","name":"American Express","description":"Career portal","category":"Company Lists","url":"https://www.americanexpress.com/en-us/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-opportunities, payments-industry, job-portal, economist-roles, finance-sector","summary":"American Express career portal showcasing job opportunities at the financial services company, particularly positions with economist titles in payments and financial technology. The portal provides insights into career paths, job requirements, and company culture for economists interested in the payments industry. It serves as a resource for understanding how economic expertise applies in corporate finance and fintech environments.","use_cases":"Exploring economist job opportunities in the payments and financial services industry, Researching career requirements and qualifications for economist roles at major financial companies","audience":"Junior-DS, Curious-browser"},{"id":"career-discover","type":"career","name":"Discover","description":"Career portal","category":"Company Lists","url":"https://jobs.discover.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, job-search, company-research, payments-industry, economist-roles","summary":"A career portal focused on discovering job opportunities at payments companies for economists and data scientists. Provides curated company lists and career guidance for professionals seeking economist-titled roles in the payments sector. Serves as a starting point for exploring career paths in fintech and payment processing companies.","use_cases":"Recent economics PhD looking for industry positions at payment companies like Stripe or PayPal, Data scientist wanting to transition into economist roles at fintech startups","audience":"Junior-DS, Curious-browser"},{"id":"career-fiserv","type":"career","name":"Fiserv","description":"Career portal","category":"Company Lists","url":"https://careers.fiserv.com","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategy","topic_tags":"career-portal, fintech-jobs, payments-industry, economist-roles, job-applications","summary":"Fiserv's career portal showcasing job opportunities at one of the world's largest financial technology companies. The company offers economist positions and data science roles focused on payments, banking technology, and financial services innovation. This portal is valuable for understanding career paths and requirements in the fintech payments sector.","use_cases":"Exploring economist job opportunities in the payments and fintech industry, Researching career requirements and skills needed for data science roles at major financial technology companies","audience":"Junior-DS, Curious-browser"},{"id":"career-fis","type":"career","name":"FIS","description":"Career portal","category":"Company Lists","url":"https://careers.fisglobal.com","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, payments, fintech, job-search, economist-roles","summary":"FIS is a major financial technology company offering payment processing and banking solutions globally. They regularly hire economists and data scientists for roles in fraud detection, risk management, and payment optimization. This career portal provides insights into economist opportunities within the payments industry.","use_cases":"Exploring economist career paths at major fintech companies, Researching payment industry employers for job applications","audience":"Junior-DS, Curious-browser"},{"id":"career-global-payments","type":"career","name":"Global Payments","description":"Career portal","category":"Company Lists","url":"https://www.globalpaymentsjobs.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, payments, job-search, economist-roles, fintech","summary":"Global Payments' career portal showcasing economist and data science opportunities at a leading payments technology company. Provides insight into roles that combine economic analysis with payments industry expertise. Useful for understanding career paths in fintech and payments economics.","use_cases":"Exploring economist positions in the payments industry, Researching career opportunities at major fintech companies","audience":"Junior-DS, Curious-browser"},{"id":"career-brex","type":"career","name":"Brex","description":"Career portal","category":"Company Lists","url":"https://www.brex.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, neobank, fintech-jobs, data-science-careers","summary":"Brex is a fintech company specializing in corporate credit cards and financial services for startups and scaling businesses. The company frequently hires economists and data scientists to work on causal inference problems, pricing models, and risk assessment. Their career portal showcases opportunities to apply economic methods to real-world fintech challenges.","use_cases":"Looking for economist or data scientist positions at a high-growth fintech company, Researching companies that value causal inference and economic modeling skills","audience":"Junior-DS, Curious-browser"},{"id":"career-ramp","type":"career","name":"Ramp","description":"Career portal","category":"Company Lists","url":"https://ramp.com/careers","difficulty":"beginner","prerequisites":"resume-writing, behavioral-interviews","topic_tags":"careers, neobank, fintech, economist-roles, job-portal","summary":"Ramp is a neobank and expense management platform that employs economists and data scientists for causal inference work. Their career portal showcases opportunities to work on economic problems in corporate finance, including roles specifically titled as economists. The company is known for applying rigorous economic methods to business problems in the fintech space.","use_cases":"Finding economist or data scientist roles at a fintech company that values causal inference skills, Researching companies that hire economists for business applications rather than traditional academic roles","audience":"Junior-DS, Curious-browser"},{"id":"career-mercury","type":"career","name":"Mercury","description":"Career portal","category":"Company Lists","url":"https://mercury.com/jobs","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, neobank, job-listings, company-research, causal-inference","summary":"Mercury's career portal provides job opportunities and company information for the neobank and fintech industry. It serves as a gateway for data scientists and economists to explore career paths in financial technology companies. The portal likely includes positions requiring causal inference skills and other quantitative methods common in fintech.","use_cases":"Finding data science jobs at neobanks and fintech companies, Researching Mercury and similar companies before applying for economist or analyst roles","audience":"Junior-DS, Curious-browser"},{"id":"career-chime","type":"career","name":"Chime","description":"Career portal","category":"Company Lists","url":"https://careers.chime.com","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, neobank, fintech, job-portal, causal-inference","summary":"Chime is a neobank career portal providing job opportunities and career resources in the fintech sector. The company is known for using causal inference methods in their data science work, making it particularly relevant for economists and data scientists interested in financial technology applications. Career seekers can explore roles that involve experimental design and causal analysis in digital banking.","use_cases":"Finding data science roles that emphasize causal inference in fintech, Researching neobank career paths for economists transitioning to industry","audience":"Junior-DS, Curious-browser"},{"id":"career-varo-bank","type":"career","name":"Varo Bank","description":"Career portal","category":"Company Lists","url":"https://jobs.lever.co/varomoney","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"neobank, fintech-careers, career-portal, causal-inference, data-science-jobs","summary":"Varo Bank's career portal showcasing job opportunities at a leading neobank focused on financial inclusion and data-driven banking. The company offers roles spanning data science, product analytics, and causal inference applications in digital banking. Particularly relevant for tech economists interested in fintech applications and measuring financial product impacts.","use_cases":"Finding data science roles at neobanks specializing in causal inference and experimentation, Exploring career opportunities in fintech companies applying economic methods to banking products","audience":"Junior-DS, Mid-DS"},{"id":"career-current","type":"career","name":"Current","description":"Career portal","category":"Company Lists","url":"https://current.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, neobank, company-lists, job-search, tech-careers","summary":"A career portal providing curated company lists and job opportunities in the tech economics space, with particular focus on neobank and fintech positions. This resource helps tech professionals discover companies that value causal inference and data science expertise. It serves as a bridge between academic research skills and industry applications.","use_cases":"Finding neobank companies that hire economists and data scientists for causal inference roles, Exploring career transitions from academia to tech companies focused on financial innovation","audience":"Junior-DS, Curious-browser"},{"id":"career-revolut-1","type":"career","name":"Revolut","description":"Career portal","category":"Company Lists","url":"https://www.revolut.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, neobank, fintech, job-opportunities, company-research","summary":"Revolut's career portal showcasing job opportunities at the digital banking and financial technology company. The portal provides insights into roles across data science, engineering, product, and business functions at one of Europe's leading neobanks. Useful for understanding career paths and requirements in the fintech industry.","use_cases":"Researching data science roles and requirements at a major neobank to understand industry expectations, Exploring career opportunities in fintech and understanding how tech roles function in digital banking","audience":"Junior-DS, Curious-browser"},{"id":"career-n26-1","type":"career","name":"N26","description":"Career portal","category":"Company Lists","url":"https://n26.com/en/careers","difficulty":"beginner","prerequisites":"basic-finance, company-research","topic_tags":"neobank, fintech-careers, causal-inference, company-portal","summary":"N26 is a German neobank's career portal showcasing opportunities in digital banking and fintech. The company is known for data-driven decision making and modern financial products. Tech economists can explore roles that combine banking domain knowledge with analytical skills.","use_cases":"Researching fintech companies that heavily use causal inference and experimentation, Finding data science roles in European neobanking sector","audience":"Junior-DS, Curious-browser"},{"id":"career-monzo","type":"career","name":"Monzo","description":"Career portal","category":"Company Lists","url":"https://monzo.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-opportunities, neobank, fintech, data-science-jobs","summary":"Monzo's career portal showcasing open positions at the UK digital bank known for data-driven product development. The company offers opportunities for data scientists and analysts to work on causal inference, experimentation, and financial product optimization. Their roles often involve A/B testing, customer behavior analysis, and machine learning applications in banking.","use_cases":"Finding data science roles at a fintech company with strong experimentation culture, Exploring career opportunities in digital banking and financial services","audience":"Junior-DS, Curious-browser"},{"id":"career-lendingclub","type":"career","name":"LendingClub","description":"Career portal","category":"Company Lists","url":"https://www.lendingclub.com/company/careers","difficulty":"beginner","prerequisites":"basic-finance, resume-writing","topic_tags":"careers, fintech, lending, credit-risk, job-search","summary":"LendingClub's career portal showcasing job opportunities at the peer-to-peer lending platform. The company offers roles in data science, risk modeling, engineering, and product development focused on credit assessment and marketplace lending. Useful for understanding career paths in fintech and the types of skills valued at lending-focused companies.","use_cases":"Exploring data science roles in fintech and credit risk modeling, Researching company culture and technical stack before applying to lending platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-prosper","type":"career","name":"Prosper","description":"Career portal","category":"Company Lists","url":"https://www.prosper.com/jobs","difficulty":"beginner","prerequisites":"basic-finance, SQL-queries","topic_tags":"fintech-careers, lending, credit-risk, career-portal","summary":"Prosper is a peer-to-peer lending platform that connects borrowers with investors. The company offers various data science and tech roles focused on credit risk modeling, fraud detection, and marketplace optimization. Their career portal provides opportunities for tech economists interested in applying quantitative methods to consumer lending and fintech.","use_cases":"Finding data science roles in fintech with focus on credit risk modeling, Exploring career opportunities in peer-to-peer lending platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-upgrade","type":"career","name":"Upgrade","description":"Career portal","category":"Company Lists","url":"https://www.upgrade.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-development, job-search, tech-industry, professional-growth","summary":"Upgrade is a career portal focused on opportunities in lending and credit risk roles within the tech industry. It serves as a curated platform connecting data professionals with fintech companies specializing in credit assessment and lending technologies. The portal provides career guidance and job listings specifically tailored to the intersection of finance and technology.","use_cases":"Finding data science roles at fintech companies focused on credit scoring and risk modeling, Exploring career transitions from traditional finance into tech-enabled lending platforms","audience":"Junior-DS, Curious-browser"},{"id":"career-avant","type":"career","name":"Avant","description":"Career portal","category":"Company Lists","url":"https://www.avant.com/jobs/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, lending-industry, fintech-jobs, credit-risk-careers","summary":"Avant is a career portal for a fintech company specializing in personal lending and credit risk assessment. The portal provides job opportunities and career information for data scientists and analysts interested in working in the consumer lending space. It offers insights into roles focused on credit modeling, risk assessment, and financial technology applications.","use_cases":"Exploring data science career opportunities in fintech and lending companies, Researching company culture and technical requirements for credit risk modeling positions","audience":"Junior-DS, Curious-browser"},{"id":"career-lendingtree","type":"career","name":"LendingTree","description":"Career portal","category":"Company Lists","url":"https://www.lendingtree.com/careers/jobs/","difficulty":"beginner","prerequisites":"resume-writing, job-search-basics","topic_tags":"careers, lending, credit-risk, job-portal, fintech","summary":"LendingTree's career portal showcasing job opportunities at one of the largest online lending marketplaces. The company specializes in connecting consumers with lenders and offers roles across data science, engineering, product, and business functions focused on credit risk, personalization, and financial technology.","use_cases":"Data scientists looking for roles in credit risk modeling and lending algorithms, Recent graduates seeking entry-level positions in fintech and consumer finance","audience":"Junior-DS, Curious-browser"},{"id":"career-bread-financial","type":"career","name":"Bread Financial","description":"Career portal","category":"Company Lists","url":"https://careers.breadfinancial.com","difficulty":"beginner","prerequisites":"resume-writing, basic-finance","topic_tags":"careers, fintech, lending, credit-risk, job-search","summary":"Bread Financial is a financial technology company specializing in digital payment solutions and credit services. Their career portal showcases opportunities in data science, risk modeling, and financial analytics roles. The company focuses on lending products and credit risk assessment, making it relevant for those interested in fintech career paths.","use_cases":"Exploring data science roles at fintech companies focused on lending and credit, Researching career opportunities in credit risk modeling and financial analytics","audience":"Junior-DS, Curious-browser"},{"id":"career-upstart-1","type":"career","name":"Upstart","description":"Career portal","category":"Company Lists","url":"https://www.upstart.com/careers","difficulty":"beginner","prerequisites":"basic-finance, credit-modeling, python-basics","topic_tags":"fintech-careers, lending-industry, credit-risk, job-portal, upstart","summary":"Upstart is a fintech company specializing in AI-powered lending and credit risk assessment. Their career portal showcases opportunities for data scientists and engineers to work on machine learning models for personal loans and credit evaluation. The company is known for using non-traditional data sources and advanced algorithms to improve lending decisions.","use_cases":"Exploring data science roles in fintech lending companies, Researching career opportunities in AI-driven credit risk modeling","audience":"Junior-DS, Curious-browser"},{"id":"career-oportun","type":"career","name":"Oportun","description":"Career portal","category":"Company Lists","url":"https://oportun.com/careers/","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"career-portal, fintech-jobs, lending, credit-risk, job-applications","summary":"Oportun's career portal showcasing opportunities at a leading fintech company specializing in responsible lending and credit risk modeling. The portal provides insights into roles spanning data science, machine learning, and financial technology positions. Tech economists can explore career paths in consumer credit, risk assessment, and inclusive financial services.","use_cases":"Junior data scientists seeking entry-level positions in fintech and credit risk modeling, Mid-level professionals exploring opportunities to apply machine learning in financial inclusion and lending","audience":"Junior-DS, Mid-DS"},{"id":"career-grayscale","type":"career","name":"Grayscale","description":"Career portal","category":"Company Lists","url":"https://grayscale.com/careers","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, crypto-jobs, company-directory, blockchain-careers, fintech","summary":"Grayscale is a career portal focused on cryptocurrency and digital asset companies. It serves as a curated directory for professionals seeking opportunities in the crypto/blockchain space. The platform helps job seekers discover companies and roles in the rapidly evolving digital asset industry.","use_cases":"Finding entry-level data science positions at cryptocurrency exchanges or blockchain startups, Researching crypto companies before applying for quantitative analyst or researcher roles","audience":"Junior-DS, Curious-browser"},{"id":"career-binance","type":"career","name":"Binance","description":"Career portal","category":"Company Lists","url":"https://www.binance.com/en/careers","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"crypto, careers, fintech, job-portal, blockchain","summary":"Binance's career portal showcasing job opportunities at one of the world's largest cryptocurrency exchanges. The platform offers positions across data science, engineering, research, and business roles in the crypto/blockchain space. Useful for exploring career paths and compensation benchmarks in the rapidly evolving digital asset industry.","use_cases":"Researching data scientist roles at major crypto exchanges, Benchmarking salaries and requirements for blockchain industry positions","audience":"Junior-DS, Curious-browser"},{"id":"career-circle","type":"career","name":"Circle","description":"Career portal","category":"Company Lists","url":"https://careers.circle.com","difficulty":"beginner","prerequisites":"resume-writing, job-search-strategies","topic_tags":"careers, crypto, job-portal, economist-jobs, web3","summary":"Circle's career portal showcasing job opportunities at the cryptocurrency and digital payments company. Features economist, data scientist, and research roles in the crypto/fintech space. Useful for exploring career paths in digital currency and blockchain economics.","use_cases":"Finding economist or data science roles specifically in cryptocurrency companies, Researching compensation and job requirements at a major stablecoin issuer","audience":"Junior-DS, Curious-browser"},{"id":"career-bitwise","type":"career","name":"Bitwise","description":"Career portal","category":"Company Lists","url":"https://jobs.lever.co/bitwiseinvestments","difficulty":"beginner","prerequisites":"job-search-basics, resume-writing","topic_tags":"career-portal, crypto-jobs, job-search, blockchain-careers","summary":"Bitwise is a career portal specializing in cryptocurrency and blockchain job opportunities. It connects job seekers with companies in the crypto space, offering positions ranging from technical roles to business functions. The platform serves as a gateway for professionals looking to enter or advance within the digital asset industry.","use_cases":"Finding entry-level positions at crypto startups or established blockchain companies, Transitioning from traditional tech roles to cryptocurrency-focused positions","audience":"Junior-DS, Curious-browser"},{"id":"career-consensys","type":"career","name":"ConsenSys","description":"Career portal","category":"Company Lists","url":"https://consensys.io/careers","difficulty":"beginner","prerequisites":"web-application-basics, blockchain-fundamentals","topic_tags":"blockchain-careers, crypto-jobs, web3-opportunities, ethereum-roles","summary":"ConsenSys is a leading blockchain technology company focused on Ethereum infrastructure and applications. Their career portal showcases opportunities in decentralized finance, blockchain development, and web3 product roles. It's valuable for understanding the skills and positions available in the rapidly growing crypto/blockchain industry.","use_cases":"Exploring blockchain industry career opportunities and required skill sets, Researching web3 company culture and technical roles for career transition","audience":"Junior-DS, Curious-browser"},{"id":"career-kraken","type":"career","name":"Kraken","description":"Career portal","category":"Company Lists","url":"https://www.kraken.com/careers","difficulty":"beginner","prerequisites":"resume-writing, job-searching","topic_tags":"careers, crypto, job-portal, fintech, company-research","summary":"Kraken is a major cryptocurrency exchange platform that offers career opportunities in tech, finance, and blockchain-related roles. Their career portal provides job listings for data scientists, engineers, researchers, and other technical positions in the crypto/fintech space. This resource is valuable for exploring opportunities at a leading cryptocurrency company.","use_cases":"Researching data science and engineering job opportunities at a major crypto exchange, Understanding career paths and technical roles available in the cryptocurrency industry","audience":"Junior-DS, Curious-browser"},{"id":"career-gemini","type":"career","name":"Gemini","description":"Career portal","category":"Company Lists","url":"https://www.gemini.com/careers","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, job-search, company-research, crypto-careers","summary":"Gemini is a career portal focused on cryptocurrency and blockchain industry opportunities. It provides job listings, company information, and career resources for professionals looking to enter or advance in the crypto sector. The platform serves as a gateway for discovering roles at crypto companies and understanding the industry landscape.","use_cases":"Researching crypto companies before applying for data scientist positions, Finding entry-level opportunities in blockchain technology companies","audience":"Junior-DS, Curious-browser"},{"id":"career-vanguard","type":"career","name":"Vanguard","description":"Career portal","category":"Company Lists","url":"https://www.vanguardjobs.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"careers, wealth-management, finance-jobs, economist-roles, company-portal","summary":"Vanguard's career portal showcasing opportunities for economists and data scientists in wealth management and asset management. The portal provides insight into roles that combine financial expertise with quantitative analysis. Particularly valuable for understanding how economic skills translate to the investment management industry.","use_cases":"Exploring economist career paths outside academia in asset management, Understanding skill requirements for quantitative roles at major investment firms","audience":"Junior-DS, Curious-browser"},{"id":"career-fidelity","type":"career","name":"Fidelity","description":"Career portal","category":"Company Lists","url":"https://jobs.fidelity.com/","difficulty":"beginner","prerequisites":"resume-writing, finance-domain-knowledge","topic_tags":"career-portal, wealth-management, economist-jobs, finance-careers, job-search","summary":"Fidelity's career portal showcasing job opportunities at one of the world's largest asset management companies. The portal features economist positions and quantitative roles in wealth management, retirement services, and investment research. Tech economists can explore opportunities to apply economic analysis to financial products and customer behavior.","use_cases":"Looking for economist or data scientist positions at a major financial services firm, Researching career paths that combine economic analysis with wealth management and investment services","audience":"Junior-DS, Curious-browser"},{"id":"career-charles-schwab","type":"career","name":"Charles Schwab","description":"Career portal","category":"Company Lists","url":"https://www.aboutschwab.com/careers","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, wealth-management, finance-jobs, economist-positions","summary":"Charles Schwab's career portal provides job opportunities at one of the largest wealth management firms. The company frequently hires economists, data scientists, and researchers for roles in investment research, risk management, and client analytics. Their positions span from entry-level analyst roles to senior economist positions focusing on market research and economic forecasting.","use_cases":"Finding economist or data scientist positions at a major financial services firm, Exploring career opportunities in wealth management and investment research","audience":"Junior-DS, Curious-browser"},{"id":"career-blackrock","type":"career","name":"BlackRock","description":"Career portal","category":"Company Lists","url":"https://careers.blackrock.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, wealth-management, finance-jobs, economist-roles","summary":"BlackRock's career portal showcasing job opportunities at the world's largest asset management firm. The portal features economist roles, quantitative analyst positions, and data science opportunities in wealth management and financial services. Provides insights into career paths, company culture, and application processes for finance-focused technical roles.","use_cases":"Exploring economist and quantitative analyst job openings at a major asset management firm, Understanding career progression and requirements for data science roles in wealth management","audience":"Junior-DS, Curious-browser"},{"id":"career-state-street","type":"career","name":"State Street","description":"Career portal","category":"Company Lists","url":"https://careers.statestreet.com/","difficulty":"beginner","prerequisites":"resume-writing, interview-preparation","topic_tags":"career-portal, wealth-management, economist-jobs, finance-careers","summary":"State Street's career portal showcasing job opportunities at the global financial services company. Particularly relevant for economists and data scientists interested in wealth management, asset servicing, and financial technology roles. Features positions ranging from entry-level analyst roles to senior economist and researcher positions.","use_cases":"Finding economist or data scientist positions in wealth management and asset servicing, Researching State Street's work culture and benefits before applying to finance roles","audience":"Junior-DS, Curious-browser"},{"id":"career-t.-rowe-price","type":"career","name":"T. Rowe Price","description":"Career portal","category":"Company Lists","url":"https://jobs.troweprice.com/","difficulty":"beginner","prerequisites":"resume-writing, linkedin-optimization","topic_tags":"career-portal, wealth-management, finance-jobs, economist-positions","summary":"T. Rowe Price's career portal showcasing open positions at the investment management firm. The company regularly hires economists, data scientists, and quantitative researchers for roles in investment research, risk management, and portfolio analytics. This portal provides insight into career opportunities at a major asset management company that values economic expertise.","use_cases":"Early career economist looking for industry positions at investment firms, Data scientist seeking roles in financial services and asset management","audience":"Junior-DS, Curious-browser"},{"id":"career-northern-trust","type":"career","name":"Northern Trust","description":"Career portal","category":"Company Lists","url":"https://www.northerntrust.com/careers"},{"id":"career-fico","type":"career","name":"FICO","description":"Career portal","category":"Company Lists","url":"https://www.fico.com/en/careers"},{"id":"career-experian","type":"career","name":"Experian","description":"Career portal","category":"Company Lists","url":"https://jobs.experian.com/"},{"id":"career-equifax","type":"career","name":"Equifax","description":"Career portal","category":"Company Lists","url":"https://careers.equifax.com"},{"id":"career-transunion","type":"career","name":"TransUnion","description":"Career portal","category":"Company Lists","url":"https://www.transunion.com/about-us/careers"},{"id":"career-nova-credit","type":"career","name":"Nova Credit","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/novacredit"},{"id":"career-plaid","type":"career","name":"Plaid","description":"Career portal","category":"Company Lists","url":"https://plaid.com/careers/"},{"id":"career-lemonade","type":"career","name":"Lemonade","description":"Career portal","category":"Company Lists","url":"https://makers.lemonade.com/"},{"id":"career-root-insurance","type":"career","name":"Root Insurance","description":"Career portal","category":"Company Lists","url":"https://inc.joinroot.com/careers/"},{"id":"career-oscar-health","type":"career","name":"Oscar Health","description":"Career portal","category":"Company Lists","url":"https://www.hioscar.com/careers"},{"id":"career-coalition","type":"career","name":"Coalition","description":"Career portal","category":"Company Lists","url":"https://www.coalitioninc.com/careers"},{"id":"career-at-bay","type":"career","name":"At-Bay","description":"Career portal","category":"Company Lists","url":"https://job-boards.greenhouse.io/atbayjobs"},{"id":"career-hippo","type":"career","name":"Hippo","description":"Career portal","category":"Company Lists","url":"https://www.hippo.com/careers"},{"id":"career-clover-health","type":"career","name":"Clover Health","description":"Career portal","category":"Company Lists","url":"https://www.cloverhealth.com/careers"},{"id":"career-socure","type":"career","name":"Socure","description":"Career portal","category":"Company Lists","url":"https://www.socure.com/company/careers"},{"id":"career-sardine","type":"career","name":"Sardine","description":"Career portal","category":"Company Lists","url":"https://www.sardine.ai/careers"},{"id":"career-trm-labs","type":"career","name":"TRM Labs","description":"Career portal","category":"Company Lists","url":"https://boards.greenhouse.io/TRMLabs"},{"id":"career-alloy","type":"career","name":"Alloy","description":"Career portal","category":"Company Lists","url":"https://www.alloy.com/careers"},{"id":"career-complyadvantage","type":"career","name":"ComplyAdvantage","description":"Career portal","category":"Company Lists","url":"https://complyadvantage.com/careers/"},{"id":"career-featurespace","type":"career","name":"Featurespace","description":"Career portal","category":"Company Lists","url":"https://www.featurespace.com/careers/"},{"id":"career-jumio","type":"career","name":"Jumio","description":"Career portal","category":"Company Lists","url":"https://www.jumio.com/careers/"},{"id":"career-persona","type":"career","name":"Persona","description":"Career portal","category":"Company Lists","url":"https://withpersona.com/careers"},{"id":"career-doubleverify","type":"career","name":"DoubleVerify","description":"Career portal","category":"Company Lists","url":"https://doubleverify.com/company/careers"},{"id":"career-integral-ad-science-(ias)","type":"career","name":"Integral Ad Science (IAS)","description":"Career portal","category":"Company Lists","url":"https://integralads.com/about-ias/careers/"},{"id":"career-appsflyer","type":"career","name":"AppsFlyer","description":"Career portal","category":"Company Lists","url":"https://careers.appsflyer.com"},{"id":"career-applovin","type":"career","name":"AppLovin","description":"Career portal","category":"Company Lists","url":"https://www.applovin.com/en/careers"},{"id":"career-matterport","type":"career","name":"Matterport","description":"Career portal","category":"Company Lists","url":"https://matterport.com/careers"},{"id":"career-vts","type":"career","name":"VTS","description":"Career portal","category":"Company Lists","url":"https://www.vts.com/careers"},{"id":"career-roofstock","type":"career","name":"Roofstock","description":"Career portal","category":"Company Lists","url":"https://www.roofstock.com/careers"},{"id":"career-project44","type":"career","name":"Project44","description":"Career portal","category":"Company Lists","url":"https://www.project44.com/company/careers/"},{"id":"career-samsara","type":"career","name":"Samsara","description":"Career portal","category":"Company Lists","url":"https://www.samsara.com/company/careers/"},{"id":"career-motive","type":"career","name":"Motive","description":"Career portal","category":"Company Lists","url":"https://gomotive.com/company/careers/"},{"id":"career-duolingo","type":"career","name":"Duolingo","description":"Career portal","category":"Company Lists","url":"https://careers.duolingo.com/"},{"id":"career-coursera","type":"career","name":"Coursera","description":"Career portal","category":"Company Lists","url":"https://about.coursera.org/careers"},{"id":"career-udemy","type":"career","name":"Udemy","description":"Career portal","category":"Company Lists","url":"https://about.udemy.com/careers/"},{"id":"career-guild-education","type":"career","name":"Guild Education","description":"Career portal","category":"Company Lists","url":"https://careers.guildeducation.com/"},{"id":"career-jetblue","type":"career","name":"JetBlue","description":"Career portal","category":"Company Lists","url":"https://careers.jetblue.com"},{"id":"career-alaska-airlines","type":"career","name":"Alaska Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.alaskaair.com"},{"id":"career-spirit-airlines","type":"career","name":"Spirit Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.spirit.com"},{"id":"career-frontier-airlines","type":"career","name":"Frontier Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.flyfrontier.com"},{"id":"career-ryanair","type":"career","name":"Ryanair","description":"Career portal","category":"Company Lists","url":"https://careers.ryanair.com"},{"id":"career-singapore-airlines","type":"career","name":"Singapore Airlines","description":"Career portal","category":"Company Lists","url":"https://careers.singaporeair.com"},{"id":"career-easyjet","type":"career","name":"easyJet","description":"Career portal","category":"Company Lists","url":"https://careers.easyjet.com"},{"id":"career-lufthansa-group","type":"career","name":"Lufthansa Group","description":"Career portal","category":"Company Lists","url":"https://www.lufthansagroup.careers"},{"id":"career-emirates","type":"career","name":"Emirates","description":"Career portal","category":"Company Lists","url":"https://www.emiratesgroupcareers.com"},{"id":"career-qatar-airways","type":"career","name":"Qatar Airways","description":"Career portal","category":"Company Lists","url":"https://careers.qatarairways.com"},{"id":"career-british-airways-iag","type":"career","name":"British Airways/IAG","description":"Career portal","category":"Company Lists","url":"https://careers.ba.com"},{"id":"career-air-france-klm","type":"career","name":"Air France-KLM","description":"Career portal","category":"Company Lists","url":"https://careers.airfrance.com"},{"id":"career-latam-airlines","type":"career","name":"LATAM Airlines","description":"Career portal","category":"Company Lists","url":"https://www.latamairlines.com/work-with-us"},{"id":"career-agoda","type":"career","name":"Agoda","description":"Career portal","category":"Company Lists","url":"https://careersatagoda.com"},{"id":"career-trivago","type":"career","name":"Trivago","description":"Career portal","category":"Company Lists","url":"https://careers.trivago.com"},{"id":"career-hopper-1","type":"career","name":"Hopper","description":"Career portal","category":"Company Lists","url":"https://hopper.com/careers"},{"id":"career-kiwi.com","type":"career","name":"Kiwi.com","description":"Career portal","category":"Company Lists","url":"https://jobs.kiwi.com"},{"id":"career-trip.com-group","type":"career","name":"Trip.com Group","description":"Career portal","category":"Company Lists","url":"https://careers.trip.com"},{"id":"career-marriott-international","type":"career","name":"Marriott International","description":"Career portal","category":"Company Lists","url":"https://careers.marriott.com"},{"id":"career-hilton","type":"career","name":"Hilton","description":"Career portal","category":"Company Lists","url":"https://jobs.hilton.com"},{"id":"career-hyatt","type":"career","name":"Hyatt","description":"Career portal","category":"Company Lists","url":"https://careers.hyatt.com"},{"id":"career-ihg","type":"career","name":"IHG","description":"Career portal","category":"Company Lists","url":"https://careers.ihg.com"},{"id":"career-wyndham","type":"career","name":"Wyndham","description":"Career portal","category":"Company Lists","url":"https://careers.wyndhamhotels.com"},{"id":"career-accor","type":"career","name":"Accor","description":"Career portal","category":"Company Lists","url":"https://careers.accor.com"},{"id":"career-choice-hotels","type":"career","name":"Choice Hotels","description":"Career portal","category":"Company Lists","url":"https://careers.choicehotels.com"},{"id":"career-mgm-resorts","type":"career","name":"MGM Resorts","description":"Career portal","category":"Company Lists","url":"https://mgmresorts.com/careers"},{"id":"career-caesars-entertainment","type":"career","name":"Caesars Entertainment","description":"Career portal","category":"Company Lists","url":"https://caesars.com/careers"},{"id":"career-royal-caribbean","type":"career","name":"Royal Caribbean","description":"Career portal","category":"Company Lists","url":"https://jobs.royalcaribbeangroup.com"},{"id":"career-carnival-corporation","type":"career","name":"Carnival Corporation","description":"Career portal","category":"Company Lists","url":"https://jobs.carnival.com"},{"id":"career-norwegian-cruise-line","type":"career","name":"Norwegian Cruise Line","description":"Career portal","category":"Company Lists","url":"https://careers.ncl.com"},{"id":"career-viking-cruises","type":"career","name":"Viking Cruises","description":"Career portal","category":"Company Lists","url":"https://vikingcareers.com"},{"id":"career-gojek-goto","type":"career","name":"Gojek/GoTo","description":"Career portal","category":"Company Lists","url":"https://gojek.io/careers"},{"id":"career-lime","type":"career","name":"Lime","description":"Career portal","category":"Company Lists","url":"https://li.me/careers"},{"id":"career-ola","type":"career","name":"Ola","description":"Career portal","category":"Company Lists","url":"https://olacabs.com/careers"},{"id":"career-hertz","type":"career","name":"Hertz","description":"Career portal","category":"Company Lists","url":"https://hertzcareers.com"},{"id":"career-zipcar","type":"career","name":"Zipcar","description":"Career portal","category":"Company Lists","url":"https://zipcar.com/careers"},{"id":"career-enterprise-holdings","type":"career","name":"Enterprise Holdings","description":"Career portal","category":"Company Lists","url":"https://jobs.enterprise.com"},{"id":"career-sixt","type":"career","name":"Sixt","description":"Career portal","category":"Company Lists","url":"https://sixt.jobs"},{"id":"career-avis-budget-group","type":"career","name":"Avis Budget Group","description":"Career portal","category":"Company Lists","url":"https://avisbudgetgroup.jobs"},{"id":"career-ups","type":"career","name":"UPS","description":"Career portal","category":"Company Lists","url":"https://jobs-ups.com"},{"id":"career-dhl","type":"career","name":"DHL","description":"Career portal","category":"Company Lists","url":"https://careers.dhl.com"},{"id":"career-xpo-logistics","type":"career","name":"XPO Logistics","description":"Career portal","category":"Company Lists","url":"https://jobs.xpo.com"},{"id":"career-c.h.-robinson","type":"career","name":"C.H. Robinson","description":"Career portal","category":"Company Lists","url":"https://jobs.chrobinson.com"},{"id":"career-j.b.-hunt","type":"career","name":"J.B. Hunt","description":"Career portal","category":"Company Lists","url":"https://careers.jbhunt.com"},{"id":"career-kodiak-robotics","type":"career","name":"Kodiak Robotics","description":"Career portal","category":"Company Lists","url":"https://kodiak.ai/careers"},{"id":"career-may-mobility","type":"career","name":"May Mobility","description":"Career portal","category":"Company Lists","url":"https://maymobility.com/careers"},{"id":"career-nuro","type":"career","name":"Nuro","description":"Career portal","category":"Company Lists","url":"https://nuro.ai/careers"},{"id":"career-motional","type":"career","name":"Motional","description":"Career portal","category":"Company Lists","url":"https://motional.com/careers"},{"id":"career-bnsf-railway","type":"career","name":"BNSF Railway","description":"Career portal","category":"Company Lists","url":"https://jobs.bnsf.com"},{"id":"career-norfolk-southern","type":"career","name":"Norfolk Southern","description":"Career portal","category":"Company Lists","url":"https://jobs.nscorp.com"},{"id":"career-csx-corporation","type":"career","name":"CSX Corporation","description":"Career portal","category":"Company Lists","url":"https://csx.com/careers"},{"id":"career-brightline","type":"career","name":"Brightline","description":"Career portal","category":"Company Lists","url":"https://gobrightline.com"},{"id":"career-geotab","type":"career","name":"Geotab","description":"Career portal","category":"Company Lists","url":"https://careers.geotab.com"},{"id":"career-verizon-connect","type":"career","name":"Verizon Connect","description":"Career portal","category":"Company Lists","url":"https://mycareer.verizon.com"},{"id":"career-trimble","type":"career","name":"Trimble","description":"Career portal","category":"Company Lists","url":"https://careers.trimble.com"},{"id":"community-assa-annual-meeting","type":"community","name":"ASSA Annual Meeting","description":"Allied Social Science Associations annual meeting. The largest gathering of economists with sessions on applied analytics, market design, and causal inference. Features AEA, Econometric Society, and 60+ allied associations.","category":"Conferences","url":"https://www.aeaweb.org/conference/","difficulty":"intermediate","prerequisites":"econometrics-basics, academic-research-methods","topic_tags":"economics-conferences, academic-networking, research-presentations, econometrics, applied-economics","summary":"The Allied Social Science Associations (ASSA) Annual Meeting is the premier gathering for economists, featuring thousands of research presentations across applied analytics, market design, and causal inference. It brings together the American Economic Association, Econometric Society, and 60+ allied organizations for networking and knowledge sharing. Essential for staying current with economic research trends and connecting with the broader economics community.","use_cases":"Present your latest causal inference research to the economics community and get feedback from leading researchers, Network with potential collaborators and learn about cutting-edge methods in market design and experimental economics","audience":"Early-PhD, Senior-DS"},{"id":"community-acm-ec-(economics-and-computation)","type":"community","name":"ACM EC (Economics and Computation)","description":"ACM Conference on Economics and Computation. Premier venue for market design, mechanism design, and algorithmic game theory research. Essential for tech economists working on auctions, pricing, and platform economics.","category":"Conferences","url":"https://www.sigecom.org/","difficulty":"advanced","prerequisites":"game-theory, optimization-theory, auction-mechanisms","topic_tags":"mechanism-design, algorithmic-game-theory, auction-theory, market-design, academic-conference","summary":"ACM EC is the premier academic conference for economics and computation research, featuring cutting-edge work in mechanism design, auction theory, and algorithmic game theory. It's the top venue where computer scientists and economists present theoretical advances and practical applications in market design. Essential reading for anyone working on auctions, pricing algorithms, or platform economics in tech companies.","use_cases":"Finding latest research on auction mechanisms for ad marketplaces or cloud resource allocation, Discovering theoretical foundations for designing pricing mechanisms in multi-sided platforms","audience":"Senior-DS, Early-PhD"},{"id":"community-causal-data-science-meeting","type":"community","name":"Causal Data Science Meeting","description":"Annual conference bringing together researchers and practitioners in causal inference and machine learning. Endorsed by Nobel laureate Guido Imbens. Strong industry presence from major tech companies.","category":"Conferences","url":"https://www.causalscience.org/","difficulty":"intermediate","prerequisites":"causal-inference-basics, randomized-controlled-trials, python-or-r","topic_tags":"causal-inference, experimentation, industry-applications, conferences, networking","summary":"Premier annual conference connecting academic researchers and industry practitioners working on causal inference and machine learning applications. Features presentations on cutting-edge methods, case studies from major tech companies, and networking opportunities for data scientists implementing causal methods in production.","use_cases":"Learning about new causal inference methods being used at top tech companies, Networking with other practitioners running A/B tests and causal analysis in industry","audience":"Mid-DS, Senior-DS"},{"id":"community-code@mit-conference","type":"community","name":"CODE@MIT Conference","description":"Conference on Digital Experimentation at MIT. Focused on experimentation, A/B testing, and causal inference in digital platforms. Strong presence from tech industry data scientists and academic researchers.","category":"Conferences","url":"https://ide.mit.edu/events/conference-on-digital-experimentation-code/","difficulty":"intermediate","prerequisites":"A-B-testing, hypothesis-testing, causal-inference","topic_tags":"experimentation, A-B-testing, digital-platforms, causal-inference, conferences","summary":"Annual conference at MIT bringing together industry data scientists and academic researchers focused on digital experimentation methods. Features presentations on A/B testing, causal inference, and experimental design specifically for tech platforms and digital products. Provides networking and learning opportunities for practitioners working on online experiments.","use_cases":"Learning about cutting-edge A/B testing methodologies from leading tech companies, Networking with other experimentation practitioners and staying current on industry best practices","audience":"Mid-DS, Senior-DS"},{"id":"community-econometric-society-world-congress","type":"community","name":"Econometric Society World Congress","description":"The focal point of the Econometric Society's meetings where researchers from all regions convene. Covers all aspects of economics including causal inference and econometrics. Premier academic gathering for econometricians.","category":"Conferences","url":"https://www.econometricsociety.org/","difficulty":"intermediate","prerequisites":"econometric-theory, regression-analysis, academic-research-methods","topic_tags":"econometrics, causal-inference, academic-conferences, research-networking, economic-theory","summary":"The Econometric Society World Congress is the premier global academic conference bringing together econometricians and economists from all regions. It features cutting-edge research presentations covering causal inference, econometric methods, and all areas of economics. This flagship event serves as the primary networking and knowledge-sharing venue for the international econometrics community.","use_cases":"Present your latest causal inference research to the global econometrics community, Network with leading researchers and discover emerging econometric methodologies","audience":"Early-PhD, Senior-DS"},{"id":"community-european-causal-inference-meeting-(eurocim)","type":"community","name":"European Causal Inference Meeting (EuroCIM)","description":"Forum for researchers interested in causal inference to meet informally. Covers health, economic, and social sciences applications. European counterpart to ACIC with strong biostatistics presence.","category":"Conferences","url":"https://eurocim.org/","difficulty":"intermediate","prerequisites":"causal-inference-basics, statistical-modeling, randomized-controlled-trials","topic_tags":"causal-inference, european-conference, biostatistics, health-economics, academic-networking","summary":"EuroCIM is an informal European conference bringing together researchers working on causal inference across health, economics, and social sciences. It serves as the European counterpart to ACIC (Atlantic Causal Inference Conference) with particularly strong representation from biostatistics. The meeting facilitates networking and knowledge sharing among causal inference practitioners in academic and industry settings.","use_cases":"Present your causal inference research to European academic community, Network with biostatisticians and health economists working on causal methods","audience":"Senior-DS, Early-PhD"},{"id":"community-global-antitrust-economics-conference","type":"community","name":"Global Antitrust Economics Conference","description":"Hosted at NYU Stern. Leading competition authorities discuss digital markets enforcement, algorithmic collusion, and antitrust in the AI economy. Essential for tech economists in competition policy.","category":"Conferences","url":"https://www.concurrences.com/","difficulty":"intermediate","prerequisites":"industrial-organization, econometric-methods, competition-policy","topic_tags":"antitrust, digital-markets, algorithmic-collusion, competition-policy, conferences","summary":"Premier annual conference bringing together competition authorities, economists, and researchers to discuss antitrust enforcement in digital markets. Features cutting-edge research on algorithmic pricing, platform competition, and AI's impact on market dynamics. Essential networking and learning venue for economists working at the intersection of technology and competition policy.","use_cases":"Learning latest enforcement approaches for digital platform monopolization cases, Networking with competition economists from global regulatory bodies like DOJ, EC, and CMA","audience":"Senior-DS, Early-PhD"},{"id":"community-iioc-(industrial-organization-conference)","type":"community","name":"IIOC (Industrial Organization Conference)","description":"International Industrial Organization Conference. Research on antitrust policy, regulatory policy, competition, algorithmic pricing, and market power. Key venue for IO economists in tech.","category":"Conferences","url":"https://www.indorgsociety.org/conference","difficulty":"advanced","prerequisites":"econometrics, microeconomics, regression-analysis","topic_tags":"industrial-organization, antitrust, market-power, algorithmic-pricing, conferences","summary":"The International Industrial Organization Conference is the premier academic venue for economists studying market competition, antitrust policy, and regulatory issues in tech industries. Researchers present cutting-edge work on algorithmic pricing, platform competition, merger analysis, and digital market power. Essential for IO economists working at the intersection of economics and technology policy.","use_cases":"Presenting research on platform market power or algorithmic collusion, Networking with leading IO economists studying tech industry regulation","audience":"Senior-DS, Early-PhD"},{"id":"community-informs-analytics+-conference","type":"community","name":"INFORMS Analytics+ Conference","description":"Premier analytics conference bringing together professionals in operations research, analytics, and data science. Features practical applications, networking, and the Franz Edelman Award for analytics achievement.","category":"Conferences","url":"https://www.informs.org/Meetings-Conferences/INFORMS-Conference-Calendar/2025-INFORMS-Analytics-Conference","difficulty":"beginner","prerequisites":"basic-statistics, business-analytics","topic_tags":"operations-research, analytics-conference, networking, edelman-award, data-science","summary":"INFORMS Analytics+ is a premier professional conference that brings together operations research practitioners, analytics professionals, and data scientists. The conference features practical applications, case studies, and networking opportunities, highlighted by the prestigious Franz Edelman Award recognizing outstanding analytics achievements. It serves as a key venue for learning about real-world analytics implementations and connecting with industry professionals.","use_cases":"Learning about successful analytics implementations and best practices from award-winning case studies, Networking with analytics professionals and discovering career opportunities in operations research and data science","audience":"Junior-DS, Mid-DS"},{"id":"community-informs-annual-meeting","type":"community","name":"INFORMS Annual Meeting","description":"Largest annual gathering for operations research and analytics professionals. Covers optimization, decision analysis, and data-driven methods. Features extensive tracks on pricing, revenue management, and marketplace design.","category":"Conferences","url":"https://meetings.informs.org/wordpress/annual/","difficulty":"intermediate","prerequisites":"linear-programming, regression-analysis, experimental-design","topic_tags":"operations-research, revenue-management, marketplace-design, optimization, analytics-conference","summary":"The premier annual conference for operations research and analytics professionals, featuring cutting-edge research in optimization, decision science, and data-driven methods. Particularly strong in pricing strategies, revenue management, and marketplace design with sessions ranging from theoretical foundations to industry applications. Essential networking venue for academics and practitioners working at the intersection of economics, statistics, and business optimization.","use_cases":"Learning latest pricing optimization techniques from industry leaders at tech companies, Networking with researchers working on similar marketplace design problems","audience":"Mid-DS, Senior-DS"},{"id":"community-mit-platform-strategy-summit","type":"community","name":"MIT Platform Strategy Summit","description":"Summit on platform dynamics, digital markets, and antitrust. Covers AI's effects on innovation, labor, and policy implications for tech platforms. Features mix of academics, industry leaders, and policymakers.","category":"Conferences","url":"https://ide.mit.edu/events/2025-mit-platform-strategy-summit/","difficulty":"intermediate","prerequisites":"microeconomics-theory, regression-analysis, antitrust-basics","topic_tags":"platform-economics, digital-markets, antitrust-policy, AI-innovation, tech-regulation","summary":"Academic and industry conference focused on platform economics, digital market dynamics, and antitrust implications in tech. Brings together researchers, practitioners, and policymakers to discuss AI's impact on innovation, labor markets, and regulatory frameworks. Provides cutting-edge insights on platform strategy and competition policy.","use_cases":"Understanding regulatory trends affecting platform business models, Learning about AI's competitive effects on digital markets","audience":"Mid-DS, Senior-DS"},{"id":"community-ml-in-economics-summer-conference","type":"community","name":"ML in Economics Summer Conference","description":"Hosted by Chicago Booth's Center for Applied AI. Brings together researchers working at the intersection of machine learning and economics. Focus on causal ML, econometric methods, and policy applications.","category":"Conferences","url":"https://www.chicagobooth.edu/research/center-for-applied-artificial-intelligence","difficulty":"intermediate","prerequisites":"causal-inference, python-scikit-learn, regression-analysis","topic_tags":"causal-ml, econometrics, academic-conference, policy-research, applied-ai","summary":"An academic conference hosted by Chicago Booth focusing on the intersection of machine learning and economics. Researchers present work on causal ML methods, econometric applications, and policy-relevant analyses. Ideal for staying current on cutting-edge methods and networking with applied AI researchers.","use_cases":"Learning about latest causal ML methods for tech product experimentation, Networking with researchers working on econometric applications of machine learning","audience":"Mid-DS, Senior-DS"},{"id":"community-nabe-annual-conference","type":"community","name":"NABE Annual Conference","description":"National Association for Business Economics annual meeting. Brings together researchers from industry, academia, and government to discuss economic policy and forecasting. Strong representation from Fed economists and corporate economists.","category":"Conferences","url":"https://nabe.com/NABE/Events/Event_List","difficulty":"intermediate","prerequisites":"econometrics-fundamentals, economic-forecasting, regression-analysis","topic_tags":"business-economics, economic-policy, forecasting, networking, federal-reserve","summary":"The National Association for Business Economics annual conference is a premier gathering of economists from industry, academia, and government focused on economic policy and forecasting. Features presentations from Federal Reserve economists and corporate economists on current economic trends and analytical methods. Provides networking opportunities and exposure to practical applications of economic research in business settings.","use_cases":"Learning how Fed economists approach macroeconomic forecasting and policy analysis, Networking with corporate economists to understand industry applications of economic methods","audience":"Mid-DS, Senior-DS"},{"id":"community-nabe-applied-analytics-conference","type":"community","name":"NABE Applied Analytics Conference","description":"NABE's conference for applied researchers. Covers causal inference, AI, and experiments in action. Practitioners from major tech companies like Amazon, Microsoft, and Meta share insights on production ML and experimentation.","category":"Conferences","url":"https://www.nabe.com/","difficulty":"intermediate","prerequisites":"A-B-testing, regression-analysis, python-or-R","topic_tags":"causal-inference, experimentation, applied-ML, industry-practices, conference","summary":"NABE's Applied Analytics Conference brings together practitioners from major tech companies to share real-world applications of causal inference, AI, and experimentation methods. The conference focuses on production-ready techniques and case studies from companies like Amazon, Microsoft, and Meta. Attendees learn how academic methods translate to industry problems and get insights into best practices for running experiments at scale.","use_cases":"Learning how top tech companies implement causal inference methods in production systems, Networking with industry practitioners and discovering new approaches to A/B testing and ML deployment","audience":"Mid-DS, Senior-DS"},{"id":"community-nber-summer-institute:-digital-economics","type":"community","name":"NBER Summer Institute: Digital Economics","description":"NBER session on Digital Economics and AI. Research on digital surveillance, AI labor effects, and human-AI collaboration. Top academic researchers from economics departments worldwide. Invitation-only but papers publicly available.","category":"Conferences","url":"https://www.nber.org/conferences/si-2025-digital-economics-and-artificial-intelligence","difficulty":"advanced","prerequisites":"econometrics, causal-inference, academic-research","topic_tags":"digital-economics, AI-labor-effects, human-AI-collaboration, academic-conference, surveillance-economics","summary":"The NBER Summer Institute Digital Economics session brings together top academic economists to present cutting-edge research on AI's economic impacts, digital surveillance, and human-AI collaboration. This invitation-only conference features the latest theoretical and empirical work from leading economics departments worldwide. Papers are publicly available and represent the frontier of digital economics research.","use_cases":"Finding latest academic research on AI's labor market effects for dissertation literature review, Accessing cutting-edge papers on digital platform economics for research collaboration","audience":"Senior-DS, Early-PhD"},{"id":"community-northwestern-antitrust-conference","type":"community","name":"Northwestern Antitrust Conference","description":"Annual conference on antitrust economics and competition policy. Covers digital acquisitions, buyer/seller power, and exclusive dealing research. Strong mix of academics, practitioners, and antitrust enforcers.","category":"Conferences","url":"https://www.law.northwestern.edu/research-faculty/clbe/events/antitrust/","difficulty":"intermediate","prerequisites":"microeconomics-theory, econometrics-basics, industrial-organization","topic_tags":"antitrust-economics, competition-policy, digital-markets, merger-analysis, academic-conference","summary":"Annual conference bringing together academics, practitioners, and antitrust enforcers to discuss cutting-edge research in competition economics. Features presentations on digital acquisitions, market power analysis, and exclusive dealing arrangements. Provides valuable networking and knowledge sharing opportunities for those working in antitrust and competition policy.","use_cases":"PhD student researching digital platform mergers needs to present findings and get feedback from industry experts, Competition economist at DOJ wants to learn latest academic methods for analyzing buyer power in tech markets","audience":"Early-PhD, Senior-DS"},{"id":"community-stanford-site","type":"community","name":"Stanford SITE","description":"Stanford Institute for Theoretical Economics summer sessions. Includes Empirical Market Design, Market Failures, and IO tracks relevant to applied researchers. Invitation-only sessions featuring top economists.","category":"Conferences","url":"https://economics.stanford.edu/site/site-2025","difficulty":"advanced","prerequisites":"graduate-microeconomics, econometric-theory, academic-research-methods","topic_tags":"market-design, industrial-organization, theoretical-economics, empirical-methods, academic-conference","summary":"Stanford SITE is an invitation-only summer institute bringing together top economists for intensive sessions on theoretical and empirical economics. The program features specialized tracks in Empirical Market Design, Market Failures, and Industrial Organization, making it highly relevant for applied researchers working at the intersection of theory and data. Participants engage with cutting-edge research methods and network with leading academics in the field.","use_cases":"PhD student seeking exposure to latest market design methodologies and networking with potential advisors or collaborators, Senior researcher looking to present work and get feedback from top economists in industrial organization","audience":"Early-PhD, Senior-DS"},{"id":"community-stigler-center-antitrust-conference","type":"community","name":"Stigler Center Antitrust Conference","description":"Chicago Booth conference on economic concentration and competition. Covers digital platforms, media markets, and antitrust policy. Mix of academics, policymakers, and industry practitioners.","category":"Conferences","url":"https://www.chicagobooth.edu/research/stigler/events","difficulty":"intermediate","prerequisites":"microeconomic-theory, econometrics-basics, antitrust-law-fundamentals","topic_tags":"antitrust, digital-platforms, competition-policy, market-concentration, regulatory-economics","summary":"Annual Chicago Booth conference bringing together academics, policymakers, and industry practitioners to discuss economic concentration and competition policy. Features cutting-edge research on digital platforms, media markets, and antitrust enforcement with a focus on empirical analysis and policy implications. Provides insights into how economists evaluate market power and inform regulatory decisions.","use_cases":"Understanding current debates on tech platform regulation and market concentration measurement, Learning empirical methods used in antitrust cases and merger analysis","audience":"Mid-DS, Senior-DS"},{"id":"community-the-web-conference-(www)","type":"community","name":"The Web Conference (WWW)","description":"Premier conference on understanding the Web through computer science, economics, and policy. Features dedicated economics and e-commerce research tracks. Strong presence from tech industry researchers.","category":"Conferences","url":"https://thewebconf.org/","difficulty":"intermediate","prerequisites":"academic-paper-reading, web-scraping, network-analysis","topic_tags":"web-economics, platform-research, academic-conference, e-commerce, digital-markets","summary":"Premier academic conference examining the Web through interdisciplinary lenses including computer science, economics, and policy research. Features dedicated tracks on economics and e-commerce with strong participation from both academia and tech industry researchers. Ideal venue for discovering cutting-edge research on digital platforms, online markets, and web-scale economic phenomena.","use_cases":"Finding latest research on platform economics and marketplace design for your company's strategy, Discovering academic collaborators working on web-scale economic problems similar to your research","audience":"Senior-DS, Curious-browser"},{"id":"community-wine","type":"community","name":"WINE","description":"Conference on Web and Internet Economics. Focuses on game theory, mechanism design, and economic aspects of internet and web systems.","category":"Conferences","url":"https://wine2025.cs.rutgers.edu/","difficulty":"intermediate","prerequisites":"game-theory, microeconomics, mechanism-design","topic_tags":"web-economics, mechanism-design, game-theory, conferences, internet-economics","summary":"WINE is a premier academic conference focused on the economic aspects of web and internet systems, covering game theory, mechanism design, and algorithmic economics. It brings together researchers from computer science, economics, and operations research to present cutting-edge work on online markets, auctions, and digital platforms. The conference serves as a key venue for understanding how economic principles apply to modern internet-based systems.","use_cases":"Finding latest research on auction mechanisms for online advertising platforms, Learning about game-theoretic approaches to ride-sharing market design","audience":"Senior-DS, Early-PhD"},{"id":"community-stanford-causal-science-conference-on-experimentation","type":"community","name":"Stanford Causal Science Conference on Experimentation","description":"Annual academic-industry bridge featuring speakers from Spotify, Google, Airbnb, Meta, Netflix, Uber, LinkedIn, and OpenAI. Topics include personalization, interference in experiments, platform design, and causal measurement at scale.","category":"Conferences","url":"https://datascience.stanford.edu/events/causal-science-center/stanford-causal-science-center-conference-experimentation","difficulty":"intermediate","prerequisites":"a-b-testing, causal-inference, experimental-design","topic_tags":"causal-inference, experimentation, academic-conference, industry-research, platform-experiments","summary":"Stanford's annual conference bridging academic causal science research with industry experimentation practices at major tech companies. Features cutting-edge talks on personalization, interference effects, and causal measurement challenges at platforms like Meta, Netflix, and Uber. Ideal for practitioners wanting to learn state-of-the-art experimental methods being developed and deployed at scale.","use_cases":"Learning how major tech companies handle network effects and interference in their A/B testing frameworks, Discovering new causal inference methods for personalization and recommendation systems being researched at Stanford and implemented in industry","audience":"Mid-DS, Senior-DS"},{"id":"community-american-causal-inference-conference-(acic)","type":"community","name":"American Causal Inference Conference (ACIC)","description":"The oldest and largest causal inference gathering, running since 2004. Brings together researchers from medicine, economics, and social sciences. Features the ACIC Data Challenge for methodological innovation.","category":"Conferences","url":"https://sci-info.org/annual-meeting/","difficulty":"intermediate","prerequisites":"causal-inference-basics, regression-analysis, research-design","topic_tags":"causal-inference, academic-conferences, methodological-innovation, cross-disciplinary, data-challenges","summary":"The premier annual conference for causal inference researchers across medicine, economics, and social sciences, running since 2004. Features cutting-edge methodological presentations and the famous ACIC Data Challenge where teams compete to develop innovative causal inference techniques. Essential networking hub for practitioners working on treatment effects, natural experiments, and observational studies.","use_cases":"Present your latest causal inference method to peers across disciplines, Participate in the data challenge to benchmark your approach against other teams","audience":"Senior-DS, Early-PhD"},{"id":"community-northwestern-workshop-on-causal-inference","type":"community","name":"Northwestern Workshop on Causal Inference","description":"Intensive 9-day training featuring Donald Rubin (Harvard), Jens Hainmueller (Stanford), and Christian Hansen (Chicago Booth). Covers difference-in-differences, ML for causal inference, regression discontinuity, and instrumental variables.","category":"Conferences","url":"https://www.law.northwestern.edu/research-faculty/events/conferences/causalinference/","difficulty":"intermediate","prerequisites":"basic-econometrics, regression-analysis, statistical-inference","topic_tags":"causal-inference, difference-in-differences, regression-discontinuity, instrumental-variables, workshop-training","summary":"Intensive 9-day causal inference workshop led by top academics from Harvard, Stanford, and Chicago Booth. Covers core identification strategies including difference-in-differences, regression discontinuity, and instrumental variables, plus modern ML approaches to causal inference. Designed for researchers and practitioners seeking rigorous training in causal methods.","use_cases":"Learning rigorous causal inference methods to evaluate product launches or policy changes, Getting intensive training on advanced econometric techniques before starting a senior research role","audience":"Early-PhD, Mid-DS"},{"id":"community-clear-(causal-learning-and-reasoning)","type":"community","name":"CLeaR (Causal Learning and Reasoning)","description":"ML-focused causal inference conference covering causal discovery, treatment effect estimation, and causal ML applications. Published in PMLR proceedings.","category":"Conferences","url":"https://www.cclear.cc/","difficulty":"advanced","prerequisites":"python-scikit-learn, causal-DAGs, observational-data-analysis","topic_tags":"causal-inference, machine-learning, treatment-effects, causal-discovery, conference-proceedings","summary":"CLeaR is a premier machine learning conference focused on causal inference methods, publishing cutting-edge research on causal discovery algorithms, treatment effect estimation, and applications of causal reasoning in ML systems. The conference proceedings contain state-of-the-art methods for identifying causal relationships from data and estimating causal effects in complex settings. Papers cover both theoretical advances and practical applications across domains like healthcare, tech platforms, and policy evaluation.","use_cases":"Finding latest methods for causal discovery from observational data in your recommendation system, Learning advanced treatment effect estimation techniques for A/B test analysis with interference","audience":"Senior-DS, Early-PhD"},{"id":"community-experimentation-island","type":"community","name":"Experimentation Island","description":"Practitioner-focused 3-day retreat for mid-to-senior growth, product, and experimentation professionals. Unconference-style sessions on experimentation culture and decision science.","category":"Conferences","url":"https://experimentationisland.com/","difficulty":"intermediate","prerequisites":"a-b-testing, statistical-significance, experimentation-design","topic_tags":"experimentation, a-b-testing, conference, decision-science, growth","summary":"Experimentation Island is a practitioner-focused 3-day retreat bringing together mid-to-senior professionals in growth, product, and experimentation roles. The unconference format features peer-led sessions on building experimentation culture and applying decision science in practice. It's designed for hands-on learning and networking among experienced practitioners.","use_cases":"Mid-level data scientist wants to learn how other companies structure their experimentation programs and overcome organizational challenges, Senior product manager seeking advanced techniques for experiment design and decision-making frameworks from industry peers","audience":"Mid-DS, Senior-DS"},{"id":"community-isms-marketing-science-conference","type":"community","name":"ISMS Marketing Science Conference","description":"Premier academic marketing venue with 12+ parallel tracks over 2.5 days. Topics span choice models, game theory, structural econometric models, randomized control trials, pricing, advertising effectiveness, and causal inference.","category":"Conferences","url":"https://connect.informs.org/isms/conferences","difficulty":"intermediate","prerequisites":"econometrics-basics, choice-modeling, causal-inference","topic_tags":"marketing-science, academic-conference, choice-models, structural-econometrics, experimental-design","summary":"ISMS Marketing Science Conference is the top academic venue for quantitative marketing research, featuring 12+ parallel tracks covering choice modeling, structural econometrics, and experimental methods. The conference attracts leading researchers presenting cutting-edge work on pricing, advertising effectiveness, and consumer behavior analysis. It's the premier networking and learning opportunity for academics and industry researchers working at the intersection of marketing and data science.","use_cases":"Learning about latest structural modeling techniques for consumer choice analysis, Networking with academic researchers working on similar pricing or advertising effectiveness problems","audience":"Early-PhD, Senior-DS"},{"id":"community-arf-marketing-analytics-accelerator","type":"community","name":"ARF Marketing Analytics Accelerator","description":"The only event focused exclusively on attribution, marketing mix models, and performance measurement. Covers MMM methodology, multi-touch attribution, causal analysis at scale, and incrementality measurement.","category":"Conferences","url":"https://thearf.org/arf-events/","difficulty":"intermediate","prerequisites":"regression-analysis, python-or-r, A-B-testing","topic_tags":"marketing-mix-modeling, attribution-modeling, incrementality-testing, causal-inference, marketing-analytics","summary":"A specialized conference focused on advanced marketing measurement techniques including marketing mix models, multi-touch attribution, and incrementality testing. Covers both methodological foundations and practical implementation of attribution systems at scale. Designed for practitioners working on measuring marketing effectiveness and ROI.","use_cases":"Building marketing mix models to optimize budget allocation across channels, Implementing multi-touch attribution systems to measure customer journey impact","audience":"Mid-DS, Senior-DS"},{"id":"community-wharton-customer-analytics-conference","type":"community","name":"Wharton Customer Analytics Conference","description":"Bridges academic rigor with practical business applications through the Wharton Customer Analytics Initiative. Features real-world customer analytics case studies alongside cutting-edge academic research on CLV and personalization.","category":"Conferences","url":"https://wca.wharton.upenn.edu/","difficulty":"intermediate","prerequisites":"customer-lifetime-value, A-B-testing, predictive-modeling","topic_tags":"customer-analytics, marketing-science, CLV-modeling, personalization, business-applications","summary":"Annual conference connecting academic customer analytics research with practical business implementations. Features case studies from industry practitioners alongside cutting-edge research on customer lifetime value, personalization algorithms, and marketing measurement.","use_cases":"Learning how major companies implement CLV models and personalization at scale, Networking with practitioners who have solved similar customer analytics challenges","audience":"Mid-DS, Senior-DS"},{"id":"community-ana-measurement-&-analytics-conference","type":"community","name":"ANA Measurement & Analytics Conference","description":"Three days covering AI advancements, retail media networks, outcome measurement, MMM, attribution, and incrementality for brand-side marketers.","category":"Conferences","url":"https://www.ana.net/conference","difficulty":"intermediate","prerequisites":"marketing-mix-modeling, attribution-modeling, experiment-design","topic_tags":"marketing-measurement, attribution, incrementality, marketing-mix-modeling, conferences","summary":"A three-day conference focused on advanced marketing measurement techniques including AI applications, retail media networks, and incrementality testing. Designed for brand-side marketers and data scientists working on marketing attribution and measurement challenges. Covers cutting-edge methods in MMM, attribution modeling, and outcome measurement frameworks.","use_cases":"Learning latest MMM techniques and attribution methodologies for marketing measurement, Networking with marketing scientists and discovering new measurement tools and platforms","audience":"Mid-DS, Senior-DS"},{"id":"community-marketing-analytics-summit","type":"community","name":"Marketing Analytics Summit","description":"Vendor-neutral practitioner conference covering marketing analytics strategy, measurement frameworks, and data-driven marketing decisions.","category":"Conferences","url":"https://marketinganalyticssummit.com/","difficulty":"intermediate","prerequisites":"marketing-mix-modeling, attribution-analysis, A-B-testing","topic_tags":"marketing-analytics, measurement-frameworks, attribution-modeling, conferences","summary":"A vendor-neutral practitioner conference focused on marketing analytics strategy, measurement frameworks, and data-driven marketing decisions. The summit brings together data scientists and marketing analysts to share best practices and learn about cutting-edge approaches to marketing measurement. Attendees gain practical insights into attribution modeling, incrementality testing, and marketing mix optimization.","use_cases":"Learning advanced attribution modeling techniques to improve marketing spend allocation, Networking with marketing analytics practitioners to share measurement framework challenges","audience":"Mid-DS, Senior-DS"},{"id":"community-informs-revenue-management-and-pricing-conference","type":"community","name":"INFORMS Revenue Management and Pricing Conference","description":"Premier forum for pricing analytics held at top business schools. Topics include dynamic pricing, demand forecasting, optimization algorithms, marketplace design, and algorithmic pricing.","category":"Conferences","url":"https://connect.informs.org/rmp/conferences","difficulty":"intermediate","prerequisites":"optimization-algorithms, demand-forecasting, statistical-modeling","topic_tags":"revenue-management, dynamic-pricing, marketplace-design, optimization-algorithms, conferences","summary":"INFORMS Revenue Management and Pricing Conference is the premier academic and industry gathering for pricing analytics professionals. The conference covers cutting-edge research in dynamic pricing, demand forecasting, and marketplace optimization, typically held at top business schools. Attendees include researchers, data scientists, and pricing professionals sharing latest methodologies and real-world applications.","use_cases":"Learning about latest dynamic pricing algorithms for e-commerce platforms, Networking with pricing researchers to explore collaboration opportunities","audience":"Mid-DS, Senior-DS"},{"id":"community-msom-conference","type":"community","name":"MSOM Conference","description":"Manufacturing and Service Operations Management conference covering service operations, platform operations, sharing economy research, and the operations-finance interface.","category":"Conferences","url":"https://connect.informs.org/msom/conferences","difficulty":"intermediate","prerequisites":"operations-research, econometric-methods, optimization-theory","topic_tags":"operations-management, service-operations, platform-economics, sharing-economy, operations-finance","summary":"The MSOM Conference is a premier academic venue for research on manufacturing and service operations management, with strong focus on modern platform and sharing economy operations. The conference covers operational aspects of tech platforms, pricing strategies, and the intersection of operations with financial decision-making. It attracts researchers working on data-driven operations problems in technology companies.","use_cases":"Finding latest research on platform matching algorithms and marketplace design for improving operational efficiency, Learning about operations-finance models for pricing and capacity decisions in sharing economy platforms","audience":"Senior-DS, Early-PhD"},{"id":"community-poms-annual-conference","type":"community","name":"POMS Annual Conference","description":"Production and Operations Management Society conference covering healthcare, supply chain, and service operations. Features college mini-conferences and practice leader forums.","category":"Conferences","url":"https://www.pomsmeetings.org/","difficulty":"intermediate","prerequisites":"operations-research, supply-chain-modeling, statistical-analysis","topic_tags":"operations-management, supply-chain, healthcare-operations, service-operations, academic-conference","summary":"The Production and Operations Management Society (POMS) Annual Conference is a premier academic gathering focused on operations research, supply chain optimization, and service management. It brings together researchers and practitioners to share cutting-edge methods in healthcare operations, logistics, and operational efficiency. The conference features specialized tracks, mini-conferences, and forums connecting academic research with industry practice.","use_cases":"Present research on supply chain optimization algorithms to academic peers, Network with healthcare operations researchers to find collaboration opportunities","audience":"Senior-DS, Early-PhD"},{"id":"community-conference-on-mechanism-and-institution-design-(cmid)","type":"community","name":"Conference on Mechanism and Institution Design (CMID)","description":"Biennial academic conference covering auction design, market design, matching, and mechanism design theory\u2014foundational for ad auctions, marketplace mechanisms, and algorithmic market design.","category":"Conferences","url":"https://mechanism-design.org/","difficulty":"advanced","prerequisites":"game-theory, optimization-theory, microeconomic-theory","topic_tags":"auction-design, market-design, mechanism-design, matching-algorithms, conference","summary":"CMID is a premier biennial academic conference bringing together researchers in mechanism design, auction theory, and market design. The conference covers theoretical foundations and applications crucial for designing ad auctions, two-sided marketplaces, and algorithmic matching systems. It's essential for tech economists working on platform economics and marketplace optimization.","use_cases":"Learning cutting-edge auction mechanisms for ad tech platforms, Networking with researchers working on marketplace design theory","audience":"Senior-DS, Early-PhD"},{"id":"community-pps-profitable-conference","type":"community","name":"PPS profitABLE Conference","description":"Largest pricing events worldwide run by Professional Pricing Society. Focus on dynamic pricing, AI in pricing, and monetization strategies. Includes CPP certification.","category":"Conferences","url":"https://pricingsociety.com/events-overview/","difficulty":"intermediate","prerequisites":"basic-statistics, pricing-fundamentals, A-B-testing","topic_tags":"dynamic-pricing, revenue-optimization, pricing-strategy, professional-development","summary":"The largest global pricing conference hosted by Professional Pricing Society, focusing on advanced pricing strategies including dynamic pricing and AI-driven monetization. Offers networking opportunities with pricing professionals and CPP certification for career advancement. Covers cutting-edge topics relevant to tech companies implementing sophisticated pricing models.","use_cases":"Learning latest dynamic pricing algorithms for e-commerce or SaaS platforms, Getting CPP certification to advance career in pricing analytics or revenue optimization","audience":"Mid-DS, Senior-DS"},{"id":"community-workshop-on-platform-analytics-(wopa)","type":"community","name":"Workshop on Platform Analytics (WoPA)","description":"Academically-focused platform economics event covering two-sided markets, personalized recommendations, marketplace design, algorithmic pricing, and content moderation economics. Program committee from Stanford, MIT, Harvard, Chicago, and Wharton.","category":"Conferences","url":"https://platformanalytics.org/","difficulty":"advanced","prerequisites":"microeconomics-theory, econometric-methods, marketplace-design","topic_tags":"platform-economics, two-sided-markets, marketplace-design, algorithmic-pricing, academic-conference","summary":"Workshop on Platform Analytics (WoPA) is an academically-focused conference bringing together researchers from top universities to present cutting-edge work on platform economics. The event covers theoretical and empirical research on two-sided markets, recommendation systems, pricing algorithms, and content moderation from an economic perspective. It serves as a premier venue for PhD students and faculty to share latest findings and network with leading platform economics researchers.","use_cases":"Present dissertation research on marketplace design to leading academics in the field, Learn about latest econometric methods for analyzing platform data and network effects","audience":"Early-PhD, Senior-DS"},{"id":"community-acm-recsys","type":"community","name":"ACM RecSys","description":"Conference on Recommender Systems with economics-relevant content through its industrial track and fairness/bias sessions. RecSys 2026 comes to Minneapolis, making it accessible for US-based tech economists.","category":"Conferences","url":"https://recsys.acm.org/","difficulty":"intermediate","prerequisites":"recommender-systems, A-B-testing, machine-learning-evaluation","topic_tags":"recommender-systems, industrial-applications, algorithmic-fairness, conference-proceedings","summary":"ACM RecSys is the premier academic conference on recommender systems, featuring both theoretical advances and industrial applications. The conference includes dedicated tracks on fairness, bias, and economic aspects of recommendation systems. It's particularly valuable for tech economists studying platform dynamics, user behavior, and algorithmic decision-making in commercial settings.","use_cases":"Learning about bias mitigation techniques in recommendation algorithms for marketplace platforms, Finding industrial case studies on how companies measure and optimize recommendation system economics","audience":"Mid-DS, Senior-DS"},{"id":"community-marketplace-risk-conference","type":"community","name":"Marketplace Risk Conference","description":"Covers trust, safety, compliance, and risk management for marketplace operations. Multiple annual US events provide networking opportunities for marketplace practitioners.","category":"Conferences","url":"https://www.marketplacerisk.com/","difficulty":"intermediate","prerequisites":"marketplace-metrics, fraud-detection, regulatory-compliance","topic_tags":"marketplace-risk, trust-safety, platform-compliance, networking-events, practitioner-conference","summary":"Annual conference series focused on trust, safety, compliance, and risk management for marketplace platforms. Brings together practitioners working on fraud prevention, content moderation, financial risk, and regulatory compliance at two-sided markets. Provides networking opportunities and case studies from companies operating digital marketplaces.","use_cases":"Learning best practices for implementing fraud detection systems in peer-to-peer marketplaces, Networking with other trust and safety professionals to discuss regulatory compliance strategies","audience":"Mid-DS, Senior-DS"},{"id":"community-shoptalk","type":"community","name":"Shoptalk","description":"Dominant retail/e-commerce event covering retail analytics, customer lifetime value, marketplace strategies, and AI in retail. One of the largest retail technology conferences.","category":"Conferences","url":"https://shoptalk.com/","difficulty":"beginner","prerequisites":"basic-statistics, business-metrics","topic_tags":"retail-analytics, e-commerce, customer-lifetime-value, marketplace-strategies, retail-ai","summary":"Shoptalk is the largest retail technology conference focusing on e-commerce analytics, customer lifetime value, and AI applications in retail. The event brings together practitioners, vendors, and researchers to discuss cutting-edge retail analytics methods and marketplace strategies. It's particularly valuable for data scientists working in retail or e-commerce looking to stay current with industry trends and network with peers.","use_cases":"Learning about latest retail analytics tools and methodologies from industry leaders, Networking with other retail data scientists and discovering career opportunities in e-commerce","audience":"Junior-DS, Mid-DS"},{"id":"community-product-led-summit","type":"community","name":"Product-Led Summit","description":"Multiple US/Canada touchpoints covering product metrics, LTV, CAC, retention, and freemium economics for product-led growth practitioners.","category":"Conferences","url":"https://world.productledalliance.com/","difficulty":"intermediate","prerequisites":"product-analytics, cohort-analysis, SQL-aggregations","topic_tags":"product-led-growth, customer-metrics, retention-analysis, freemium-models, conferences","summary":"Product-Led Summit is a conference series across multiple US/Canada locations focused on product-led growth strategies and metrics. It covers essential PLG topics including product metrics, customer lifetime value, customer acquisition cost, retention analysis, and freemium business model economics. The summit targets product managers, growth analysts, and data scientists working on product-driven growth initiatives.","use_cases":"Learning industry best practices for measuring and optimizing product-led growth funnels, Networking with other practitioners implementing freemium and self-serve product strategies","audience":"Mid-DS, Junior-DS"},{"id":"community-joint-statistical-meetings-(jsm)","type":"community","name":"Joint Statistical Meetings (JSM)","description":"Largest gathering of statisticians in North America including business/industry tracks alongside academic research. Covers applied statistics across all domains.","category":"Conferences","url":"https://www.amstat.org/meetings/joint-statistical-meetings","difficulty":"beginner","prerequisites":"basic-statistics, data-visualization","topic_tags":"statistical-conferences, applied-statistics, networking, professional-development, industry-academia","summary":"JSM is the premier annual conference for statisticians and data scientists in North America, featuring thousands of presentations across academic research and industry applications. It offers sessions on cutting-edge statistical methods, case studies from major tech companies, and extensive networking opportunities. The conference serves both as a learning venue for emerging practitioners and a platform for sharing advanced research.","use_cases":"Junior data scientist attending to learn about statistical methods being used in industry and network with potential mentors, Academic researcher presenting their latest work on causal inference methods to get feedback from both industry and academic peers","audience":"Junior-DS, Early-PhD"},{"id":"community-kdd-(acm-sigkdd)","type":"community","name":"KDD (ACM SIGKDD)","description":"Premier data mining conference with significant A/B testing and experimentation content. Papers from Netflix, Amazon, and Uber on variance reduction, experimentation at scale, and causal inference. Applied Data Science Track covers business applications.","category":"Conferences","url":"https://kdd2025.kdd.org/","difficulty":"intermediate","prerequisites":"statistical-hypothesis-testing, python-scikit-learn, experimental-design","topic_tags":"data-mining, ab-testing, causal-inference, variance-reduction, experimentation","summary":"KDD is the premier data mining conference featuring cutting-edge research on A/B testing, experimentation, and causal inference from major tech companies. The Applied Data Science Track showcases real-world implementations of variance reduction techniques and large-scale experimentation frameworks. Papers cover both theoretical advances and practical solutions for business experimentation challenges.","use_cases":"Learning latest variance reduction techniques for improving A/B test sensitivity, Finding industry best practices for running experiments at scale from Netflix, Amazon, Uber","audience":"Mid-DS, Senior-DS"},{"id":"community-asa-symposium-on-data-science-&-statistics-(sdss)","type":"community","name":"ASA Symposium on Data Science & Statistics (SDSS)","description":"Bridges data science, computer science, and statistics with practitioner-oriented content. Covers modern statistical methods and their applications in industry.","category":"Conferences","url":"https://www.amstat.org/meetings/symposium-on-data-science-amp-statistics","difficulty":"intermediate","prerequisites":"statistical-hypothesis-testing, python-pandas, regression-analysis","topic_tags":"data-science-conference, applied-statistics, industry-methods, statistical-computing, practitioner-talks","summary":"ASA's premier conference bridging academic statistics and industry data science practice. Features talks on modern statistical methods, computational tools, and real-world applications from both researchers and practitioners. Ideal for learning about cutting-edge techniques being deployed in tech and other data-driven industries.","use_cases":"Learning about new statistical methods being used in industry before they become mainstream, Finding practical implementations of advanced statistical techniques for your current projects","audience":"Mid-DS, Junior-DS"},{"id":"community-decision-sciences-institute-(dsi)-conference","type":"community","name":"Decision Sciences Institute (DSI) Conference","description":"Covers decision sciences across business functional areas, including analytics, AI applications, and quantitative methods for business decision-making.","category":"Conferences","url":"https://decisionsciences.org/annual-conference/","difficulty":"beginner","prerequisites":"basic-statistics, business-fundamentals","topic_tags":"decision-sciences, business-analytics, quantitative-methods, AI-applications, conference","summary":"The Decision Sciences Institute (DSI) Conference is an interdisciplinary academic conference covering quantitative methods and analytics applications across all business functional areas. It attracts researchers and practitioners working on decision-making problems using statistics, operations research, AI, and other analytical approaches. The conference provides a venue for sharing cutting-edge research and practical applications in business decision sciences.","use_cases":"Present research on new predictive models for supply chain optimization to an interdisciplinary business audience, Learn about latest AI applications in marketing analytics and network with decision science researchers from different business domains","audience":"Senior-DS, Early-PhD"},{"id":"community-posit::conf","type":"community","name":"posit::conf","description":"Enterprise data science content for R and Python users. Covers data science workflows, reproducibility, and modern analytical tooling.","category":"Conferences","url":"https://posit.co/conference/","difficulty":"intermediate","prerequisites":"R-programming, python-data-analysis, git-version-control","topic_tags":"data-science-workflows, reproducible-research, R-python-integration, enterprise-analytics, statistical-computing","summary":"posit::conf is an annual conference focused on enterprise data science workflows using R and Python. The conference covers modern analytical tooling, reproducible research practices, and data science infrastructure for organizations. Sessions include technical tutorials, case studies, and best practices from industry practitioners.","use_cases":"Learning enterprise-grade data science deployment strategies and reproducible workflow management, Discovering new R and Python packages and tools for production analytics environments","audience":"Mid-DS, Senior-DS"},{"id":"community-osqf-(open-source-quantitative-finance)","type":"community","name":"osQF (Open Source Quantitative Finance)","description":"Focused venue for applied finance using R and Python. Single-track conference covering econometrics, risk tools, portfolio management, and market microstructure. Formerly R/Finance.","category":"Conferences","url":"https://osqf.org/","difficulty":"intermediate","prerequisites":"python-pandas, R-programming, time-series-analysis","topic_tags":"quantitative-finance, econometrics, portfolio-management, risk-modeling, open-source","summary":"osQF is a single-track conference focused on applied quantitative finance using R and Python, formerly known as R/Finance. It covers practical implementations of econometric methods, risk management tools, portfolio optimization, and market microstructure analysis. The venue emphasizes open-source approaches to financial modeling and attracts practitioners working at the intersection of finance and data science.","use_cases":"Learning modern approaches to portfolio optimization and risk management from industry practitioners, Discovering new R and Python packages for financial econometrics and market analysis","audience":"Mid-DS, Senior-DS"},{"id":"community-conference-on-ai-ml-and-business-analytics","type":"community","name":"Conference on AI/ML and Business Analytics","description":"Bridges AI/ML researchers across computer science, economics, marketing, management, and finance. Hosted at top business schools since 2014, rotating among Columbia, Chicago Booth, Stanford GSB, NYU Stern, and others.","category":"Conferences","url":"https://business.columbia.edu/","difficulty":"intermediate","prerequisites":"statistical-inference, econometric-methods, machine-learning-fundamentals","topic_tags":"academic-conferences, business-analytics, ai-ml-economics, interdisciplinary-research, networking","summary":"An annual academic conference that brings together researchers from computer science, economics, marketing, management, and finance to discuss AI/ML applications in business. Hosted at top business schools since 2014, it rotates among prestigious institutions like Columbia, Chicago Booth, Stanford GSB, and NYU Stern. The conference serves as a key networking and knowledge-sharing venue for interdisciplinary researchers working at the intersection of technology and business.","use_cases":"Present research on causal inference methods applied to tech platform data, Network with economists and data scientists working on similar business problems","audience":"Senior-DS, Early-PhD"},{"id":"community-ashecon-(american-society-of-health-economists)","type":"community","name":"ASHEcon (American Society of Health Economists)","description":"Premier US health economics research conference across 180+ sessions. Features theoretical and empirical research on healthcare costs, insurance, pharmaceuticals, and policy with applied analytics including claims data analysis.","category":"Conferences","url":"https://www.ashecon.org/","difficulty":"intermediate","prerequisites":"econometrics-basics, regression-analysis, healthcare-data","topic_tags":"health-economics, healthcare-policy, applied-econometrics, insurance-markets, pharmaceutical-economics","summary":"ASHEcon is the premier annual conference for health economics researchers in the US, featuring 180+ sessions on theoretical and empirical research. The conference covers healthcare costs, insurance markets, pharmaceutical economics, and policy analysis with heavy emphasis on applied analytics and claims data analysis. Attendees present cutting-edge research and network with leading academics and industry practitioners in health economics.","use_cases":"Present your research on healthcare price transparency effects using difference-in-differences on claims data, Learn latest methods for analyzing Medicare Advantage risk adjustment from leading health economists","audience":"Senior-DS, Early-PhD"},{"id":"community-ispor-(health-economics-and-outcomes-research)","type":"community","name":"ISPOR (Health Economics and Outcomes Research)","description":"Most applied health economics option with two major annual conferences. Sessions cover real-world evidence, health technology assessment, AI in HEOR, and drug pricing. Strong industry and pharma presence.","category":"Conferences","url":"https://www.ispor.org/","difficulty":"intermediate","prerequisites":"health-economics-basics, regression-analysis, pharmaceutical-market-knowledge","topic_tags":"health-economics, outcomes-research, pharmaceutical-pricing, real-world-evidence, health-technology-assessment","summary":"ISPOR is the leading professional organization for health economics and outcomes research, hosting two major annual conferences focused on applied methods in healthcare. The conferences feature sessions on real-world evidence generation, health technology assessment, AI applications in HEOR, and pharmaceutical pricing strategies. It attracts a strong mix of industry professionals, pharma researchers, and academic health economists.","use_cases":"Pharmaceutical company analyst presenting cost-effectiveness analysis of new drug to regulatory bodies, Health economist networking with industry professionals while learning latest RWE methodologies for hospital outcomes research","audience":"Mid-DS, Senior-DS"},{"id":"community-academyhealth-annual-research-meeting","type":"community","name":"AcademyHealth Annual Research Meeting","description":"Largest health services research forum bringing together researchers, policymakers, and practitioners across 21 thematic tracks covering healthcare delivery, health economics, digital health, and AI in healthcare.","category":"Conferences","url":"https://www.academyhealth.org/","difficulty":"intermediate","prerequisites":"health-economics-basics, research-methodology, statistical-inference","topic_tags":"health-services-research, healthcare-economics, digital-health, AI-healthcare, policy-research","summary":"Premier annual conference for health services researchers featuring 21 specialized tracks on healthcare delivery, economics, and emerging technologies. Brings together academic researchers, industry practitioners, and policymakers to share cutting-edge research and discuss implementation challenges. Ideal venue for networking, learning about latest methodological advances, and understanding policy implications of health economics research.","use_cases":"Present your health economics research to interdisciplinary audience of researchers and policymakers, Learn about latest AI applications in healthcare and digital health measurement techniques","audience":"Senior-DS, Early-PhD"},{"id":"community-gsu-ms-ai-and-fintech-conference","type":"community","name":"GSU-MS AI and FinTech Conference","description":"Georgia State University conference partnering with Management Science journal, featuring dual submission options. Topics include AI in finance, big data in financial economics, DeFi, and cryptoeconomics.","category":"Conferences","url":"https://robinson.gsu.edu/","difficulty":"intermediate","prerequisites":"financial-econometrics, python-pandas, regression-analysis","topic_tags":"fintech, AI-finance, DeFi, cryptoeconomics, academic-conference","summary":"Academic conference hosted by Georgia State University in partnership with Management Science journal, focusing on AI applications in finance and emerging financial technologies. Features dual submission options allowing researchers to present work and potentially publish in a top-tier journal. Covers cutting-edge topics like decentralized finance, cryptocurrency economics, and machine learning in financial markets.","use_cases":"Present research on algorithmic trading strategies to academic and industry audience, Network with fintech researchers and learn about latest AI applications in financial services","audience":"Senior-DS, Early-PhD"},{"id":"community-federal-reserve-bank-of-san-francisco-fintech-conference","type":"community","name":"Federal Reserve Bank of San Francisco Fintech Conference","description":"Convenes academics, industry experts, and regulators on fintech opportunities, featuring Fed speakers including Governors. Covers regulatory implications and fintech innovation.","category":"Conferences","url":"https://www.frbsf.org/news-and-media/events/","difficulty":"intermediate","prerequisites":"financial-markets-knowledge, regulatory-frameworks, econometrics","topic_tags":"fintech, financial-regulation, monetary-policy, banking-innovation, conferences","summary":"Annual conference hosted by the Federal Reserve Bank of San Francisco bringing together academics, industry professionals, and regulators to discuss fintech innovations and their regulatory implications. Features presentations from Fed Governors and other senior officials on emerging financial technologies. Provides insights into regulatory perspectives on digital payments, cryptocurrencies, and financial innovation.","use_cases":"Understanding regulatory stance on fintech innovations for compliance strategy, Learning about Fed research priorities in digital finance and payment systems","audience":"Mid-DS, Senior-DS"},{"id":"community-wharton-people-analytics-conference","type":"community","name":"Wharton People Analytics Conference","description":"Leading HR analytics event now in its 12th year. Features academic research competitions alongside industry speakers from Google and Mastercard on AI and future of work, workforce transformation, and evidence-based HR.","category":"Conferences","url":"https://wpa.wharton.upenn.edu/","difficulty":"intermediate","prerequisites":"descriptive-statistics, data-visualization, survey-design","topic_tags":"people-analytics, HR-research, workforce-analytics, academic-conference, industry-applications","summary":"Annual conference bringing together academics and practitioners in people analytics and HR research. Features competitive academic presentations alongside industry case studies from major tech companies on AI applications in workforce management. Covers evidence-based approaches to talent management, organizational behavior, and future of work trends.","use_cases":"Learning latest research methods for analyzing employee engagement and retention data, Discovering how companies like Google implement AI-driven hiring and performance evaluation systems","audience":"Mid-DS, Senior-DS"},{"id":"community-sole-eale-annual-meeting","type":"community","name":"SOLE/EALE Annual Meeting","description":"Primary academic labor economics conference. The 2025 edition is the 6th World Labor Conference held jointly with European and Asian associations, providing global labor economics perspectives.","category":"Conferences","url":"https://www.sole-jole.org/","difficulty":"intermediate","prerequisites":"econometrics-fundamentals, academic-writing, statistical-inference","topic_tags":"labor-economics, academic-conferences, research-presentations, networking, peer-review","summary":"The SOLE/EALE Annual Meeting is the premier global academic conference for labor economists, bringing together researchers from the Society of Labor Economists and European Association of Labour Economists. The 2025 edition marks the 6th World Labor Conference, featuring cutting-edge research presentations, networking opportunities, and collaboration between international labor economics communities.","use_cases":"Present your labor economics research to leading academics and get feedback before journal submission, Network with international labor economists and discover collaboration opportunities for cross-country studies","audience":"Early-PhD, Senior-DS"},{"id":"community-areuea-(real-estate-and-urban-economics)","type":"community","name":"AREUEA (Real Estate and Urban Economics)","description":"Premier academic real estate conferences including ASSA session (January), National Conference (May), and International Conference (July). Growing tech/proptech tracks cover climate risk, appraisal bias, and real estate technology.","category":"Conferences","url":"https://www.areuea.org/","difficulty":"intermediate","prerequisites":"econometrics-fundamentals, python-pandas, research-methodology","topic_tags":"real-estate-economics, urban-economics, proptech, academic-conferences, climate-risk","summary":"AREUEA is the leading academic association for real estate and urban economics research, hosting three major conferences annually. The organization brings together researchers studying housing markets, urban development, and increasingly proptech applications. Their conferences feature cutting-edge research on topics like algorithmic bias in appraisals, climate risk modeling, and real estate technology.","use_cases":"Present research on housing market dynamics or proptech applications to leading academics in the field, Network with researchers studying similar problems in real estate economics and learn about latest methodologies","audience":"Early-PhD, Senior-DS"},{"id":"community-analytics-unite","type":"community","name":"Analytics Unite","description":"Retail and CPG analytics conference covering customer analytics, pricing optimization, and data-driven retail strategies. Strong industry practitioner focus.","category":"Conferences","url":"https://www.analyticsunite.com/","difficulty":"intermediate","prerequisites":"SQL-basics, A-B-testing, customer-segmentation","topic_tags":"retail-analytics, pricing-optimization, customer-analytics, CPG-analytics, industry-conference","summary":"Analytics Unite is a retail and CPG analytics conference focused on practical applications of customer analytics, pricing optimization, and data-driven retail strategies. The conference targets industry practitioners working in retail, e-commerce, and consumer packaged goods companies. Attendees learn about real-world implementations of analytics solutions from experienced practitioners in the field.","use_cases":"Learning how other retail companies implement pricing optimization strategies and customer segmentation models, Networking with retail analytics practitioners to discover new tools and approaches for improving conversion rates and customer lifetime value","audience":"Mid-DS, Junior-DS"},{"id":"community-arf-audiencexscience","type":"community","name":"ARF AUDIENCExSCIENCE","description":"Covers audience measurement methodology and privacy-preserving techniques for media and advertising research.","category":"Conferences","url":"https://thearf.org/arf-events/","difficulty":"intermediate","prerequisites":"survey-methodology, differential-privacy, statistical-sampling","topic_tags":"audience-measurement, privacy-preserving, media-research, advertising-analytics, conference","summary":"ARF AUDIENCExSCIENCE is a conference focused on audience measurement methodology and privacy-preserving techniques for media and advertising research. It brings together researchers and practitioners working on measuring media consumption, advertising effectiveness, and audience analytics while addressing privacy concerns. The conference covers both traditional measurement approaches and emerging privacy-first methodologies.","use_cases":"Developing privacy-preserving methods for measuring TV/streaming audience sizes without exposing individual viewing habits, Implementing differential privacy techniques for advertising attribution while maintaining measurement accuracy","audience":"Mid-DS, Senior-DS"},{"id":"community-sjdm-annual-meeting","type":"community","name":"SJDM Annual Meeting","description":"Society for Judgment and Decision Making annual meeting. Covers experimental studies, utility theory, and applications to medicine, law, and consumer behavior. Foundational behavioral economics venue.","category":"Conferences","url":"https://www.sjdm.org/","difficulty":"beginner","prerequisites":"experimental-design, statistical-inference, behavioral-economics-basics","topic_tags":"behavioral-economics, experimental-methods, decision-theory, consumer-behavior, academic-conferences","summary":"The Society for Judgment and Decision Making annual meeting is a premier academic conference focusing on behavioral economics and decision science. It features experimental studies on how people make choices, utility theory, and applications across healthcare, legal, and consumer domains. This venue attracts researchers studying cognitive biases, preference formation, and decision-making processes.","use_cases":"Learning about experimental methods for studying consumer choice behavior and decision biases, Networking with behavioral economists and finding collaborators for interdisciplinary decision science research","audience":"Early-PhD, Curious-browser"},{"id":"community-bdrm-(behavioral-decision-research-in-management)","type":"community","name":"BDRM (Behavioral Decision Research in Management)","description":"Biennial conference at business schools covering behavioral decision research. Features keynotes from pioneers like Daniel Kahneman. Strong focus on business applications of behavioral economics.","category":"Conferences","url":"https://www.bdrm.org/","difficulty":"intermediate","prerequisites":"behavioral-economics, experimental-design, statistical-inference","topic_tags":"behavioral-economics, decision-science, experimental-methods, business-applications, conference","summary":"BDRM is a biennial conference focused on behavioral decision research in business contexts, featuring leading researchers like Daniel Kahneman. The conference emphasizes practical applications of behavioral economics principles to management and organizational decision-making. It serves as a key venue for academics and practitioners to share cutting-edge research on how psychological factors influence business decisions.","use_cases":"Presenting research on consumer choice behavior and pricing strategies to academic peers, Learning about latest behavioral interventions for improving employee decision-making in organizations","audience":"Senior-DS, Early-PhD"},{"id":"community-decision-sciences-institute-annual-meeting","type":"community","name":"Decision Sciences Institute Annual Meeting","description":"Annual conference covering business analytics, AI in decisions, and quantitative decision making. Strong industry-academic mix with focus on practical applications.","category":"Conferences","url":"https://decisionsciences.org/","difficulty":"intermediate","prerequisites":"statistical-inference, python-or-r, experimental-design","topic_tags":"decision-science, business-analytics, quantitative-methods, industry-conference","summary":"Annual conference bringing together academics and industry practitioners working on business analytics, AI-driven decision making, and quantitative methods. Features presentations on cutting-edge decision science applications with strong emphasis on practical implementation. Ideal for staying current on industry trends and networking with decision science professionals.","use_cases":"Learning about latest industry applications of decision science methods for your current projects, Networking with practitioners and academics to find collaboration opportunities or job prospects","audience":"Mid-DS, Senior-DS"},{"id":"community-bspa-annual-conference","type":"community","name":"BSPA Annual Conference","description":"Behavioral Science & Policy Association conference connecting academics, practitioners, and policymakers. Features 8-minute short presentations on policy-relevant behavioral research.","category":"Conferences","url":"https://behavioralpolicy.org/","difficulty":"beginner","prerequisites":"experimental-design, behavioral-economics, statistical-inference","topic_tags":"behavioral-science, policy-research, academic-networking, research-presentation, evidence-based-policy","summary":"The BSPA Annual Conference is a premier gathering for behavioral scientists, policy researchers, and practitioners working at the intersection of psychology and public policy. The conference features rapid-fire 8-minute presentations that showcase actionable behavioral insights for policy applications. It serves as a key networking hub for academics seeking to translate research into real-world policy solutions.","use_cases":"Present your behavioral intervention study to policymakers and get feedback on practical implementation, Network with other researchers working on similar policy problems like nudging retirement savings or improving vaccine uptake","audience":"Early-PhD, Curious-browser"},{"id":"community-eadm-spudm","type":"community","name":"EADM/SPUDM","description":"European Association for Decision Making / Subjective Probability, Utility, and Decision Making. European counterpart to SJDM covering judgment and decision making research.","category":"Conferences","url":"https://www.eadm.eu/","difficulty":"beginner","prerequisites":"basic-statistics, research-methodology","topic_tags":"decision-making, behavioral-economics, academic-conferences, research-community, judgment-analysis","summary":"EADM/SPUDM is the European Association for Decision Making and Subjective Probability, Utility, and Decision Making - a research community focused on judgment and decision-making studies. It serves as the European counterpart to SJDM, bringing together researchers studying how people make decisions under uncertainty. The community hosts conferences and facilitates collaboration among behavioral economists, psychologists, and decision scientists.","use_cases":"Finding European collaborators for behavioral economics research projects, Presenting experimental results on consumer decision-making to academic peers","audience":"Early-PhD, Senior-DS"},{"id":"community-ic2s2-(international-conference-on-computational-social-science)","type":"community","name":"IC2S2 (International Conference on Computational Social Science)","description":"Premier venue for computational methods in social science. Covers text analysis, network analysis, behavioral modeling, and large-scale social data. Strong presence from tech companies and CSS researchers.","category":"Conferences","url":"https://www.ic2s2.org/","difficulty":"intermediate","prerequisites":"python-pandas, social-network-analysis, natural-language-processing","topic_tags":"computational-social-science, network-analysis, text-mining, behavioral-modeling, academic-conference","summary":"IC2S2 is the leading international conference for computational social science, bringing together researchers using data science methods to study social phenomena. The conference features cutting-edge research on social networks, digital behavior, text analysis, and large-scale social data from both academic and industry perspectives. It's an ideal venue for learning about the latest methods in CSS and networking with researchers at the intersection of computer science and social science.","use_cases":"Learning about state-of-the-art methods for analyzing social media data and online behavior patterns, Networking with computational social scientists from tech companies and academia to find collaboration opportunities","audience":"Mid-DS, Senior-DS"},{"id":"community-netsci-(network-science-conference)","type":"community","name":"NetSci (Network Science Conference)","description":"Celebrates its 20th anniversary in Boston 2026. Covers network algorithms, social networks, information spreading, and economic networks. Premier venue for network science research.","category":"Conferences","url":"https://www.netsci2026.com/","difficulty":"intermediate","prerequisites":"graph-theory, python-networkx, statistical-inference","topic_tags":"network-science, graph-algorithms, social-networks, academic-conferences","summary":"NetSci is the premier annual conference for network science research, bringing together researchers studying complex networks across disciplines. The conference covers cutting-edge methods in network analysis, from algorithmic advances to applications in social systems and economics. It's the go-to venue for staying current with network science developments and connecting with the research community.","use_cases":"Learning about new graph neural network architectures for recommendation systems, Discovering methods for analyzing information cascades in social media platforms","audience":"Senior-DS, Early-PhD"},{"id":"community-complex-networks-conference","type":"community","name":"Complex Networks Conference","description":"Annual conference on graph ML, economic networks, and recommendation systems. Covers network-based approaches to complex systems and computational methods.","category":"Conferences","url":"https://complexnetworks.org/","difficulty":"intermediate","prerequisites":"graph-theory, networkx, linear-algebra","topic_tags":"network-analysis, graph-ml, economic-networks, recommendation-systems, conferences","summary":"The Complex Networks Conference is an annual academic gathering focused on graph machine learning, economic networks, and recommendation systems. It brings together researchers and practitioners working on network-based approaches to understanding complex systems and developing computational methods. The conference covers cutting-edge research in network science with applications to economics, social systems, and technology platforms.","use_cases":"Learning about state-of-the-art graph neural networks for recommendation systems in tech platforms, Discovering new methods for analyzing economic networks like supply chains or financial markets","audience":"Mid-DS, Senior-DS"},{"id":"community-social-simulation-conference","type":"community","name":"Social Simulation Conference","description":"European conference on agent-based modeling and policy simulation. Covers computational models of social systems, emergent behavior, and policy evaluation.","category":"Conferences","url":"https://www.essa.eu/","difficulty":"intermediate","prerequisites":"agent-based-modeling, python-simulation, network-analysis","topic_tags":"agent-based-modeling, social-simulation, policy-evaluation, computational-social-science, conference","summary":"European conference focused on agent-based modeling and computational approaches to understanding social systems. Researchers present work on modeling emergent behaviors, social dynamics, and policy interventions using simulation methods. Key venue for connecting computational modeling with real-world policy applications.","use_cases":"Policy researcher wanting to learn simulation methods for evaluating intervention effects, Data scientist working on social network analysis seeking advanced modeling techniques","audience":"Mid-DS, Senior-DS"},{"id":"community-nabe-tech-economics-conference","type":"community","name":"NABE Tech Economics Conference","description":"The largest causal inference conference specifically for tech industry economists. Theme: 'Causal Inference, A.I., and Experiments in Action.' Features Industry Job Fair and strong networking for tech economists.","category":"Conferences","url":"https://www.nabe.com/","difficulty":"intermediate","prerequisites":"causal-inference, experimental-design, econometrics","topic_tags":"causal-inference, experimentation, tech-industry, networking, conferences","summary":"The premier annual conference bringing together economists working in tech companies to share cutting-edge research on causal inference, AI applications, and experimental methods. Features presentations of industry research, methodological advances, and extensive networking opportunities including a dedicated job fair for tech economist positions.","use_cases":"Learning latest experimental design techniques used at major tech companies, Networking with other tech economists and finding new job opportunities","audience":"Mid-DS, Senior-DS"},{"id":"community-iapp-ai-governance-global","type":"community","name":"IAPP AI Governance Global","description":"Premier AI governance conference with 1,000+ privacy and AI governance professionals. Covers EU AI Act implementation, practical governance frameworks, and AI compliance strategies.","category":"Conferences","url":"https://iapp.org/","difficulty":"intermediate","prerequisites":"data-privacy-regulations, AI-model-deployment, regulatory-compliance-frameworks","topic_tags":"AI-governance, regulatory-compliance, EU-AI-Act, privacy-regulations, conferences","summary":"IAPP AI Governance Global is the premier conference for AI governance professionals, bringing together 1,000+ experts to discuss EU AI Act implementation and practical compliance frameworks. The conference focuses on translating AI regulations into actionable governance strategies for organizations deploying AI systems. Attendees learn about cutting-edge compliance approaches and network with privacy and governance professionals.","use_cases":"Learning how to implement EU AI Act compliance frameworks for your organization's AI systems, Networking with AI governance experts to develop practical privacy-preserving ML deployment strategies","audience":"Mid-DS, Senior-DS"},{"id":"community-acm-facct-(fairness,-accountability,-and-transparency)","type":"community","name":"ACM FAccT (Fairness, Accountability, and Transparency)","description":"Flagship venue for algorithmic fairness, accountability, and transparency research. Covers bias in ML, algorithmic auditing, and responsible AI. Strong mix of CS, law, and social science.","category":"Conferences","url":"https://facctconference.org/","difficulty":"intermediate","prerequisites":"python-scikit-learn, statistical-hypothesis-testing, research-paper-writing","topic_tags":"algorithmic-fairness, AI-ethics, bias-detection, responsible-AI, conference-proceedings","summary":"Premier academic conference bringing together computer scientists, social scientists, and legal scholars to address fairness, accountability, and transparency in algorithmic systems. Papers cover methods for detecting and mitigating bias in ML models, frameworks for algorithmic auditing, and policy implications of automated decision-making. Essential venue for staying current on responsible AI research and connecting theory with real-world applications.","use_cases":"Finding latest methods for auditing hiring algorithms for demographic bias, Learning interdisciplinary approaches to evaluate fairness in recommendation systems","audience":"Senior-DS, Early-PhD"},{"id":"community-aies-(ai,-ethics,-and-society)","type":"community","name":"AIES (AI, Ethics, and Society)","description":"Conference on AI ethics, policy, and societal impacts. Sold out in-person attendance reflects strong demand. Covers ethical frameworks, policy implications, and social effects of AI.","category":"Conferences","url":"https://www.aies-conference.com/","difficulty":"beginner","prerequisites":"research-ethics, AI-fundamentals, policy-analysis","topic_tags":"AI-ethics, conference, policy, societal-impact, responsible-AI","summary":"AIES is a premier conference focused on the ethical, policy, and societal implications of artificial intelligence systems. It brings together researchers, practitioners, and policymakers to discuss frameworks for responsible AI development and deployment. The conference's sold-out attendance demonstrates the growing importance of ethical considerations in AI research and industry practice.","use_cases":"Understanding current debates and frameworks around AI fairness and bias mitigation for implementing responsible AI practices, Networking with interdisciplinary researchers working on AI policy and governance for collaborative research opportunities","audience":"Curious-browser, Early-PhD"},{"id":"community-clear-(causal-learning-and-reasoning)-1","type":"community","name":"CLeaR (Causal Learning and Reasoning)","description":"Dedicated venue for causal inference attracting both ML and economics researchers. Covers causal discovery, causal representation learning, and applications to decision-making.","category":"Conferences","url":"https://www.cclear.cc/","difficulty":"intermediate","prerequisites":"causal-inference-basics, directed-acyclic-graphs, python-scikit-learn","topic_tags":"causal-inference, machine-learning, causal-discovery, decision-making, conferences","summary":"CLeaR is a specialized academic conference that bridges machine learning and economics through causal inference research. It focuses on cutting-edge methods for causal discovery, causal representation learning, and their applications to real-world decision-making problems. The venue attracts researchers working on both theoretical foundations and practical implementations of causal methods.","use_cases":"Finding latest research on causal discovery algorithms for observational data, Learning about causal representation learning techniques for complex datasets","audience":"Senior-DS, Early-PhD"},{"id":"community-quant-ux-con","type":"community","name":"Quant UX Con","description":"The only conference specifically for quantitative UX research. Covers choice modeling, segmentation, logs analysis, A/B testing, and UX metrics. Essential for quant UX researchers in tech.","category":"Conferences","url":"https://www.quantuxcon.org/","difficulty":"intermediate","prerequisites":"A/B-testing, statistical-significance, user-research-methods","topic_tags":"quantitative-UX, A/B-testing, user-analytics, choice-modeling, conferences","summary":"Quant UX Con is the premier conference dedicated to quantitative user experience research methods. It brings together practitioners working at the intersection of data science and UX, covering advanced topics like choice modeling, behavioral segmentation, and experimentation in product contexts. Essential for professionals who apply statistical methods to understand and improve user experiences in tech products.","use_cases":"Learning advanced choice modeling techniques for feature prioritization decisions, Networking with other quant UX researchers and discovering new tools for user behavior analysis","audience":"Mid-DS, Senior-DS"},{"id":"community-uxpa-international-conference","type":"community","name":"UXPA International Conference","description":"User Experience Professionals Association international conference. Covers UX research methods, usability, and user-centered design with mix of qualitative and quantitative approaches.","category":"Conferences","url":"https://uxpa.org/","difficulty":"beginner","prerequisites":"basic-statistics, survey-design","topic_tags":"user-experience, qualitative-research, usability-testing, behavioral-research, product-design","summary":"UXPA International Conference is the premier gathering for user experience professionals worldwide. It features presentations on UX research methodologies, usability studies, and user-centered design approaches combining both qualitative and quantitative techniques. The conference serves as a key knowledge-sharing venue for practitioners working at the intersection of human behavior and product design.","use_cases":"Learning latest UX research methods for improving product features and user interfaces, Networking with UX professionals to understand industry best practices for user testing and behavioral analysis","audience":"Junior-DS, Curious-browser"},{"id":"community-acm-chi-(conference-on-human-factors-in-computing-systems)","type":"community","name":"ACM CHI (Conference on Human Factors in Computing Systems)","description":"Premier HCI conference with 5,000+ attendees. Increasingly features behavioral economics in HCI, platform labor, and algorithmic decision-making research. Essential for human-computer interaction.","category":"Conferences","url":"https://chi.acm.org/","difficulty":"intermediate","prerequisites":"user-experience-design, statistical-hypothesis-testing, human-subjects-research","topic_tags":"human-computer-interaction, behavioral-economics, algorithmic-decision-making, platform-labor, conference-proceedings","summary":"ACM CHI is the premier academic conference for human-computer interaction research, attracting over 5,000 researchers, designers, and practitioners annually. The conference increasingly features work at the intersection of HCI and economics, including studies on platform labor markets, algorithmic bias, and behavioral interventions in digital systems. Essential venue for understanding how economic principles apply to technology design and user behavior.","use_cases":"Finding cutting-edge research on how algorithmic recommendations affect user decision-making and economic outcomes, Discovering methodologies for studying gig economy platforms and digital labor market dynamics","audience":"Senior-DS, Curious-browser"},{"id":"community-cscw-(computer-supported-cooperative-work)","type":"community","name":"CSCW (Computer-Supported Cooperative Work)","description":"ACM conference on computer-supported cooperative work. Covers gig economy, crowdsourcing economics, and algorithmic management. Strong presence of researchers studying platform labor.","category":"Conferences","url":"https://cscw.acm.org/","difficulty":"intermediate","prerequisites":"survey-methodology, causal-inference, ethnographic-methods","topic_tags":"platform-economics, algorithmic-management, gig-economy, cooperative-work, conferences","summary":"CSCW is ACM's premier conference on computer-supported cooperative work, featuring interdisciplinary research on how technology shapes work and collaboration. The conference has strong coverage of platform labor, gig economy dynamics, and algorithmic management systems. Researchers present both qualitative and quantitative studies on crowdsourcing, digital labor markets, and worker-platform interactions.","use_cases":"Understanding how algorithmic management affects gig worker outcomes and platform efficiency, Learning qualitative methods for studying remote work coordination and digital collaboration tools","audience":"Senior-DS, Early-PhD"},{"id":"community-isf-(international-symposium-on-forecasting)","type":"community","name":"ISF (International Symposium on Forecasting)","description":"Premier forecasting conference covering demand forecasting, economic prediction, and ML methods. IIF's flagship event attracting forecasters from academia and industry.","category":"Conferences","url":"https://isf.forecasters.org/","difficulty":"intermediate","prerequisites":"time-series-analysis, statistical-modeling, forecasting-metrics","topic_tags":"forecasting, time-series, conferences, demand-planning, economic-prediction","summary":"The International Symposium on Forecasting is the premier annual conference for forecasting practitioners and researchers, hosted by the International Institute of Forecasters. It brings together academics and industry professionals to share latest developments in demand forecasting, economic prediction, and machine learning approaches to forecasting. Attendees learn cutting-edge methods, network with forecasting experts, and present their own research.","use_cases":"Learning about new forecasting methodologies and connecting with other practitioners in demand planning or economic forecasting, Presenting research on novel time series methods or forecasting applications to get feedback from the forecasting community","audience":"Mid-DS, Senior-DS"},{"id":"community-manifest-(forecasting-festival)","type":"community","name":"Manifest (Forecasting Festival)","description":"Festival for forecasting, prediction markets, and AI. Brings together forecasters, prediction market enthusiasts, and AI researchers in an unconference format.","category":"Conferences","url":"https://www.manifest.is/","difficulty":"beginner","prerequisites":"basic-probability, statistical-inference","topic_tags":"forecasting, prediction-markets, AI-research, unconference, networking","summary":"An annual festival bringing together forecasters, prediction market enthusiasts, and AI researchers in an unconference format. The event focuses on prediction methodologies, market mechanisms, and AI applications in forecasting. It's designed for learning cutting-edge forecasting techniques and networking with practitioners across academia and industry.","use_cases":"Learning about state-of-the-art forecasting methods and connecting with other practitioners, Discovering new prediction market platforms and evaluation techniques for forecasting models","audience":"Curious-browser, Senior-DS"},{"id":"community-prediction-market-conference","type":"community","name":"Prediction Market Conference","description":"New conference by Kalshi Research debuting April 2026. Brings together 500+ builders, traders, and policymakers from Harvard, Stanford, Yale, and UChicago to discuss prediction markets.","category":"Conferences","url":"https://kalshi.com/","difficulty":"beginner","prerequisites":"basic-probability, market-mechanisms","topic_tags":"prediction-markets, forecasting, behavioral-economics, market-design, conference","summary":"A new academic conference launching in April 2026 focused on prediction markets, bringing together researchers, practitioners, and policymakers. The event connects builders, traders, and academics from top universities to discuss the latest developments in prediction market theory and applications. It serves as a networking and knowledge-sharing venue for anyone interested in forecasting markets and their societal implications.","use_cases":"Learning about cutting-edge research in prediction market design and regulation, Networking with other researchers and practitioners working on forecasting and market mechanisms","audience":"Curious-browser, Senior-DS"},{"id":"community-mit-sloan-sports-analytics-conference","type":"community","name":"MIT Sloan Sports Analytics Conference","description":"The premier sports analytics venue with 2,500+ attendees from 80+ professional teams and 220+ academic institutions. Covers analytics across all major sports with strong business focus.","category":"Conferences","url":"https://www.sloansportsconference.com/","difficulty":"intermediate","prerequisites":"python-pandas, statistical-hypothesis-testing, data-visualization","topic_tags":"sports-analytics, business-analytics, conference, networking, applied-statistics","summary":"The MIT Sloan Sports Analytics Conference is the largest annual gathering for sports analytics professionals and researchers. It brings together practitioners from professional teams, academics, and industry leaders to share cutting-edge methods and business applications. The conference covers analytics across all major sports with emphasis on real-world implementation and business impact.","use_cases":"Learning how professional sports teams use analytics for player evaluation and game strategy, Networking with sports industry professionals to transition from traditional data science to sports analytics","audience":"Mid-DS, Curious-browser"},{"id":"community-sabr-analytics-conference","type":"community","name":"SABR Analytics Conference","description":"Society for American Baseball Research analytics conference. Focuses on baseball sabermetrics with the Diamond Dollars Case Competition. Essential for baseball analytics professionals.","category":"Conferences","url":"https://sabr.org/analytics","difficulty":"intermediate","prerequisites":"statistics-fundamentals, R-or-python, data-visualization","topic_tags":"sports-analytics, sabermetrics, baseball-statistics, analytics-conference, case-competition","summary":"Annual conference by the Society for American Baseball Research focusing on baseball analytics and sabermetrics. Features presentations on cutting-edge baseball analysis techniques and hosts the Diamond Dollars Case Competition. Essential networking and learning opportunity for sports analytics professionals working in baseball.","use_cases":"Sports analyst looking to network with baseball analytics community and learn latest sabermetric methods, Data scientist interested in applying analytics techniques to sports data through case competition participation","audience":"Mid-DS, Curious-browser"},{"id":"community-carnegie-mellon-sports-analytics-conference-(cmsac)","type":"community","name":"Carnegie Mellon Sports Analytics Conference (CMSAC)","description":"Emphasizes cutting-edge statistical methods with representatives from 15+ professional teams. Methods-focused conference bridging academic statistics and sports practice.","category":"Conferences","url":"https://www.stat.cmu.edu/cmsac/","difficulty":"intermediate","prerequisites":"python-pandas, statistical-modeling, regression-analysis","topic_tags":"sports-analytics, statistical-methods, academic-conference, professional-sports, causal-inference","summary":"Carnegie Mellon Sports Analytics Conference (CMSAC) is a methods-focused academic conference that bridges cutting-edge statistical research with real-world sports applications. Representatives from 15+ professional teams attend alongside academic researchers to discuss advanced analytical techniques. The conference emphasizes rigorous statistical methods applied to sports data and decision-making.","use_cases":"Learning state-of-the-art statistical methods being used by professional sports teams for player evaluation and strategy, Networking with sports analytics professionals and academics to understand industry best practices and research directions","audience":"Mid-DS, Senior-DS"},{"id":"community-hudl-performance-insights","type":"community","name":"Hudl Performance Insights","description":"Premier soccer/football analytics event with 400+ delegates. Covers performance analysis, tactical insights, and data-driven coaching in football.","category":"Conferences","url":"https://www.hudl.com/","difficulty":"intermediate","prerequisites":"python-pandas, tableau-dashboards, sports-domain-knowledge","topic_tags":"sports-analytics, football-performance, tactical-analysis, event-data, conferences","summary":"Premier soccer/football analytics conference bringing together 400+ performance analysts, data scientists, and coaches. Features cutting-edge applications of data science to football performance analysis, tactical insights, and evidence-based coaching methodologies. Covers both technical implementation and practical application in professional football environments.","use_cases":"Learning how top football clubs use tracking data and event data to optimize player performance and tactical decisions, Networking with sports analytics professionals and discovering career opportunities in the football industry","audience":"Mid-DS, Curious-browser"},{"id":"community-nessis-(new-england-symposium-on-statistics-in-sports)","type":"community","name":"NESSIS (New England Symposium on Statistics in Sports)","description":"Academic statistics conference at Harvard focusing on rigorous statistical methods for sports. Features peer-reviewed research from statisticians across sports domains.","category":"Conferences","url":"http://www.nessis.org/","difficulty":"intermediate","prerequisites":"statistical-inference, regression-analysis, academic-writing","topic_tags":"sports-analytics, statistical-methods, academic-conference, peer-review, harvard","summary":"NESSIS is an academic statistics conference at Harvard that brings together researchers applying rigorous statistical methods to sports problems. The conference features peer-reviewed research presentations from statisticians working across various sports domains. It provides a platform for sharing cutting-edge methodological approaches and fostering collaboration between academia and sports analytics practitioners.","use_cases":"Presenting your sports analytics research to an academic audience and getting peer feedback, Learning about state-of-the-art statistical methods being applied to sports problems similar to your research","audience":"Early-PhD, Senior-DS"},{"id":"community-arf-audiencexscience-1","type":"community","name":"ARF AUDIENCExSCIENCE","description":"Flagship audience measurement conference with peer-reviewed research on cross-platform measurement, attention metrics, and AI in advertising. Premier venue for advertising researchers.","category":"Conferences","url":"https://thearf.org/","difficulty":"intermediate","prerequisites":"statistical-testing, experimental-design, survey-methodology","topic_tags":"audience-measurement, advertising-research, cross-platform-analytics, attention-metrics, marketing-science","summary":"Premier conference for advertising and audience measurement researchers featuring peer-reviewed studies on cross-platform measurement, attention metrics, and AI applications in advertising. Brings together industry practitioners and academics working on problems in media measurement and advertising effectiveness. Essential venue for staying current with methodological advances in audience research.","use_cases":"Learning about new methodologies for measuring advertising effectiveness across digital and traditional media platforms, Networking with researchers working on similar problems in audience measurement and presenting your own research findings","audience":"Mid-DS, Senior-DS"},{"id":"community-arf-marketing-analytics-accelerator-1","type":"community","name":"ARF Marketing Analytics Accelerator","description":"The only event focused exclusively on attribution and marketing mix modeling. Covers MMM methodology, multi-touch attribution, and incrementality measurement.","category":"Conferences","url":"https://thearf.org/","difficulty":"intermediate","prerequisites":"marketing-mix-modeling, attribution-modeling, causal-inference","topic_tags":"marketing-mix-modeling, attribution, incrementality, conferences, marketing-analytics","summary":"A specialized conference focused on attribution and marketing mix modeling (MMM) for marketing analytics professionals. Covers advanced techniques for measuring marketing effectiveness, multi-touch attribution, and incrementality testing. Ideal for data scientists and analysts working on marketing measurement problems in tech companies.","use_cases":"Learning latest MMM methodologies for measuring cross-channel marketing impact, Networking with marketing analytics practitioners to discuss attribution challenges","audience":"Mid-DS, Senior-DS"},{"id":"community-programmatic-i-o","type":"community","name":"Programmatic I/O","description":"World's largest programmatic advertising conference with events in Las Vegas (May) and NYC (September). Covers adtech, programmatic buying, and digital advertising economics.","category":"Conferences","url":"https://www.programmatic.io/","difficulty":"beginner","prerequisites":"digital-marketing-basics, auction-theory","topic_tags":"programmatic-advertising, adtech, marketing-science, conferences, digital-economics","summary":"Programmatic I/O is the world's largest programmatic advertising conference held twice yearly in Las Vegas and NYC. It brings together adtech professionals, data scientists, and researchers working on automated ad buying, real-time bidding, and digital advertising economics. The conference covers cutting-edge developments in programmatic platforms, attribution modeling, and advertising optimization techniques.","use_cases":"Learning about latest adtech platforms and programmatic buying strategies for digital marketing roles, Networking with industry professionals and discovering new tools for ad auction optimization and attribution analysis","audience":"Junior-DS, Curious-browser"},{"id":"community-streaming-media-conference","type":"community","name":"Streaming Media Conference","description":"Covers streaming economics, monetization, and content delivery. Focuses on the business and technology of streaming video platforms.","category":"Conferences","url":"https://www.streamingmedia.com/","difficulty":"intermediate","prerequisites":"basic-statistics, digital-marketing-fundamentals, business-analytics","topic_tags":"streaming-economics, monetization-models, content-delivery, video-platforms, media-business","summary":"Conference focused on the intersection of technology and economics in streaming media platforms. Covers monetization strategies, content delivery optimization, and business models for video streaming services. Valuable for practitioners working on streaming platform economics, content strategy, and media technology business decisions.","use_cases":"A data scientist at Netflix needs to understand industry best practices for content recommendation monetization, A product manager at a streaming startup wants to learn about subscription vs advertising revenue models","audience":"Mid-DS, Curious-browser"},{"id":"community-gdc-festival-of-gaming","type":"community","name":"GDC Festival of Gaming","description":"Game Developers Conference with 30,000 attendees. Strong content on game economics, virtual economy design, monetization analytics, and player behavior analysis.","category":"Conferences","url":"https://gdconf.com/","difficulty":"intermediate","prerequisites":"data-visualization, A-B-testing, cohort-analysis","topic_tags":"game-economics, monetization-analytics, virtual-economies, player-behavior, conference-networking","summary":"The Game Developers Conference is the world's largest professional game industry event with 30,000+ attendees, featuring extensive sessions on game economics and monetization strategies. The conference provides deep insights into virtual economy design, player behavior analytics, and revenue optimization techniques used by major gaming companies. Attendees gain access to cutting-edge research on in-game purchasing patterns, player lifetime value modeling, and behavioral economics applications in gaming.","use_cases":"Learning how mobile game companies optimize their monetization funnels and implement dynamic pricing strategies, Understanding how to design and balance virtual economies in multiplayer games to maximize player engagement and revenue","audience":"Mid-DS, Senior-DS"},{"id":"community-esportsnext","type":"community","name":"EsportsNext","description":"Flagship B2B conference for esports executives covering monetization strategies, digital fan engagement, and esports business models.","category":"Conferences","url":"https://esportsnext.gg/","difficulty":"beginner","prerequisites":"basic-business-strategy, market-research-fundamentals","topic_tags":"esports-business, gaming-monetization, digital-engagement, B2B-conferences, business-strategy","summary":"EsportsNext is a flagship B2B conference focused on esports business strategy, bringing together executives to discuss monetization models, fan engagement tactics, and industry growth opportunities. The conference provides insights into the rapidly evolving esports economy and digital entertainment business models. It's designed for business leaders looking to understand or enter the esports market.","use_cases":"Business development manager researching esports sponsorship opportunities and revenue models, Product manager at gaming company exploring fan engagement strategies and monetization approaches","audience":"Curious-browser, Junior-DS"},{"id":"community-manifest-vegas-(supply-chain)","type":"community","name":"Manifest Vegas (Supply Chain)","description":"Largest global supply chain and logistics tech event with 6,000+ attendees, 1,200+ startups, and 300+ speakers. Covers supply chain analytics, optimization, and logistics technology.","category":"Conferences","url":"https://www.manife.st/","difficulty":"beginner","prerequisites":"basic-analytics, business-operations","topic_tags":"supply-chain, logistics-optimization, networking-events, industry-conference, startup-showcase","summary":"Major annual conference focusing on supply chain and logistics technology with thousands of attendees from startups to enterprise. Features presentations on analytics, optimization methods, and emerging tech solutions in supply chain management. Ideal for networking, learning industry trends, and discovering new tools and vendors.","use_cases":"Learning about new supply chain analytics tools and vendor solutions for implementation at your company, Networking with industry professionals and discovering career opportunities in supply chain tech","audience":"Junior-DS, Curious-browser"},{"id":"community-cscmp-edge","type":"community","name":"CSCMP EDGE","description":"Council of Supply Chain Management Professionals conference covering supply chain analytics and resilience. Features 2,000+ decision-makers and practical applications.","category":"Conferences","url":"https://cscmpconference.org/","difficulty":"beginner","prerequisites":"basic-statistics, excel-spreadsheets","topic_tags":"supply-chain, logistics-optimization, business-analytics, conference, networking","summary":"CSCMP EDGE is a major supply chain management conference bringing together over 2,000 industry practitioners and decision-makers. The event focuses on practical applications of analytics in supply chain operations, resilience strategies, and emerging trends in logistics. It serves as a networking hub for professionals seeking to implement data-driven solutions in supply chain management.","use_cases":"Supply chain analysts attending to learn about new forecasting methods and network optimization tools being adopted by major retailers, Data scientists in logistics companies networking with practitioners to understand real-world constraints and success metrics for supply chain ML models","audience":"Junior-DS, Curious-browser"},{"id":"community-informs-tsl-workshop","type":"community","name":"INFORMS TSL Workshop","description":"INFORMS Transportation Science and Logistics workshop focusing on ML and OR for transportation optimization. Academic-focused with strong methods content.","category":"Conferences","url":"https://connect.informs.org/tsl/","difficulty":"intermediate","prerequisites":"linear-programming, python-scikit-learn, network-optimization","topic_tags":"transportation-optimization, operations-research, machine-learning, supply-chain, academic-conference","summary":"INFORMS Transportation Science and Logistics workshop brings together researchers working on machine learning and operations research applications in transportation optimization. The workshop features academic presentations on cutting-edge methods for routing, logistics, and supply chain problems. Attendees learn about the latest algorithmic advances and theoretical developments in transportation OR.","use_cases":"Learning state-of-the-art methods for vehicle routing and logistics optimization, Networking with academic researchers working on transportation ML/OR problems","audience":"Early-PhD, Senior-DS"},{"id":"community-itc-vegas-(insuretech-connect)","type":"community","name":"ITC Vegas (InsureTech Connect)","description":"Largest insurtech event with 10,000+ attendees and 500+ speakers. Covers AI/data analytics, predictive underwriting, and claims automation in insurance.","category":"Conferences","url":"https://vegas.insuretechconnect.com/","difficulty":"beginner","prerequisites":"insurance-domain-knowledge, basic-analytics","topic_tags":"insurtech, insurance-conferences, predictive-modeling, claims-automation, underwriting-analytics","summary":"ITC Vegas is the premier insurtech conference bringing together 10,000+ industry professionals to explore AI and data analytics applications in insurance. The event features 500+ speakers covering cutting-edge topics like predictive underwriting, automated claims processing, and data-driven risk assessment. It's ideal for data scientists and analysts working in or entering the insurance industry to learn about domain-specific challenges and solutions.","use_cases":"Data scientist at insurance company seeking latest ML techniques for fraud detection and risk modeling, Tech professional exploring career opportunities in insurtech and learning about industry-specific data challenges","audience":"Junior-DS, Curious-browser"},{"id":"community-cas-rpm-seminar","type":"community","name":"CAS RPM Seminar","description":"Casualty Actuarial Society Ratemaking, Product, and Modeling seminar. Premier P&C actuarial conference for pricing and predictive analytics with iCAS Data Science Forum workshops.","category":"Conferences","url":"https://www.casact.org/","difficulty":"intermediate","prerequisites":"generalized-linear-models, actuarial-pricing, python-scikit-learn","topic_tags":"actuarial-science, insurance-pricing, predictive-modeling, property-casualty, ratemaking","summary":"The CAS RPM Seminar is the leading property and casualty insurance conference focused on ratemaking, product development, and predictive modeling. Actuaries and data scientists attend to learn cutting-edge pricing techniques, regulatory approaches, and advanced analytics methods specific to P&C insurance. The event includes the iCAS Data Science Forum with hands-on workshops on modern data science tools for actuarial applications.","use_cases":"Learning modern machine learning techniques for insurance pricing and risk assessment, Networking with P&C actuaries and staying current on regulatory changes affecting ratemaking","audience":"Mid-DS, Senior-DS"},{"id":"community-nrf-retail's-big-show","type":"community","name":"NRF Retail's Big Show","description":"Industry's largest retail event with 40,000+ attendees. Covers retail AI, dynamic pricing, demand forecasting, and consumer analytics.","category":"Conferences","url":"https://nrfbigshow.nrf.com/","difficulty":"beginner","prerequisites":"basic-statistics, business-analytics","topic_tags":"retail-analytics, demand-forecasting, dynamic-pricing, consumer-behavior, industry-conference","summary":"NRF Retail's Big Show is the retail industry's premier conference featuring 40,000+ attendees discussing the latest in retail technology and analytics. The event covers key tech-econ topics including AI applications, dynamic pricing strategies, demand forecasting methods, and consumer analytics. It serves as a networking hub and knowledge exchange for retail professionals, data scientists, and researchers working in the commerce space.","use_cases":"Learning about latest retail AI implementations and pricing algorithms from industry practitioners, Networking with retail data scientists and discovering real-world applications of forecasting models","audience":"Junior-DS, Curious-browser"},{"id":"community-shoptalk-1","type":"community","name":"Shoptalk","description":"Leading retail and e-commerce innovation conference with 10,000+ attendees. Unique matchmaking facilitates 40,000+ one-on-one meetings. Strong analytics and personalization content.","category":"Conferences","url":"https://shoptalk.com/","difficulty":"beginner","prerequisites":"basic-statistics, business-analytics","topic_tags":"retail-analytics, e-commerce, conference-networking, industry-trends, personalization","summary":"Shoptalk is the premier retail and e-commerce conference bringing together 10,000+ industry professionals to discuss innovation and analytics. The conference features extensive content on personalization, customer analytics, and retail technology with unique networking opportunities through structured matchmaking. It serves as a key learning and connection hub for data scientists working in retail and e-commerce domains.","use_cases":"Learning about latest retail analytics trends and personalization techniques from industry leaders, Networking with retail data science teams and discovering new tools and methodologies used in e-commerce","audience":"Junior-DS, Curious-browser"},{"id":"community-groceryshop","type":"community","name":"Groceryshop","description":"Leading grocery and CPG innovation event with 5,000+ attendees. Covers category management, pricing optimization, and consumer analytics in grocery retail.","category":"Conferences","url":"https://groceryshop.com/","difficulty":"beginner","prerequisites":"retail-analytics, basic-statistics","topic_tags":"grocery-retail, pricing-optimization, category-management, consumer-analytics, CPG","summary":"Groceryshop is a major industry conference focused on grocery and CPG innovation, attracting 5,000+ retail professionals. The event covers practical topics like category management, pricing optimization, and consumer analytics specific to grocery retail. It's ideal for data scientists working in retail or CPG companies to learn industry best practices and network with peers.","use_cases":"Learning pricing strategies and demand forecasting techniques specific to grocery retail, Networking with retail analytics professionals and discovering new tools for category management","audience":"Junior-DS, Mid-DS"},{"id":"community-saastr-annual","type":"community","name":"SaaStr Annual","description":"Largest non-vendor SaaS conference with 10,000-13,000 attendees. Covers SaaS metrics, unit economics, churn analysis, and AI applications in SaaS businesses.","category":"Conferences","url":"https://www.saastrannual.com/","difficulty":"beginner","prerequisites":"basic-finance, SaaS-business-models","topic_tags":"SaaS-metrics, unit-economics, churn-analysis, conference, networking","summary":"SaaStr Annual is the largest independent SaaS conference attracting 10,000+ attendees including founders, investors, and data professionals. The event focuses on SaaS business fundamentals like unit economics, churn analysis, and emerging AI applications in subscription businesses. It's particularly valuable for learning industry best practices and networking with SaaS practitioners.","use_cases":"Learning how leading SaaS companies measure and optimize key metrics like LTV, CAC, and churn rates, Networking with SaaS data teams and discovering new tools and methodologies for subscription business analysis","audience":"Junior-DS, Curious-browser"},{"id":"community-gainsight-pulse","type":"community","name":"Gainsight Pulse","description":"Premier customer success conference with 2,500+ attendees. Covers churn prediction, customer health scoring, and retention analytics.","category":"Conferences","url":"https://www.gainsight.com/pulse/","difficulty":"beginner","prerequisites":"basic-statistics, customer-analytics-concepts","topic_tags":"customer-success, churn-prediction, retention-analytics, conferences, networking","summary":"Gainsight Pulse is the premier customer success conference bringing together 2,500+ professionals to learn about churn prediction, customer health scoring, and retention analytics. The conference features talks, workshops, and networking opportunities focused on data-driven customer success strategies. Attendees gain insights into industry best practices and cutting-edge tools for improving customer retention and growth.","use_cases":"Learning industry best practices for implementing churn prediction models in a customer success team, Networking with other professionals working on customer health scoring and retention analytics","audience":"Junior-DS, Mid-DS"},{"id":"community-data-council","type":"community","name":"Data Council","description":"Vendor-neutral data engineering and analytics conference with 1,200-2,000 attendees. Covers data infrastructure, causal inference, and A/B testing practices.","category":"Conferences","url":"https://www.datacouncil.ai/","difficulty":"beginner","prerequisites":"basic-statistics, data-visualization","topic_tags":"data-engineering, ab-testing, causal-inference, analytics-conference, networking","summary":"Data Council is a vendor-neutral conference focusing on practical data engineering and analytics with 1,200-2,000 attendees. The event covers real-world applications of data infrastructure, causal inference methods, and A/B testing best practices. It's designed for practitioners seeking to learn from industry experts and network with peers across different experience levels.","use_cases":"Learning about industry best practices for A/B testing implementation from conference talks, Networking with other data professionals to discuss causal inference challenges and solutions","audience":"Junior-DS, Mid-DS"},{"id":"community-odsc-(open-data-science-conference)","type":"community","name":"ODSC (Open Data Science Conference)","description":"One of the largest data science conferences with ~20,000 annual attendees across East (Boston, May) and West (SF, October) events. Covers ML, AI, and data science applications.","category":"Conferences","url":"https://odsc.com/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"data-science-conferences, machine-learning-events, networking, professional-development, industry-trends","summary":"ODSC is one of the largest data science conferences with approximately 20,000 annual attendees across Boston (May) and San Francisco (October) events. The conference covers machine learning, AI, and data science applications with talks ranging from beginner tutorials to cutting-edge research. It serves as a major networking and learning hub for data science professionals at all career stages.","use_cases":"Learning about latest ML tools and frameworks through hands-on workshops and vendor presentations, Networking with other data scientists and discovering job opportunities in the tech industry","audience":"Junior-DS, Mid-DS"},{"id":"community-wine-(web-and-internet-economics)","type":"community","name":"WINE (Web and Internet Economics)","description":"Conference on algorithmic game theory, revenue management, and learning in markets. Strong overlap between CS theory and economics.","category":"Conferences","url":"http://wine-conference.org/","difficulty":"advanced","prerequisites":"game-theory, mechanism-design, algorithmic-complexity","topic_tags":"algorithmic-game-theory, mechanism-design, revenue-optimization, market-design, conferences","summary":"WINE is a premier academic conference bridging computer science theory and economics, focusing on algorithmic game theory, auction design, and computational market mechanisms. The conference attracts researchers working on theoretical foundations of internet economics, platform design, and automated decision-making in strategic environments. It's essential for understanding cutting-edge work in computational economics and market design.","use_cases":"Designing auction mechanisms for ad exchanges or cloud resource allocation, Developing pricing algorithms for two-sided marketplaces like rideshare or delivery platforms","audience":"Senior-DS, Early-PhD"},{"id":"community-aamas-(autonomous-agents-and-multi-agent-systems)","type":"community","name":"AAMAS (Autonomous Agents and Multi-Agent Systems)","description":"Premier venue for multi-agent systems with Game Theory & Mechanism Design track. Covers agent-based markets, auctions, and strategic behavior.","category":"Conferences","url":"https://aamas2025.org/","difficulty":"intermediate","prerequisites":"game-theory, nash-equilibrium, auction-theory","topic_tags":"multi-agent-systems, mechanism-design, auction-theory, strategic-behavior, conference","summary":"AAMAS is the top-tier academic conference for research on autonomous agents and multi-agent systems, with strong focus on economic applications. The venue features cutting-edge work on auction design, market mechanisms, and strategic interactions between computational agents. Researchers present theoretical foundations and practical implementations of agent-based economic systems.","use_cases":"Finding latest research on auction mechanisms for ad exchanges or spectrum allocation, Learning about strategic behavior modeling for recommendation systems with multiple competing agents","audience":"Senior-DS, Early-PhD"},{"id":"community-datatalks.club","type":"community","name":"DataTalks.Club","description":"Large Slack community (74,000+ members) for data scientists, ML engineers, and analysts. Free courses, weekly events, and active discussions on ML and data engineering.","category":"Online","url":"https://datatalks.club/","difficulty":"beginner","prerequisites":"basic-data-concepts, slack-usage","topic_tags":"community, networking, learning, data-science, slack","summary":"DataTalks.Club is a massive Slack-based community with over 74,000 data professionals including data scientists, ML engineers, and analysts. The community offers free courses, weekly events, and active discussions covering machine learning, data engineering, and career development. It serves as a platform for networking, learning, and staying updated on industry trends and best practices.","use_cases":"Getting career advice and feedback on data science projects from experienced practitioners, Finding study partners for machine learning courses and discussing technical challenges with peers","audience":"Junior-DS, Curious-browser"},{"id":"community-dbt-community","type":"community","name":"dbt Community","description":"Slack community (66,000+ members) for analytics engineers. Discussions on data transformation, SQL best practices, and modern data stack. Global meetup groups.","category":"Online","url":"https://www.getdbt.com/community/","difficulty":"beginner","prerequisites":"SQL-basics, data-modeling-concepts","topic_tags":"dbt, analytics-engineering, data-transformation, sql-best-practices, modern-data-stack","summary":"Active Slack community with 66,000+ analytics engineers discussing dbt (data build tool), SQL optimization, and modern data stack architecture. Members share best practices for data transformation, troubleshoot pipeline issues, and coordinate local meetups globally.","use_cases":"Getting help debugging dbt model compilation errors or Jinja templating issues, Learning SQL best practices and data modeling patterns from experienced analytics engineers","audience":"Junior-DS, Mid-DS"},{"id":"community-economics-discord","type":"community","name":"Economics Discord","description":"Discord community (3,500+ members) run by economics professors and practitioners. Discussions on economic research, econometrics, and policy.","category":"Online","url":"https://discord.gg/economics","difficulty":"beginner","prerequisites":"basic-economics, academic-writing","topic_tags":"economics-community, discord-server, academic-discussion, econometrics, economic-policy","summary":"Large Discord server with 3,500+ economics professionals including professors and practitioners. Provides real-time discussions on economic research, econometric methods, and policy analysis. Serves as a networking and learning platform for economists at all career stages.","use_cases":"Getting quick feedback on research ideas or econometric approaches from experienced economists, Networking with other economics professionals and finding collaborators for research projects","audience":"Early-PhD, Curious-browser"},{"id":"community-locally-optimistic","type":"community","name":"Locally Optimistic","description":"Slack community (8,000+ members) for analytics leaders. Exchange experiences and advice on building data teams, analytics strategy, and career growth.","category":"Online","url":"https://locallyoptimistic.com/community/","difficulty":"beginner","prerequisites":"data-analysis-experience, team-management-basics","topic_tags":"analytics-leadership, data-teams, career-development, slack-community","summary":"Locally Optimistic is a Slack community with over 8,000 analytics professionals focused on leadership and team building. Members share experiences on managing data teams, developing analytics strategies, and advancing their careers. It's particularly valuable for those transitioning into or already in analytics leadership roles.","use_cases":"Getting advice on hiring and structuring a new data science team, Learning how other companies approach analytics strategy and stakeholder management","audience":"Mid-DS, Senior-DS"},{"id":"community-data-science-learning-community","type":"community","name":"Data Science Learning Community","description":"Slack community for data science learners. Weekly book clubs, TidyTuesday projects, and peer support for R, Python, and statistics.","category":"Online","url":"https://dslc.io/","difficulty":"beginner","prerequisites":"basic-r-syntax, basic-python-syntax","topic_tags":"data-science-community, peer-learning, tidytuesday, book-clubs, slack-workspace","summary":"A Slack-based learning community focused on data science skill development through collaborative activities. Members participate in weekly book clubs, work on TidyTuesday data visualization challenges, and provide peer support for R, Python, and statistics questions. The community offers structured learning opportunities and networking for data science practitioners at all levels.","use_cases":"Getting feedback on TidyTuesday visualizations and code from peers, Finding study partners for working through data science textbooks together","audience":"Junior-DS, Curious-browser"},{"id":"community-academic-economics-discord","type":"community","name":"Academic Economics Discord","description":"Discord server (8,400+ members) for discussing econ grad school paths, life in PhD programs, and academic economics careers.","category":"Online","url":"https://discord.gg/academicecon","difficulty":"beginner","prerequisites":"economics-undergraduate, graduate-school-applications","topic_tags":"academic-community, economics-phd, career-networking, discord-community","summary":"A large Discord community of 8,400+ members focused on academic economics career guidance and networking. The server provides a platform for discussing PhD program applications, graduate school experiences, and academic career paths in economics. It serves as a hub for connecting with peers, mentors, and professionals in academic economics.","use_cases":"Getting advice on economics PhD program applications and choosing between programs, Connecting with current PhD students to learn about academic life and research opportunities","audience":"Early-PhD, Curious-browser"},{"id":"community-matteo-courthoud","type":"community","name":"Matteo Courthoud","description":"Zalando Applied Scientist. Weekly posts on causal inference with code \u2014 CUPED, causal forests, AIPW, and more.","category":"Blogs","url":"https://matteocourthoud.github.io/","difficulty":"intermediate","prerequisites":"python-programming, basic-statistics, experimental-design","topic_tags":"causal-inference, experimentation, applied-science, code-tutorials, cuped","summary":"Weekly blog by Zalando Applied Scientist covering practical causal inference methods with Python implementations. Posts include hands-on tutorials for techniques like CUPED, causal forests, and AIPW with real code examples. Ideal for practitioners wanting to learn modern causal inference methods through applied examples.","use_cases":"Learning to implement causal inference methods like CUPED for your A/B tests, Understanding how to apply causal forests in practice with code examples","audience":"Mid-DS, Junior-DS"},{"id":"community-apoorva-lal","type":"community","name":"Apoorva Lal","description":"Amazon/Netflix researcher. Causal inference notes, pyfixest maintainer, clean Python implementations of econometric methods.","category":"Blogs","url":"https://apoorvalal.github.io/","difficulty":"intermediate","prerequisites":"python-pandas, difference-in-differences, fixed-effects-regression","topic_tags":"causal-inference, econometrics, python-implementations, pyfixest, personal-blog","summary":"Personal blog by Apoorva Lal, a researcher at Amazon/Netflix, featuring detailed notes on causal inference methods and clean Python implementations of econometric techniques. He maintains pyfixest, a Python package for fixed effects estimation, and shares practical code examples for applying econometric methods in tech settings.","use_cases":"Learning how to implement difference-in-differences or fixed effects models in Python for A/B testing, Finding clean code examples for causal inference methods when transitioning from R to Python","audience":"Junior-DS, Mid-DS"},{"id":"community-nick-huntington-klein","type":"community","name":"Nick Huntington-Klein","description":"'The Effect' author. Animated causal inference plots, Library of Statistical Techniques founder.","category":"Blogs","url":"https://nickchk.com/","difficulty":"beginner","prerequisites":"basic-statistics, causal-inference-concepts","topic_tags":"causal-inference, econometrics, educational-content, statistical-techniques, data-visualization","summary":"Nick Huntington-Klein's personal blog and educational content, featuring animated visualizations of causal inference concepts and founding the Library of Statistical Techniques. He's the author of 'The Effect', a popular causal inference textbook, and creates accessible explanations of econometric methods through interactive plots and clear writing.","use_cases":"Learning causal inference fundamentals through visual explanations and animated examples, Finding accessible explanations of statistical techniques for academic or industry applications","audience":"Early-PhD, Junior-DS"},{"id":"community-scott-cunningham","type":"community","name":"Scott Cunningham","description":"'Causal Inference: The Mixtape' author. Substack on causal inference, Mixtape Sessions workshops.","category":"Blogs","url":"https://causalinf.substack.com/","difficulty":"beginner","prerequisites":"basic-statistics, regression-analysis","topic_tags":"causal-inference, difference-in-differences, instrumental-variables, econometrics, personal-blog","summary":"Scott Cunningham is the author of 'Causal Inference: The Mixtape' and runs popular Mixtape Sessions workshops teaching causal inference methods. His blog and Substack provide accessible explanations of causal inference techniques with practical examples and intuitive explanations. The content bridges academic rigor with practical implementation for data scientists and economists.","use_cases":"Learning causal inference fundamentals through clear explanations and examples, Following up on Mixtape Sessions workshops with additional resources and discussions","audience":"Early-PhD, Junior-DS"},{"id":"community-andrew-gelman","type":"community","name":"Andrew Gelman","description":"Columbia statistician. 20 years of blogging on Bayesian stats, causal inference, and social science methodology.","category":"Blogs","url":"https://statmodeling.substack.com/","difficulty":"intermediate","prerequisites":"basic-statistics, regression-analysis, bayesian-concepts","topic_tags":"bayesian-statistics, causal-inference, statistical-methodology, social-science, research-critique","summary":"Andrew Gelman's influential blog covering Bayesian statistics, causal inference, and research methodology with a focus on social science applications. Known for thoughtful critiques of statistical practices, discussion of modeling decisions, and accessible explanations of complex statistical concepts. Essential reading for anyone working with observational data or conducting statistical research.","use_cases":"Learning about common pitfalls in statistical analysis and research design, Understanding best practices for Bayesian modeling and causal inference in social science contexts","audience":"Early-PhD, Mid-DS"},{"id":"community-james-brand","type":"community","name":"James Brand","description":"Microsoft researcher. Demand estimation, cloud pricing, Julia packages for IO.","category":"Blogs","url":"https://www.jamesbrandecon.com/","difficulty":"intermediate","prerequisites":"demand-estimation, julia-programming, industrial-organization","topic_tags":"demand-estimation, cloud-pricing, julia-packages, industrial-organization, microsoft-research","summary":"James Brand is a Microsoft researcher specializing in demand estimation and cloud pricing strategies. His work focuses on industrial organization economics with practical applications in tech pricing. He develops Julia packages for IO research and shares insights on pricing models in cloud computing.","use_cases":"Learning about demand estimation methods for cloud services pricing, Finding Julia implementations of industrial organization econometric models","audience":"Mid-DS, Senior-DS"},{"id":"community-eugene-yan","type":"community","name":"Eugene Yan","description":"Principal Applied Scientist at Amazon. RecSys, LLMs, and ML systems. Author of applied-llms.org and applyingml.com. Prolific writer on building ML products at scale.","category":"Blogs","url":"https://eugeneyan.com/","difficulty":"intermediate","prerequisites":"python-scikit-learn, A-B-testing, system-design","topic_tags":"machine-learning-systems, recommendation-systems, large-language-models, ml-engineering, applied-ml","summary":"Eugene Yan is a Principal Applied Scientist at Amazon who writes extensively about building and scaling ML systems in production. His blog covers practical aspects of recommendation systems, LLMs, and ML engineering with real-world examples from tech companies. He's known for bridging the gap between ML research and production implementation.","use_cases":"Learning how to transition ML models from research to production systems, Understanding best practices for building recommendation systems at scale","audience":"Mid-DS, Senior-DS"},{"id":"community-paul-goldsmith-pinkham","type":"community","name":"Paul Goldsmith-Pinkham","description":"Yale researcher. 'A Causal Affair' substack with Reader's Digest breakdowns of Econometrica papers. Accessible yet rigorous causal inference.","category":"Blogs","url":"https://paulgp.substack.com/","difficulty":"intermediate","prerequisites":"basic-econometrics, causal-inference, regression-analysis","topic_tags":"causal-inference, econometrics, academic-blog, research-digest","summary":"Paul Goldsmith-Pinkham's 'A Causal Affair' substack provides accessible breakdowns of complex econometrics papers from top journals like Econometrica. The Yale researcher translates rigorous causal inference research into digestible explanations while maintaining technical accuracy. Perfect for staying current with cutting-edge methods without drowning in mathematical proofs.","use_cases":"Learning about new causal inference methods from recent academic papers without reading full technical papers, Understanding how top econometricians approach identification strategies in published research","audience":"Mid-DS, Early-PhD"},{"id":"community-sean-j.-taylor","type":"community","name":"Sean J. Taylor","description":"Ex-Lyft/Facebook DS lead. Co-creator of Prophet. Writes on causal inference in tech, experimentation, and 'when do we actually need causal inference?'","category":"Blogs","url":"https://seanjtaylor.com/","difficulty":"intermediate","prerequisites":"a-b-testing, regression-analysis, causal-inference","topic_tags":"causal-inference, experimentation, tech-industry, prophet-forecasting, personal-blog","summary":"Sean J. Taylor's personal blog features insights from his experience as a data science leader at major tech companies. He writes extensively about practical causal inference applications, experimental design challenges, and forecasting methods including his co-creation Prophet. The blog bridges academic rigor with real-world tech industry problems.","use_cases":"Learning when causal inference is actually needed vs overkill for business problems, Understanding how experimentation works at scale in ride-sharing and social media companies","audience":"Mid-DS, Senior-DS"},{"id":"community-francis-ditraglia","type":"community","name":"Francis DiTraglia","description":"Oxford econometrician. Frank, educational posts on statistical pitfalls, instrumental variables, and how to read econometrics papers.","category":"Blogs","url":"https://www.econometrics.blog/","difficulty":"intermediate","prerequisites":"linear-regression, instrumental-variables, statistical-inference","topic_tags":"econometrics, causal-inference, statistical-pitfalls, educational-content","summary":"Francis DiTraglia's blog provides clear, educational explanations of econometric concepts and common statistical pitfalls. An Oxford econometrician, he writes accessible posts about instrumental variables, how to properly read econometrics papers, and methodological issues that practitioners encounter. His content bridges the gap between theoretical econometrics and practical application.","use_cases":"Learning how to avoid common mistakes when implementing instrumental variables in empirical research, Understanding how to critically evaluate econometric papers and identify potential methodological issues","audience":"Early-PhD, Junior-DS"},{"id":"community-andrew-heiss","type":"community","name":"Andrew Heiss","description":"Master of R/Tidyverse explainers. Demystifying series on ATE vs ATT, DAGs, Bayesian priors. Clear code examples for causal inference.","category":"Blogs","url":"https://www.andrewheiss.com/","difficulty":"beginner","prerequisites":"r-programming, basic-statistics, ggplot2","topic_tags":"causal-inference, r-tidyverse, dags, ate-att, bayesian-methods","summary":"Andrew Heiss is a renowned educator who creates exceptionally clear explanations of causal inference concepts using R and the Tidyverse. His blog features comprehensive tutorials on complex topics like DAGs, treatment effects, and Bayesian methods with practical R code examples. Perfect for data scientists wanting to understand causal inference through hands-on implementation.","use_cases":"Learning how to implement difference-in-differences analysis in R with real data examples, Understanding the difference between ATE and ATT through step-by-step R code walkthroughs","audience":"Junior-DS, Early-PhD"},{"id":"community-david-mckenzie","type":"community","name":"David McKenzie","description":"World Bank researcher. Legendary methodology posts on randomization, power calculations, and missing data \u2014 directly applicable to A/B testing.","category":"Blogs","url":"https://blogs.worldbank.org/en/team/d/david-mckenzie","difficulty":"intermediate","prerequisites":"hypothesis-testing, randomized-experiments, statistical-power","topic_tags":"randomization, experimental-design, power-calculations, missing-data, a-b-testing","summary":"David McKenzie is a World Bank researcher whose blog provides practical methodology guidance for running experiments and analyzing data. His posts cover essential topics like randomization techniques, power calculations, and handling missing data that directly translate to industry A/B testing. The content bridges academic rigor with real-world application.","use_cases":"Learning proper randomization methods for A/B testing platform experiments, Understanding how to calculate statistical power before launching product experiments","audience":"Junior-DS, Mid-DS"},{"id":"community-marc-bellemare","type":"community","name":"Marc Bellemare","description":"'Metrics Monday archive. Applied econometrics advice on standard errors, weak instruments, and practical research design.","category":"Blogs","url":"https://marcfbellemare.com/wordpress/","difficulty":"intermediate","prerequisites":"linear-regression, hypothesis-testing, econometrics-basics","topic_tags":"applied-econometrics, research-design, causal-inference, standard-errors","summary":"Marc Bellemare's Metrics Monday archive provides practical applied econometrics advice covering standard errors, weak instruments, and research design issues. The blog offers accessible explanations of common econometric problems that researchers encounter in practice. It's particularly valuable for those implementing econometric methods and needing guidance on best practices.","use_cases":"Debugging econometric models with problematic standard errors or weak instruments, Learning proper research design techniques for causal inference studies","audience":"Early-PhD, Mid-DS"},{"id":"community-matheus-facure","type":"community","name":"Matheus Facure","description":"'Causal Inference for the Brave and True' author. The primary bridge between econometric theory and Python production code. DML, uplift modeling, and synthetic controls implemented.","category":"Blogs","url":"https://matheusfacure.github.io/","difficulty":"intermediate","prerequisites":"python-pandas, linear-regression, econometrics-basics","topic_tags":"causal-inference, python-implementation, econometrics, uplift-modeling, synthetic-controls","summary":"Matheus Facure's blog bridges the gap between econometric theory and practical Python implementation for causal inference. Author of 'Causal Inference for the Brave and True', he provides accessible explanations and code for advanced methods like DML, uplift modeling, and synthetic controls. Essential resource for data scientists wanting to move beyond correlation to causation in their analyses.","use_cases":"Learning how to implement double machine learning for treatment effect estimation in Python, Finding practical code examples for synthetic control methods to evaluate policy interventions","audience":"Junior-DS, Mid-DS"},{"id":"community-aleksander-molak","type":"community","name":"Aleksander Molak","description":"Causal Discovery specialist. When you need to discover the causal graph from data (not assume it). DoWhy, CausalPy, and Bayesian networks.","category":"Blogs","url":"https://aleksander-molak.medium.com/","difficulty":"intermediate","prerequisites":"python-programming, basic-statistics, networkx-or-graph-theory","topic_tags":"causal-discovery, causal-inference, bayesian-networks, dowhy, causalpy","summary":"Aleksander Molak specializes in causal discovery methods for inferring causal structures directly from observational data rather than assuming them. His work focuses on practical applications of tools like DoWhy and CausalPy for discovering causal graphs and relationships. This resource is valuable for data scientists who need to move beyond correlation to understand actual causal mechanisms in their data.","use_cases":"Discovering which user actions causally drive product engagement when you don't know the causal structure beforehand, Inferring causal relationships between business metrics to prioritize which levers to pull for maximum impact","audience":"Mid-DS, Senior-DS"},{"id":"community-juan-camilo-orduz","type":"community","name":"Juan Camilo Orduz","description":"Applied Scientist. Bayesian stats, PyMC, and geo-experimentation. Solves business problems (marketing attribution, geo-lift) with heavy-duty Bayesian math.","category":"Blogs","url":"https://juanitorduz.github.io/","difficulty":"intermediate","prerequisites":"python-programming, bayesian-statistics, PyMC","topic_tags":"bayesian-statistics, geo-experimentation, marketing-attribution, PyMC, causal-inference","summary":"Personal blog by Juan Camilo Orduz covering applied Bayesian statistics with PyMC for solving business problems. Focuses on practical implementations of geo-experimentation, marketing attribution, and causal inference methods. Provides code examples and mathematical explanations for real-world applications.","use_cases":"Measuring the causal impact of marketing campaigns using geo-lift experiments, Building Bayesian models for multi-touch attribution in digital marketing","audience":"Mid-DS, Senior-DS"},{"id":"community-alex-deng","type":"community","name":"Alex Deng","description":"Co-author 'Trustworthy Online Controlled Experiments'. Deep A/B testing statistics \u2014 variance reduction, sequential testing, stopping rules without p-hacking.","category":"Blogs","url":"https://alexdeng.github.io/","difficulty":"intermediate","prerequisites":"hypothesis-testing, confidence-intervals, experimental-design","topic_tags":"a-b-testing, experimental-design, causal-inference, variance-reduction, sequential-testing","summary":"Alex Deng is co-author of 'Trustworthy Online Controlled Experiments' and expert in A/B testing statistics. His work focuses on advanced experimental methods including variance reduction techniques, sequential testing, and proper stopping rules that avoid p-hacking. Essential resource for practitioners running rigorous online experiments.","use_cases":"Learning proper statistical methods for running A/B tests without inflating Type I error, Implementing variance reduction techniques like CUPED to improve experiment sensitivity","audience":"Mid-DS, Senior-DS"},{"id":"community-christoph-molnar","type":"community","name":"Christoph Molnar","description":"'Interpretable Machine Learning' author. Opens black-box models to understand feature importance (Shapley values) \u2014 the ML equivalent of regression coefficients.","category":"Blogs","url":"https://christophm.github.io/","difficulty":"intermediate","prerequisites":"python-scikit-learn, SHAP-library, model-evaluation","topic_tags":"interpretable-ML, SHAP, model-explainability, feature-importance, black-box-models","summary":"Christoph Molnar's blog focuses on making machine learning models interpretable and explainable. He's the author of 'Interpretable Machine Learning' and covers techniques like SHAP values, permutation importance, and other methods to understand what drives model predictions. His content bridges the gap between complex ML algorithms and practical model interpretation for business stakeholders.","use_cases":"Explaining model predictions to business stakeholders who need to understand why certain customers were flagged for churn, Debugging model performance by identifying which features are driving unexpected predictions in production","audience":"Mid-DS, Junior-DS"},{"id":"community-nathan-lambert","type":"community","name":"Nathan Lambert","description":"Interconnects. The primary chronicler of RLHF. RLHF as mechanism design for AI: eliciting preferences and training reward models.","category":"Blogs","url":"https://www.interconnects.ai/","difficulty":"intermediate","prerequisites":"reinforcement-learning, pytorch-transformers, preference-learning","topic_tags":"RLHF, preference-learning, AI-alignment, reward-modeling, mechanism-design","summary":"Nathan Lambert's blog chronicles the development and application of Reinforcement Learning from Human Feedback (RLHF). He provides deep insights into how RLHF works as a mechanism design problem for AI systems, focusing on eliciting human preferences and training reward models. The blog is essential reading for understanding the theoretical foundations and practical implementation of preference-based AI training.","use_cases":"Understanding the latest developments in RLHF for implementing human preference alignment in AI systems, Learning about mechanism design approaches to training reward models from human feedback","audience":"Mid-DS, Senior-DS"},{"id":"community-andrej-karpathy","type":"community","name":"Andrej Karpathy","description":"Neural nets from scratch, LLMs as operating systems. Explains the intuition of optimization landscapes, not just how to write code.","category":"Blogs","url":"https://karpathy.ai/","difficulty":"intermediate","prerequisites":"python-basics, linear-algebra, backpropagation","topic_tags":"neural-networks, deep-learning, LLMs, optimization, educational-content","summary":"Andrej Karpathy's blog provides intuitive explanations of neural networks and deep learning concepts, focusing on building understanding from first principles. He covers topics from basic neural nets to large language models, emphasizing the mathematical intuition behind optimization and model behavior. Popular among practitioners who want to understand not just how to implement models, but why they work.","use_cases":"Learning how neural networks actually work under the hood before using high-level frameworks, Understanding the mathematical foundations of LLMs and transformer architectures","audience":"Junior-DS, Mid-DS"},{"id":"community-lilian-weng","type":"community","name":"Lilian Weng","description":"Lil'Log. OpenAI Safety Systems lead. The single best technical summaries on DL, agents, and RL. Often cited as primary sources in papers.","category":"Blogs","url":"https://lilianweng.github.io/","difficulty":"intermediate","prerequisites":"pytorch-basics, neural-networks, reinforcement-learning","topic_tags":"deep-learning, reinforcement-learning, ai-agents, technical-blog, research-summaries","summary":"Lilian Weng's technical blog providing comprehensive, well-researched explanations of cutting-edge AI topics including deep learning, reinforcement learning, and AI agents. Her posts are frequently cited in academic papers and serve as go-to references for understanding complex AI concepts with clear mathematical explanations and practical insights.","use_cases":"Understanding latest RL algorithms before implementing them in research, Getting accessible explanations of complex AI papers for literature reviews","audience":"Mid-DS, Senior-DS"},{"id":"community-sebastian-raschka","type":"community","name":"Sebastian Raschka","description":"Ahead of AI. PyTorch, LLM training, efficient finetuning (LoRA). Bridges academic papers and 'will this run on my GPU?' practicality.","category":"Blogs","url":"https://magazine.sebastianraschka.com/","difficulty":"intermediate","prerequisites":"pytorch-basics, python-transformers, gpu-programming","topic_tags":"pytorch, llm-training, lora-finetuning, deep-learning, practical-ai","summary":"Sebastian Raschka's blog provides practical deep learning insights, focusing on PyTorch implementations and efficient LLM training techniques like LoRA. He translates cutting-edge research papers into actionable guidance for practitioners working with real GPU constraints and production systems.","use_cases":"Learning how to implement LoRA fine-tuning for large language models within GPU memory limits, Understanding practical PyTorch optimization techniques for training efficiency and model deployment","audience":"Mid-DS, Junior-DS"},{"id":"community-tor-lattimore","type":"community","name":"Tor Lattimore","description":"DeepMind. The definitive resource on bandit algorithms. Essential for pricing, dynamic allocation, and experimentation.","category":"Blogs","url":"https://tor-lattimore.com/","difficulty":"intermediate","prerequisites":"probability-theory, python-programming, statistical-inference","topic_tags":"bandit-algorithms, reinforcement-learning, experimentation, dynamic-allocation, pricing","summary":"Tor Lattimore's blog provides authoritative insights into bandit algorithms and multi-armed bandit problems from a DeepMind researcher. The content covers theoretical foundations and practical applications of bandit methods for dynamic decision-making problems. Essential reading for anyone implementing adaptive experimentation, dynamic pricing, or resource allocation systems.","use_cases":"Implementing multi-armed bandit tests for website optimization instead of traditional A/B tests, Building dynamic pricing algorithms that learn optimal prices through exploration and exploitation","audience":"Mid-DS, Senior-DS"},{"id":"community-pranjal-rawat","type":"community","name":"Pranjal Rawat","description":"applied researcher. Posts on applied research, causal inference, and data science in industry.","category":"Blogs","url":"https://pranjalrawat42.substack.com/","difficulty":"intermediate","prerequisites":"python-programming, causal-inference-basics, A/B-testing","topic_tags":"applied-research, causal-inference, industry-data-science, personal-blog","summary":"Personal blog by Pranjal Rawat covering applied research methods, causal inference techniques, and data science practices in industry settings. Focuses on bridging academic methods with real-world implementation challenges. Valuable resource for practitioners looking to apply rigorous analytical methods in business contexts.","use_cases":"Learning how to implement causal inference methods in industry settings, Finding practical guidance on running experiments and analyzing results in tech companies","audience":"Junior-DS, Mid-DS"},{"id":"community-deepak-singh","type":"community","name":"Deepak Singh","description":"Founder of pmcurve.com. Ex-Flipkart, Unacademy. Product management, growth, AI for PMs, and vibe-coding.","category":"Blogs","url":"https://www.pmcurve.com/","difficulty":"beginner","prerequisites":"product-management-basics, SQL-queries","topic_tags":"product-management, growth-hacking, AI-for-product, startup-strategy","summary":"Personal blog by Deepak Singh covering product management insights, growth strategies, and AI applications for PMs based on experience at Indian tech companies like Flipkart and Unacademy. Offers practical advice on product strategy, user growth, and incorporating AI into product workflows. Targets product managers and aspiring PMs looking for real-world case studies and actionable frameworks.","use_cases":"Learning product management best practices and growth strategies from experienced Indian tech company PM, Understanding how to integrate AI tools and methodologies into product management workflows","audience":"Junior-DS, Curious-browser"},{"id":"community-casey-winters","type":"community","name":"Casey Winters","description":"Ex-Greylock, Pinterest, Eventbrite growth leader. Writes on AI, marketplaces, growth strategy, and product.","category":"Blogs","url":"https://www.caseyaccidental.com/","difficulty":"intermediate","prerequisites":"product-analytics, growth-metrics, A-B-testing","topic_tags":"growth-strategy, marketplace-dynamics, product-management, AI-strategy, blog","summary":"Casey Winters is a prominent growth strategist and former executive at Greylock, Pinterest, and Eventbrite who writes extensively about growth strategy, marketplace dynamics, AI applications, and product development. His blog provides practical insights on scaling tech products, growth experimentation, and strategic decision-making for consumer and B2B platforms. The content bridges strategic thinking with tactical execution, making complex growth concepts accessible to practitioners.","use_cases":"Understanding marketplace network effects and two-sided platform growth strategies, Learning AI implementation strategies for product and growth teams","audience":"Mid-DS, Senior-DS"},{"id":"community-yuzheng-sun-(\u8bfe\u4ee3\u8868\u7acb\u6b63)","type":"community","name":"Yuzheng Sun (\u8bfe\u4ee3\u8868\u7acb\u6b63)","description":"Superlinear Academy founder. Ex-Statsig Evangelist, ex-Tencent VP, PhD Cornell. Growth analytics, A/B testing, and AI. Co-author 'Growth Data Analytics Playbook' (WSJ CIO Journal featured).","category":"Blogs","url":"https://yuzheng.substack.com/","difficulty":"intermediate","prerequisites":"A/B-testing, python-pandas, SQL-queries","topic_tags":"growth-analytics, A/B-testing, experimentation, blog, substack","summary":"Yuzheng Sun's blog covers growth analytics, A/B testing, and AI applications from a practitioner's perspective. As founder of Superlinear Academy and co-author of the 'Growth Data Analytics Playbook', he shares insights from his experience at Statsig and Tencent. The content bridges academic rigor with industry practice in experimentation and growth measurement.","use_cases":"Learning best practices for running A/B tests and growth experiments at tech companies, Understanding advanced growth analytics techniques and their real-world applications","audience":"Mid-DS, Junior-DS"},{"id":"community-jed-kolko","type":"community","name":"Jed Kolko","description":"Senior Fellow at Peterson Institute; Senior Advisor at JPMC Institute. Former Chief Economist at Indeed and Trulia. Labor market analytics, housing economics, and economic data interpretation.","category":"Blogs","url":"https://jedkolko.substack.com/","difficulty":"beginner","prerequisites":"basic-economics, data-visualization","topic_tags":"labor-economics, housing-market, economic-commentary, data-interpretation, policy-analysis","summary":"Jed Kolko is a prominent economist who writes accessible analysis on labor markets, housing economics, and economic data interpretation. His work bridges academic research and practical industry insights from roles at Indeed, Trulia, and major financial institutions. His writing helps readers understand complex economic trends through clear data storytelling and real-world applications.","use_cases":"Understanding how to interpret monthly jobs reports and labor market indicators, Learning how housing market data connects to broader economic trends","audience":"Curious-browser, Junior-DS"},{"id":"community-arpit-gupta","type":"community","name":"Arpit Gupta","description":"Associate Professor of Finance at NYU Stern. Finance, real estate economics, housing affordability, and fintech analysis. Bridges academic research with accessible policy commentary.","category":"Blogs","url":"https://arpitrage.substack.com/","difficulty":"beginner","prerequisites":"basic-economics, financial-markets-knowledge","topic_tags":"finance, real-estate, housing-policy, fintech, economic-commentary","summary":"Arpit Gupta is an Associate Professor of Finance at NYU Stern who writes accessible content bridging academic finance research with practical policy analysis. His work focuses on real estate economics, housing affordability, and fintech, making complex financial concepts understandable for broader audiences. Great resource for understanding how academic finance research applies to real-world housing and financial technology issues.","use_cases":"Understanding housing market trends and affordability challenges for policy analysis, Learning how academic finance research translates to fintech industry applications","audience":"Curious-browser, Junior-DS"},{"id":"community-leo-saenger","type":"community","name":"Leo Saenger","description":"Economist with hedge fund background focusing on commercial real estate and ML applications. Harvard economics. Market design, CRE dynamics, and macroeconomic forecasting evaluation.","category":"Blogs","url":"https://saenger.substack.com/","difficulty":"intermediate","prerequisites":"econometrics-fundamentals, python-pandas, time-series-analysis","topic_tags":"commercial-real-estate, market-design, macroeconomic-forecasting, hedge-fund-analysis, ML-economics","summary":"Leo Saenger is an economist with hedge fund experience who writes about commercial real estate markets, market design, and macroeconomic forecasting through an ML lens. His content bridges traditional economics with modern data science applications, particularly in real estate and financial markets. Readers can access insights on CRE market dynamics, forecasting methodologies, and practical applications of economic theory in finance.","use_cases":"Understanding how ML techniques apply to commercial real estate valuation and market analysis, Learning about macroeconomic forecasting methods used in hedge fund and investment contexts","audience":"Mid-DS, Senior-DS"},{"id":"community-emily-glassberg-sands","type":"community","name":"Emily Glassberg Sands","description":"Head of Information at Stripe. Harvard Economics PhD, former Head of Data Science at Coursera. Teconomics Blog on applied causal inference in tech settings, A/B testing methodology.","category":"Blogs","url":"https://medium.com/teconomics-blog","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference, python-pandas","topic_tags":"causal-inference, A-B-testing, fintech, experimentation, applied-economics","summary":"Emily Glassberg Sands is Head of Information at Stripe with a Harvard Economics PhD and former Head of Data Science at Coursera. Her Teconomics Blog focuses on applied causal inference in tech settings and A/B testing methodology. The blog provides practical insights on experimental design and causal analysis for tech companies.","use_cases":"Learning how to design and analyze A/B tests at scale in fintech environments, Understanding causal inference methods applied to real-world tech product decisions","audience":"Mid-DS, Junior-DS"},{"id":"community-michael-luca","type":"community","name":"Michael Luca","description":"Professor and Director of Technology and Society Initiative at Johns Hopkins Carey Business School. Platform design, online marketplace mechanisms, experimentation methodology. Co-authored 'The Power of Experiments.'","category":"Blogs","url":"https://hbr.org/search?search_type=search-all&term=michael+luca","difficulty":"intermediate","prerequisites":"A-B-testing, causal-inference, python-pandas","topic_tags":"platform-design, marketplace-economics, experimentation, digital-platforms, causal-methods","summary":"Michael Luca is a Professor at Johns Hopkins Carey Business School specializing in platform design, online marketplace mechanisms, and experimentation methodology. His blog covers insights on digital platform economics, A/B testing best practices, and causal inference applications in tech companies. He co-authored 'The Power of Experiments' and regularly writes about experimental design for practitioners.","use_cases":"Learning best practices for designing experiments in marketplace settings, Understanding economic principles behind platform design decisions","audience":"Mid-DS, Senior-DS"},{"id":"community-lenny-rachitsky","type":"community","name":"Lenny Rachitsky","description":"Former Growth PM Lead at Airbnb (7 years). Marketplace economics, supply-demand dynamics, platform growth mechanics. Multi-part series on kickstarting and scaling marketplace businesses. 700,000+ subscribers.","category":"Blogs","url":"https://www.lennysnewsletter.com/","difficulty":"beginner","prerequisites":"basic-economics, product-management-fundamentals","topic_tags":"marketplace-economics, platform-growth, supply-demand, product-strategy, growth-pm","summary":"Lenny Rachitsky's newsletter draws from 7 years leading growth at Airbnb to teach marketplace economics and platform growth mechanics. He provides practical frameworks for understanding supply-demand dynamics and scaling platform businesses. With 700,000+ subscribers, his multi-part series offer accessible insights into building and growing marketplace products.","use_cases":"Learning how to kickstart a two-sided marketplace from zero supply and demand, Understanding growth strategies for scaling platform businesses like rideshare or delivery apps","audience":"Junior-DS, Curious-browser"},{"id":"community-elena-verna","type":"community","name":"Elena Verna","description":"Head of Growth at Dropbox; formerly SVP Growth at SurveyMonkey, Miro, Amplitude. Monetization strategy, pricing optimization, and growth economics. Created Reforge's Monetization & Pricing course. 79,000+ subscribers.","category":"Blogs","url":"https://www.elenaverna.com/","difficulty":"intermediate","prerequisites":"funnel-analysis, cohort-analysis, pricing-models","topic_tags":"growth-economics, monetization, pricing-optimization, growth-strategy, personal-blog","summary":"Elena Verna's personal blog featuring insights on growth economics, monetization strategy, and pricing optimization from her leadership roles at major tech companies. Covers practical frameworks for growth experimentation, user acquisition economics, and revenue optimization. Content draws from real-world experience scaling products at Dropbox, SurveyMonkey, Miro, and Amplitude.","use_cases":"Learning growth economics frameworks for optimizing user acquisition costs and lifetime value, Understanding monetization strategies and pricing models used by successful SaaS companies","audience":"Mid-DS, Senior-DS"},{"id":"community-sangeet-paul-choudary","type":"community","name":"Sangeet Paul Choudary","description":"Founder of Platform Thinking Labs. Platform economics, network effects mechanics, BigTech competitive strategy. Author of 'Platform Revolution' and 'Platform Scale'. 40,000+ subscribers.","category":"Blogs","url":"https://platforms.substack.com/","difficulty":"intermediate","prerequisites":"basic-economics, network-theory, competitive-strategy","topic_tags":"platform-economics, network-effects, competitive-strategy, business-models, two-sided-markets","summary":"Sangeet Paul Choudary is a leading expert on platform economics and network effects, providing strategic insights into how digital platforms create and capture value. His work focuses on the competitive dynamics of BigTech companies and the mechanics of network effects in platform businesses. The content is valuable for understanding platform business models and their economic implications.","use_cases":"Understanding how to analyze network effects in marketplace businesses, Developing competitive strategy against platform incumbents like Amazon or Google","audience":"Mid-DS, Senior-DS"},{"id":"community-dan-hockenmaier","type":"community","name":"Dan Hockenmaier","description":"Head of Strategy and Analytics at Faire; formerly Director of Growth at Thumbtack. Marketplace strategy, pricing economics, growth modeling, and unit economics optimization. Reforge Partner.","category":"Blogs","url":"https://www.danhock.com/","difficulty":"intermediate","prerequisites":"SQL-joins, A-B-testing, cohort-analysis","topic_tags":"marketplace-strategy, growth-analytics, pricing-economics, unit-economics","summary":"Dan Hockenmaier is Head of Strategy and Analytics at Faire with extensive experience in marketplace strategy and growth modeling at companies like Thumbtack. His blog covers practical approaches to pricing economics, unit economics optimization, and growth analytics in marketplace and platform businesses. Content targets practitioners working on marketplace dynamics and growth strategy implementation.","use_cases":"Learning how to optimize unit economics and pricing strategies for marketplace platforms, Understanding growth modeling techniques used at successful marketplace companies like Thumbtack and Faire","audience":"Mid-DS, Senior-DS"},{"id":"community-adam-fishman","type":"community","name":"Adam Fishman","description":"Executive-in-Residence at Reforge; formerly CPO at Imperfect Foods, VP Product/Growth at Patreon and Lyft. Growth strategy, monetization friction analysis, and conversion optimization. 19,000+ subscribers.","category":"Blogs","url":"https://www.fishmanafnewsletter.com/","difficulty":"beginner","prerequisites":"product-analytics, A-B-testing, conversion-funnels","topic_tags":"product-growth, monetization, conversion-optimization, growth-strategy, substack-blog","summary":"Adam Fishman's blog covers practical product growth strategies and monetization tactics from his experience as CPO and VP roles at major tech companies. The content focuses on reducing friction in user conversion flows and optimizing growth strategies with real-world examples. With 19,000+ subscribers, it provides accessible insights for product teams working on growth challenges.","use_cases":"Learning how to reduce checkout friction and improve conversion rates for an e-commerce product, Understanding monetization strategies and pricing optimization for subscription-based products","audience":"Junior-DS, Mid-DS"},{"id":"community-kevin-kwok","type":"community","name":"Kevin Kwok","description":"Partner at Sutter Hill Ventures; formerly investor at Greylock Partners. Platform economics analysis, network effects mechanics, and growth loops. Famous essays include 'Why Figma Wins.'","category":"Blogs","url":"https://kwokchain.com/","difficulty":"intermediate","prerequisites":"basic-economics, product-metrics, market-analysis","topic_tags":"platform-economics, network-effects, venture-capital, product-strategy, growth-analysis","summary":"Kevin Kwok's blog features deep dives into platform economics, network effects, and product strategy from a VC perspective. He analyzes how tech companies build sustainable competitive advantages through network effects and platform dynamics. His essays like 'Why Figma Wins' are widely referenced for understanding product-market fit and competitive positioning.","use_cases":"Understanding how network effects create defensible moats for tech products, Analyzing competitive dynamics and growth strategies in platform businesses","audience":"Mid-DS, Curious-browser"},{"id":"community-mike-shields","type":"community","name":"Mike Shields","description":"Former journalist at Business Insider, WSJ, AdWeek. Ad tech economics, auction dynamics, programmatic advertising mechanics, and CTV advertising economics.","category":"Blogs","url":"https://mikeshields.substack.com/","difficulty":"intermediate","prerequisites":"auction-theory, programmatic-advertising, digital-marketing-metrics","topic_tags":"ad-tech, programmatic-advertising, auction-dynamics, ctv-economics, journalism","summary":"Mike Shields' blog provides industry insights on ad tech economics from a veteran journalist's perspective, covering programmatic advertising mechanics, auction dynamics, and connected TV (CTV) advertising economics. His content bridges technical concepts with practical industry knowledge, drawing from extensive reporting experience at major business publications. The blog is valuable for understanding the business and economic forces shaping digital advertising technology.","use_cases":"Understanding how programmatic ad auctions impact campaign performance and budget allocation, Learning about CTV advertising market dynamics for strategic planning or investment decisions","audience":"Mid-DS, Curious-browser"},{"id":"community-james-ledoux","type":"community","name":"James LeDoux","description":"Data Scientist (previously at MLB Advanced Media). Technical analysis of ad tech auction mechanisms. Collected 30,000+ Prebid.js auctions examining bidding patterns and monetization strategy.","category":"Blogs","url":"https://jamesrledoux.com/","difficulty":"intermediate","prerequisites":"python-data-analysis, auction-theory, javascript-debugging","topic_tags":"ad-tech, auction-mechanisms, prebid-js, monetization-strategy, bidding-patterns","summary":"James LeDoux is a data scientist who conducts technical analysis of ad tech auction mechanisms, with particular expertise in Prebid.js auction data. His work includes large-scale analysis of 30,000+ auctions to understand bidding patterns and monetization strategies in programmatic advertising.","use_cases":"Understanding how programmatic ad auctions work and optimizing bidding strategies, Learning from real-world analysis of large-scale ad tech auction data","audience":"Mid-DS, Curious-browser"},{"id":"community-emily-riederer","type":"community","name":"Emily Riederer","description":"Senior Manager, Data Science & Analytics at Capital One. Causal inference in industry settings, data quality frameworks, reproducible analytical workflows. rOpenSci Editorial Board member.","category":"Blogs","url":"https://www.emilyriederer.com/","difficulty":"intermediate","prerequisites":"python-pandas, SQL, hypothesis-testing","topic_tags":"causal-inference, data-quality, reproducible-research, industry-analytics, personal-blog","summary":"Personal blog by Emily Riederer, Senior Manager of Data Science & Analytics at Capital One, focusing on causal inference applications in industry, data quality frameworks, and reproducible analytical workflows. Provides practical insights on implementing rigorous data science practices in corporate environments. Features real-world case studies and methodological guidance for applied researchers.","use_cases":"Learning how to implement causal inference methods in industry settings with messy data, Understanding data quality frameworks and validation processes for production analytics","audience":"Mid-DS, Junior-DS"},{"id":"community-ellie-murray","type":"community","name":"Ellie Murray","description":"Assistant Professor of Epidemiology at Boston University. Co-host of Casual Inference podcast. Causal inference methodology for evidence-based decision-making with accessible explainers.","category":"Blogs","url":"https://epiellie.substack.com/","difficulty":"beginner","prerequisites":"basic-statistics, regression-analysis","topic_tags":"causal-inference, epidemiology, explainer-content, podcast","summary":"Ellie Murray provides accessible explanations of causal inference methods through her blog and Casual Inference podcast. Her content focuses on making epidemiological and causal inference concepts understandable for practitioners in data science and research. She bridges academic rigor with practical applications for evidence-based decision-making.","use_cases":"Learning causal inference fundamentals before implementing methods in A/B testing, Understanding epidemiological approaches to causal questions in health tech or policy research","audience":"Early-PhD, Junior-DS"},{"id":"community-lucy-d'agostino-mcgowan","type":"community","name":"Lucy D'Agostino McGowan","description":"Associate Professor of Statistical Sciences at Wake Forest. Co-host of Casual Inference podcast. Causal inference education, analytic design theory. Created 'causal quartets' demonstrating causal mechanisms.","category":"Blogs","url":"https://livefreeordichotomize.com/","difficulty":"beginner","prerequisites":"basic-statistics, causal-inference-fundamentals","topic_tags":"causal-inference, education, statistical-methods, podcast, teaching","summary":"Lucy D'Agostino McGowan is an Associate Professor at Wake Forest who co-hosts the Casual Inference podcast and creates educational content about causal inference methods. Her blog focuses on making causal inference concepts accessible through innovative teaching approaches like 'causal quartets'. She provides practical insights on experimental design and statistical thinking for applied researchers.","use_cases":"Learning causal inference fundamentals through clear explanations and examples, Finding educational resources and teaching materials for statistical methods","audience":"Early-PhD, Curious-browser"},{"id":"community-robert-kubinec","type":"community","name":"Robert Kubinec","description":"Assistant Professor of Political Science at University of South Carolina. Bayesian statistics, causal inference, political economy, and corruption measurement. DiD limitations and panel data frameworks.","category":"Blogs","url":"https://www.robertkubinec.com/","difficulty":"intermediate","prerequisites":"difference-in-differences, bayesian-statistics, panel-data-methods","topic_tags":"causal-inference, political-economy, bayesian-methods, panel-data, corruption-measurement","summary":"Personal blog by Robert Kubinec, Assistant Professor of Political Science at University of South Carolina, focusing on Bayesian statistics, causal inference, and political economy research. The blog covers methodological insights on difference-in-differences limitations, panel data frameworks, and corruption measurement techniques. Particularly valuable for researchers working at the intersection of economics, political science, and applied statistics.","use_cases":"Learning about limitations and best practices for DiD designs in policy evaluation, Understanding Bayesian approaches to measuring corruption and institutional quality","audience":"Early-PhD, Mid-DS"},{"id":"community-vincent-arel-bundock","type":"community","name":"Vincent Arel-Bundock","description":"Professor at Universit\u00e9 de Montr\u00e9al. Creator of the marginaleffects R/Python package. Causal inference including frontdoor adjustment, marginal effects interpretation. Author of 'Model to Meaning.'","category":"Blogs","url":"https://arelbundock.com/","difficulty":"intermediate","prerequisites":"causal-inference, R-programming, regression-analysis","topic_tags":"causal-inference, marginal-effects, frontdoor-adjustment, R-packages, econometrics","summary":"Vincent Arel-Bundock is a professor and creator of the marginaleffects package for R and Python, focusing on causal inference methods and interpretation of statistical models. His blog covers advanced topics like frontdoor adjustment and practical guidance on extracting meaningful insights from econometric models. Essential resource for practitioners working on causal analysis and model interpretation.","use_cases":"Learning how to properly interpret and communicate results from causal inference models, Understanding implementation details and best practices for the marginaleffects package","audience":"Mid-DS, Senior-DS"},{"id":"community-thomas-vladeck","type":"community","name":"Thomas Vladeck","description":"Founder of Gradient (quantitative market research) and Recast (media mix modeling). Statistics, causal inference, and marketing economics applications including pricing and media attribution.","category":"Blogs","url":"https://tvladeck.substack.com/","difficulty":"intermediate","prerequisites":"regression-analysis, A-B-testing, bayesian-statistics","topic_tags":"causal-inference, marketing-analytics, media-mix-modeling, pricing-strategy, quantitative-research","summary":"Thomas Vladeck's blog covers practical applications of statistics and causal inference in marketing economics, with focus on media attribution and pricing strategies. He shares insights from building Gradient (quantitative market research) and Recast (media mix modeling), making advanced econometric concepts accessible for business applications. Content bridges academic rigor with real-world implementation challenges in marketing measurement.","use_cases":"Learning how to implement media mix modeling for marketing attribution at a tech company, Understanding best practices for pricing experiments and causal inference in product analytics","audience":"Mid-DS, Senior-DS"},{"id":"community-michael-kaminsky","type":"community","name":"Michael Kaminsky","description":"Co-founder of Recast (media mix modeling); former analytics leader at Harry's. Marketing mix modeling, causal inference in marketing, incrementality testing, and validation of MMM results.","category":"Blogs","url":"https://getrecast.com/author/getrecastdev/","difficulty":"intermediate","prerequisites":"marketing-mix-modeling, causal-inference, python-pandas","topic_tags":"marketing-mix-modeling, causal-inference, incrementality-testing, media-attribution, marketing-analytics","summary":"Michael Kaminsky is co-founder of Recast and former analytics leader at Harry's, specializing in marketing mix modeling and causal inference for marketing. His blog covers practical approaches to measuring marketing incrementality, validating MMM results, and implementing causal inference methods in marketing contexts. Content targets practitioners working on attribution, media planning, and marketing measurement challenges.","use_cases":"Learning how to validate and improve marketing mix model results, Understanding best practices for incrementality testing in digital marketing","audience":"Mid-DS, Senior-DS"},{"id":"community-ken-acquah","type":"community","name":"Ken Acquah","description":"Data scientist specializing in causal inference applications. Causal Flows substack covering propensity score methods, experimentation design, and building data-driven cultures. 1,000+ subscribers.","category":"Blogs","url":"https://causalflows.substack.com/","difficulty":"intermediate","prerequisites":"propensity-score-matching, python-pandas, experimental-design","topic_tags":"causal-inference, propensity-scores, experimentation, data-culture, substack","summary":"Ken Acquah's Causal Flows is a Substack focused on practical causal inference applications for data scientists. With 1,000+ subscribers, it covers propensity score methods, experimental design, and strategies for building data-driven organizational cultures. The content bridges theoretical causal inference concepts with real-world implementation challenges.","use_cases":"Learning how to implement propensity score matching in observational studies, Understanding best practices for A/B testing and experimental design in tech companies","audience":"Junior-DS, Mid-DS"},{"id":"community-carlos-fern\u00e1ndez-lor\u00eda","type":"community","name":"Carlos Fern\u00e1ndez-Lor\u00eda","description":"Assistant Professor at HKUST Business School; PhD from NYU Stern. Counterfactual explanations for AI systems, causal post-processing of predictive models. Published in MIS Quarterly on explainable AI.","category":"Blogs","url":"https://carlos-fernandez.net/","difficulty":"intermediate","prerequisites":"causal-inference, machine-learning-models, python-scikit-learn","topic_tags":"counterfactual-explanations, explainable-ai, causal-post-processing, model-interpretability, academic-research","summary":"Carlos Fern\u00e1ndez-Lor\u00eda is an Assistant Professor at HKUST Business School specializing in counterfactual explanations for AI systems and causal approaches to model interpretability. His research focuses on post-processing predictive models to provide meaningful explanations, with publications in top-tier journals like MIS Quarterly. His blog likely covers cutting-edge developments in explainable AI and causal methods for machine learning.","use_cases":"Learning about state-of-the-art methods for making AI models more interpretable and explainable, Understanding how to apply causal inference techniques to improve model explanations and fairness","audience":"Mid-DS, Senior-DS"},{"id":"community-massimiliano-costacurta","type":"community","name":"Massimiliano Costacurta","description":"Data scientist specializing in reinforcement learning and pricing. Multi-armed bandits for dynamic pricing, contextual bandits for personalization. Detailed implementations with practical code.","category":"Blogs","url":"https://towardsdatascience.com/@massimiliano-costacurta","difficulty":"intermediate","prerequisites":"python-programming, reinforcement-learning-basics, multi-armed-bandits","topic_tags":"reinforcement-learning, dynamic-pricing, contextual-bandits, personalization, pricing-optimization","summary":"Personal blog by Massimiliano Costacurta focusing on practical applications of reinforcement learning in pricing and personalization. Features detailed implementations of multi-armed bandits for dynamic pricing strategies and contextual bandits for personalized recommendations with working code examples.","use_cases":"implementing dynamic pricing algorithms for e-commerce platforms, building personalized recommendation systems using contextual bandit approaches","audience":"Mid-DS, Junior-DS"},{"id":"community-microsoft-research-alice-(econml-dowhy)","type":"community","name":"Microsoft Research ALICE (EconML/DoWhy)","description":"Most widely-adopted causal ML tools. EconML for heterogeneous treatment effects, DoWhy for causal inference. Key researchers: Vasilis Syrgkanis, Amit Sharma.","category":"Research Labs","url":"https://www.microsoft.com/en-us/research/project/alice/","difficulty":"intermediate","prerequisites":"python-pandas, scikit-learn, causal-inference-basics","topic_tags":"causal-ml, heterogeneous-treatment-effects, econml, dowhy, microsoft-research","summary":"Microsoft Research ALICE develops EconML and DoWhy, the most widely-adopted open-source libraries for causal machine learning. EconML specializes in estimating heterogeneous treatment effects using ML methods, while DoWhy provides a unified framework for causal inference with explicit assumptions testing.","use_cases":"Estimating personalized treatment effects in A/B tests to optimize user targeting, Analyzing causal impact of pricing changes across different customer segments","audience":"Mid-DS, Senior-DS"},{"id":"community-uber-causalml","type":"community","name":"Uber CausalML","description":"Industry standard for uplift modeling and CATE estimation. Meta-learners (S, T, X, R). Key researchers: Huigang Chen, Totte Harinen.","category":"Research Labs","url":"https://www.uber.com/blog/causal-inference-at-uber/","difficulty":"intermediate","prerequisites":"python-scikit-learn, causal-inference-basics, treatment-effect-estimation","topic_tags":"causal-ml, uplift-modeling, meta-learners, treatment-effects, open-source","summary":"Uber's CausalML is the industry-standard open-source library for uplift modeling and conditional average treatment effect (CATE) estimation. It implements meta-learners including S-learner, T-learner, X-learner, and R-learner for measuring heterogeneous treatment effects. The library is widely used by data scientists at tech companies for personalization and experimentation.","use_cases":"Measuring personalized treatment effects from A/B tests to optimize user targeting, Building uplift models to identify which customers respond best to marketing campaigns","audience":"Mid-DS, Senior-DS"},{"id":"community-google-market-algorithms","type":"community","name":"Google Market Algorithms","description":"Auction design, mechanism design, autobidding systems. Led by Vahab Mirrokni. Shapes Google's advertising marketplace.","category":"Research Labs","url":"https://research.google/teams/market-algorithms/","difficulty":"advanced","prerequisites":"auction-theory, game-theory, convex-optimization","topic_tags":"auction-design, mechanism-design, advertising-auctions, market-design, algorithmic-game-theory","summary":"Google's premier research group focused on auction mechanisms and market algorithms that power the world's largest digital advertising ecosystem. Led by Vahab Mirrokni, the team develops cutting-edge auction formats, bidding algorithms, and market design solutions. Their work directly influences billions of dollars in ad spend and shapes how automated bidding systems interact in real-time auctions.","use_cases":"Designing new auction mechanisms for emerging ad formats like video or shopping ads, Developing autobidding algorithms that optimize advertiser ROI while maximizing platform revenue","audience":"Senior-DS, Early-PhD"},{"id":"community-meta-core-data-science","type":"community","name":"Meta Core Data Science","description":"Experimentation at scale, network effects, peer effects, advertising analytics. Led by Nicolas Stier-Moses (VP).","category":"Research Labs","url":"https://engineering.fb.com/category/core-infra/","difficulty":"intermediate","prerequisites":"causal-inference, experimental-design, python-pandas","topic_tags":"experimentation, network-effects, peer-effects, advertising-analytics, meta","summary":"Meta's Core Data Science team focuses on large-scale experimentation, network effects, peer effects, and advertising analytics under VP Nicolas Stier-Moses. The team develops methodologies for measuring causal effects in social networks and optimizing ad targeting at Meta's scale. Their work addresses unique challenges of experimentation on platforms with billions of interconnected users.","use_cases":"Running A/B tests on social media features while accounting for network spillover effects, Measuring the causal impact of advertising campaigns on user engagement and revenue","audience":"Mid-DS, Senior-DS"},{"id":"community-netflix-causal-inference","type":"community","name":"Netflix Causal Inference","description":"Causal inference for recommender systems. CompCI project, annual CIDER roundtable. Research advisor: Nathan Kallus (Cornell).","category":"Research Labs","url":"https://research.netflix.com/research-area/experimentation-and-causal-inference","difficulty":"advanced","prerequisites":"causal-inference, recommender-systems, python-numpy","topic_tags":"causal-inference, recommender-systems, netflix, research-community, tech-lab","summary":"Netflix's research community focused on applying causal inference methods to recommendation systems. Led by Cornell's Nathan Kallus, it includes the CompCI project and annual CIDER roundtable for advancing causal methods in personalization and content recommendation.","use_cases":"Measuring causal impact of recommendation algorithm changes on user engagement, Designing experiments to understand treatment effects in personalized content delivery","audience":"Senior-DS, Early-PhD"},{"id":"community-spotify-causal-inference-lab","type":"community","name":"Spotify Causal Inference Lab","description":"Synthetic control, long-term causal effects. Published in Nature Machine Intelligence (2023). Led by Ciar\u00e1n Gilligan-Lee.","category":"Research Labs","url":"https://research.atspotify.com/causal-inference","difficulty":"advanced","prerequisites":"synthetic-control-methods, difference-in-differences, python-causallib","topic_tags":"synthetic-control, long-term-causal-effects, spotify-research, causal-inference, research-lab","summary":"Spotify's research lab focused on advanced causal inference methods, particularly synthetic control and long-term causal effect estimation. Led by Ciar\u00e1n Gilligan-Lee, the lab has published cutting-edge research in Nature Machine Intelligence on novel approaches to measuring causal impacts over extended time horizons. The lab develops methods specifically applicable to tech platform experimentation and observational studies.","use_cases":"Measuring long-term effects of music recommendation algorithm changes on user engagement, Estimating causal impact of new features when randomized experiments are not feasible","audience":"Senior-DS, Early-PhD"},{"id":"community-amazon-science-economics","type":"community","name":"Amazon Science Economics","description":"Pricing Labs for A/B testing price changes, switchback experiments, marketplace analytics at scale.","category":"Research Labs","url":"https://amazon.science/research-areas/economics","difficulty":"intermediate","prerequisites":"a-b-testing, causal-inference, python-econometrics","topic_tags":"pricing-experiments, marketplace-economics, amazon-research, switchback-design, industrial-organization","summary":"Amazon Science Economics is a research lab focused on pricing experimentation and marketplace analytics at massive scale. The team develops methods for A/B testing price changes, switchback experiments, and causal inference in two-sided markets. Their work spans theoretical econometrics and practical implementation of pricing strategies across Amazon's ecosystem.","use_cases":"Running price experiments without spillover effects using switchback designs, Measuring cross-side network effects in marketplace pricing decisions","audience":"Mid-DS, Senior-DS"},{"id":"community-linkedin-economic-graph","type":"community","name":"LinkedIn Economic Graph","description":"Labor market analysis using LinkedIn's professional network data. Skills taxonomy, workforce trends.","category":"Research Labs","url":"https://economicgraph.linkedin.com/","difficulty":"intermediate","prerequisites":"python-pandas, network-analysis, occupational-codes","topic_tags":"labor-economics, network-data, workforce-analytics, skills-taxonomy, linkedin-research","summary":"LinkedIn's Economic Graph is a research initiative that analyzes global labor market trends using the professional network's data on skills, jobs, and career transitions. It provides insights into workforce dynamics, skill demand patterns, and economic mobility across industries and regions. Researchers and economists use this data to understand how labor markets evolve and respond to technological and economic changes.","use_cases":"Analyzing regional skill gaps and workforce migration patterns for economic development policy, Studying the impact of automation on specific job categories and required skill transitions","audience":"Mid-DS, Senior-DS"},{"id":"community-salesforce-ai-economist","type":"community","name":"Salesforce AI Economist","description":"Open-source framework for economic policy simulation using reinforcement learning. Multi-agent economic environments.","category":"Research Labs","url":"https://www.salesforceairesearch.com/projects/the-ai-economist","difficulty":"advanced","prerequisites":"reinforcement-learning, multi-agent-systems, economic-modeling","topic_tags":"reinforcement-learning, economic-simulation, multi-agent, policy-modeling, open-source","summary":"Salesforce AI Economist is an open-source framework that uses reinforcement learning to simulate economic policy scenarios with multiple agents. It enables researchers to model complex economic interactions and evaluate policy interventions in controlled environments. The framework is particularly valuable for studying emergent behaviors in economic systems and testing policy designs before real-world implementation.","use_cases":"Testing the effects of different tax policies on economic inequality using multi-agent simulations, Modeling market dynamics and competition between firms in digital platforms","audience":"Senior-DS, Early-PhD"},{"id":"community-stanford-golub-capital-social-impact-lab-(grf)","type":"community","name":"Stanford Golub Capital Social Impact Lab (GRF)","description":"Created Generalized Random Forests (grf R package). Susan Athey, Stefan Wager, Guido Imbens (Nobel). The gold standard for causal forests.","category":"Research Labs","url":"https://www.gsb.stanford.edu/faculty-research/labs-initiatives/sil","difficulty":"intermediate","prerequisites":"causal-inference, random-forests, R-programming","topic_tags":"causal-forests, treatment-effects, machine-learning, R-package, heterogeneous-effects","summary":"Stanford's Social Impact Lab that developed Generalized Random Forests (GRF), the leading method for estimating heterogeneous treatment effects using machine learning. Led by Nobel laureate Guido Imbens, Susan Athey, and Stefan Wager, they created the gold-standard R package for causal forests. Essential resource for anyone doing modern causal inference with machine learning methods.","use_cases":"Estimating heterogeneous treatment effects in A/B tests to find which user segments respond differently to product changes, Analyzing policy interventions to identify subgroups that benefit most from treatment programs","audience":"Mid-DS, Senior-DS"},{"id":"community-mit-economics-&-data-science","type":"community","name":"MIT Economics & Data Science","description":"Costis Daskalakis (mechanism design), Parag Pathak (school choice, NBER Market Design), Nikhil Agarwal (empirical market design).","category":"Research Labs","url":"https://economics.mit.edu/research","difficulty":"advanced","prerequisites":"mechanism-design-theory, empirical-io-methods, structural-econometrics","topic_tags":"mechanism-design, market-design, empirical-io, structural-econometrics, school-choice","summary":"MIT Economics & Data Science lab featuring leading researchers in mechanism design and empirical market design. The lab combines theoretical mechanism design with empirical analysis of real-world markets, particularly in education and matching markets. Research focuses on structural econometric methods to evaluate market design interventions and policy applications.","use_cases":"Studying school choice mechanisms and their welfare effects using matching theory, Learning structural methods for analyzing auction and matching market data","audience":"Early-PhD, Senior-DS"},{"id":"community-harvard-econcs-group","type":"community","name":"Harvard EconCS Group","description":"Mechanism design, computational social choice, AI for markets. David Parkes, Milind Tambe, Yiling Chen. GemNet won EC'24 Exemplary Paper.","category":"Research Labs","url":"https://econcs.seas.harvard.edu/","difficulty":"advanced","prerequisites":"game-theory, linear-programming, auction-theory","topic_tags":"mechanism-design, computational-social-choice, multi-agent-systems, algorithmic-game-theory, market-design","summary":"Harvard's EconCS group focuses on mechanism design, computational social choice, and AI applications in market settings. Led by renowned researchers David Parkes, Milind Tambe, and Yiling Chen, the group produces cutting-edge research including award-winning papers like GemNet at EC'24. The lab bridges economics and computer science to solve complex problems in auction design, voting systems, and AI-driven markets.","use_cases":"Research collaboration opportunities for PhD students working on auction mechanisms or voting algorithms, Finding state-of-the-art methods for designing truthful mechanisms in multi-agent AI systems","audience":"Senior-DS, Early-PhD"},{"id":"community-uc-berkeley-simons-institute","type":"community","name":"UC Berkeley Simons Institute","description":"World's premier collaborative programs in theoretical CS and economics. Semester programs on Economics and Computation.","category":"Research Labs","url":"https://simons.berkeley.edu/","difficulty":"intermediate","prerequisites":"graduate-level-economics, theoretical-computer-science, academic-research-methods","topic_tags":"theoretical-computer-science, economics-and-computation, research-collaboration, academic-programs, algorithmic-game-theory","summary":"The UC Berkeley Simons Institute is the world's leading center for collaborative research in theoretical computer science and economics. It hosts semester-long programs that bring together top researchers to work on cutting-edge problems at the intersection of economics and computation. Participants engage in workshops, seminars, and collaborative research on topics like algorithmic game theory, market design, and computational economics.","use_cases":"Finding collaborators and networking opportunities for research in algorithmic economics or computational social choice, Accessing cutting-edge research presentations and workshops on topics like mechanism design or online algorithms","audience":"Early-PhD, Senior-DS"},{"id":"community-opportunity-insights","type":"community","name":"Opportunity Insights","description":"Raj Chetty's lab. Opportunity Atlas, Social Capital Atlas, Economic Tracker. Most widely-used public policy big data.","category":"Research Labs","url":"https://opportunityinsights.org/","difficulty":"beginner","prerequisites":"descriptive-statistics, data-visualization, basic-econometrics","topic_tags":"economic-mobility, social-capital, policy-research, public-data, atlas-tools","summary":"Raj Chetty's research lab producing influential economic mobility and social capital research with public data tools. The lab creates widely-used atlases and datasets that map opportunity and social connections across the US. Their work combines big data with causal inference to inform public policy on inequality and economic mobility.","use_cases":"Policy researcher studying how neighborhood characteristics affect children's economic outcomes, Academic exploring the relationship between social capital and economic mobility for dissertation research","audience":"Early-PhD, Curious-browser"},{"id":"community-mlops-community","type":"community","name":"MLOps Community","description":"~28,000 members. ML operations, experimentation at scale, A/B testing infrastructure. Covers experiment tracking, feature stores, and statistical methods for online experiments.","category":"Online","url":"https://mlops.community/join","difficulty":"intermediate","prerequisites":"A/B-testing-fundamentals, python-scikit-learn, docker-containers","topic_tags":"mlops, experimentation-platforms, A/B-testing, feature-stores, online-communities","summary":"Large Slack community focused on machine learning operations and experimentation infrastructure at scale. Members discuss practical challenges around experiment tracking, feature stores, deployment pipelines, and statistical methods for online experiments. Active forum for sharing MLOps tools, debugging production issues, and learning from practitioners at major tech companies.","use_cases":"Getting help debugging experiment tracking setup or statistical significance issues in production A/B tests, Learning about MLOps tooling choices and implementation patterns from practitioners at companies with similar scale","audience":"Junior-DS, Mid-DS"},{"id":"community-optimizely-developer-community","type":"community","name":"Optimizely Developer Community","description":"~5,700 members. A/B testing, feature flagging, experiment design. Developer-focused community for experimentation practitioners.","category":"Online","url":"https://world.optimizely.com/","difficulty":"beginner","prerequisites":"basic-statistics, web-development-basics","topic_tags":"ab-testing, experimentation, feature-flagging, developer-community, optimizely","summary":"A Slack-based developer community with ~5,700 members focused on A/B testing, feature flagging, and experiment design using Optimizely's platform. The community provides a space for experimentation practitioners to share best practices, troubleshoot implementation issues, and discuss experimental methodologies. It's particularly valuable for developers implementing experimentation frameworks in production environments.","use_cases":"Getting help debugging A/B test implementation issues in your product, Learning best practices for feature flag rollout strategies from experienced practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-stan-community","type":"community","name":"Stan Community","description":"Developer-focused community for Bayesian causal inference and probabilistic programming. The Discourse forum (discourse.mc-stan.org) tends to be more active than Slack.","category":"Online","url":"https://mc-stan.org/community/","difficulty":"intermediate","prerequisites":"bayesian-statistics, stan-syntax, mcmc-sampling","topic_tags":"bayesian-inference, probabilistic-programming, stan, causal-inference, community","summary":"Developer-focused community for Stan users working on Bayesian causal inference and probabilistic programming. The active Discourse forum provides technical support, model debugging help, and discussions of advanced statistical methods. Most useful for practitioners implementing Stan models who need community guidance on complex problems.","use_cases":"Getting help debugging a Stan model that won't converge, Learning best practices for implementing difference-in-differences in a Bayesian framework","audience":"Mid-DS, Senior-DS"},{"id":"community-measure-slack","type":"community","name":"Measure Slack","description":"~23,000 members. The undisputed leader for marketing measurement professionals. Channels cover R/statistics, marketing mix modeling, attribution, GA4, Adobe Analytics, Tableau, and Looker. Senior practitioners actively engage.","category":"Online","url":"https://join.measure.chat/","difficulty":"intermediate","prerequisites":"marketing-attribution, R-programming, statistical-modeling","topic_tags":"marketing-measurement, slack-community, attribution-modeling, marketing-mix-modeling, analytics-tools","summary":"Measure Slack is the premier community for marketing measurement professionals with ~23,000 members. The community features specialized channels for R/statistics, marketing mix modeling, attribution, and major analytics platforms like GA4 and Adobe Analytics. Senior practitioners actively share insights and best practices across measurement methodologies.","use_cases":"Getting expert feedback on marketing mix modeling approach and statistical methodology, Learning best practices for attribution modeling implementation in GA4 or Adobe Analytics","audience":"Mid-DS, Senior-DS"},{"id":"community-revgenius","type":"community","name":"RevGenius","description":"~35,000 members. B2B marketing, revenue operations, GTM analytics. Large community for revenue-focused professionals.","category":"Online","url":"https://www.revgenius.com/","difficulty":"beginner","prerequisites":"basic-statistics, excel-pivot-tables","topic_tags":"revenue-operations, B2B-marketing, GTM-analytics, slack-community, networking","summary":"RevGenius is a large Slack community of ~35,000 revenue operations and B2B marketing professionals. Members share best practices, discuss tools, and network around go-to-market analytics and revenue optimization strategies. It's a valuable resource for learning industry trends and connecting with practitioners in the revenue space.","use_cases":"Junior analyst looking to learn revenue attribution methodologies from experienced practitioners, Marketing operations professional seeking recommendations for A/B testing tools and implementation advice","audience":"Junior-DS, Curious-browser"},{"id":"community-analytics-for-marketers","type":"community","name":"Analytics for Marketers","description":"Active community for marketing analytics practitioners. Practical discussions on marketing measurement and analytics tools.","category":"Online","url":"https://www.communityinviter.com/apps/analyticsform/analytics-for-marketers","difficulty":"beginner","prerequisites":"google-analytics, excel-pivot-tables, SQL-basics","topic_tags":"marketing-analytics, attribution-modeling, slack-community, marketing-measurement, digital-marketing","summary":"Analytics for Marketers is an active Slack community where marketing analytics practitioners share practical insights and discuss measurement challenges. Members exchange best practices on attribution modeling, campaign analysis, and analytics tool implementations. The community focuses on real-world marketing measurement problems rather than theoretical approaches.","use_cases":"Getting advice on implementing multi-touch attribution models for your company's digital campaigns, Troubleshooting Google Analytics setup issues or finding alternatives to deprecated marketing analytics tools","audience":"Junior-DS, Mid-DS"},{"id":"community-growmance","type":"community","name":"Growmance","description":"~17,000 members. Growth experiments, marketing science. Community for growth practitioners focused on experimentation.","category":"Online","url":"https://growmance.com/","difficulty":"beginner","prerequisites":"A-B-testing, basic-statistics, growth-metrics","topic_tags":"growth-experimentation, marketing-science, A-B-testing, slack-community, growth-hacking","summary":"Growmance is a 17,000-member Slack community focused on growth experimentation and marketing science. It serves as a hub for growth practitioners to share experiment results, discuss testing methodologies, and learn from real-world growth case studies. The community is ideal for those looking to connect with others running growth experiments at tech companies.","use_cases":"Getting feedback on experimental design for a new feature launch from experienced growth practitioners, Learning about growth metrics and KPIs used by other companies through community discussions","audience":"Junior-DS, Mid-DS"},{"id":"community-mixpanel-community","type":"community","name":"Mixpanel Community","description":"Active community for user behavior analysis, funnels, and retention analytics. Product analytics practitioners.","category":"Online","url":"https://community.mixpanel.com/","difficulty":"beginner","prerequisites":"product-analytics-basics, SQL-queries, event-tracking","topic_tags":"product-analytics, user-behavior, retention-analysis, funnel-optimization, community","summary":"Mixpanel Community is an active Slack-based community focused on product analytics, user behavior analysis, and retention metrics. Practitioners share best practices, troubleshoot implementation issues, and discuss advanced funnel optimization techniques. It's a go-to resource for anyone working with event-based analytics and user journey measurement.","use_cases":"Getting help with complex funnel analysis setup and interpretation, Learning retention cohort analysis best practices from experienced practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-mind-the-product","type":"community","name":"Mind the Product","description":"~60,000 members. Product management and data-driven decisions. One of the largest product communities.","category":"Online","url":"https://www.mindtheproduct.com/","difficulty":"beginner","prerequisites":"basic-statistics, product-metrics","topic_tags":"product-management, community, data-driven-decisions, experimentation","summary":"Mind the Product is one of the largest product management communities with ~60,000 members focusing on data-driven product decisions. The community serves as a hub for product managers, data scientists, and analysts to share best practices, discuss experimentation strategies, and learn from real-world case studies. Members can access discussions on A/B testing, product analytics, and evidence-based decision making.","use_cases":"Junior data scientist at a tech company needs to understand how product managers think about metrics and KPIs, Product manager wants to learn best practices for setting up experiments and interpreting results from experienced practitioners","audience":"Junior-DS, Curious-browser"},{"id":"community-amplitude-community","type":"community","name":"Amplitude Community","description":"Active community for product analytics and session replays. Discussions on behavioral analytics and product insights.","category":"Online","url":"https://community.amplitude.com/","difficulty":"beginner","prerequisites":"google-analytics, product-metrics, cohort-analysis","topic_tags":"product-analytics, behavioral-analytics, session-replay, community-support, amplitude","summary":"Amplitude Community is an active discussion forum focused on product analytics and session replay tools. Members share best practices for behavioral analytics, discuss implementation challenges, and exchange insights on product measurement strategies. The community serves as a support network for analysts working with digital product data.","use_cases":"Getting help debugging Amplitude implementation issues or understanding advanced segmentation features, Learning best practices for setting up product funnels and interpreting user behavioral patterns","audience":"Junior-DS, Mid-DS"},{"id":"community-wizops-(wizards-of-ops)","type":"community","name":"WizOps (Wizards of Ops)","description":"~9,000 members. RevOps, pricing operations, business systems. Community for operations professionals.","category":"Online","url":"https://wizops.org/","difficulty":"beginner","prerequisites":"basic-analytics, business-metrics","topic_tags":"revenue-operations, pricing-strategy, business-systems, operations-community","summary":"WizOps is a 9,000-member Slack community focused on revenue operations, pricing operations, and business systems. The community serves operations professionals who work at the intersection of business strategy and data systems. Members share best practices, troubleshoot operational challenges, and discuss tools for optimizing business processes.","use_cases":"Getting advice on implementing a new pricing model or revenue tracking system, Learning how other companies structure their RevOps teams and processes","audience":"Junior-DS, Mid-DS"},{"id":"community-revenue-operations-alliance","type":"community","name":"Revenue Operations Alliance","description":"Growing community for pricing strategy, revenue forecasting, and GTM operations professionals.","category":"Online","url":"https://revenueoperationsalliance.com/","difficulty":"beginner","prerequisites":"excel-basics, basic-sql","topic_tags":"pricing-strategy, revenue-operations, gtm-analytics, community, slack","summary":"The Revenue Operations Alliance is a Slack-based professional community focused on pricing strategy, revenue forecasting, and go-to-market operations. It connects practitioners working on revenue optimization, pricing decisions, and GTM analytics across different companies and industries. Members share best practices, discuss tools, and collaborate on solving revenue-related business challenges.","use_cases":"Getting advice on implementing dynamic pricing models for a SaaS product from experienced RevOps professionals, Learning about forecasting methodologies and tools used by other companies for quarterly revenue planning","audience":"Junior-DS, Mid-DS"},{"id":"community-researchops-community","type":"community","name":"ResearchOps Community","description":"~15,000 members. Research operations and process optimization for UX and market researchers.","category":"Online","url":"https://researchops.community/","difficulty":"beginner","prerequisites":"user-research-methods, survey-design, basic-project-management","topic_tags":"research-operations, ux-research, community, process-optimization, research-methods","summary":"A 15,000-member Slack community focused on research operations and process optimization for UX and market researchers. Members share best practices, tools, and methodologies for scaling research functions within organizations. The community provides networking opportunities and knowledge sharing for research professionals looking to improve operational efficiency.","use_cases":"Learning how to set up research repositories and participant recruitment processes at a new company, Finding templates and workflows for managing multiple concurrent user research studies","audience":"Junior-DS, Curious-browser"},{"id":"community-pyslackers","type":"community","name":"PySlackers","description":"~40,000 members. Python, statsmodels, pandas, scientific computing. Large Python community for data science.","category":"Online","url":"https://pyslackers.com/","difficulty":"beginner","prerequisites":"python-basics, pandas-fundamentals","topic_tags":"python-community, data-science-support, slack-workspace, scientific-computing, peer-learning","summary":"PySlackers is a large Slack community with ~40,000 Python practitioners focused on data science tools and scientific computing. Members discuss Python libraries like pandas and statsmodels, share code solutions, and help troubleshoot technical issues. It serves as a real-time support network for Python developers working in data science.","use_cases":"Getting help debugging pandas data manipulation code from experienced practitioners, Finding recommendations for Python packages and best practices for statistical analysis workflows","audience":"Junior-DS, Curious-browser"},{"id":"community-r-for-data-science","type":"community","name":"R for Data Science","description":"~17,000 members. R programming, tidyverse, statistical modeling. Active community for R practitioners.","category":"Online","url":"https://rfordatasci.com/","difficulty":"beginner","prerequisites":"basic-R-syntax, data-manipulation-concepts","topic_tags":"R-programming, tidyverse, statistical-modeling, data-science-community","summary":"Large Slack community of ~17,000 R practitioners focused on tidyverse approaches and statistical modeling. Members share code examples, troubleshoot issues, and discuss best practices for data analysis in R. Active forum for getting help with R programming challenges and staying current with ecosystem developments.","use_cases":"Getting help debugging ggplot2 visualizations or dplyr data transformations, Finding R package recommendations for specific statistical modeling tasks","audience":"Junior-DS, Curious-browser"},{"id":"community-data-visualization-society","type":"community","name":"Data Visualization Society","description":"~17,000 members. Data visualization and storytelling with data. Community for data viz practitioners.","category":"Online","url":"https://www.datavisualizationsociety.org/","difficulty":"beginner","prerequisites":"basic-statistics, data-manipulation","topic_tags":"data-visualization, community, storytelling, design-principles","summary":"A 17,000+ member community focused on data visualization and storytelling with data. Provides networking, learning resources, and best practices for data viz practitioners across skill levels. Active Slack community where members share work, get feedback, and discuss visualization techniques.","use_cases":"Getting feedback on chart designs and visualization choices from experienced practitioners, Learning about new visualization tools and staying updated on data viz trends and best practices","audience":"Junior-DS, Curious-browser"},{"id":"community-data-quality-camp","type":"community","name":"Data Quality Camp","description":"~9,000 members. Data reliability and data quality engineering. Community focused on data quality practices.","category":"Online","url":"https://dataquality.camp/","difficulty":"beginner","prerequisites":"SQL-basics, data-warehouse-concepts","topic_tags":"data-quality, data-engineering, data-reliability, community, slack","summary":"Data Quality Camp is a 9,000-member Slack community focused on data reliability and data quality engineering practices. It serves as a platform for data professionals to share best practices, troubleshoot data quality issues, and stay updated on tools and methodologies. The community is particularly valuable for learning practical approaches to ensuring data accuracy and reliability in production systems.","use_cases":"Getting advice on implementing data quality checks in your ETL pipeline, Learning about new data monitoring tools and getting recommendations from practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-data-science-salon-slack","type":"community","name":"Data Science Salon Slack","description":"~3,000 members. Senior practitioners and industry applications. Professional community for experienced data scientists.","category":"Online","url":"https://datascience.salon/","difficulty":"intermediate","prerequisites":"professional-experience, data-science-fundamentals, slack-usage","topic_tags":"professional-networking, slack-community, industry-practitioners, career-development","summary":"Data Science Salon Slack is a professional community of ~3,000 experienced data scientists focused on industry applications and senior-level practice. The community emphasizes real-world problem solving and knowledge sharing among seasoned practitioners. Members can access discussions on advanced techniques, career guidance, and industry trends from peers with substantial experience.","use_cases":"Getting advice on complex production ML system architecture from senior practitioners, Networking with experienced data scientists for career advancement or job opportunities","audience":"Mid-DS, Senior-DS"},{"id":"community-hugging-face-discord","type":"community","name":"Hugging Face Discord","description":"~200,000 members. Open-source ML, NLP, transformers. Community events, reading clubs, and direct access to developers working on transformers and open-source ML.","category":"Online","url":"https://huggingface.co/join/discord","difficulty":"beginner","prerequisites":"python-basics, pytorch-transformers","topic_tags":"hugging-face, transformers, nlp, open-source, community","summary":"Massive Discord community of ~200,000 members focused on Hugging Face's open-source ML ecosystem, particularly transformers and NLP. Features active discussions, reading groups, community events, and direct interaction with core developers. Essential resource for staying current with the rapidly evolving transformer and open-source ML landscape.","use_cases":"Getting help debugging Hugging Face transformers implementation issues, Staying updated on latest model releases and participating in community reading groups","audience":"Junior-DS, Curious-browser"},{"id":"community-python-discord","type":"community","name":"Python Discord","description":"~415,000 members. Python programming with data science channels. 24/7 expert help across 100+ helpers and regular hackathons.","category":"Online","url":"https://pythondiscord.com/","difficulty":"beginner","prerequisites":"python-basics, programming-fundamentals","topic_tags":"python-programming, community-support, data-science-help, discord-server, peer-learning","summary":"Python Discord is a massive community of 415,000+ Python developers offering real-time help and collaboration. The server features dedicated data science channels with 24/7 expert assistance from 100+ helpers, plus regular hackathons for hands-on learning. It's an ideal resource for getting unstuck on coding problems and connecting with the Python ecosystem.","use_cases":"Getting help debugging pandas data manipulation code when stuck on a specific error, Participating in data science hackathons to practice skills and build portfolio projects","audience":"Junior-DS, Early-PhD"},{"id":"community-fast.ai-discord","type":"community","name":"fast.ai Discord","description":"Large community for practical ML and accessible deep learning. Community around the famous fast.ai courses.","category":"Online","url":"https://course.fast.ai/","difficulty":"beginner","prerequisites":"python-basics, jupyter-notebooks","topic_tags":"deep-learning, community, pytorch, practical-ml, beginner-friendly","summary":"Active Discord community centered around fast.ai's practical deep learning courses and philosophy. Members discuss course materials, share projects, get help with implementations, and engage in beginner-friendly ML discussions. Known for making deep learning accessible to practitioners without extensive math backgrounds.","use_cases":"Getting help debugging fastai code while working through the course exercises, Finding study partners and discussion groups for deep learning projects","audience":"Junior-DS, Curious-browser"},{"id":"community-data-science-ml-ai-discord","type":"community","name":"Data Science/ML/AI Discord","description":"~30,000 members. General data science, ML, and visualization discussions.","category":"Online","url":"https://discord.com/invite/v3zeSGb","difficulty":"beginner","prerequisites":"basic-python, discord-account","topic_tags":"community, discord, networking, data-science, machine-learning","summary":"A large Discord server with approximately 30,000 members focused on data science, machine learning, and data visualization discussions. The community provides a platform for real-time chat, question-and-answer sessions, and networking among data professionals at all levels. Members can engage in general discussions, seek help with technical problems, and stay updated on industry trends.","use_cases":"Getting quick help debugging a pandas error or ML model issue, Networking with other data professionals and finding mentorship opportunities","audience":"Junior-DS, Curious-browser"},{"id":"community-the-data-share-(tds)","type":"community","name":"The Data Share (TDS)","description":"~500 online. Towards Data Science community for career discussions and data science content.","category":"Online","url":"https://discord.com/invite/eaPVRW3","difficulty":"beginner","prerequisites":"discord-basics, data-science-fundamentals","topic_tags":"career-development, community, networking, data-science-careers","summary":"The Data Share (TDS) is an active Discord community of ~500 members focused on career discussions and data science content sharing. It serves as a networking hub for data professionals to discuss career paths, share experiences, and get advice from peers. The community is affiliated with Towards Data Science and provides an informal space for real-time conversations about industry trends and career development.","use_cases":"Getting career advice from other data scientists when considering job transitions or negotiating offers, Networking with data professionals and finding mentorship opportunities in an informal online setting","audience":"Junior-DS, Curious-browser"},{"id":"community-mlops-discord-(@chipro)","type":"community","name":"MLOps Discord (@chipro)","description":"Growing MLOps community by Chip Huyen. Discussions on production ML and ML systems.","category":"Online","url":"https://discord.com/invite/Mw77HPrgjF","difficulty":"intermediate","prerequisites":"docker-containers, python-scikit-learn, model-deployment","topic_tags":"mlops, production-ml, model-deployment, discord-community, ml-systems","summary":"A Discord community focused on MLOps and production machine learning systems, founded by Chip Huyen. Members discuss best practices for deploying, monitoring, and scaling ML models in production environments. The community serves as a knowledge-sharing hub for practitioners working on real-world ML infrastructure challenges.","use_cases":"Getting help debugging model deployment issues in production, Learning about ML monitoring and observability tools from practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-statistics-discord","type":"community","name":"Statistics Discord","description":"~5,700 members. Statistical methodology discussions for statisticians and data scientists.","category":"Online","url":"https://discord.com/invite/statistics","difficulty":"beginner","prerequisites":"basic-statistics, hypothesis-testing","topic_tags":"statistics-community, statistical-methods, data-science-discussion, peer-learning, discord","summary":"A Discord server with ~5,700 members focused on statistical methodology discussions. It serves as a community platform for statisticians and data scientists to discuss methods, get help with statistical problems, and share knowledge in real-time.","use_cases":"Getting quick feedback on statistical analysis approach from peers, Asking for help debugging statistical code or interpreting results","audience":"Junior-DS, Early-PhD"},{"id":"community-discord-(r-programming)","type":"community","name":"discoRd (R Programming)","description":"~4,000 members. R programming and statistical computing community.","category":"Online","url":"https://discord.com/invite/WW86mVFtwb","difficulty":"beginner","prerequisites":"R-programming, basic-statistics","topic_tags":"R-programming, statistical-computing, community-support, discord","summary":"A Discord server with approximately 4,000 members focused on R programming and statistical computing. The community provides real-time help, discussion, and support for R users at all levels. Members can ask questions, share code, and collaborate on statistical analysis projects.","use_cases":"Getting help debugging R code or statistical analysis from experienced practitioners, Finding collaborators or mentors for R-based data science projects","audience":"Junior-DS, Early-PhD"},{"id":"community-humans-of-julia","type":"community","name":"Humans of Julia","description":"~3,600 members. Julia for scientific computing. Community for Julia language users.","category":"Online","url":"https://discord.com/invite/C5h9D4j","difficulty":"intermediate","prerequisites":"julia-basics, scientific-computing-fundamentals","topic_tags":"julia-programming, scientific-computing, community-support, discord-server","summary":"A Discord community of ~3,600 Julia programming language enthusiasts focused on scientific computing applications. Members share code, discuss best practices, troubleshoot issues, and collaborate on Julia-based research and data science projects. The community serves as a real-time support network for Julia users across academia and industry.","use_cases":"Getting help debugging Julia performance issues in computational models, Finding collaborators for open-source Julia package development","audience":"Junior-DS, Mid-DS"},{"id":"community-quant-data-discord","type":"community","name":"Quant Data Discord","description":"~15,000 members. Gamma exposure, dark pool, options flow. Quantitative trading community.","category":"Online","url":"https://discord.com/invite/quantdata","difficulty":"intermediate","prerequisites":"options-pricing-models, python-pandas, financial-derivatives","topic_tags":"quantitative-trading, options-flow, gamma-exposure, dark-pools, discord-community","summary":"A Discord community of ~15,000 quantitative traders focused on options flow analysis, gamma exposure modeling, and dark pool activity. Members discuss trading strategies, share market insights, and collaborate on quantitative analysis techniques for derivatives markets.","use_cases":"Getting real-time insights on unusual options activity and gamma positioning from experienced quant traders, Finding collaborators and mentors for developing systematic trading strategies using options flow data","audience":"Mid-DS, Senior-DS"},{"id":"community-quant-trading-app-discord","type":"community","name":"Quant Trading App Discord","description":"~10,000 members. Quantitative trading and technical analysis discussions.","category":"Online","url":"https://discord.com/invite/quant-trading-app","difficulty":"beginner","prerequisites":"basic-finance, python-basics","topic_tags":"quantitative-trading, technical-analysis, discord-community, trading-strategies, market-data","summary":"A Discord community of ~10,000 members focused on quantitative trading strategies and technical analysis discussions. Members share trading ideas, discuss market patterns, and collaborate on algorithmic trading approaches. The community provides a space for both beginners and experienced traders to exchange knowledge about systematic trading methods.","use_cases":"Getting feedback on a new trading strategy before implementation, Finding collaborators for developing algorithmic trading systems","audience":"Curious-browser, Junior-DS"},{"id":"community-quant-talk-discord","type":"community","name":"Quant Talk Discord","description":"~1,500 members. Algo trading strategies and backtesting discussions.","category":"Online","url":"https://disboard.org/server/823943906008891403","difficulty":"intermediate","prerequisites":"python-pandas, statistical-hypothesis-testing, financial-markets-basics","topic_tags":"algorithmic-trading, backtesting, quantitative-finance, discord-community, trading-strategies","summary":"A Discord community of ~1,500 members focused on algorithmic trading strategies and backtesting methodologies. Members discuss quantitative trading approaches, share backtesting results, and collaborate on trading system development. The community serves as a practical forum for both learning and refining systematic trading strategies.","use_cases":"Getting feedback on a momentum trading strategy backtest from experienced quant traders, Finding collaborators to develop and test a mean reversion algorithm for cryptocurrency markets","audience":"Mid-DS, Curious-browser"},{"id":"community-quantconnect-discord","type":"community","name":"QuantConnect Discord","description":"Active community for algorithmic trading platform users. Quantitative trading and strategy development.","category":"Online","url":"https://www.quantconnect.com/docs/discord","difficulty":"intermediate","prerequisites":"python-programming, financial-markets-basics, API-integration","topic_tags":"algorithmic-trading, quantitative-finance, discord-community, trading-strategies, backtesting","summary":"QuantConnect Discord is an active community platform for users of the QuantConnect algorithmic trading platform. Members discuss quantitative trading strategies, share code, troubleshoot implementation issues, and collaborate on trading algorithm development. The community provides real-time support for both beginners learning algorithmic trading and experienced quants developing sophisticated strategies.","use_cases":"Getting help debugging a trading algorithm that's failing backtests on the QuantConnect platform, Finding collaborators or mentors for developing machine learning-based trading strategies","audience":"Junior-DS, Mid-DS"},{"id":"community-r-datascience","type":"community","name":"r/datascience","description":"~1.5M subscribers. Industry discussions, career advice, tooling. Active weekly career threads useful for understanding market dynamics.","category":"Online","url":"https://www.reddit.com/r/datascience/","difficulty":"beginner","prerequisites":"basic-statistics, career-awareness","topic_tags":"career-advice, industry-discussion, data-science-community, market-trends, tooling-advice","summary":"Large Reddit community focused on data science careers, industry trends, and practical tooling discussions. Features active weekly career threads and real-world perspectives from practitioners across experience levels. Valuable for understanding current market dynamics, salary expectations, and common challenges in data science roles.","use_cases":"Getting career advice and salary benchmarking from industry practitioners, Understanding current market trends and in-demand skills in data science","audience":"Junior-DS, Curious-browser"},{"id":"community-r-machinelearning","type":"community","name":"r/MachineLearning","description":"~3M subscribers. Research papers and cutting-edge algorithms. Premier subreddit for ML research discussion.","category":"Online","url":"https://www.reddit.com/r/MachineLearning/","difficulty":"intermediate","prerequisites":"python-basics, statistical-modeling, research-paper-reading","topic_tags":"machine-learning, research-community, academic-discussion, paper-reviews, cutting-edge-methods","summary":"The largest Reddit community for machine learning research with nearly 3 million subscribers discussing cutting-edge papers, algorithms, and methodologies. Members share recent publications, debate novel approaches, and provide expert commentary on breakthrough research. It serves as a premier forum for staying current with the rapidly evolving ML research landscape.","use_cases":"Following discussions on newly published papers to understand community reception and critiques, Getting expert opinions on implementing complex algorithms from recent research before production use","audience":"Senior-DS, Early-PhD"},{"id":"community-r-statistics","type":"community","name":"r/statistics","description":"~400K subscribers. Methodological debates, Bayesian vs frequentist discussions. Active statistics community.","category":"Online","url":"https://www.reddit.com/r/statistics/","difficulty":"beginner","prerequisites":"basic-probability, hypothesis-testing","topic_tags":"statistics-community, methodological-discussions, bayesian-frequentist, reddit-forum","summary":"Large Reddit community focused on statistical methodology discussions and debates. Active forum where statisticians and data scientists discuss theoretical concepts, argue methodological approaches, and seek advice on statistical problems.","use_cases":"Getting feedback on experimental design choices before running an A/B test, Understanding different perspectives on Bayesian vs frequentist approaches for a specific analysis","audience":"Early-PhD, Curious-browser"},{"id":"community-r-askeconomics","type":"community","name":"r/AskEconomics","description":"~1.4M subscribers. High-quality moderated economics Q&A. Answers must be comprehensive and well-sourced, valuable for policy questions.","category":"Online","url":"https://www.reddit.com/r/AskEconomics/","difficulty":"beginner","prerequisites":"basic-economics, undergraduate-statistics","topic_tags":"economics-q-and-a, community-discussion, policy-analysis, reddit-forum","summary":"A large Reddit community with rigorous moderation where users ask economics questions and receive well-sourced, comprehensive answers from economists and experts. The subreddit maintains high academic standards and is particularly valuable for understanding economic policy implications and real-world applications of economic theory.","use_cases":"Getting expert explanations of current economic events and policy proposals, Finding well-sourced answers to specific economics questions for research or coursework","audience":"Early-PhD, Curious-browser"},{"id":"community-r-econometrics","type":"community","name":"r/econometrics","description":"~30K subscribers. Econometric methods and software discussions for applied econometricians.","category":"Online","url":"https://www.reddit.com/r/econometrics/","difficulty":"intermediate","prerequisites":"regression-analysis, statistical-software, hypothesis-testing","topic_tags":"econometrics, reddit-community, applied-methods, statistical-discussion, peer-support","summary":"Active Reddit community of ~30K applied econometricians discussing methods, software implementation, and research problems. Members share code, debug issues, and get feedback on econometric approaches from practitioners and academics.","use_cases":"Getting help debugging instrumental variables estimation in R or Stata, Finding peer review of your identification strategy before submitting research","audience":"Early-PhD, Mid-DS"},{"id":"community-r-analytics","type":"community","name":"r/analytics","description":"~150K subscribers. Applied analytics, KPIs, stakeholder management for analytics practitioners.","category":"Online","url":"https://www.reddit.com/r/analytics/","difficulty":"beginner","prerequisites":"basic-statistics, business-metrics","topic_tags":"analytics-community, business-metrics, stakeholder-management, reddit, practitioner-advice","summary":"r/analytics is a Reddit community of ~150K analytics practitioners focused on applied analytics, KPI development, and stakeholder management. Members discuss real-world challenges in translating data insights into business value and managing analytics projects. The community emphasizes practical advice for working with business stakeholders and implementing analytics solutions.","use_cases":"Getting advice on how to present analytics findings to non-technical executives, Learning best practices for defining and tracking business KPIs across different industries","audience":"Junior-DS, Mid-DS"},{"id":"community-r-operationsresearch","type":"community","name":"r/OperationsResearch","description":"~15K subscribers. Optimization and mathematical modeling discussions for OR practitioners.","category":"Online","url":"https://www.reddit.com/r/OperationsResearch/","difficulty":"intermediate","prerequisites":"linear-programming, python-optimization, mathematical-modeling","topic_tags":"operations-research, optimization, mathematical-modeling, community, reddit","summary":"A Reddit community of ~15K operations research practitioners discussing optimization problems, mathematical modeling techniques, and OR applications. Members share solutions to complex scheduling, routing, and resource allocation problems while discussing both theoretical approaches and practical implementation challenges.","use_cases":"Getting help with formulating a complex supply chain optimization problem as a linear program, Finding recommendations for optimization solvers when dealing with large-scale integer programming problems","audience":"Mid-DS, Senior-DS"},{"id":"community-r-rstats","type":"community","name":"r/rstats","description":"~90K subscribers. R programming for statistical computing. Active community for R users.","category":"Online","url":"https://www.reddit.com/r/rstats/","difficulty":"beginner","prerequisites":"R-basics, statistical-computing","topic_tags":"R-programming, statistical-computing, community-support, data-analysis, reddit","summary":"Large Reddit community of ~90K members focused on R programming for statistical computing and data analysis. Active forum where R users share code, ask questions, discuss packages, and get help with statistical programming challenges. Valuable resource for learning R best practices and staying updated on the R ecosystem.","use_cases":"Getting help debugging R code or statistical analysis issues, Learning about new R packages and staying updated on R community developments","audience":"Junior-DS, Curious-browser"},{"id":"community-r-dataengineering","type":"community","name":"r/dataengineering","description":"~250K subscribers. Data infrastructure and pipelines. Community for data engineers.","category":"Online","url":"https://www.reddit.com/r/dataengineering/","difficulty":"beginner","prerequisites":"SQL-basics, python-programming, cloud-platforms","topic_tags":"data-engineering, data-pipelines, infrastructure, community, reddit","summary":"Large Reddit community focused on data engineering topics including infrastructure, ETL pipelines, and data platform architecture. Members share experiences, troubleshoot issues, and discuss tools like Airflow, Kafka, and cloud data services. Valuable resource for learning best practices and staying current with data engineering trends.","use_cases":"Getting help debugging Apache Airflow DAG issues from experienced practitioners, Learning about new data pipeline tools and getting implementation advice from the community","audience":"Junior-DS, Mid-DS"},{"id":"community-cross-validated-(stack-exchange)","type":"community","name":"Cross Validated (Stack Exchange)","description":"500K+ users. Premier Q&A site for statistics and ML methodology. Famous statisticians participate. Community blog with high-quality answers often rivaling textbook explanations.","category":"Online","url":"https://stats.stackexchange.com/","difficulty":"beginner","prerequisites":"basic-statistics, hypothesis-testing","topic_tags":"statistics, machine-learning, Q&A, community, methodology","summary":"Cross Validated is Stack Exchange's statistics and machine learning Q&A community with over 500,000 users including prominent statisticians and researchers. It provides expert answers to methodology questions that often match textbook quality explanations. The platform serves as a go-to resource for understanding statistical concepts, debugging analysis approaches, and learning best practices from experienced practitioners.","use_cases":"Getting expert help debugging a statistical analysis or understanding why results don't match expectations, Learning proper methodology for A/B testing, causal inference, or model validation from community experts","audience":"Junior-DS, Curious-browser"},{"id":"community-stan-forums","type":"community","name":"Stan Forums","description":"10K+ users. Bayesian modeling, HMC/MCMC. Stan developers respond directly. Excellent for hierarchical models and diagnostics.","category":"Online","url":"https://discourse.mc-stan.org/","difficulty":"intermediate","prerequisites":"bayesian-inference, R-or-python, probabilistic-modeling","topic_tags":"bayesian-modeling, MCMC, hierarchical-models, stan, community","summary":"Active community forum with 10,000+ users focused on Bayesian modeling using Stan. Stan core developers participate directly, providing expert guidance on hierarchical models, MCMC diagnostics, and implementation challenges. Essential resource for troubleshooting complex Bayesian workflows and learning best practices.","use_cases":"Getting help debugging Stan model convergence issues, Learning how to implement hierarchical models for A/B testing","audience":"Mid-DS, Senior-DS"},{"id":"community-pymc-discourse","type":"community","name":"PyMC Discourse","description":"5K+ users. PyMC and Bayesian statistics. Core developers active. Good for frequentist-to-Bayesian transition.","category":"Online","url":"https://discourse.pymc.io/","difficulty":"intermediate","prerequisites":"python-basics, statistics-distributions, mcmc-concepts","topic_tags":"bayesian-statistics, pymc, probabilistic-programming, mcmc, community","summary":"PyMC Discourse is an active forum with 5K+ users focused on PyMC and Bayesian statistics, where core developers regularly participate. It's particularly valuable for data scientists transitioning from frequentist to Bayesian approaches. The community provides help with implementation, debugging, and best practices for probabilistic programming.","use_cases":"Getting help debugging PyMC model convergence issues, Learning how to implement hierarchical Bayesian models for A/B testing","audience":"Junior-DS, Mid-DS"},{"id":"community-or-stack-exchange","type":"community","name":"OR Stack Exchange","description":"20K+ users. Operations research and optimization. Launched with INFORMS support. High-quality modeling answers.","category":"Online","url":"https://or.stackexchange.com/","difficulty":"beginner","prerequisites":"linear-programming, mathematical-modeling","topic_tags":"operations-research, optimization, mathematical-modeling, linear-programming, community-forum","summary":"OR Stack Exchange is a Q&A community with 20,000+ users focused on operations research and optimization problems. Launched with INFORMS support, it provides high-quality answers about mathematical modeling, linear programming, and optimization techniques. The community attracts both academic researchers and industry practitioners working on complex decision-making problems.","use_cases":"Getting help debugging optimization models or understanding why a linear program is infeasible, Finding best practices for implementing specific OR algorithms or choosing between different optimization solvers","audience":"Early-PhD, Junior-DS"},{"id":"community-kaggle-discussions","type":"community","name":"Kaggle Discussions","description":"15M+ users. Competition strategies and ML techniques. Learn from Grandmasters. Public notebooks and solution breakdowns.","category":"Online","url":"https://www.kaggle.com/discussions","difficulty":"beginner","prerequisites":"python-basics, scikit-learn","topic_tags":"machine-learning, competitions, community, data-science, kaggle","summary":"Kaggle Discussions is the community forum for the world's largest data science platform with over 15 million users. It features competition strategies, ML technique discussions, and solution breakdowns from Kaggle Grandmasters. Users can access public notebooks, learn winning approaches, and get help with data science problems.","use_cases":"Learning competition-winning ML strategies from Grandmaster solutions, Getting help debugging machine learning models from the community","audience":"Junior-DS, Curious-browser"},{"id":"community-hacker-news","type":"community","name":"Hacker News","description":"Millions of users. Tech industry and ML research discussions. Monthly 'Who's Hiring' threads. Paper discussions.","category":"Online","url":"https://news.ycombinator.com/","difficulty":"beginner","prerequisites":"web-browsing, basic-reading-comprehension","topic_tags":"tech-community, discussion-forum, industry-news, career-networking, paper-discussion","summary":"Hacker News is a large online community where tech professionals and researchers discuss industry trends, share research papers, and engage in technical discussions. The platform features millions of users from startups to big tech companies, with regular job posting threads and active paper discussions. It serves as both a news aggregator and networking platform for the tech community.","use_cases":"Finding tech job opportunities through monthly 'Who's Hiring' threads, Participating in discussions about newly published ML/AI research papers","audience":"Junior-DS, Curious-browser"},{"id":"community-american-statistical-association-(asa)","type":"community","name":"American Statistical Association (ASA)","description":"19,000+ members across 22 subject-area sections. Key sections: Business and Economic Statistics, Survey Research Methods, Statistical Computing, Statistical Learning and Data Science. 78 geographic chapters host local events. Membership $195/year regular, $30/year student.","category":"Online","url":"https://community.amstat.org/","difficulty":"beginner","prerequisites":"basic-statistics, undergraduate-degree","topic_tags":"professional-association, statistics, networking, career-development, conferences","summary":"The American Statistical Association is the premier professional organization for statisticians and data scientists with over 19,000 members. It offers specialized sections covering business statistics, survey methods, and data science, plus local chapters for networking. Members gain access to journals, conferences, career resources, and professional development opportunities.","use_cases":"Early career data scientist looking to network with peers and attend professional conferences, PhD student seeking to publish research and connect with academic statisticians in specialized sections","audience":"Early-PhD, Junior-DS"},{"id":"community-informs-communities","type":"community","name":"INFORMS Communities","description":"Operations research community with specialized groups: Revenue Management & Pricing Section, Decision Analysis Section, Analytics Section, Junior Faculty Interest Group. Membership ~$170/year. Annual Meeting and Analytics Conference are premier networking events.","category":"Online","url":"https://connect.informs.org/","difficulty":"beginner","prerequisites":"basic-statistics, professional-development","topic_tags":"operations-research, professional-networking, revenue-management, decision-analysis","summary":"INFORMS is the premier professional association for operations research and analytics practitioners, offering specialized sections in revenue management, pricing, and decision analysis. The organization hosts major conferences and provides networking opportunities for researchers and industry professionals. Membership costs around $170/year and includes access to journals, conferences, and community groups.","use_cases":"Finding collaborators and mentors in operations research and analytics through specialized interest groups, Attending the annual conference to present research and learn about cutting-edge methods in revenue optimization","audience":"Early-PhD, Senior-DS"},{"id":"community-aea-econspark","type":"community","name":"AEA EconSpark","description":"American Economic Association's moderated discussion forum launched in 2018. 20,000-23,000 members. Non-members can register for approval. JOE Network essential for economics job market information.","category":"Online","url":"https://www.aeaweb.org/economics-discussion-forum","difficulty":"beginner","prerequisites":"economics-fundamentals, academic-writing","topic_tags":"professional-networking, economics-community, job-market, discussion-forum","summary":"AEA EconSpark is the American Economic Association's official discussion forum with over 20,000 economics professionals and researchers. It provides moderated discussions on economics topics and houses the essential JOE Network for job market information. The platform serves as a key networking and information-sharing hub for the economics community.","use_cases":"PhD student seeking advice on job market applications and connecting with other economists in their field, Economics researcher looking to discuss methodological questions and get feedback from peers on research ideas","audience":"Early-PhD, Curious-browser"},{"id":"community-american-marketing-association-(ama)","type":"community","name":"American Marketing Association (AMA)","description":"30,000+ members. In 2024, absorbed the Digital Analytics Association (DAA). Data & Analytics Learning Hub, Virtual Conference on Marketing Analytics, 70+ local chapters. DAA's competency frameworks and salary surveys preserved.","category":"Online","url":"https://www.ama.org/topics/data-and-analytics/","difficulty":"beginner","prerequisites":"basic-statistics, excel-or-similar","topic_tags":"marketing-analytics, professional-development, digital-analytics, community-networking","summary":"The American Marketing Association (AMA) is a 30,000+ member professional organization that absorbed the Digital Analytics Association in 2024. It offers marketing analytics education through their Data & Analytics Learning Hub, virtual conferences, and 70+ local chapters. The organization maintains competency frameworks and salary surveys for analytics professionals.","use_cases":"Finding local networking events and mentorship opportunities in marketing analytics, Accessing industry salary benchmarks and career development frameworks for digital analytics roles","audience":"Junior-DS, Curious-browser"},{"id":"community-acm-sigkdd","type":"community","name":"ACM SIGKDD","description":"Premier data mining community. SIGKDD membership ~$25/year with ACM membership. Explorations Newsletter and prestigious KDD Cup competition. KDD Conference is the top venue for data mining research.","category":"Online","url":"https://www.kdd.org/","difficulty":"beginner","prerequisites":"basic-research-methods, academic-writing","topic_tags":"data-mining, professional-development, research-community, academic-conferences, networking","summary":"ACM SIGKDD is the premier professional association for data mining and knowledge discovery researchers and practitioners. The community offers networking opportunities, access to cutting-edge research through the KDD conference, and professional development resources including newsletters and competitions. Membership provides access to the top venue for data mining research and connects members with leading experts in the field.","use_cases":"Stay current with latest data mining research trends and methodologies, Network with other data scientists and researchers at KDD conference and events","audience":"Early-PhD, Curious-browser"},{"id":"community-kdnuggets-ai,-big-data,-data-science,-ml","type":"community","name":"KDnuggets AI, Big Data, Data Science, ML","description":"~107K members. Research-focused and moderated LinkedIn group. One of the few LinkedIn groups maintaining genuine technical discussions.","category":"Online","url":"https://www.linkedin.com/groups/54257/","difficulty":"beginner","prerequisites":"linkedin-account, basic-data-terminology","topic_tags":"professional-networking, data-science-community, research-discussions, linkedin-groups, technical-forums","summary":"Large LinkedIn professional group with over 107,000 members focused on AI, big data, and machine learning discussions. Known for maintaining higher quality technical conversations compared to typical LinkedIn groups through active moderation. Serves as a networking and knowledge-sharing platform for data professionals at all levels.","use_cases":"Junior data scientist looking to connect with peers and stay updated on industry trends and discussions, Early PhD student seeking to engage with practitioners and learn about real-world applications of research methods","audience":"Junior-DS, Early-PhD"},{"id":"community-advanced-analytics,-predictive-modeling-&-statistical-analyses","type":"community","name":"Advanced Analytics, Predictive Modeling & Statistical Analyses","description":"~133K members. Quantitative professionals discussing advanced analytics and statistical modeling.","category":"Online","url":"https://www.linkedin.com/groups/2143","difficulty":"intermediate","prerequisites":"regression-analysis, hypothesis-testing, R-or-python","topic_tags":"predictive-modeling, statistical-analysis, professional-community, discussion-forum","summary":"Large LinkedIn community of quantitative professionals sharing knowledge about advanced analytics and statistical modeling techniques. Members discuss implementation challenges, share best practices, and troubleshoot complex analytical problems across industries.","use_cases":"Getting feedback on experimental design for A/B testing from experienced practitioners, Finding solutions to specific modeling challenges like handling imbalanced datasets or feature selection","audience":"Mid-DS, Senior-DS"},{"id":"community-data-science-central","type":"community","name":"Data Science Central","description":"330K+ members. DataScienceCentral.com ecosystem. Large community for data science professionals.","category":"Online","url":"https://www.linkedin.com/groups/35222/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"data-science-community, professional-networking, career-development, online-forum","summary":"Data Science Central is a large online community with over 330,000 members focused on data science professionals and enthusiasts. The platform serves as a networking hub, knowledge-sharing forum, and career development resource within the DataScienceCentral.com ecosystem. Members can connect with peers, share insights, ask questions, and stay updated on industry trends and best practices.","use_cases":"Junior data scientist seeking career advice and mentorship from experienced professionals in the field, Mid-level analyst looking to network with peers and discover new tools, techniques, or job opportunities","audience":"Junior-DS, Curious-browser"},{"id":"community-consumer-insights-interest-group","type":"community","name":"Consumer Insights Interest Group","description":"~53K members. Market research best practices and consumer insights discussions.","category":"Online","url":"https://www.linkedin.com/groups/50700/","difficulty":"beginner","prerequisites":"survey-design, basic-statistics, consumer-behavior-theory","topic_tags":"consumer-insights, market-research, community-discussion, business-intelligence, customer-analytics","summary":"A large LinkedIn professional group focused on sharing market research methodologies and consumer insight strategies. Members discuss best practices for understanding customer behavior, conducting surveys, and translating data into business recommendations. Valuable for networking and staying current with industry trends in consumer research.","use_cases":"Junior data scientist at e-commerce company needs guidance on customer segmentation approaches and survey design methodologies, Market researcher looking to connect with peers and learn about emerging tools for consumer sentiment analysis","audience":"Junior-DS, Curious-browser"},{"id":"community-women-in-operations-research-&-management-science-(worms)","type":"community","name":"Women in Operations Research & Management Science (WORMS)","description":"Active community supporting women in OR and management science fields.","category":"Online","url":"https://www.linkedin.com/groups/12398144/","difficulty":"beginner","prerequisites":"operations-research-fundamentals, professional-networking","topic_tags":"operations-research, management-science, professional-community, networking, diversity-inclusion","summary":"WORMS is an active LinkedIn community that supports women working in operations research and management science. The group provides networking opportunities, career guidance, and professional development resources for women in OR/MS fields. Members share job opportunities, research insights, and connect with peers across academia and industry.","use_cases":"Finding mentorship and career advice as a woman entering operations research, Networking with other women practitioners to share experiences and job opportunities in management science","audience":"Early-PhD, Junior-DS"},{"id":"community-new-york-open-statistical-programming-(nyhackr)","type":"community","name":"New York Open Statistical Programming (nyhackr)","description":"15,000+ members. Monthly meetups on R, Python, Julia, and open-source statistics. NYC's premier statistical programming community.","category":"Meetups","url":"https://www.meetup.com/nyhackr/","difficulty":"beginner","prerequisites":"basic-programming, statistical-concepts","topic_tags":"statistical-programming, networking, open-source, community, meetups","summary":"NYC's largest statistical programming community with 15,000+ members hosting monthly meetups on R, Python, Julia, and open-source statistics. The group provides networking opportunities, learning sessions, and knowledge sharing for data professionals at all levels. Regular events feature talks from industry experts and hands-on workshops covering practical statistical programming techniques.","use_cases":"Networking with other data professionals and statisticians in NYC area, Learning new statistical programming techniques through presentations and workshops","audience":"Junior-DS, Curious-browser"},{"id":"community-nyc-data-science","type":"community","name":"NYC Data Science","description":"10,000+ members. Monthly meetups on data science and software engineering for data.","category":"Meetups","url":"https://www.meetup.com/nyc-data-science/","difficulty":"beginner","prerequisites":"basic-python, data-visualization-concepts","topic_tags":"networking, professional-development, data-science-community, nyc-meetups","summary":"NYC Data Science is a large professional community with over 10,000 members focused on data science and software engineering practices. The group hosts monthly in-person meetups covering various data science topics, tools, and industry best practices. It serves as a networking hub for data professionals at all career levels in the New York City area.","use_cases":"Finding mentors and peers when transitioning into a data science career, Learning about new tools and methodologies through community presentations and discussions","audience":"Junior-DS, Curious-browser"},{"id":"community-nyc-experimentation-meetup","type":"community","name":"NYC Experimentation Meetup","description":"Quarterly meetups specifically for A/B testing and experimentation practitioners. Statsig-hosted.","category":"Meetups","url":"https://lu.ma/gp5xxkoh","difficulty":"intermediate","prerequisites":"hypothesis-testing, experimental-design, statistical-significance","topic_tags":"experimentation, ab-testing, networking, practitioners, nyc","summary":"Quarterly in-person meetups in NYC focused on A/B testing and experimentation practices, hosted by Statsig. Brings together practitioners to share experiences, discuss challenges, and learn about new methods in experimentation. Ideal for data scientists and researchers actively running experiments who want to connect with the local community.","use_cases":"Connect with other experimentation practitioners in NYC to discuss implementation challenges and best practices, Learn about new A/B testing methodologies and tools from industry practitioners","audience":"Mid-DS, Senior-DS"},{"id":"community-data-umbrella-nyc","type":"community","name":"Data Umbrella NYC","description":"Regular meetups focused on diversity in data science and open source contributions.","category":"Meetups","url":"https://www.meetup.com/data-umbrella/","difficulty":"beginner","prerequisites":"basic-programming, git-basics","topic_tags":"diversity-in-tech, open-source-contributions, networking, community-building, data-science-careers","summary":"Data Umbrella NYC is a community meetup group that promotes diversity and inclusion in data science while encouraging open source contributions. The group hosts regular events in New York City featuring talks, workshops, and networking opportunities. It's particularly valuable for underrepresented groups in tech and those looking to contribute to open source projects.","use_cases":"Finding mentorship and networking opportunities as an underrepresented person in data science, Learning how to make your first open source contributions to data science projects","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-nyc","type":"community","name":"PyData NYC","description":"Large community for Python data science. Monthly meetups and annual conference.","category":"Meetups","url":"https://www.meetup.com/PyDataNYC/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python-community, data-science-meetups, networking, new-york, professional-development","summary":"PyData NYC is a large community focused on Python data science with monthly meetups and an annual conference. It brings together data scientists, researchers, and Python enthusiasts to share knowledge, network, and learn about the latest tools and techniques. The community serves as a hub for professional development and staying current with Python data science trends.","use_cases":"Finding networking opportunities and job connections in the NYC data science community, Learning about new Python libraries and best practices from industry practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-nyc-asa-chapter","type":"community","name":"NYC ASA Chapter","description":"American Statistical Association New York chapter. Quarterly events for statistics professionals.","category":"Meetups","url":"https://community.amstat.org/nycasa/home","difficulty":"beginner","prerequisites":"basic-statistics, networking-skills","topic_tags":"professional-networking, statistics-community, new-york, career-development","summary":"The American Statistical Association's New York chapter hosts quarterly networking events for statistics professionals in the NYC area. These events provide opportunities to connect with peers, learn about industry trends, and advance careers in statistics and data science. Perfect for professionals at all levels looking to build their network in the New York statistics community.","use_cases":"Meeting other statisticians and data scientists in NYC for career networking and job opportunities, Learning about current statistical methods and industry applications through presentations and informal discussions","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-boston-cambridge","type":"community","name":"PyData Boston-Cambridge","description":"Large community for Python data science. Monthly meetups. PyData Boston 2025 Dec 8-10 at Microsoft NERD.","category":"Meetups","url":"https://www.meetup.com/PyData-Boston-Cambridge/","difficulty":"beginner","prerequisites":"python-basics, pandas-fundamentals","topic_tags":"community, meetups, boston, networking, python-data-science","summary":"PyData Boston-Cambridge is a large community focused on Python data science with regular monthly meetups and networking opportunities. The community hosts an annual conference (PyData Boston 2025 on Dec 8-10 at Microsoft NERD) bringing together practitioners across experience levels. Members share knowledge, discuss tools and techniques, and connect with other Python data professionals in the Boston area.","use_cases":"Finding local Python data science professionals to network with and learn from, Attending talks and workshops on the latest Python data science tools and best practices","audience":"Junior-DS, Curious-browser"},{"id":"community-boston-ai-professionals","type":"community","name":"Boston AI Professionals","description":"Large community for technical AI/ML talks in the Boston area.","category":"Meetups","url":"https://www.meetup.com/boston-ai/","difficulty":"beginner","prerequisites":"basic-networking-skills, professional-communication","topic_tags":"meetups, networking, boston, ai-community, professional-development","summary":"Boston AI Professionals is a large community that hosts technical AI/ML presentations and networking events in the Boston metropolitan area. The group brings together practitioners, researchers, and enthusiasts to share knowledge and build professional connections. Members can attend talks on cutting-edge AI topics and connect with peers in the local tech ecosystem.","use_cases":"Finding local AI/ML professionals to network with when starting a career in Boston, Staying current on AI trends and techniques through regular technical presentations","audience":"Junior-DS, Curious-browser"},{"id":"community-boston-dbt-meetup","type":"community","name":"Boston dbt Meetup","description":"1,085+ members. Monthly meetups for analytics engineering and dbt practitioners.","category":"Meetups","url":"https://www.meetup.com/boston-dbt-meetup/","difficulty":"beginner","prerequisites":"dbt-core, SQL-basics","topic_tags":"dbt, analytics-engineering, data-transformation, community, boston","summary":"Monthly meetup group for analytics engineers and dbt practitioners in the Boston area with over 1,000 members. The community focuses on sharing best practices, discussing data transformation workflows, and networking among analytics professionals. Participants learn about modern data stack tools and techniques through presentations and discussions.","use_cases":"Connect with local analytics engineers to share dbt implementation experiences, Learn about new dbt features and community packages from practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-asa-boston-chapter","type":"community","name":"ASA Boston Chapter","description":"American Statistical Association Boston chapter. Quarterly events with pharma/biostat focus.","category":"Meetups","url":"https://community.amstat.org/bostonchapter/home","difficulty":"beginner","prerequisites":"basic-statistics, hypothesis-testing","topic_tags":"professional-networking, biostatistics, pharma, meetups, boston","summary":"The ASA Boston Chapter organizes quarterly meetups for statisticians and data professionals in the Boston area. Events focus primarily on pharmaceutical and biostatistics applications, featuring presentations from industry practitioners and researchers. A valuable networking opportunity for connecting with the local statistical community.","use_cases":"Networking with biostatisticians and pharma professionals in Boston, Learning about statistical applications in pharmaceutical research","audience":"Junior-DS, Curious-browser"},{"id":"community-data-science-dc","type":"community","name":"Data Science DC","description":"Part of Data Community DC (dc2.org). Monthly technical talks on ML and AI.","category":"Meetups","url":"https://www.meetup.com/data-science-dc/","difficulty":"beginner","prerequisites":"basic-python, statistics-fundamentals","topic_tags":"meetups, machine-learning, networking, washington-dc, community","summary":"Data Science DC is a monthly meetup series in Washington DC focused on technical presentations about machine learning and AI. It's part of the larger Data Community DC network and provides opportunities for data scientists to learn about new methods and network with peers. The talks typically cover practical applications and emerging trends in the field.","use_cases":"Finding local data science networking opportunities in Washington DC area, Learning about current ML/AI trends through technical presentations","audience":"Junior-DS, Curious-browser"},{"id":"community-statistical-seminars-dc","type":"community","name":"Statistical Seminars DC","description":"Part of Data Community DC. Statistical methods and methodology discussions.","category":"Meetups","url":"https://www.dc2.org/","difficulty":"intermediate","prerequisites":"basic-statistics, hypothesis-testing, experimental-design","topic_tags":"statistical-methods, methodology, DC-community, seminars, statistical-theory","summary":"Statistical Seminars DC is a meetup group focused on statistical methods and methodology discussions as part of the broader Data Community DC. The group provides a forum for practitioners and researchers to discuss statistical approaches, share best practices, and explore methodological challenges. It's designed for statisticians and data scientists looking to deepen their understanding of statistical theory and application.","use_cases":"Learning about new statistical methods and their practical applications from local experts, Networking with statisticians and methodologists in the Washington DC area while discussing current research","audience":"Mid-DS, Senior-DS"},{"id":"community-r-govys","type":"community","name":"R Govys","description":"R for government practitioners. Focus on R programming for public sector data analysis.","category":"Meetups","url":"https://rgovys.github.io/","difficulty":"beginner","prerequisites":"R-programming, public-sector-data","topic_tags":"R-programming, government-analysis, meetups, washington-dc, public-sector","summary":"R Govys is a Washington DC-based meetup community for government practitioners using R for data analysis. The group focuses on applying R programming techniques to public sector datasets and policy analysis. Members share experiences with government-specific data challenges and R solutions for public administration.","use_cases":"Government analyst learning R techniques for budget analysis and reporting, Public health researcher connecting with peers using R for epidemiological studies","audience":"Junior-DS, Curious-browser"},{"id":"community-data-visualization-dc","type":"community","name":"Data Visualization DC","description":"Part of Data Community DC. Data visualization and storytelling with data.","category":"Meetups","url":"https://www.meetup.com/Data-Visualization-DC/","difficulty":"beginner","prerequisites":"basic-plotting, data-storytelling-principles","topic_tags":"data-visualization, storytelling, meetups, networking, washington-dc","summary":"Data Visualization DC is a meetup group focused on data visualization techniques and storytelling with data, part of the broader Data Community DC network. The group brings together practitioners to share visualization best practices, tools, and presentation techniques. It's ideal for anyone looking to improve their data communication skills and connect with the local data visualization community.","use_cases":"Learning new visualization tools and techniques from community presentations, Networking with other data professionals in the Washington DC area","audience":"Junior-DS, Curious-browser"},{"id":"community-datakind-dc","type":"community","name":"DataKind DC","description":"Part of Data Community DC. Data science for social good projects.","category":"Meetups","url":"https://www.datakind.org/chapters/datakind-dc/","difficulty":"beginner","prerequisites":"python-pandas, data-visualization, statistical-analysis","topic_tags":"data-for-good, volunteer-projects, social-impact, community-engagement, washington-dc","summary":"DataKind DC is a volunteer organization that connects data scientists with nonprofits and social organizations to tackle social challenges using data. Members work on pro-bono projects ranging from predicting homelessness to optimizing food distribution. It's part of the broader Data Community DC ecosystem and provides opportunities to apply data skills for social good while networking with like-minded professionals.","use_cases":"Contributing data science skills to help a local nonprofit analyze their program effectiveness, Networking with other data professionals while working on meaningful social impact projects","audience":"Junior-DS, Curious-browser"},{"id":"community-toronto-data-science-&-big-data","type":"community","name":"Toronto Data Science & Big Data","description":"17,380+ members. WeCloudData workshops. Largest data science meetup in Canada.","category":"Meetups","url":"https://www.meetup.com/Toronto-Data-Science-Big-Data-Meetup/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"meetups, networking, toronto, data-science, community","summary":"Toronto's largest data science meetup community with over 17,000 members, featuring WeCloudData workshops and regular networking events. Provides opportunities to learn from industry practitioners, discover new tools and techniques, and connect with other data professionals in the Greater Toronto Area. Offers both beginner-friendly introductions and advanced technical presentations.","use_cases":"Finding local data science networking opportunities and workshops in Toronto, Learning about industry trends and best practices from Toronto-based data professionals","audience":"Junior-DS, Curious-browser"},{"id":"community-toronto-cognitive,-ai-&-data-science","type":"community","name":"Toronto Cognitive, AI & Data Science","description":"12,821+ members. Hands-on meetups. One of the largest Canadian AI/data groups.","category":"Meetups","url":"https://www.meetup.com/toronto-cognitive-ai-data-science-meetup/","difficulty":"beginner","prerequisites":"basic-networking, python-fundamentals","topic_tags":"meetups, toronto, ai-community, networking, canada","summary":"Toronto Cognitive, AI & Data Science is one of Canada's largest AI and data science meetup communities with over 12,800 members. The group focuses on hands-on meetups covering machine learning, data science, and AI topics. It provides networking opportunities and practical learning experiences for data professionals at all levels in the Toronto area.","use_cases":"Finding local networking opportunities and meeting other data professionals in Toronto, Attending hands-on workshops and talks to learn new AI/ML techniques from practitioners","audience":"Junior-DS, Curious-browser"},{"id":"community-toronto-people-analytics","type":"community","name":"Toronto People Analytics","description":"615+ members. HR analytics and people data discussions.","category":"Meetups","url":"https://www.meetup.com/toronto-people-analytics/","difficulty":"beginner","prerequisites":"descriptive-statistics, data-visualization, excel-or-sql","topic_tags":"hr-analytics, people-analytics, meetups, toronto, networking","summary":"A Toronto-based meetup community with 615+ members focused on HR analytics and people data discussions. The group brings together professionals working with employee data, workforce analytics, and human resources metrics. Members share experiences, learn best practices, and network around people analytics challenges in the workplace.","use_cases":"Networking with local HR analytics professionals and learning about industry trends in employee data analysis, Getting advice on implementing people analytics projects like turnover prediction or performance measurement systems","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-toronto","type":"community","name":"PyData Toronto","description":"Python for data science community in Toronto.","category":"Meetups","url":"https://www.meetup.com/PyData-Toronto/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python-community, toronto-meetups, data-science-networking, professional-development","summary":"PyData Toronto is a local community meetup for Python practitioners in data science, analytics, and machine learning. The group hosts regular events featuring talks, workshops, and networking opportunities focused on Python tools and techniques for data work. It's ideal for connecting with peers, learning about new libraries, and staying current with Python ecosystem developments.","use_cases":"Finding local Python data science professionals for networking and career advice, Learning about new Python packages and best practices through community presentations","audience":"Junior-DS, Mid-DS"},{"id":"community-growthto","type":"community","name":"GrowthTO","description":"2,349+ members. Growth marketing and analytics community in Toronto.","category":"Meetups","url":"https://www.meetup.com/growthto/","difficulty":"beginner","prerequisites":"basic-analytics, excel-or-sql","topic_tags":"growth-marketing, community, networking, toronto, analytics","summary":"GrowthTO is a 2,349+ member community focused on growth marketing and analytics in Toronto. The group brings together practitioners, analysts, and marketers to share insights, best practices, and networking opportunities in the growth space. It's a valuable resource for learning about experimentation, user acquisition, and data-driven marketing strategies.","use_cases":"Finding local growth marketing professionals to network with and learn from, Discovering job opportunities and career advice in Toronto's tech scene","audience":"Junior-DS, Curious-browser"},{"id":"community-sf-bay-area-machine-learning","type":"community","name":"SF Bay Area Machine Learning","description":"10,000+ members. Monthly meetups hosted at tech companies. Industry ML discussions.","category":"Meetups","url":"https://www.meetup.com/SF-Bay-Area-Machine-Learning/","difficulty":"beginner","prerequisites":"basic-machine-learning, networking-skills","topic_tags":"networking, san-francisco, industry-ml, meetups","summary":"Large machine learning community in the San Francisco Bay Area with over 10,000 members and monthly meetups hosted at major tech companies. The group focuses on industry applications of ML rather than academic research. It provides networking opportunities and practical discussions about real-world ML implementation challenges.","use_cases":"Connect with other ML practitioners in the Bay Area tech scene, Learn about industry best practices and real-world ML applications from company presentations","audience":"Junior-DS, Mid-DS"},{"id":"community-pydata-san-francisco","type":"community","name":"PyData San Francisco","description":"5,000+ members. Monthly meetups on Python, R, Julia. Part of NumFOCUS program.","category":"Meetups","url":"https://www.meetup.com/PyData-SanFrancisco/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"meetups, networking, python-community, san-francisco, data-science-events","summary":"PyData San Francisco is a large community of 5,000+ data professionals hosting monthly meetups focused on Python, R, and Julia programming. The group is part of the NumFOCUS ecosystem and provides networking opportunities, technical talks, and learning sessions for data scientists and analysts in the Bay Area.","use_cases":"networking with local data professionals and finding job opportunities, learning about new Python packages and tools through technical presentations","audience":"Junior-DS, Curious-browser"},{"id":"community-bay-area-user-group","type":"community","name":"Bay Area useR Group","description":"4,000+ members. Monthly meetups for R programming and statistical computing.","category":"Meetups","url":"https://www.meetup.com/R-Users/","difficulty":"beginner","prerequisites":"R-basics, statistical-computing","topic_tags":"R-programming, statistical-computing, networking, professional-development, bay-area","summary":"The Bay Area useR Group is a large community of 4,000+ R programming enthusiasts who meet monthly to share knowledge and best practices in statistical computing. The meetups provide networking opportunities and learning sessions for R users at all skill levels in the San Francisco Bay Area.","use_cases":"Connect with other R practitioners in the Bay Area for career networking and knowledge sharing, Learn new R techniques and packages through presentations and workshops at monthly meetups","audience":"Junior-DS, Curious-browser"},{"id":"community-data-science-salon-sf","type":"community","name":"Data Science Salon SF","description":"1,783 members. Monthly meetups for senior practitioners. Professional-level discussions.","category":"Meetups","url":"https://www.meetup.com/data-science-salon-sf/","difficulty":"intermediate","prerequisites":"data-analysis-experience, professional-communication, statistics-fundamentals","topic_tags":"networking, professional-development, san-francisco, data-science-community","summary":"Data Science Salon SF is a monthly meetup for senior data science practitioners in San Francisco with 1,783 members. The group focuses on professional-level discussions and networking opportunities for experienced data scientists. It provides a platform for sharing industry insights, discussing advanced methodologies, and building professional connections in the Bay Area tech scene.","use_cases":"Senior data scientist looking to network with peers and discuss advanced techniques, Mid-level practitioner seeking mentorship and career advancement opportunities in SF","audience":"Mid-DS, Senior-DS"},{"id":"community-informs-san-francisco-chapter","type":"community","name":"INFORMS San Francisco Chapter","description":"Monthly meetups for operations research and analytics professionals.","category":"Meetups","url":"https://connect.informs.org/sanfrancisco/home","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-concepts","topic_tags":"operations-research, analytics, networking, san-francisco, meetups","summary":"The INFORMS San Francisco Chapter hosts monthly meetups for operations research and analytics professionals in the Bay Area. These gatherings provide opportunities to learn about cutting-edge OR methods, network with industry practitioners, and stay current with analytics trends. Members include academics, consultants, and industry professionals working in optimization, forecasting, and decision science.","use_cases":"Junior data scientist looking to network with senior practitioners and learn about operations research applications in tech companies, Academic researcher seeking to connect with industry professionals and understand real-world applications of OR methods","audience":"Junior-DS, Curious-browser"},{"id":"community-sf-bay-area-asa-chapter","type":"community","name":"SF Bay Area ASA Chapter","description":"American Statistical Association Bay Area chapter. Quarterly events for statistics professionals.","category":"Meetups","url":"https://community.amstat.org/sfbayareaasa/home","difficulty":"beginner","prerequisites":"basic-statistics, professional-experience","topic_tags":"networking, statistics, professional-development, bay-area, meetups","summary":"The SF Bay Area ASA Chapter is the local American Statistical Association chapter serving statistics professionals in the San Francisco Bay Area. They host quarterly events featuring presentations, networking opportunities, and professional development activities. This community connects statisticians, data scientists, and analytics professionals across academia and industry.","use_cases":"Networking with other statistics professionals in the Bay Area tech industry, Learning about new statistical methods and industry applications through quarterly presentations","audience":"Junior-DS, Mid-DS"},{"id":"community-seattle-ai-and-ml-group","type":"community","name":"Seattle AI and ML Group","description":"20,000+ members. Deep tech talks on AI/GenAI. Food/drinks at venues. One of the largest in the country\u2014events regularly sell out.","category":"Meetups","url":"https://www.meetup.com/seattle-ai-ml/","difficulty":"beginner","prerequisites":"basic-networking, interest-in-ai","topic_tags":"ai-community, seattle-meetups, networking, machine-learning, generative-ai","summary":"Large Seattle-based meetup group with over 20,000 members focused on AI and machine learning. Features deep technical talks on AI/GenAI topics with networking opportunities over food and drinks. Events frequently sell out, making it one of the largest AI communities in the country.","use_cases":"Junior data scientist new to Seattle looking to network with AI practitioners and learn about industry trends, Curious browser wanting to explore AI concepts through accessible community talks before diving into technical materials","audience":"Junior-DS, Curious-browser"},{"id":"community-seattle-data-analytics-ml","type":"community","name":"Seattle Data/Analytics/ML","description":"5,550 members. Lightning talks and workshops at tech companies.","category":"Meetups","url":"https://www.meetup.com/seattle-data-analytics-ml/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"seattle-meetup, networking, lightning-talks, tech-workshops","summary":"Seattle Data/Analytics/ML is a large meetup community with 5,550 members that hosts lightning talks and workshops at tech companies. It provides networking opportunities and learning experiences for data professionals in the Seattle area. The format includes short presentations and hands-on workshops covering current industry practices.","use_cases":"Finding networking opportunities with other data professionals in Seattle, Learning about industry best practices through company-hosted workshops","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-seattle","type":"community","name":"PyData Seattle","description":"2,423 members. Monthly meetups plus annual conference planned for 2025.","category":"Meetups","url":"https://www.meetup.com/PyData-Seattle/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python, data-science, networking, seattle, community","summary":"PyData Seattle is a local community of 2,423 data science professionals and enthusiasts in the Seattle area. The group hosts monthly meetups and is planning an annual conference for 2025, providing opportunities for learning, networking, and sharing data science knowledge. It's part of the global PyData network focused on Python tools for data analysis and scientific computing.","use_cases":"Finding local data scientists to network with and learn from in the Seattle area, Discovering job opportunities and recruiting talent in the Pacific Northwest tech scene","audience":"Junior-DS, Curious-browser"},{"id":"community-analytics.club-seattle","type":"community","name":"Analytics.Club Seattle","description":"926 members. Expert talks, online and offline events.","category":"Meetups","url":"https://www.meetup.com/Analytics-Club-Seattle/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-concepts","topic_tags":"networking, seattle, meetups, analytics, community","summary":"Analytics.Club Seattle is a 926-member community that hosts expert talks and both online and offline events focused on analytics and data science. The club provides networking opportunities and knowledge sharing for analytics professionals in the Seattle area. Members can attend presentations, participate in discussions, and connect with peers across different experience levels.","use_cases":"Finding local networking opportunities with other analytics professionals in Seattle, Attending expert talks to learn about new methods and industry trends","audience":"Junior-DS, Curious-browser"},{"id":"community-informs-pnw-chapter","type":"community","name":"INFORMS PNW Chapter","description":"Pacific Northwest operations research chapter. Regular events for OR professionals.","category":"Meetups","url":"https://connect.informs.org/pacificnorthwest/home","difficulty":"beginner","prerequisites":"operations-research-basics, professional-networking","topic_tags":"operations-research, networking, pacific-northwest, professional-development, meetups","summary":"INFORMS Pacific Northwest Chapter is a regional professional organization for operations research practitioners and researchers. The chapter hosts regular events, talks, and networking opportunities for OR professionals in the Seattle area and broader Pacific Northwest region. It serves as a hub for connecting academics, industry practitioners, and students working in optimization, analytics, and decision sciences.","use_cases":"Finding networking opportunities with other operations research professionals in the Pacific Northwest, Attending technical talks and workshops to learn about new OR methods and industry applications","audience":"Curious-browser, Junior-DS"},{"id":"community-data-science-salon-la","type":"community","name":"Data Science Salon LA","description":"711 members. Media/entertainment focus. Senior practitioners in LA area.","category":"Meetups","url":"https://www.meetup.com/data-science-salon-la/","difficulty":"intermediate","prerequisites":"python-programming, data-analysis-experience, professional-networking","topic_tags":"data-science-community, los-angeles, media-entertainment, networking, meetups","summary":"Data Science Salon LA is a professional meetup community with 711 members focused on data science applications in media and entertainment. The group brings together senior practitioners in the Los Angeles area for networking and knowledge sharing. It serves as a platform for career development and staying current with industry trends specific to the entertainment sector.","use_cases":"Finding mentorship and career guidance from senior data scientists in LA's entertainment industry, Networking with peers working on similar problems in streaming, gaming, or media analytics","audience":"Mid-DS, Senior-DS"},{"id":"community-los-angeles-ai-llms-ml","type":"community","name":"Los Angeles AI/LLMs/ML","description":"2,733 members. AI/ML tech talks in the LA area.","category":"Meetups","url":"https://www.meetup.com/los-angeles-ai-ml/","difficulty":"beginner","prerequisites":"basic-python, scikit-learn","topic_tags":"meetups, los-angeles, networking, ai-community, tech-talks","summary":"Los Angeles AI/LLMs/ML is a 2,733-member meetup community focused on artificial intelligence and machine learning tech talks in the LA area. The group provides networking opportunities and educational presentations for AI/ML practitioners at all levels. It serves as a local hub for staying current with industry trends and connecting with peers in the Southern California tech scene.","use_cases":"Finding local networking opportunities to connect with other AI/ML practitioners in Los Angeles, Attending tech talks to learn about latest developments in LLMs and machine learning from industry experts","audience":"Junior-DS, Curious-browser"},{"id":"community-datacon-la-users-group","type":"community","name":"DataCon LA Users Group","description":"3,347 members. Annual DataCon LA conference and regular meetups.","category":"Meetups","url":"https://www.meetup.com/datacon-la/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"networking, meetups, los-angeles, community, data-science","summary":"DataCon LA Users Group is a 3,347-member community centered around the annual DataCon LA conference with regular local meetups. The group connects data professionals in the Los Angeles area through networking events, technical presentations, and knowledge sharing. It serves as a platform for both newcomers and experienced practitioners to build professional relationships and stay current with industry trends.","use_cases":"Finding local data science professionals to network with and learn from in the LA area, Discovering job opportunities and career advice from established data scientists in Los Angeles","audience":"Junior-DS, Curious-browser"},{"id":"community-socal-r-users-group","type":"community","name":"SoCal R Users Group","description":"2,000+ members. R programming events in Southern California.","category":"Meetups","url":"https://www.meetup.com/socal-rug/","difficulty":"beginner","prerequisites":"R-basics, data-manipulation","topic_tags":"R-programming, networking, meetups, southern-california","summary":"SoCal R Users Group is a 2,000+ member community organizing R programming events in Southern California. The group provides networking opportunities, learning sessions, and local connections for R practitioners. It serves as a regional hub for sharing knowledge, finding collaborators, and staying updated on R ecosystem developments.","use_cases":"Finding local R programming mentors and networking with other data professionals, Learning about R best practices and new packages through community presentations","audience":"Junior-DS, Curious-browser"},{"id":"community-southern-california-asa-chapter","type":"community","name":"Southern California ASA Chapter","description":"American Statistical Association chapter for Southern California.","category":"Meetups","url":"https://community.amstat.org/socalasa/home","difficulty":"beginner","prerequisites":"basic-statistics, r-programming","topic_tags":"professional-networking, statistics-community, southern-california, meetups","summary":"The Southern California ASA Chapter is a regional branch of the American Statistical Association serving the Los Angeles area and surrounding regions. The chapter organizes regular meetups, workshops, and networking events for statisticians, data scientists, and analytics professionals. Members can attend talks on current statistical methods, connect with industry peers, and stay updated on local job opportunities and professional development.","use_cases":"Finding local networking opportunities and mentorship as a new data scientist in the LA area, Attending technical talks and workshops to learn about emerging statistical methods and industry applications","audience":"Junior-DS, Curious-browser"},{"id":"community-austin-ai,-genai-and-ml","type":"community","name":"Austin AI, GenAI and ML","description":"6,000+ members. Tech talks at Oracle HQ. Very active community.","category":"Meetups","url":"https://www.meetup.com/austin-ai-ml/","difficulty":"beginner","prerequisites":"basic-networking, presentation-skills","topic_tags":"austin-meetups, ai-community, tech-talks, networking","summary":"Austin's largest AI and machine learning meetup with over 6,000 members, hosting regular tech talks at Oracle headquarters. The community is very active and provides networking opportunities for AI practitioners at all levels. Members can attend presentations on cutting-edge AI topics and connect with local tech professionals.","use_cases":"Finding local AI practitioners to collaborate with on projects, Staying updated on Austin's AI job market and company landscape","audience":"Junior-DS, Curious-browser"},{"id":"community-women-in-data-science-and-ai---atx","type":"community","name":"Women in Data Science and AI - ATX","description":"1,402 members. Women-focused meetups, socials, and workshops at Atlassian.","category":"Meetups","url":"https://www.meetup.com/women-in-data-science-atx/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-interest","topic_tags":"community, networking, women-in-tech, austin, meetups","summary":"Women in Data Science and AI - ATX is a 1,400+ member community in Austin hosting women-focused meetups, social events, and educational workshops at Atlassian. The group provides networking opportunities, skill-building sessions, and career support for women in data science and AI fields. It serves as a local hub for professional development and community building in the Austin tech scene.","use_cases":"Finding mentorship and networking opportunities as a woman entering data science in Austin, Attending workshops to learn new technical skills while building professional relationships","audience":"Junior-DS, Curious-browser"},{"id":"community-austin-data-meetup","type":"community","name":"Austin Data Meetup","description":"1,500+ members. Monthly happy hours and networking for data professionals.","category":"Meetups","url":"https://www.meetup.com/austin-data-meetup/","difficulty":"beginner","prerequisites":"basic-networking-skills, data-science-fundamentals","topic_tags":"networking, austin, data-professionals, meetups, community","summary":"Austin Data Meetup is a local community of 1,500+ data professionals who gather monthly for happy hours and networking events. The group provides opportunities to connect with peers, share experiences, and build professional relationships in the Austin tech scene. It's ideal for data practitioners at all levels looking to expand their network and stay connected with the local data community.","use_cases":"New data scientist relocating to Austin looking to build professional network, Mid-level analyst seeking mentorship and career advice from local data professionals","audience":"Junior-DS, Mid-DS"},{"id":"community-denver-data-dudes-and-dudettes","type":"community","name":"Denver Data Dudes and Dudettes","description":"1,500+ members. Monthly happy hours with a strong Slack community extending conversations beyond meetups. Tight-knit community feel.","category":"Meetups","url":"https://www.meetup.com/denver-data-dudes-and-dudettes/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"denver-community, data-science-networking, local-meetups, career-development","summary":"Denver Data Dudes and Dudettes is a 1,500+ member community focused on data science networking in the Denver area. The group hosts monthly happy hours and maintains an active Slack workspace for ongoing discussions. It provides a tight-knit community environment for data professionals to connect, share knowledge, and advance their careers.","use_cases":"Finding local data science mentors and peers when starting a career in Denver, Staying connected with the Denver data community while job searching or changing roles","audience":"Junior-DS, Curious-browser"},{"id":"community-denver-mlops-community","type":"community","name":"Denver MLOps Community","description":"800+ members. MLOps practices and production ML discussions.","category":"Meetups","url":"https://www.meetup.com/denver-mlops/","difficulty":"intermediate","prerequisites":"docker-containers, model-deployment, CI-CD-pipelines","topic_tags":"mlops, production-ml, model-deployment, community, denver","summary":"A local Denver community of 800+ machine learning practitioners focused on MLOps practices and production ML systems. Members share experiences, discuss tooling, and network around operationalizing machine learning models in real-world environments. Great for learning from peers and staying current with MLOps trends.","use_cases":"Connect with local ML engineers to discuss model deployment challenges and solutions, Learn about MLOps tools and best practices from practitioners in your area","audience":"Junior-DS, Mid-DS"},{"id":"community-denver-data-science-and-ml","type":"community","name":"Denver Data Science and ML","description":"2,500+ members. Talks plus weekend study groups for data scientists.","category":"Meetups","url":"https://www.meetup.com/denver-data-science/","difficulty":"beginner","prerequisites":"basic-python, statistics-fundamentals","topic_tags":"networking, community, professional-development, denver, study-groups","summary":"Denver Data Science and ML is a 2,500+ member community offering regular talks and weekend study groups for data scientists. The group provides networking opportunities and collaborative learning environments for practitioners at all levels. Members can attend presentations on current topics and participate in structured study sessions to develop skills together.","use_cases":"Finding local data scientists to network with and learn from in Denver, Joining study groups to work through technical concepts with peers on weekends","audience":"Junior-DS, Curious-browser"},{"id":"community-r-ladies-aurora","type":"community","name":"R-Ladies Aurora","description":"500+ members. R programming for women in the Denver/Aurora area. Hybrid events.","category":"Meetups","url":"https://www.meetup.com/rladies-aurora/","difficulty":"beginner","prerequisites":"R-basics, data-manipulation","topic_tags":"R-programming, women-in-tech, networking, denver-meetups","summary":"R-Ladies Aurora is a 500+ member community supporting women and gender minorities in R programming in the Denver/Aurora area. The group hosts hybrid events combining technical workshops, networking opportunities, and skill-building sessions. It provides a supportive environment for learning R programming and connecting with other data professionals in the region.","use_cases":"Finding local R programming mentorship and networking opportunities as a woman entering data science, Attending beginner-friendly R workshops and meetups to build programming skills in a supportive community setting","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-chicago","type":"community","name":"PyData Chicago","description":"6,325 members. Monthly hybrid events. IBM, Allstate, Civis sponsors.","category":"Meetups","url":"https://www.meetup.com/PyData-Chicago/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"meetups, chicago, python-community, networking, data-science-events","summary":"PyData Chicago is a large data science meetup with over 6,300 members that hosts monthly hybrid events sponsored by major companies like IBM and Allstate. The community brings together Python users working in data science, analytics, and research across the Chicago area. Members can attend talks, network with peers, and learn about new tools and techniques in the Python data ecosystem.","use_cases":"Finding local data science professionals to network with and learn from their experiences, Discovering new Python libraries and best practices through community presentations and workshops","audience":"Junior-DS, Curious-browser"},{"id":"community-chicago-data,-analytics-&-ai","type":"community","name":"Chicago Data, Analytics & AI","description":"3,000+ members. Industry talks on data and AI in Chicago.","category":"Meetups","url":"https://www.meetup.com/chicago-data-analytics-ai/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-concepts","topic_tags":"networking, chicago, meetups, data-science-community, professional-development","summary":"Chicago Data, Analytics & AI is a large professional meetup community with over 3,000 members focused on data science and AI topics. The group hosts regular industry talks and networking events in the Chicago area. It serves as a platform for data professionals to learn about current trends, share experiences, and build professional connections.","use_cases":"Finding local networking opportunities and learning about industry trends in Chicago's data science scene, Connecting with other data professionals for career development and knowledge sharing","audience":"Junior-DS, Mid-DS"},{"id":"community-odsc-chicago","type":"community","name":"ODSC Chicago","description":"2,000+ members. Open Data Science Conference Chicago community with in-person events.","category":"Meetups","url":"https://www.meetup.com/odsc-chicago/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"chicago-meetups, data-science-community, networking, professional-development","summary":"ODSC Chicago is a 2,000+ member community organizing in-person Open Data Science Conference events in the Chicago area. The group provides networking opportunities, technical presentations, and professional development for data scientists at all career levels. Members can attend talks, workshops, and social events to stay current with industry trends and build professional connections.","use_cases":"Finding local networking opportunities and meeting other data scientists in Chicago, Attending technical talks and workshops to learn new tools and methodologies","audience":"Junior-DS, Mid-DS"},{"id":"community-uchicago-data-science-institute","type":"community","name":"UChicago Data Science Institute","description":"2,000+ members. Academic-industry bridge events at University of Chicago.","category":"Meetups","url":"https://datascience.uchicago.edu/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"networking, academic-industry, chicago, events, career-development","summary":"The UChicago Data Science Institute community brings together over 2,000 academics and industry professionals through regular meetups and events. It serves as a bridge between university research and practical data science applications in the Chicago area. Members can attend talks, workshops, and networking events to learn about cutting-edge research and industry best practices.","use_cases":"Junior data scientist looking to network with peers and learn about industry trends in Chicago, PhD student seeking connections between academic research and real-world applications","audience":"Junior-DS, Early-PhD"},{"id":"community-strategic-data-analytics-users-chicago","type":"community","name":"Strategic Data/Analytics Users Chicago","description":"4,427 members. Business analytics discussions in Chicago.","category":"Meetups","url":"https://www.meetup.com/strategic-data-analytics-users-chicago/","difficulty":"beginner","prerequisites":"basic-statistics, business-analytics-fundamentals","topic_tags":"meetups, chicago, business-analytics, networking, community","summary":"A Chicago-based meetup group with over 4,400 members focused on business analytics discussions and networking. The community brings together data professionals to share experiences, learn about industry trends, and connect with peers in the Chicago area. It serves as a platform for both learning and professional development in the analytics field.","use_cases":"Finding local networking opportunities with other data professionals in Chicago, Learning about business analytics trends and best practices from community discussions","audience":"Junior-DS, Curious-browser"},{"id":"community-data-science-atl","type":"community","name":"Data Science ATL","description":"5,445+ members. Southeast's largest data science ecosystem. Monthly meetups covering ML, analytics, and data engineering.","category":"Meetups","url":"https://www.meetup.com/data-science-atl/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"meetups, networking, atlanta, community, data-science","summary":"Data Science ATL is the Southeast's largest data science community with over 5,400 members. The group hosts monthly meetups covering machine learning, analytics, and data engineering topics. It provides networking opportunities and knowledge sharing for data professionals at all career levels in the Atlanta area.","use_cases":"Finding local networking opportunities when starting a data science career in Atlanta, Connecting with other data professionals to learn about job opportunities and industry trends","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-atlanta","type":"community","name":"PyData Atlanta","description":"3,000+ members. Python for data analysis and scientific computing in Atlanta. Part of the global PyData network.","category":"Meetups","url":"https://www.meetup.com/pydata-atlanta/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python-meetups, data-science-community, atlanta-networking, scientific-computing","summary":"PyData Atlanta is a local chapter of the global PyData network with over 3,000 members focused on Python applications in data analysis and scientific computing. The community provides networking opportunities, technical presentations, and knowledge sharing for data professionals in the Atlanta area. Members range from beginners learning Python data tools to experienced practitioners sharing advanced techniques.","use_cases":"Finding local data science professionals for networking and career opportunities, Attending technical talks to learn new Python libraries and data analysis methods","audience":"Junior-DS, Mid-DS"},{"id":"community-atlanta-ai-developers-group","type":"community","name":"Atlanta AI Developers Group","description":"3,350 members meeting weekly. Active AI and ML community in Atlanta covering practical applications and latest research.","category":"Meetups","url":"https://www.meetup.com/atlanta-ai-developers/","difficulty":"beginner","prerequisites":"basic-python, machine-learning-fundamentals","topic_tags":"community, networking, atlanta, meetups, ai-ml","summary":"Large active AI/ML meetup community in Atlanta with 3,350 members holding weekly meetings. Covers both practical applications and latest research developments in artificial intelligence and machine learning. Great resource for networking, learning, and staying current with industry trends.","use_cases":"Junior data scientist new to Atlanta looking to network and learn from local practitioners, Mid-career professional wanting to stay updated on latest AI research and connect with Atlanta tech community","audience":"Junior-DS, Mid-DS"},{"id":"community-data-science-study-group:-south-florida","type":"community","name":"Data Science Study Group: South Florida","description":"2,359 members. Miami's primary data science community for learning and networking.","category":"Meetups","url":"https://www.meetup.com/data-science-study-group/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"data-science-community, networking, miami, meetups, learning-groups","summary":"South Florida's largest data science meetup group with nearly 2,400 members focused on learning and professional networking. The community provides opportunities for knowledge sharing, career development, and staying current with industry trends in the Miami tech scene. Members range from beginners to experienced practitioners looking to connect with local data science professionals.","use_cases":"Junior data scientist new to Miami looking to build professional network and learn from experienced practitioners, Career changer transitioning into data science seeking mentorship and hands-on learning opportunities","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-miami","type":"community","name":"PyData Miami","description":"1,788 members. Python data science community in South Florida with monthly events.","category":"Meetups","url":"https://www.meetup.com/pydata-miami/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python-community, data-science-networking, miami-meetups, professional-development","summary":"PyData Miami is a local chapter of the global PyData community focused on Python-based data science tools and techniques. The group hosts monthly meetups, talks, and networking events for data professionals in South Florida. It serves as a platform for learning, sharing knowledge, and connecting with other data practitioners in the Miami area.","use_cases":"Finding mentorship and networking opportunities as a new data scientist in Miami, Learning about local job opportunities and industry trends in South Florida's tech scene","audience":"Junior-DS, Curious-browser"},{"id":"community-r-ladies-miami","type":"community","name":"R-Ladies Miami","description":"1,291 members. Part of global R-Ladies network promoting gender diversity in the R community.","category":"Meetups","url":"https://www.meetup.com/rladies-miami/","difficulty":"beginner","prerequisites":"basic-R, data-visualization","topic_tags":"R-programming, networking, community, diversity, meetups","summary":"R-Ladies Miami is a local chapter of the global R-Ladies organization focused on promoting gender diversity in the R programming community. The group provides networking opportunities, workshops, and mentorship for R users of all skill levels in the Miami area. Members can participate in hands-on coding sessions, presentations, and collaborative projects while building connections with other data professionals.","use_cases":"Finding mentorship and networking opportunities as a woman entering the R/data science field, Connecting with local R practitioners for collaboration on projects or career advice","audience":"Junior-DS, Curious-browser"},{"id":"community-nashville-data-nerds","type":"community","name":"Nashville Data Nerds","description":"1,500+ members with four monthly touchpoints: main meetup (1st Wed), Directors Roundtable (2nd Fri), Breakfast (3rd Tue), Brilliant Women in Data (4th Tue).","category":"Meetups","url":"https://www.meetup.com/nashville-data-nerds/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"data-community, nashville, networking, meetups, professional-development","summary":"Nashville Data Nerds is a local data science community with over 1,500 members offering four monthly networking events. The group provides opportunities for data professionals to connect, learn, and share knowledge through regular meetups, roundtables, and specialized events. It serves as a hub for Nashville's data science ecosystem with events targeting different experience levels and interests.","use_cases":"Finding local data science networking opportunities in Nashville, Connecting with other data professionals for career development and knowledge sharing","audience":"Junior-DS, Mid-DS"},{"id":"community-research-triangle-analysts","type":"community","name":"Research Triangle Analysts","description":"3,046 members. 501(c)(3) nonprofit with monthly meetings and annual Analytics>Forward unconference. Strong ties to SAS, Duke, UNC, NC State.","category":"Meetups","url":"https://www.meetup.com/research-triangle-analysts/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"networking, analytics-community, research-triangle, professional-development, meetups","summary":"Research Triangle Analysts is a 3,000+ member nonprofit organization serving the North Carolina analytics community with monthly meetings and an annual unconference. The group connects professionals across academia (Duke, UNC, NC State) and industry (particularly SAS) for knowledge sharing and networking. It provides a platform for learning about analytics trends, best practices, and career development in the Research Triangle area.","use_cases":"New data scientist relocating to Raleigh/Durham area looking to build professional network and learn local industry practices, Academic researcher seeking to connect with industry practitioners and stay current on applied analytics methods","audience":"Junior-DS, Curious-browser"},{"id":"community-charlotte-data-science-ai","type":"community","name":"Charlotte Data Science/AI","description":"1,093 members. Charlotte's data science and AI community with connections to UNC Charlotte.","category":"Meetups","url":"https://www.meetup.com/charlotte-data-science/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"community, networking, charlotte, meetups, career-development","summary":"Charlotte's largest data science and AI community with over 1,000 members and connections to UNC Charlotte. The group provides networking opportunities, knowledge sharing, and career development for data professionals in the Charlotte area. Members can connect with peers, learn about job opportunities, and stay updated on local industry trends.","use_cases":"Finding mentorship and networking opportunities when starting a data science career in Charlotte, Connecting with local data professionals to learn about job openings and industry practices","audience":"Junior-DS, Curious-browser"},{"id":"community-data-analytics-&-ai---tampa-bay","type":"community","name":"Data Analytics & AI - Tampa Bay","description":"USF-sponsored meetup with free monthly events. Covers data analytics and AI with academic and industry speakers.","category":"Meetups","url":"https://www.meetup.com/data-analytics-tampa-bay/","difficulty":"beginner","prerequisites":"basic-statistics, data-curiosity","topic_tags":"networking, tampa-bay, meetups, professional-development, community","summary":"A USF-sponsored monthly meetup in Tampa Bay focused on data analytics and AI topics. Features presentations from both academic researchers and industry practitioners, providing networking and learning opportunities for data professionals at all levels.","use_cases":"Junior data scientist new to Tampa Bay looking to network with local professionals, Mid-career analyst wanting to stay current on AI trends through accessible presentations","audience":"Junior-DS, Curious-browser"},{"id":"community-orlando-ml-and-data-science","type":"community","name":"Orlando ML and Data Science","description":"2,198 members. Central Florida's data science community. Gartner D&A Summit location city.","category":"Meetups","url":"https://www.meetup.com/orlando-ml-data-science/","difficulty":"beginner","prerequisites":"basic-statistics, python-or-r","topic_tags":"meetups, networking, professional-development, orlando, community","summary":"Orlando ML and Data Science is Central Florida's largest data science community with over 2,000 members. The group hosts regular meetups, workshops, and networking events for data professionals at all career levels. Located in the same city as Gartner's D&A Summit, it provides access to both local practitioners and visiting industry experts.","use_cases":"Finding mentorship and career guidance from experienced data scientists in the Orlando area, Networking with local tech companies and discovering job opportunities in Central Florida","audience":"Junior-DS, Curious-browser"},{"id":"community-minneanalytics","type":"community","name":"MinneAnalytics","description":"17,000 members - largest in the Midwest. Umbrella for 25+ specialized user groups including AppliedAI, Twin Cities Data Visualization, and LEHRN (People Analytics).","category":"Meetups","url":"https://minneanalytics.org/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-experience","topic_tags":"networking, community, meetups, minneapolis, data-science","summary":"MinneAnalytics is the Midwest's largest data science community with 17,000 members spanning 25+ specialized groups. It provides networking opportunities, learning resources, and career development through regular meetups covering topics from AI to people analytics. The community serves as a hub for data professionals at all career stages in the Minneapolis-St. Paul area.","use_cases":"Finding local data science networking events and job opportunities in Minneapolis, Connecting with specialized communities like data visualization or people analytics practitioners","audience":"Junior-DS, Curious-browser"},{"id":"community-pgh-data-science","type":"community","name":"PGH Data Science","description":"1,877 members. Pittsburgh's primary data science community with CMU connections and strong academic-industry mix.","category":"Meetups","url":"https://www.meetup.com/pgh-data-science/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"networking, pittsburgh, community, meetups, career-development","summary":"PGH Data Science is Pittsburgh's largest data science community with 1,877 members, featuring strong connections to CMU and a healthy mix of academic researchers and industry practitioners. The community provides networking opportunities, technical presentations, and career development resources for data scientists at all levels in the Pittsburgh area.","use_cases":"Junior data scientist new to Pittsburgh looking to network and learn about local job opportunities, Academic researcher wanting to connect with industry practitioners and understand real-world applications of their work","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-pittsburgh","type":"community","name":"PyData Pittsburgh","description":"908 members. Python data science community in Pittsburgh. Part of the global PyData network.","category":"Meetups","url":"https://www.meetup.com/pydata-pittsburgh/","difficulty":"beginner","prerequisites":"python-basics, data-manipulation","topic_tags":"python-community, networking, pittsburgh, data-science-meetups","summary":"PyData Pittsburgh is a local chapter of the global PyData network with 908 members focused on Python data science applications. The community provides networking opportunities, technical talks, and learning resources for data practitioners in the Pittsburgh area. It's ideal for connecting with peers, staying current with Python ecosystem developments, and finding mentorship or collaboration opportunities.","use_cases":"Finding local data science networking opportunities and learning from peer presentations, Connecting with Pittsburgh-based data practitioners for job opportunities or collaboration","audience":"Junior-DS, Curious-browser"},{"id":"community-big-data-madison","type":"community","name":"Big Data Madison","description":"2,728 members. Madison's data community with ties to UW-Madison Data Science Hub. Weekly coding meetups and workshops.","category":"Meetups","url":"https://www.meetup.com/big-data-madison/","difficulty":"beginner","prerequisites":"basic-programming, data-analysis-interest","topic_tags":"networking, community, wisconsin, professional-development, meetups","summary":"Big Data Madison is a 2,700+ member community connected to UW-Madison's Data Science Hub that hosts weekly coding meetups and workshops. The group provides networking opportunities and skill-building sessions for data professionals in the Madison area. It serves as a local hub for both beginners learning data skills and experienced practitioners sharing knowledge.","use_cases":"Finding local data science networking opportunities in Madison, Attending hands-on coding workshops to learn new data science techniques","audience":"Junior-DS, Curious-browser"},{"id":"community-cbusdaw-(columbus-data-&-analytics-wednesdays)","type":"community","name":"CBUSDAW (Columbus Data & Analytics Wednesdays)","description":"Free monthly speaker events on Marketing Mix Modeling, data storytelling, and analytics. Ohio State TDAI connections.","category":"Meetups","url":"https://www.meetup.com/columbus-data-analytics/","difficulty":"beginner","prerequisites":"basic-statistics, data-visualization-tools","topic_tags":"marketing-mix-modeling, data-storytelling, analytics-meetups, networking, professional-development","summary":"CBUSDAW is a free monthly meetup in Columbus featuring speakers on marketing analytics, data storytelling, and general analytics topics. Connected to Ohio State's TDAI program, it provides networking opportunities and practical insights for data professionals. The events cover accessible topics suitable for practitioners at various levels looking to learn and connect with the local data community.","use_cases":"Finding local networking opportunities with other data professionals in Columbus, Learning practical applications of marketing mix modeling from industry speakers","audience":"Junior-DS, Curious-browser"},{"id":"community-cleveland-ai-&-data","type":"community","name":"Cleveland AI & Data","description":"4,618 members. Merged Big Data and AI groups hosting 'Mega Meetups' with 100+ attendees at venues like Cleveland Museum of Natural History.","category":"Meetups","url":"https://www.meetup.com/cleveland-ai-data/","difficulty":"beginner","prerequisites":"basic-networking, event-planning-interest","topic_tags":"meetups, networking, cleveland, community, ai-data","summary":"Cleveland AI & Data is a large tech community with 4,618 members formed by merging Big Data and AI groups. They host regular 'Mega Meetups' with 100+ attendees at prestigious venues like the Cleveland Museum of Natural History. The group provides networking opportunities and knowledge sharing for data professionals in the Cleveland area.","use_cases":"Finding local networking opportunities in Cleveland's tech scene, Connecting with other data professionals and AI practitioners in Ohio","audience":"Curious-browser, Junior-DS"},{"id":"community-data-science-kc","type":"community","name":"Data Science KC","description":"Kansas City's data science community with monthly 2nd Thursday meetups and University Showcase events.","category":"Meetups","url":"https://www.meetup.com/data-science-kc/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"networking, community, kansas-city, professional-development, meetups","summary":"Data Science KC is Kansas City's local data science community that hosts regular monthly meetups on the second Thursday of each month. The group organizes networking events and University Showcase presentations to connect data professionals in the Kansas City area. It provides opportunities for learning, sharing experiences, and building professional relationships within the local data science ecosystem.","use_cases":"New data scientist relocating to Kansas City looking to build professional network, Mid-career professional seeking to present their work at University Showcase events","audience":"Junior-DS, Mid-DS"},{"id":"community-indypy","type":"community","name":"IndyPy","description":"2,197 members. Indianapolis Python community with IT Social networking events and data science content.","category":"Meetups","url":"https://www.meetup.com/indypy/","difficulty":"beginner","prerequisites":"python-basics, data-structures","topic_tags":"python-community, networking, data-science-meetups, indianapolis, professional-development","summary":"IndyPy is Indianapolis's largest Python community with over 2,100 members focused on IT social networking and data science content. The group organizes regular meetups, workshops, and networking events for Python developers and data scientists in the Indianapolis area. It serves as a local hub for learning, career development, and connecting with other Python practitioners.","use_cases":"Junior data scientist new to Indianapolis looking to network with local Python developers and learn about job opportunities, Python developer seeking to present their work, get feedback on projects, or find collaborators for open source contributions","audience":"Junior-DS, Curious-browser"},{"id":"community-detroit-user-group","type":"community","name":"Detroit useR Group","description":"315 members. R programming community in Detroit for statistical computing and data science.","category":"Meetups","url":"https://www.meetup.com/detroit-user/","difficulty":"beginner","prerequisites":"R-basics, statistical-computing","topic_tags":"R-programming, statistical-computing, data-science, networking, detroit","summary":"Detroit useR Group is a local R programming community with 315 members focused on statistical computing and data science. The group provides networking opportunities, knowledge sharing, and learning resources for R users in the Detroit area. It's ideal for anyone working with R who wants to connect with local practitioners and stay current with R developments.","use_cases":"Finding local R practitioners to network with and learn from, Getting help with R programming challenges from community members","audience":"Junior-DS, Curious-browser"},{"id":"community-stl-big-data","type":"community","name":"STL Big Data","description":"St. Louis big data community with SQL Saturday events. CIC venue for analytics meetups.","category":"Meetups","url":"https://www.meetup.com/stl-big-data/","difficulty":"beginner","prerequisites":"basic-SQL, data-analysis-fundamentals","topic_tags":"big-data, SQL-Saturday, analytics-meetups, St-Louis, community-networking","summary":"STL Big Data is a St. Louis-based community that organizes SQL Saturday events and analytics meetups at the CIC venue. It provides networking opportunities for data professionals and learning sessions focused on big data technologies and SQL practices. The community serves as a local hub for data practitioners to share knowledge and connect with peers.","use_cases":"Finding local data professionals to network with in St. Louis area, Attending SQL Saturday workshops to learn database optimization techniques","audience":"Junior-DS, Curious-browser"},{"id":"community-energy-analytics-and-data-science-(houston)","type":"community","name":"Energy Analytics and Data Science (Houston)","description":"3,108 members. Major energy analytics hub meeting at the Ion Prototyping Lab. Focus on energy sector data science.","category":"Meetups","url":"https://www.meetup.com/energy-analytics-data-science/","difficulty":"beginner","prerequisites":"python-pandas, basic-statistics, domain-knowledge-energy","topic_tags":"energy-analytics, data-science-community, houston-meetups, networking, industry-applications","summary":"Large Houston-based meetup group focused on data science applications in the energy sector. Members gather at the Ion Prototyping Lab to share techniques, network, and discuss energy industry challenges. Provides opportunities to learn from practitioners working on oil & gas, renewables, and energy trading analytics.","use_cases":"Network with energy sector data scientists and learn industry-specific applications, Find collaborators or job opportunities in Houston's energy analytics market","audience":"Junior-DS, Mid-DS"},{"id":"community-houston-energy-data-science","type":"community","name":"Houston Energy Data Science","description":"2,918 members. Another major Houston energy data science community meeting at the Ion Prototyping Lab.","category":"Meetups","url":"https://www.meetup.com/houston-energy-data-science/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"energy-data-science, houston-meetup, networking, community, ion-lab","summary":"Houston Energy Data Science is a large professional community of 2,918 members focused on data science applications in the energy sector. The group meets at the Ion Prototyping Lab, providing networking and learning opportunities for data scientists working in Houston's energy industry. This community serves as a hub for sharing best practices, discussing industry trends, and connecting professionals in the energy data science space.","use_cases":"Junior data scientist new to Houston's energy sector looking to network and learn industry-specific applications, Mid-level data scientist seeking to connect with peers and stay updated on energy industry data science trends","audience":"Junior-DS, Mid-DS"},{"id":"community-dfw-data-science","type":"community","name":"DFW Data Science","description":"4,083 members - largest in Texas. Monthly meetups with enterprise focus. Connected to ASA North Texas Chapter.","category":"Meetups","url":"https://www.meetup.com/dfw-data-science/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"networking, meetups, dallas, enterprise-data-science, professional-development","summary":"DFW Data Science is the largest data science community in Texas with over 4,000 members, hosting monthly meetups focused on enterprise applications. Connected to the American Statistical Association North Texas Chapter, it provides networking opportunities and industry insights for data professionals in the Dallas-Fort Worth area.","use_cases":"Finding local networking opportunities and job connections in the Dallas data science market, Learning about enterprise data science practices and tools used by major companies in Texas","audience":"Junior-DS, Mid-DS"},{"id":"community-san-diego-ai-developers-group","type":"community","name":"San Diego AI Developers Group","description":"5,000+ members. Active AI community with ties to UCSD's Hal\u0131c\u0131o\u011flu Data Science Institute.","category":"Meetups","url":"https://www.meetup.com/san-diego-ai-developers/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"ai-community, san-diego, networking, meetups, professional-development","summary":"Large AI developer community in San Diego with over 5,000 members and academic connections to UCSD's data science institute. Provides networking opportunities, technical talks, and career development for AI practitioners at all levels. Offers both in-person meetups and online events covering current AI trends and applications.","use_cases":"Finding mentorship and networking opportunities when starting an AI career in San Diego, Connecting with local AI practitioners to learn about job opportunities and industry trends","audience":"Junior-DS, Curious-browser"},{"id":"community-san-diego-data-science-&-r-users-group","type":"community","name":"San Diego Data Science & R Users Group","description":"1,811 members. Active since 2009. Long-standing data science community in San Diego.","category":"Meetups","url":"https://www.meetup.com/sd-data-science-r-users/","difficulty":"beginner","prerequisites":"basic-statistics, r-programming","topic_tags":"meetups, r-programming, networking, san-diego, community","summary":"The San Diego Data Science & R Users Group is a well-established meetup community with over 1,800 members, running since 2009. It provides networking opportunities, presentations, and knowledge sharing for data professionals in the San Diego area. Members typically discuss R programming techniques, data science applications, and industry trends through regular in-person and virtual events.","use_cases":"Finding local networking opportunities and mentorship in the San Diego data science community, Learning about new R packages and techniques through member presentations and workshops","audience":"Junior-DS, Curious-browser"},{"id":"community-big-data-utah","type":"community","name":"Big Data Utah","description":"3,855 members. Salt Lake City's data community in the 'Silicon Slopes' corridor. Connected to Big Mountain Data & Dev Conference.","category":"Meetups","url":"https://www.meetup.com/big-data-utah/","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-fundamentals","topic_tags":"data-community, networking, utah, meetups, silicon-slopes","summary":"Big Data Utah is a 3,855-member data community based in Salt Lake City's Silicon Slopes tech corridor. The group provides networking opportunities, knowledge sharing, and connections to the Big Mountain Data & Dev Conference. It serves as a regional hub for data professionals to connect, learn, and advance their careers in Utah's growing tech scene.","use_cases":"Finding local data science networking opportunities in Utah, Connecting with other data professionals in the Silicon Slopes area","audience":"Junior-DS, Mid-DS"},{"id":"community-utah-data-engineering-meetup","type":"community","name":"Utah Data Engineering Meetup","description":"3,017 members. Data engineering focused community in Utah's tech corridor.","category":"Meetups","url":"https://www.meetup.com/utah-data-engineering/","difficulty":"beginner","prerequisites":"SQL-basics, python-programming","topic_tags":"data-engineering, meetups, utah, networking, community","summary":"A large data engineering community meetup group based in Salt Lake City with over 3,000 members. The group focuses on data pipeline engineering, infrastructure, and tooling discussions relevant to Utah's growing tech scene. Members can network, learn about local opportunities, and share knowledge about data engineering practices.","use_cases":"Finding data engineering job opportunities and networking in Utah's tech corridor, Learning about data engineering tools and best practices from local practitioners","audience":"Junior-DS, Mid-DS"},{"id":"community-dataphx","type":"community","name":"DATAPHX","description":"1,500+ members. Phoenix data community. City hosted INFORMS 2023 annual meeting.","category":"Meetups","url":"https://www.meetup.com/dataphx/","difficulty":"beginner","prerequisites":"basic-networking, professional-communication","topic_tags":"phoenix-meetups, data-science-community, networking, informs, professional-development","summary":"DATAPHX is a 1,500+ member data science community based in Phoenix, Arizona. The group provides networking opportunities, knowledge sharing, and professional development for data professionals in the Phoenix area. Phoenix notably hosted the INFORMS 2023 annual meeting, highlighting the city's growing presence in operations research and analytics.","use_cases":"Finding local data science professionals and mentors in the Phoenix area, Discovering job opportunities and career advancement through networking events","audience":"Junior-DS, Curious-browser"},{"id":"community-pydata-pdx","type":"community","name":"PyData PDX","description":"1,489 members. Portland's Python data science community meeting monthly with the Portland R User Group.","category":"Meetups","url":"https://www.meetup.com/pydata-pdx/","difficulty":"beginner","prerequisites":"python-basics, data-analysis-fundamentals","topic_tags":"python-community, data-science-meetups, portland, networking, local-events","summary":"PyData PDX is Portland's Python data science community with nearly 1,500 members who meet monthly alongside the Portland R User Group. The meetup provides networking opportunities, technical presentations, and knowledge sharing for Python practitioners in data science, analytics, and related fields. It serves as a local hub for connecting with other data professionals and staying current with Python ecosystem developments.","use_cases":"Finding local Python data science professionals for networking and job opportunities, Learning about new Python tools and techniques through community presentations and discussions","audience":"Junior-DS, Curious-browser"},{"id":"community-ai-tinkerers-montreal","type":"community","name":"AI Tinkerers Montreal","description":"Monthly AI demos with participants from Google, Microsoft, Shopify, and Mila. Part of Montreal's world-class AI ecosystem.","category":"Meetups","url":"https://www.meetup.com/ai-tinkerers-montreal/","difficulty":"beginner","prerequisites":"basic-python, jupyter-notebooks","topic_tags":"ai-meetups, montreal-tech, networking, demo-presentations, industry-academia","summary":"AI Tinkerers Montreal is a monthly meetup featuring live AI demos and presentations from practitioners at top tech companies and research institutions. The community brings together Montreal's vibrant AI ecosystem including Google, Microsoft, Shopify, and Mila researchers. It's an accessible venue for learning about cutting-edge AI applications and networking with the local tech community.","use_cases":"networking with AI practitioners in Montreal's tech scene, seeing real-world AI demos and learning about industry applications","audience":"Junior-DS, Curious-browser"},{"id":"community-statistical-society-of-montreal","type":"community","name":"Statistical Society of Montreal","description":"Joint regional ASA-SSC chapter serving Montreal's statistics community with academic and industry connections.","category":"Meetups","url":"https://ssc.ca/en/about/sections-regions/montreal","difficulty":"beginner","prerequisites":"basic-statistics, networking-skills","topic_tags":"professional-networking, statistics-community, montreal, career-development","summary":"The Statistical Society of Montreal is a joint regional chapter of ASA and SSC that connects Montreal's statistics professionals through meetups, talks, and networking events. It serves both academics and industry practitioners working in statistics and data science. Members can attend presentations on current statistical methods, connect with peers, and stay updated on local job opportunities and research.","use_cases":"Finding local networking opportunities and career connections in Montreal's statistics community, Attending technical talks and workshops to learn about new statistical methods from academic and industry speakers","audience":"Junior-DS, Curious-browser"},{"id":"community-uw-data-science-club-(waterloo)","type":"community","name":"UW Data Science Club (Waterloo)","description":"5,272+ Instagram followers. Weekly workshops, hackathons, and the CxC Data Hackathon. Vector Institute connections.","category":"Meetups","url":"https://uwdatascience.ca/","difficulty":"beginner","prerequisites":"basic-programming, data-manipulation","topic_tags":"data-science-community, hackathons, workshops, networking, student-groups","summary":"University of Waterloo Data Science Club is an active student community with 5,272+ Instagram followers offering weekly workshops and hackathons. The club organizes the CxC Data Hackathon and maintains connections with Vector Institute. It provides hands-on learning opportunities and networking for students interested in data science.","use_cases":"Students looking to practice data science skills through hackathons and collaborative projects, Early career professionals seeking to network with peers and learn through workshops in the Waterloo tech ecosystem","audience":"Junior-DS, Curious-browser"},{"id":"community-learn-data-science-(vancouver)","type":"community","name":"Learn Data Science (Vancouver)","description":"7,074 members. Vancouver's largest data science community with monthly career events.","category":"Meetups","url":"https://www.meetup.com/learn-data-science/","difficulty":"beginner","prerequisites":"basic-networking, career-planning","topic_tags":"networking, career-development, vancouver, community, meetups","summary":"Vancouver's largest data science community with over 7,000 members hosting monthly career-focused events. The meetup provides networking opportunities, industry talks, and career guidance for data professionals at all levels. Members can connect with peers, learn about job opportunities, and stay current with local data science trends.","use_cases":"Finding mentorship and networking opportunities when starting a data science career in Vancouver, Connecting with local employers and discovering job opportunities in the Vancouver tech scene","audience":"Junior-DS, Curious-browser"},{"id":"community-analytics-club-vancouver","type":"community","name":"Analytics Club Vancouver","description":"Vancouver analytics community with monthly career events and professional networking.","category":"Meetups","url":"https://www.meetup.com/analytics-club-vancouver/","difficulty":"beginner","prerequisites":"basic-networking-skills, career-development-awareness","topic_tags":"networking, career-development, vancouver, analytics-community, professional-events","summary":"Analytics Club Vancouver is a local professional community that hosts monthly career-focused events and networking opportunities for analytics professionals in the Vancouver area. The group provides a platform for data scientists, analysts, and related professionals to connect, share experiences, and advance their careers. It serves as a valuable resource for both newcomers to the field and experienced practitioners looking to expand their professional network.","use_cases":"New data scientist in Vancouver looking to build professional connections and learn about local job opportunities, Experienced analytics professional seeking to mentor others and stay connected with the local tech community","audience":"Junior-DS, Curious-browser"},{"id":"community-yyc-data-society-(calgary)","type":"community","name":"YYC Data Society (Calgary)","description":"Umbrella organization unifying PyData Calgary, Data for Good (10-year anniversary), and DAMA chapter.","category":"Meetups","url":"https://www.yycdata.ca/","difficulty":"beginner","prerequisites":"basic-python, data-visualization-concepts","topic_tags":"meetups, data-community, calgary, networking, data-for-good","summary":"YYC Data Society is Calgary's umbrella organization that brings together PyData Calgary, Data for Good, and DAMA chapter members. It provides networking opportunities, technical talks, and collaborative projects for data professionals in the Calgary area. The community welcomes practitioners at all levels looking to connect with local data scientists and analysts.","use_cases":"Finding mentorship and career guidance from experienced Calgary data professionals, Connecting with local companies and discovering job opportunities in Calgary's tech scene","audience":"Junior-DS, Curious-browser"},{"id":"community-calgaryr","type":"community","name":"CalgaryR","description":"1,477 members. R Consortium and University of Calgary sponsored R community.","category":"Meetups","url":"https://www.meetup.com/calgaryr/","difficulty":"beginner","prerequisites":"basic-R, statistical-concepts","topic_tags":"R-programming, community-meetups, Calgary, data-science-networking","summary":"CalgaryR is a 1,477-member R programming community sponsored by the R Consortium and University of Calgary. The group organizes meetups, workshops, and networking events for R users in the Calgary area. It serves as a platform for learning R, sharing best practices, and connecting with other data professionals.","use_cases":"Attending local R meetups to learn new packages and techniques, Networking with other R users and data scientists in Calgary","audience":"Junior-DS, Curious-browser"},{"id":"community-machine-learning-&-ai-ottawa","type":"community","name":"Machine Learning & AI Ottawa","description":"4,411 members. Ottawa's ML and AI community with strong government analytics presence due to federal departments.","category":"Meetups","url":"https://www.meetup.com/machine-learning-ai-ottawa/","difficulty":"beginner","prerequisites":"basic-statistics, python-basics","topic_tags":"meetups, ottawa, government-analytics, networking, community","summary":"Machine Learning & AI Ottawa is a 4,411-member community focused on ML and AI in Canada's capital. The group has a strong government analytics presence due to Ottawa's concentration of federal departments and agencies. It provides networking opportunities and knowledge sharing for data professionals working in both public and private sectors.","use_cases":"Connecting with other data scientists working in government analytics and policy research, Finding job opportunities and career guidance in Ottawa's tech and public sector","audience":"Junior-DS, Mid-DS"},{"id":"community-statistical-society-of-ottawa","type":"community","name":"Statistical Society of Ottawa","description":"Joint SSC-ASA chapter serving Ottawa's statistics community. Strong government and academic connections.","category":"Meetups","url":"https://ssc.ca/en/about/sections-regions/ottawa","difficulty":"beginner","prerequisites":"basic-statistics, networking-fundamentals","topic_tags":"statistics-community, professional-networking, government-statistics, academic-statistics, ottawa","summary":"The Statistical Society of Ottawa is a joint chapter of the Statistical Society of Canada (SSC) and American Statistical Association (ASA) that serves the Ottawa statistics community. It connects statisticians and data scientists working in government, academia, and industry through regular meetups, talks, and networking events. The society provides a platform for knowledge sharing and professional development in Canada's capital region.","use_cases":"Finding networking opportunities with government statisticians at Statistics Canada and other federal agencies, Attending talks and workshops to learn about statistical methods used in public policy and academic research","audience":"Junior-DS, Curious-browser"},{"id":"community-stratechery-(ben-thompson)","type":"community","name":"Stratechery (Ben Thompson)","description":"The gold standard for tech strategy analysis. Aggregation theory, platform dynamics, and business model breakdowns.","category":"Blogs","url":"https://stratechery.com/","difficulty":"beginner","prerequisites":"business-fundamentals, basic-economics","topic_tags":"tech-strategy, platform-economics, business-models, aggregation-theory, competitive-analysis","summary":"Stratechery is Ben Thompson's influential blog providing deep strategic analysis of tech companies and platform dynamics. Known for frameworks like Aggregation Theory, it breaks down how tech giants build moats and capture value. Essential reading for understanding the business logic behind major tech decisions and market movements.","use_cases":"Understanding why a tech company made a strategic pivot or acquisition, Learning frameworks to analyze platform businesses and network effects","audience":"Curious-browser, Junior-DS"},{"id":"community-new-things-under-the-sun-(matt-clancy)","type":"community","name":"New Things Under the Sun (Matt Clancy)","description":"innovation research research summaries. Academic findings on R&D, productivity, and science \u2014 in plain language.","category":"Blogs","url":"https://www.newthingsunderthesun.com/","difficulty":"beginner","prerequisites":"basic-statistics, research-methods","topic_tags":"innovation-research, R&D-productivity, science-policy, research-summaries, blog","summary":"A blog by Matt Clancy that translates academic research on innovation, R&D, and scientific productivity into accessible summaries. Provides plain-language explanations of findings from economics of innovation literature. Useful for understanding how innovation works at organizational and societal levels.","use_cases":"Understanding research findings on team productivity and collaboration for organizational planning, Learning about innovation economics concepts before diving into academic papers","audience":"Curious-browser, Early-PhD"},{"id":"community-marginal-revolution-(tyler-cowen)","type":"community","name":"Marginal Revolution (Tyler Cowen)","description":"The econ blog. Tech, innovation, markets \u2014 prolific, eclectic, and influential. A daily must-read.","category":"Blogs","url":"https://marginalrevolution.com/","difficulty":"beginner","prerequisites":"basic-economics, market-analysis","topic_tags":"economics-blog, innovation, markets, tech-policy, commentary","summary":"Tyler Cowen's influential economics blog covering technology, innovation, markets, and policy with daily posts and eclectic commentary. Known for thought-provoking takes on economic trends, book recommendations, and spotting emerging patterns in tech and society. Essential reading for staying current on economic thinking about technology and innovation.","use_cases":"Staying updated on economic perspectives on tech trends and policy developments, Finding book recommendations and intellectual commentary on innovation and markets","audience":"Curious-browser, Early-PhD"},{"id":"community-measuringu","type":"community","name":"MeasuringU","description":"Survey science, conjoint analysis, and quantitative UX research. Statistical rigor for product research.","category":"Blogs","url":"https://measuringu.com/","difficulty":"intermediate","prerequisites":"survey-design, statistical-inference, conjoint-analysis","topic_tags":"user-experience, survey-methods, conjoint-analysis, product-research, quantitative-ux","summary":"MeasuringU is a blog focused on applying statistical rigor to user experience research, particularly through survey science and conjoint analysis methods. It provides practical guidance for product researchers who want to move beyond basic UX metrics to more sophisticated quantitative approaches. The content bridges academic survey methodology with real-world product development challenges.","use_cases":"Designing statistically valid user satisfaction surveys for product launches, Running conjoint studies to understand feature preferences and pricing sensitivity","audience":"Mid-DS, Junior-DS"},{"id":"community-eugene-yan-1","type":"community","name":"Eugene Yan","description":"ML systems, recommendations, and LLMs in production. Practical insights from an Amazon Principal Applied Scientist.","category":"Blogs","url":"https://eugeneyan.com/","difficulty":"intermediate","prerequisites":"python-scikit-learn, A-B-testing, docker-containers","topic_tags":"machine-learning-systems, recommendation-systems, production-ml, applied-science, llm-deployment","summary":"Eugene Yan's blog offers practical insights on building and deploying ML systems at scale, with focus on recommendation engines and LLMs in production environments. As an Amazon Principal Applied Scientist, he shares real-world experiences and best practices for moving from research to production. Content covers system design, experimentation frameworks, and operational challenges in large-scale ML applications.","use_cases":"Learning how to deploy recommendation systems in production environments, Understanding best practices for LLM implementation and scaling at tech companies","audience":"Mid-DS, Senior-DS"},{"id":"community-al-roth's-market-design-blog","type":"community","name":"Al Roth's Market Design Blog","description":"Direct commentary from the architect of modern market design (Nobel 2012). Roth redesigned NRMP, co-founded kidney exchange programs, advised on school choice. Practitioner insights unavailable elsewhere.","category":"Blogs","url":"https://marketdesigner.blogspot.com","difficulty":"beginner","prerequisites":"microeconomics, game-theory","topic_tags":"market-design, mechanism-design, applied-microeconomics, matching-theory, economics-blog","summary":"Nobel laureate Al Roth's personal blog providing practitioner insights on market design applications. Covers real-world implementations of matching markets, kidney exchanges, and school choice systems. Essential reading for understanding how economic theory translates to policy and business practice.","use_cases":"Learning how matching algorithms are actually implemented in healthcare and education systems, Understanding the policy considerations behind successful market design projects","audience":"Early-PhD, Curious-browser"},{"id":"community-hal-varian","type":"community","name":"Hal Varian","description":"PhD Berkeley. Google's Chief Economist from 2002-2025. Pioneered the role of economist in tech, designed Google's ad auction system, and proved economics could drive billions in tech revenue. Former Dean of UC Berkeley School of Information. Author of foundational textbooks 'Intermediate Microeconomics' and 'Information Rules'.","category":"Leading Lights","url":"https://people.ischool.berkeley.edu/~hal/","difficulty":"beginner","prerequisites":"microeconomics-basics, auction-theory","topic_tags":"hal-varian, google-economist, ad-auctions, tech-economics, leading-lights","summary":"Hal Varian is Google's Chief Economist who pioneered the role of economists in tech companies and designed Google's revolutionary ad auction system. He transformed academic economic theory into practical systems that generate billions in revenue. His work demonstrates how rigorous economic thinking can solve real-world tech problems at massive scale.","use_cases":"Understanding how economists contribute to tech product design and strategy, Learning about the intersection of auction theory and digital advertising markets","audience":"Curious-browser, Early-PhD"},{"id":"community-susan-athey","type":"community","name":"Susan Athey","description":"PhD Stanford. The Economics of Technology Professor at Stanford GSB. John Bates Clark Medal winner. Served as consulting Chief Economist at Microsoft for 6 years. Pioneered causal machine learning methods including causal forests. On boards of Expedia, Lending Club, Ripple. Elected to National Academy of Sciences.","category":"Leading Lights","url":"https://www.gsb.stanford.edu/faculty-research/faculty/susan-athey","difficulty":"intermediate","prerequisites":"causal-inference, random-forests, econometrics","topic_tags":"causal-machine-learning, causal-forests, tech-economics, industry-academia, leading-researcher","summary":"Susan Athey is a pioneering economist who bridges machine learning and causal inference, most famous for developing causal forests and other causal ML methods. As Stanford's Economics of Technology Professor and former Microsoft Chief Economist, she exemplifies the intersection of academic rigor and industry application. Her work is essential reading for anyone doing causal analysis with modern ML tools.","use_cases":"Learning about causal machine learning methods and their foundational papers, Understanding how top economists transition between academia and major tech companies","audience":"Mid-DS, Senior-DS"},{"id":"community-pat-bajari-(1969-2025)","type":"community","name":"Pat Bajari (1969-2025)","description":"PhD Minnesota. Amazon's Chief Economist and VP from 2010-2020s. Built Amazon's economics team from scratch to 400+ PhD economists, creating the template for tech economics teams industry-wide. Previously faculty at Harvard, Stanford, Duke, Michigan. Fellow of Econometric Society.","category":"Leading Lights","url":"https://patbajari.ai/","difficulty":"beginner","prerequisites":"microeconomics, causal-inference","topic_tags":"tech-economics, industry-leaders, amazon-economics, economics-teams, career-development","summary":"Pat Bajari was Amazon's pioneering Chief Economist who built the company's economics team from zero to 400+ PhD economists, establishing the modern template for economics functions at major tech companies. His work at Amazon from 2010-2020s demonstrated how rigorous economic analysis could drive business decisions at scale in the tech industry.","use_cases":"Understanding how economics teams are structured and function at major tech companies, Learning about career paths from academia to industry economics leadership","audience":"Curious-browser, Early-PhD"},{"id":"community-steve-tadelis","type":"community","name":"Steve Tadelis","description":"PhD Stanford. Sarin Chair Professor at UC Berkeley Haas. Led economics team at eBay Research Labs (2011-2013), then VP of Economics and Market Design at Amazon. Famous for groundbreaking research on digital advertising effectiveness and drip pricing. Amazon Scholar 2017-2021.","category":"Leading Lights","url":"https://faculty.haas.berkeley.edu/stadelis/","difficulty":"intermediate","prerequisites":"causal-inference, A-B-testing, econometrics","topic_tags":"digital-advertising, market-design, drip-pricing, tech-economics, leading-researcher","summary":"Steve Tadelis is a renowned economist bridging academia and industry, known for pioneering research on digital advertising effectiveness and market design at major tech companies. His work at eBay and Amazon has shaped how we understand online advertising ROI and pricing strategies in digital markets. Essential figure for understanding the intersection of economic theory and tech platform design.","use_cases":"Learning about foundational research in digital advertising measurement and attribution, Understanding how economic theory applies to marketplace and platform design decisions","audience":"Mid-DS, Senior-DS"},{"id":"community-michael-ostrovsky","type":"community","name":"Michael Ostrovsky","description":"PhD Harvard. Fred H. Merrill Professor at Stanford GSB, Co-Director NBER Market Design. Spent 15+ years advising Yahoo, Google, LinkedIn, Pinterest on auction-based advertising. Co-founder of Topsort. Won Kalai Prize for work on generalized second-price auctions.","category":"Leading Lights","url":"https://web.stanford.edu/~ost/","difficulty":"intermediate","prerequisites":"auction-theory, game-theory, econometrics","topic_tags":"auction-design, market-design, advertising-auctions, generalized-second-price, platform-economics","summary":"Michael Ostrovsky is a leading authority on auction theory and market design, particularly known for his work on generalized second-price auctions used in online advertising. He has advised major tech companies on their auction-based advertising systems and co-founded Topsort, bringing deep theoretical knowledge to practical applications. His research bridges economic theory and real-world platform design.","use_cases":"Understanding auction mechanisms for ad platforms or marketplace design, Learning about the theoretical foundations behind Google AdWords and similar advertising auction systems","audience":"Mid-DS, Senior-DS"},{"id":"community-preston-mcafee","type":"community","name":"Preston McAfee","description":"PhD Purdue. Distinguished Scientist at Google (2020-present). Previously Chief Economist at Microsoft (2014-2018), Director at Google (2012-2014), Chief Economist and VP at Yahoo Research (2007-2012). Designed FCC spectrum auctions with Milgrom and Wilson. Founded ACM Transactions of Economics and Computation journal.","category":"Leading Lights","url":"https://vita.mcafee.cc/","difficulty":"intermediate","prerequisites":"auction-theory, game-theory, microeconomics","topic_tags":"auction-design, spectrum-auctions, mechanism-design, computational-economics, tech-economics","summary":"Preston McAfee is a distinguished tech economist who designed the FCC spectrum auctions and founded the ACM Transactions of Economics and Computation journal. He has held chief economist roles at major tech companies including Google, Microsoft, and Yahoo Research. His work bridges theoretical economics with practical applications in technology companies and government policy.","use_cases":"Learning about auction mechanism design from a practitioner who implemented real-world spectrum auctions, Understanding how economic theory gets applied at major tech companies through leadership examples","audience":"Senior-DS, Early-PhD"},{"id":"community-john-list","type":"community","name":"John List","description":"PhD Wyoming. Kenneth C. Griffin Distinguished Service Professor at UChicago. First Chief Economist at Uber, then Lyft, now Walmart. Pioneered field experiments methodology. #5 most influential economist in world per RePEc. Revolutionized how tech companies run experiments.","category":"Leading Lights","url":"https://voices.uchicago.edu/jlist/","difficulty":"beginner","prerequisites":"randomized-controlled-trials, causal-inference-fundamentals","topic_tags":"field-experiments, causal-inference, tech-economics, experimental-design, industry-research","summary":"John List is a pioneering economist who developed modern field experimental methods and served as Chief Economist at major tech companies including Uber, Lyft, and Walmart. He revolutionized how technology companies design and run experiments to make data-driven decisions. His work bridges academic rigor with practical industry applications of causal inference.","use_cases":"Learning how major tech companies approach experimental design and causal inference, Understanding the evolution of field experiments from academic research to industry practice","audience":"Junior-DS, Curious-browser"},{"id":"community-michael-luca-1","type":"community","name":"Michael Luca","description":"PhD Harvard. Lee J. Styslinger III Associate Professor at Harvard Business School. Research on platform design and data-driven decision making. Ongoing collaborations with Yelp, Facebook, UK government. Co-authored seminal 'Economists in Tech Companies' paper with Susan Athey.","category":"Leading Lights","url":"https://www.hbs.edu/faculty/Pages/profile.aspx?facId=602417","difficulty":"intermediate","prerequisites":"causal-inference, experimental-design, python-pandas","topic_tags":"platform-economics, digital-markets, field-experiments, causal-inference, tech-industry","summary":"Michael Luca is a Harvard Business School professor specializing in platform design and data-driven decision making with extensive industry collaborations. His research bridges academic rigor with practical tech industry applications, particularly in digital platforms and online marketplaces. Co-authored influential work on economists' roles in tech companies, making him a key figure for understanding industry-academia connections.","use_cases":"Learning how academic economists transition to and collaborate with tech companies, Understanding field experimental approaches for platform and marketplace design","audience":"Early-PhD, Mid-DS"},{"id":"community-peter-coles","type":"community","name":"Peter Coles","description":"PhD Stanford. Head Economist for Policy at Airbnb. Previously Head Economist at eBay, and Harvard Business School professor. Worked with Nobel laureate Alvin Roth on market design. Designed the AEA job market signaling mechanism. Called Silicon Valley 'an absolute candy store for economists'.","category":"Leading Lights","url":"https://scholar.google.com/citations?user=5vi6xPQAAAAJ","difficulty":"intermediate","prerequisites":"market-design-theory, mechanism-design, causal-inference","topic_tags":"market-design, platform-economics, job-market-signaling, airbnb-economics, tech-policy","summary":"Peter Coles is Head Economist for Policy at Airbnb and a leading expert in market design applications for tech platforms. He collaborated with Nobel laureate Alvin Roth and designed the AEA job market signaling mechanism, bringing academic rigor to real-world marketplace problems. His work spans platform economics, policy design, and practical applications of mechanism design theory.","use_cases":"Learning about market design applications in tech platforms like Airbnb and eBay, Understanding how academic economists transition to industry roles and apply theory to business problems","audience":"Mid-DS, Senior-DS"},{"id":"community-erik-brynjolfsson","type":"community","name":"Erik Brynjolfsson","description":"PhD MIT. Jerry Yang Professor at Stanford, Director of Digital Economy Lab at Stanford HAI. Pioneer in economics of AI and digital transformation. Author of 'The Second Machine Age' and 'Machine, Platform, Crowd'. Co-chaired National Academies AI committees. Testified to Congress on AI.","category":"Leading Lights","url":"https://www.brynjolfsson.com/","difficulty":"beginner","prerequisites":"basic-economics, research-methods","topic_tags":"digital-economics, AI-economics, platform-economics, productivity-research, technology-impact","summary":"Erik Brynjolfsson is a leading economist studying how AI and digital technologies transform business and society. His research on productivity, platforms, and automation provides foundational frameworks for understanding tech's economic impact. Essential reading for anyone working at the intersection of technology and economics.","use_cases":"Understanding economic theories behind digital platform business models, Learning foundational frameworks for measuring AI's impact on productivity and employment","audience":"Early-PhD, Curious-browser"},{"id":"community-michael-schwarz","type":"community","name":"Michael Schwarz","description":"PhD Harvard. Corporate VP and Chief Economist at Microsoft. Previously Chief Economist for Google Cloud. Leads Microsoft's Office of the Chief Economist on demand forecasting, Azure pricing, market design, and antitrust. Expert in auction design and marketplace economics.","category":"Leading Lights","url":"https://www.microsoft.com/en-us/research/people/mschwarz/","difficulty":"intermediate","prerequisites":"microeconomic-theory, game-theory, econometrics","topic_tags":"auction-design, marketplace-economics, cloud-pricing, antitrust, demand-forecasting","summary":"Michael Schwarz is Chief Economist at Microsoft and former Chief Economist for Google Cloud, specializing in auction design and marketplace economics. He applies economic theory to tech platform challenges including Azure pricing, demand forecasting, and antitrust issues. His work bridges academic rigor with practical implementation in large-scale digital markets.","use_cases":"Learning about economic approaches to cloud platform pricing and market design, Understanding how major tech companies apply auction theory to their business models","audience":"Mid-DS, Senior-DS"},{"id":"roadmap-learn-python","type":"roadmap","name":"Learn Python","description":"Programming fundamentals for researchers \u2014 data manipulation, visualization, and workflows","category":"","url":""},{"id":"roadmap-learn-statistics","type":"roadmap","name":"Learn Statistics","description":"Hypothesis testing, inference, and distributions \u2014 the foundation for empirical work","category":"","url":""},{"id":"roadmap-learn-ml","type":"roadmap","name":"Learn ML","description":"Prediction, tree models, and cross-validation \u2014 for forecasting and pattern recognition","category":"","url":""},{"id":"roadmap-learn-causal-inference","type":"roadmap","name":"Learn Causal Inference","description":"Treatment effects, DiD, RDD, and IV \u2014 answer 'what if' questions with data","category":"","url":""},{"id":"roadmap-learn-product-sense","type":"roadmap","name":"Learn Product Sense","description":"PM thinking, metrics selection, and product strategy \u2014 build intuition for what to build and why","category":"","url":""},{"id":"roadmap-learn-experimentation","type":"roadmap","name":"Learn Experimentation","description":"A/B testing, power analysis, and statistical rigor \u2014 bridge your training to industry experiments","category":"","url":""},{"id":"roadmap-learn-sql","type":"roadmap","name":"Learn SQL","description":"Querying data, joins, and aggregations \u2014 essential for any data role","category":"","url":""},{"id":"roadmap-learn-data-structures","type":"roadmap","name":"Learn Data Structures","description":"Arrays, linked lists, trees, and graphs \u2014 the building blocks for efficient algorithms","category":"","url":""},{"id":"roadmap-learn-algorithms","type":"roadmap","name":"Learn Algorithms","description":"Sorting, searching, dynamic programming, and graph algorithms \u2014 the patterns that power interviews","category":"","url":""},{"id":"roadmap-learn-leetcode","type":"roadmap","name":"Learn LeetCode","description":"Coding interview practice \u2014 curated problem sets and patterns for FAANG interviews","category":"","url":""},{"id":"roadmap-learn-automation","type":"roadmap","name":"Learn Automation","description":"Web scraping, APIs, and workflow automation \u2014 collect and process data at scale","category":"","url":""},{"id":"roadmap-learn-optimization-(or)","type":"roadmap","name":"Learn Optimization (OR)","description":"Linear programming, convex optimization, and combinatorial methods \u2014 solve pricing, scheduling, and allocation problems","category":"","url":""},{"id":"roadmap-learn-agentic-workflows","type":"roadmap","name":"Learn Agentic Workflows","description":"Build AI agents that reason, plan, and execute \u2014 tool use, multi-agent systems, and orchestration","category":"","url":""},{"id":"roadmap-learn-forecasting","type":"roadmap","name":"Learn Forecasting","description":"Time series analysis, demand forecasting, and prediction \u2014 ARIMA, Prophet, and modern ML methods for business planning","category":"","url":""},{"id":"book-information-rules","type":"book","name":"Information Rules","description":"The foundational text on network economics - Varian became Google's Chief Economist","category":"Platform Economics","url":"https://www.amazon.com/Information-Rules-Strategic-Network-Economy/dp/087584863X","difficulty":"intermediate","prerequisites":"microeconomics-principles, basic-game-theory, market-analysis","topic_tags":"network-effects, pricing-strategy, two-sided-markets, digital-economics, platform-strategy","summary":"A seminal book by Shapiro and Varian that established the economic principles governing information-based businesses and network effects. It provides frameworks for understanding pricing, versioning, and competitive strategy in technology markets. Essential reading for anyone working on platform economics, digital marketplaces, or tech company strategy.","use_cases":"Designing pricing strategies for SaaS products with network effects, Analyzing competitive dynamics in two-sided marketplace businesses","audience":"Mid-DS, Curious-browser"},{"id":"book-matchmakers","type":"book","name":"Matchmakers","description":"Rigorous platform economics by two top IO economists","category":"Platform Economics","url":"https://www.amazon.com/Matchmakers-New-Economics-Multisided-Platforms/dp/1633691721","difficulty":"intermediate","prerequisites":"microeconomics-theory, game-theory, econometrics","topic_tags":"platform-economics, two-sided-markets, industrial-organization, network-effects, market-design","summary":"Comprehensive textbook on platform economics and two-sided markets by leading industrial organization economists. Covers theoretical foundations, empirical methods, and real-world applications of platforms like ride-sharing, app stores, and payment systems. Essential reading for understanding how digital marketplaces create value by connecting different user groups.","use_cases":"Analyzing pricing strategies for a two-sided marketplace startup, Understanding network effects and competitive dynamics in platform industries","audience":"Early-PhD, Senior-DS"},{"id":"book-platform-revolution","type":"book","name":"Platform Revolution","description":"Most comprehensive platform strategy book","category":"Platform Economics","url":"https://www.amazon.com/Platform-Revolution-Networked-Markets-Transforming/dp/0393249131","difficulty":"beginner","prerequisites":"basic-microeconomics, business-strategy-fundamentals","topic_tags":"platform-strategy, network-effects, two-sided-markets, digital-platforms, business-models","summary":"Platform Revolution is a foundational guide to understanding how digital platforms create value through network effects and multi-sided markets. The book covers platform design principles, competitive dynamics, and monetization strategies used by companies like Amazon, Uber, and Facebook. It provides frameworks for analyzing platform ecosystems and identifying opportunities in the platform economy.","use_cases":"Understanding how to design marketplace features that encourage network effects, Analyzing competitive positioning against platform-based competitors","audience":"Junior-DS, Curious-browser"},{"id":"book-who-gets-what-and-why","type":"book","name":"Who Gets What and Why","description":"Market design from a Nobel laureate - auctions, matching markets","category":"Pricing & Market Design","url":"https://www.amazon.com/Who-Gets-What-Why-Matchmaking/dp/0544291131","difficulty":"beginner","prerequisites":"microeconomics, game-theory-basics","topic_tags":"market-design, auction-theory, matching-algorithms, mechanism-design, behavioral-economics","summary":"Accessible introduction to market design by Nobel Prize winner Alvin Roth, explaining how economists design markets and matching systems. Covers real-world applications like kidney exchanges, school choice, and spectrum auctions without heavy mathematics. Essential reading for understanding how economic theory shapes platform design and marketplace mechanisms.","use_cases":"Designing matching algorithms for two-sided marketplaces like rideshare or dating apps, Understanding auction mechanisms for ad exchanges or procurement systems","audience":"Curious-browser, Junior-DS"},{"id":"book-prediction-machines","type":"book","name":"Prediction Machines","description":"Best economic framework for AI as cheap prediction","category":"AI & Machine Learning","url":"https://www.amazon.com/Prediction-Machines-Economics-Artificial-Intelligence/dp/1633695670","difficulty":"beginner","prerequisites":"basic-economics, business-strategy","topic_tags":"economic-framework, AI-strategy, prediction-economics, business-AI, decision-making","summary":"A foundational book that reframes artificial intelligence as a technology that makes prediction cheap, providing an economic lens for understanding AI's impact on business and society. Written by economists, it offers a clear framework for thinking about when and how to deploy AI systems based on prediction costs and complementary assets. Essential reading for anyone wanting to understand AI's economic implications without technical complexity.","use_cases":"Understanding when AI adoption makes economic sense for your organization, Developing business strategy around AI capabilities and limitations","audience":"Curious-browser, Junior-DS"},{"id":"book-power-and-prediction","type":"book","name":"Power and Prediction","description":"AI's system-level disruption - sequel to Prediction Machines","category":"AI & Machine Learning","url":"https://www.amazon.com/Power-Prediction-Disruptive-Artificial-Intelligence/dp/1647824192","difficulty":"beginner","prerequisites":"basic-economics, technology-adoption-models","topic_tags":"AI-strategy, system-disruption, economic-transformation, prediction-markets, business-strategy","summary":"A strategic framework for understanding how AI creates system-level disruptions beyond individual task automation. Written by economists Ajay Agrawal, Joshua Gans, and Avi Goldfarb as a follow-up to Prediction Machines, exploring how prediction improvements reshape entire business ecosystems and economic structures.","use_cases":"Strategic planning for AI adoption across organizational systems, Understanding competitive dynamics in AI-transformed industries","audience":"Senior-DS, Curious-browser"},{"id":"book-the-attention-merchants","type":"book","name":"The Attention Merchants","description":"History and economics of attention and advertising","category":"Advertising & Attention","url":"https://www.amazon.com/Attention-Merchants-Scramble-Inside-Heads/dp/0385352018","difficulty":"beginner","prerequisites":"basic-economics, business-strategy-fundamentals","topic_tags":"attention-economy, digital-advertising, media-history, business-models, platform-economics","summary":"A comprehensive history of how businesses have captured and monetized human attention, from newspapers to digital platforms. The book explores the economic models underlying advertising-supported media and how tech companies have refined attention capture into a science. Essential reading for understanding the business fundamentals behind today's digital economy.","use_cases":"Understanding how advertising-supported business models work at tech companies, Analyzing the economic incentives behind social media platform design decisions","audience":"Junior-DS, Curious-browser"},{"id":"book-subprime-attention-crisis","type":"book","name":"Subprime Attention Crisis","description":"Programmatic advertising as a bubble: inflated metrics, click fraud, and misrepresented value \u2014 parallels to the 2008 housing crisis","category":"Advertising & Attention","url":"https://www.amazon.com/Subprime-Attention-Crisis-Advertising-Originals/dp/0374538654","difficulty":"beginner","prerequisites":"basic-economics, digital-marketing-concepts","topic_tags":"programmatic-advertising, ad-fraud, attention-economy, market-bubbles, digital-metrics","summary":"This book argues that programmatic advertising represents a market bubble similar to the 2008 subprime mortgage crisis, driven by inflated metrics, widespread fraud, and fundamental misunderstanding of digital ad value. It examines how automated ad buying, fake clicks, and bot traffic create systemic risks in the digital advertising economy. The analysis provides crucial context for data scientists and economists working in digital marketing and attention-based business models.","use_cases":"Understanding why digital advertising metrics may be unreliable when building attribution models, Evaluating the validity of programmatic advertising data before running marketing mix modeling","audience":"Curious-browser, Junior-DS"},{"id":"book-priceless","type":"book","name":"Priceless","description":"Pricing psychology and behavioral economics","category":"Pricing & Market Design","url":"https://www.amazon.com/Priceless-Myth-Fair-Value-Advantage/dp/0809078813","difficulty":"beginner","prerequisites":"basic-statistics, experimental-design","topic_tags":"behavioral-economics, pricing-psychology, consumer-behavior, market-research, decision-making","summary":"A foundational book exploring how psychological biases and cognitive limitations affect pricing decisions and consumer behavior. Written for general audiences, it covers key behavioral economics principles like anchoring, loss aversion, and reference point effects in pricing contexts. Essential reading for understanding why traditional economic models fail to predict real-world pricing outcomes.","use_cases":"Designing A/B tests for pricing experiments and understanding psychological factors that influence willingness to pay, Building behavioral assumptions into demand forecasting models and price optimization algorithms","audience":"Junior-DS, Curious-browser"},{"id":"book-confessions-of-the-pricing-man","type":"book","name":"Confessions of the Pricing Man","description":"Practitioner pricing strategy from the world's leading pricing consultant","category":"Pricing & Market Design","url":"https://www.amazon.com/Confessions-Pricing-Man-Affects-Everything/dp/3319203991","difficulty":"beginner","prerequisites":"basic-microeconomics, business-fundamentals","topic_tags":"pricing-strategy, business-operations, revenue-optimization, consulting, practitioner-guide","summary":"A practitioner's guide to pricing strategy written by Hermann Simon, the world's leading pricing consultant and founder of Simon-Kucher & Partners. The book shares real-world insights, case studies, and frameworks for effective pricing decisions across industries. Essential reading for anyone involved in pricing decisions, from product managers to executives.","use_cases":"Setting pricing strategy for a new product launch at a tech company, Evaluating and improving existing pricing models to maximize revenue","audience":"Junior-DS, Curious-browser"},{"id":"book-the-age-of-surveillance-capitalism","type":"book","name":"The Age of Surveillance Capitalism","description":"Data economics and behavioral surplus extraction","category":"Competition & Antitrust","url":"https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1610395697","difficulty":"intermediate","prerequisites":"microeconomics-theory, market-structure-analysis, behavioral-economics","topic_tags":"surveillance-capitalism, data-extraction, platform-economics, behavioral-surplus, tech-regulation","summary":"Shoshana Zuboff's foundational work analyzing how tech platforms extract economic value from human behavioral data as a form of 'surveillance capitalism'. The book examines how companies like Google and Facebook create behavioral surplus from user interactions and convert it into predictive products sold to third parties. Essential reading for understanding the economic structures underlying modern digital platforms and their implications for competition policy.","use_cases":"Understanding how platform business models monetize user data for antitrust analysis, Analyzing the economic incentives behind data collection practices in tech companies","audience":"Senior-DS, Curious-browser"},{"id":"book-weapons-of-math-destruction","type":"book","name":"Weapons of Math Destruction","description":"Algorithmic bias and fairness - ML economics","category":"AI & Machine Learning","url":"https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815","difficulty":"beginner","prerequisites":"basic-statistics, data-analysis-concepts","topic_tags":"algorithmic-bias, fairness, ethics, policy, book","summary":"Cathy O'Neil's influential book examining how algorithms can perpetuate and amplify social inequalities across hiring, lending, criminal justice, and other domains. Accessible to non-technical readers, it provides frameworks for identifying harmful algorithmic systems and understanding their economic and social impacts. Essential reading for anyone working with ML systems that affect people's lives.","use_cases":"Understanding potential biases in recommendation systems or hiring algorithms, Building ethical frameworks for ML product development","audience":"Junior-DS, Curious-browser"},{"id":"book-the-alignment-problem","type":"book","name":"The Alignment Problem","description":"AI alignment with human values - relevant to responsible AI","category":"AI & Machine Learning","url":"https://www.amazon.com/Alignment-Problem-Machine-Learning-Values/dp/0393635821","difficulty":"beginner","prerequisites":"basic-python, neural-networks, reinforcement-learning","topic_tags":"ai-alignment, ai-safety, responsible-ai, machine-learning-ethics, human-ai-interaction","summary":"A comprehensive introduction to the AI alignment problem - the challenge of ensuring AI systems pursue goals aligned with human values and intentions. The book explores both technical and philosophical aspects of building AI that remains beneficial and controllable as it becomes more capable. Essential reading for anyone working on AI systems who wants to understand potential risks and mitigation strategies.","use_cases":"Understanding safety considerations when deploying machine learning models in production, Designing reward functions and objective functions that align with business goals and ethical constraints","audience":"Junior-DS, Curious-browser"},{"id":"book-the-curse-of-bigness","type":"book","name":"The Curse of Bigness","description":"Concise antitrust primer for tech","category":"Competition & Antitrust","url":"https://www.amazon.com/Curse-Bigness-Antitrust-New-Gilded/dp/0999745468","difficulty":"beginner","prerequisites":"microeconomics-basics, market-structure-concepts","topic_tags":"antitrust-law, tech-monopolies, market-concentration, competition-policy, regulatory-economics","summary":"An accessible introduction to antitrust principles and their application to modern technology companies. Written by Tim Wu, it explains how market concentration harms innovation and consumers, with particular focus on Big Tech platforms. Essential reading for understanding the economic and legal foundations of competition policy in digital markets.","use_cases":"Understanding regulatory risks when analyzing tech company investments or market strategies, Preparing policy briefs on platform competition and market dominance issues","audience":"Curious-browser, Junior-DS"},{"id":"book-the-great-reversal","type":"book","name":"The Great Reversal","description":"Data-driven competition economics","category":"Competition & Antitrust","url":"https://www.amazon.com/Great-Reversal-America-Gave-Markets/dp/0674237544","difficulty":"beginner","prerequisites":"basic-economics, market-analysis, statistical-concepts","topic_tags":"market-concentration, antitrust-policy, economic-analysis, competition-economics, regulatory-economics","summary":"A comprehensive examination of how market concentration has increased across industries in the United States, leading to reduced competition, higher prices, and lower wages. The book presents empirical evidence showing how dominant firms have gained market power and discusses policy solutions to restore competitive markets. Essential reading for understanding modern competition policy and its economic implications.","use_cases":"Understanding market concentration trends when analyzing industry competition, Building economic arguments for antitrust policy recommendations","audience":"Curious-browser, Early-PhD"},{"id":"book-the-platform-delusion","type":"book","name":"The Platform Delusion","description":"Contrarian take - when network effects don't matter","category":"Platform Economics","url":"https://www.amazon.com/Platform-Delusion-Wins-Loses-Titans/dp/0593189434","difficulty":"beginner","prerequisites":"basic-economics, business-strategy","topic_tags":"platform-economics, network-effects, business-strategy, contrarian-analysis, market-dynamics","summary":"A contrarian examination of when platform strategies fail and network effects don't create sustainable competitive advantages. The book challenges conventional wisdom about digital platforms by analyzing cases where traditional business fundamentals matter more than network size. Essential reading for understanding the limitations of platform thinking in business strategy.","use_cases":"Evaluating whether a company's platform strategy claims are credible during investment analysis, Designing product strategy for markets where network effects may be weaker than expected","audience":"Curious-browser, Junior-DS"},{"id":"book-radical-markets","type":"book","name":"Radical Markets","description":"Mechanism design ideas - auctions, Harberger taxes, quadratic voting","category":"Pricing & Market Design","url":"https://www.amazon.com/Radical-Markets-Uprooting-Capitalism-Democracy/dp/0691177503","difficulty":"intermediate","prerequisites":"microeconomics-theory, game-theory-basics, auction-mechanisms","topic_tags":"mechanism-design, auction-theory, quadratic-voting, harberger-tax, market-design","summary":"Radical Markets presents innovative mechanism design proposals including Harberger taxes, quadratic voting, and new auction formats to address market failures and inequality. The book bridges economic theory with practical policy applications, making complex concepts accessible to practitioners. It's essential reading for anyone working on platform economics, voting systems, or alternative market structures.","use_cases":"designing voting mechanisms for DAOs or corporate governance, implementing dynamic pricing systems that account for social welfare","audience":"Mid-DS, Curious-browser"},{"id":"book-uberland","type":"book","name":"Uberland","description":"Algorithmic management and gig economy","category":"Labor & Gig Economy","url":"https://www.amazon.com/Uberland-Algorithms-Rewriting-Rules-Work/dp/0520298578","difficulty":"beginner","prerequisites":"basic-economics, survey-methods","topic_tags":"algorithmic-management, gig-economy, platform-labor, worker-autonomy, digital-platforms","summary":"Uberland examines how algorithmic management systems control and coordinate workers in the gig economy, particularly focusing on ride-sharing platforms. The book analyzes how algorithms shape worker behavior, earnings, and autonomy while appearing to offer flexibility. It provides insights into the power dynamics between platforms, workers, and the technology that mediates their relationship.","use_cases":"Understanding how platform algorithms influence worker decision-making for labor economics research, Analyzing the social and economic impacts of gig work platforms for policy research","audience":"Curious-browser, Early-PhD"},{"id":"book-the-filter-bubble","type":"book","name":"The Filter Bubble","description":"Personalization and recommendation economics","category":"Advertising & Attention","url":"https://www.amazon.com/Filter-Bubble-What-Internet-Hiding/dp/1594203008","difficulty":"beginner","prerequisites":"basic-statistics, web-analytics","topic_tags":"personalization, recommendation-systems, algorithmic-bias, platform-economics, information-filtering","summary":"A foundational book exploring how personalized algorithms create 'filter bubbles' that limit information diversity and shape user behavior. Eli Pariser examines the economic and social implications of recommendation systems used by major tech platforms. Essential reading for understanding the broader impacts of personalization beyond just technical implementation.","use_cases":"Understanding algorithmic bias in recommendation systems before designing A/B tests, Evaluating the societal impact of personalization features in product development","audience":"Junior-DS, Curious-browser"},{"id":"book-invisible-engines","type":"book","name":"Invisible Engines","description":"Early platform economics - software as two-sided markets","category":"Platform Economics","url":"https://www.amazon.com/Invisible-Engines-Platforms-Innovation-Industries/dp/0262550687","difficulty":"beginner","prerequisites":"basic-microeconomics, business-strategy-fundamentals","topic_tags":"platform-economics, two-sided-markets, software-platforms, network-effects, business-strategy","summary":"A foundational book explaining how software platforms create value by connecting different user groups, introducing the concept of two-sided markets in technology. Essential reading for understanding platform business models, network effects, and the economic principles behind companies like Microsoft, Google, and payment systems. Provides the theoretical framework that underlies modern platform economics without requiring advanced mathematical background.","use_cases":"Understanding how to design pricing strategies for multi-sided platforms, Analyzing competitive dynamics and market entry strategies for platform businesses","audience":"Junior-DS, Curious-browser"},{"id":"book-credit-risk-modeling-using-excel-and-vba","type":"book","name":"Credit Risk Modeling using Excel and VBA","description":"Practitioner guide to credit risk with Excel/VBA implementations. PD, LGD, EAD estimation and portfolio models.","category":"Risk Modeling","url":"https://www.amazon.com/Credit-Risk-Modeling-using-Excel/dp/0470660929","difficulty":"intermediate","prerequisites":"excel-vba-programming, basic-statistics, financial-modeling","topic_tags":"credit-risk, probability-of-default, excel-vba, portfolio-modeling, loss-given-default","summary":"A hands-on guide to building credit risk models using Excel and VBA, covering probability of default (PD), loss given default (LGD), and exposure at default (EAD) estimation techniques. The book provides practical implementations of portfolio credit risk models with ready-to-use Excel templates and VBA code for risk practitioners.","use_cases":"Building internal credit scoring models for loan approval decisions at a bank, Implementing regulatory capital calculations for credit risk under Basel II/III frameworks","audience":"Junior-DS, Mid-DS"},{"id":"book-generalized-linear-models-for-insurance-rating","type":"book","name":"Generalized Linear Models for Insurance Rating","description":"CAS Monograph Series. Industry standard for insurance pricing - GLMs, tweedie, territorial ratemaking.","category":"Risk Modeling","url":"https://www.casact.org/monograph/cas-monograph-no-5","difficulty":"intermediate","prerequisites":"linear-regression, maximum-likelihood-estimation, R-programming","topic_tags":"generalized-linear-models, insurance-pricing, actuarial-science, tweedie-distribution, territorial-rating","summary":"Industry-standard monograph covering generalized linear models for insurance pricing and risk assessment. Provides comprehensive treatment of GLM theory, Tweedie distributions, and territorial ratemaking techniques specifically applied to insurance contexts. Essential reference for actuaries and data scientists working in insurance pricing and risk modeling.","use_cases":"Building auto insurance premium pricing models using claim frequency and severity data, Developing territorial rating factors for property insurance based on geographic risk patterns","audience":"Mid-DS, Senior-DS"},{"id":"domain-pricing-&-subscriptions","type":"domain","name":"Pricing & Subscriptions","description":"Dynamic pricing, subscription dynamics, and revenue optimization \u2014 price elasticity estimation and causal inference form the core toolkit","category":"","url":""},{"id":"domain-ads-&-auctions","type":"domain","name":"Ads & Auctions","description":"Mechanism design and auction theory in industry \u2014 researchers with game theory backgrounds have direct advantages here","category":"","url":""},{"id":"domain-marketing-analytics","type":"domain","name":"Marketing Analytics","description":"CLV modeling, attribution, and retention analytics \u2014 researchers' panel data experience transfers directly to cohort analysis","category":"","url":""},{"id":"domain-risk,-safety-&-trust","type":"domain","name":"Risk, Safety & Trust","description":"Fraud detection, credit risk, and trust & safety ML \u2014 causal inference handles adversarial, imbalanced problems","category":"","url":""},{"id":"domain-recommendation-systems","type":"domain","name":"Recommendation Systems","description":"Random utility models underpin collaborative filtering \u2014 preference elicitation mirrors revealed preference theory","category":"","url":""},{"id":"domain-search-&-ranking","type":"domain","name":"Search & Ranking","description":"Learning-to-rank combines ML with causal inference \u2014 counterfactual learning addresses position bias like selection bias correction","category":"","url":""},{"id":"domain-logistics-&-supply-chain","type":"domain","name":"Logistics & Supply Chain","description":"Minimal starter kit for routing, dispatch, and demand forecasting \u2014 free, practitioner-focused resources","category":"","url":""},{"id":"domain-growth-data-science","type":"domain","name":"Growth Data Science","description":"Growth loops, funnel analysis, and experimentation \u2014 diff-in-diff and regression discontinuity power incrementality testing","category":"","url":""},{"id":"paper-bootstrap-methods:-another-look-at-the-jackknife","type":"paper","name":"Bootstrap Methods: Another Look at the Jackknife","description":"THE paper that created the bootstrap field. Shows that by drawing samples with replacement from observed data, you can estimate the sampling distribution of virtually any statistic\u2014no closed-form solutions required. Won the 2018 International Prize in Statistics.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full"},{"id":"paper-bootstrap-methods-for-standard-errors,-confidence-intervals,-and-other-measures-of-statistical","type":"paper","name":"Bootstrap Methods for Standard Errors, Confidence Intervals, and Other Measures of Statistical Accuracy","description":"The paper that made bootstrap accessible to practitioners. Shows how to apply bootstrap to real problems: bias estimation, prediction error, confidence intervals, time series, regression. Covers bootstrap CIs (percentile, BCa), when bootstrap fails, and practical diagnostics.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://projecteuclid.org/journals/statistical-science/volume-1/issue-1/Bootstrap-Methods-for-Standard-Errors-Confidence-Intervals-and-Other-Measures/10.1214/ss/1177013815.full"},{"id":"paper-a-scalable-bootstrap-for-massive-data","type":"paper","name":"A Scalable Bootstrap for Massive Data","description":"The Bag of Little Bootstraps (BLB) solves the fundamental problem that standard bootstrap requires O(B\u00d7n) operations\u2014impossible for terabyte-scale data. BLB takes small subsamples of size n^0.6, runs weighted bootstrap within each, and achieves same statistical efficiency while being trivially parallelizable across Spark/MapReduce.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12050"},{"id":"paper-estimating-uncertainty-for-massive-data-streams","type":"paper","name":"Estimating Uncertainty for Massive Data Streams","description":"The Poisson bootstrap replaces multinomial resampling with independent Poisson(1) weights for each observation. Enables single-pass streaming computation where you don't need to know n in advance, and each data shard can be processed independently. Built into Google's production analysis primitives.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://research.google/pubs/estimating-uncertainty-for-massive-data-streams/"},{"id":"paper-bootstrap-based-improvements-for-inference-with-clustered-errors","type":"paper","name":"Bootstrap-Based Improvements for Inference with Clustered Errors","description":"The wild cluster bootstrap handles clustered/panel data (users within cities, sessions within users, days within experiments) and provides valid inference even with few clusters (5-30) where standard cluster-robust SEs severely over-reject. Essential for diff-in-diff, geographic experiments, and switchback designs.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://direct.mit.edu/rest/article/90/3/414/57731/Bootstrap-Based-Improvements-for-Inference-with"},{"id":"paper-resampling-free-bootstrap-inference-for-quantiles","type":"paper","name":"Resampling-Free Bootstrap Inference for Quantiles","description":"A Spotify paper that achieves 828x speedup for quantile bootstrap by deriving the analytical distribution of bootstrap quantile indices. Enables bootstrap CIs for medians/percentiles on hundreds of millions of observations in milliseconds. Already deployed in production at Spotify.","category":"Statistics > Bootstrap & Resampling Methods","url":"https://arxiv.org/abs/2202.10992"},{"id":"paper-nonparametric-estimation-from-incomplete-observations","type":"paper","name":"Nonparametric Estimation from Incomplete Observations","description":"Introduced the Kaplan-Meier estimator (product-limit estimator), the universal method for estimating survival curves from censored data. Every survival analysis begins here\u2014essential for visualizing retention curves, comparing cohorts, and calculating median time-to-churn.","category":"Statistics > Survival Analysis & Time-to-Event Models","url":"https://www.jstor.org/stable/2281868"},{"id":"paper-regression-models-and-life-tables","type":"paper","name":"Regression Models and Life-Tables","description":"Introduced the Cox proportional hazards model, enabling regression analysis on survival data while leaving the baseline hazard unspecified. Ranked 24th among all scientific papers ever published. The workhorse for identifying churn drivers and estimating treatment effects of retention interventions.","category":"Statistics > Survival Analysis & Time-to-Event Models","url":"https://www.jstor.org/stable/2985181"},{"id":"paper-a-proportional-hazards-model-for-the-subdistribution-of-a-competing-risk","type":"paper","name":"A Proportional Hazards Model for the Subdistribution of a Competing Risk","description":"Extended Cox regression to competing risks\u2014situations where multiple mutually exclusive event types are possible. Answers 'what's the probability of Event A by time t, given Event B could happen first?' Critical for subscription dynamics where users can churn, upgrade, downgrade, or convert.","category":"Statistics > Survival Analysis & Time-to-Event Models","url":"https://www.jstor.org/stable/2670170"},{"id":"paper-random-survival-forests","type":"paper","name":"Random Survival Forests","description":"Extended random forests to censored survival data, creating a nonparametric, ensemble-based alternative to Cox regression. Captures complex interactions without proportional hazards assumption. The go-to ML approach for churn prediction with high-dimensional feature sets.","category":"Statistics > Survival Analysis & Time-to-Event Models","url":"https://projecteuclid.org/journals/annals-of-applied-statistics/volume-2/issue-3/Random-survival-forests/10.1214/08-AOAS169.full"},{"id":"paper-deepsurv:-personalized-treatment-recommender-system-using-a-cox-proportional-hazards-deep-neur","type":"paper","name":"DeepSurv: Personalized Treatment Recommender System Using a Cox Proportional Hazards Deep Neural Network","description":"Married deep learning with Cox regression by replacing the linear predictor with a neural network. Includes framework for personalized treatment recommendations\u2014identifying which retention interventions work best for which users. The bridge between survival analysis and modern recommender systems.","category":"Statistics > Survival Analysis & Time-to-Event Models","url":"https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0482-1"},{"id":"paper-sampling-based-approaches-to-calculating-marginal-densities","type":"paper","name":"Sampling-Based Approaches to Calculating Marginal Densities","description":"Birth of modern Bayesian computation. Demonstrated that the Gibbs sampler could solve any Bayesian posterior computation problem by iteratively sampling from conditional distributions. Before this paper, hierarchical models were limited to conjugate priors. After it, arbitrary model complexity became computationally feasible.","category":"Statistics > Bayesian Hierarchical Models","url":"https://www.jstor.org/stable/2289776"},{"id":"paper-data-analysis-using-stein's-estimator-and-its-generalizations","type":"paper","name":"Data Analysis Using Stein's Estimator and Its Generalizations","description":"Made James-Stein shrinkage practical and intuitive using baseball batting averages. Showed that shrinking individual estimates toward their collective mean reduces MSE by >50% vs raw sample means. Explains why hierarchical models work\u2014borrowing information via shrinkage slashes estimation error for small cells.","category":"Statistics > Bayesian Hierarchical Models","url":"https://www.jstor.org/stable/2285923"},{"id":"paper-prior-distributions-for-variance-parameters-in-hierarchical-models","type":"paper","name":"Prior Distributions for Variance Parameters in Hierarchical Models","description":"Identified that conventional inverse-gamma priors for variance parameters often dominate the posterior when group-level sample sizes are small. Introduced half-Cauchy and half-t priors as robust alternatives\u2014now the default in Stan and PyMC. The fix for when hierarchical models return implausible variance estimates.","category":"Statistics > Bayesian Hierarchical Models","url":"https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-3/Prior-distributions-for-variance-parameters-in-hierarchical-models-comment-on/10.1214/06-BA117A.full"},{"id":"paper-the-no-u-turn-sampler:-adaptively-setting-path-lengths-in-hamiltonian-monte-carlo","type":"paper","name":"The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo","description":"NUTS eliminated painful manual tuning that made HMC impractical for non-experts. By automatically determining trajectory lengths, achieved near-optimal efficiency without user intervention. Powers Stan, PyMC, NumPyro\u2014the reason you can fit 50-parameter hierarchical MMMs without tuning anything.","category":"Statistics > Bayesian Hierarchical Models","url":"https://jmlr.org/papers/v15/hoffman14a.html"},{"id":"paper-inferring-causal-impact-using-bayesian-structural-time-series-models","type":"paper","name":"Inferring Causal Impact Using Bayesian Structural Time-Series Models","description":"CausalImpact combines Bayesian structural time-series with synthetic control to estimate counterfactual outcomes when experiments are impossible. Answers 'what would have happened without the intervention?' Google's most-used internal causal inference tool for measuring TV campaigns and regional launches.","category":"Statistics > Bayesian Hierarchical Models","url":"https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-1/Inferring-causal-impact-using-Bayesian-structural-time-series-models/10.1214/14-AOAS788.full"},{"id":"paper-bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects","type":"paper","name":"Bayesian Methods for Media Mix Modeling with Carryover and Shape Effects","description":"Established modern Bayesian MMM paradigm now implemented in Google's LightweightMMM and Meridian. Key innovations: flexible functional forms for adstock decay and saturation, full Bayesian treatment propagating uncertainty to ROAS estimates. The starting point for marketing budget optimization at scale.","category":"Statistics > Bayesian Hierarchical Models","url":"https://research.google/pubs/bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects/"},{"id":"paper-generalized-linear-models","type":"paper","name":"Generalized Linear Models","description":"THE seminal paper that unified linear, logistic, and Poisson regression under a single framework. Showed any exponential family outcome can be modeled through a link function connecting mean response to linear predictor. Introduced iteratively reweighted least squares (IRLS) for ML estimation. Understanding this lets you choose the right GLM family for any outcome type.","category":"Statistics > Generalized Linear Models","url":"https://www.jstor.org/stable/2344614"},{"id":"paper-quasi-likelihood-functions,-generalized-linear-models,-and-the-gauss-newton-method","type":"paper","name":"Quasi-Likelihood Functions, Generalized Linear Models, and the Gauss-Newton Method","description":"Introduced quasi-likelihood\u2014requiring only mean-variance relationship specification, not full distribution. Enables valid inference when count data has variance exceeding mean (overdispersion). Real behavioral data almost never follows Poisson assumptions; quasi-likelihood gives valid SEs by specifying variance = \u03c6 \u00d7 mean.","category":"Statistics > Generalized Linear Models","url":"https://www.jstor.org/stable/2334725"},{"id":"paper-zero-inflated-poisson-regression,-with-an-application-to-defects-in-manufacturing","type":"paper","name":"Zero-Inflated Poisson Regression, with an Application to Defects in Manufacturing","description":"Developed Zero-Inflated Poisson (ZIP) model for data from a mixture: with probability p, outcome is always zero (structural zeros), otherwise follows Poisson. Essential for engagement metrics\u2014separates 'never-users' from 'not-yet users' when modeling clicks, sessions, or purchases. Implemented in R's pscl package.","category":"Statistics > Generalized Linear Models","url":"https://www.jstor.org/stable/1269547"},{"id":"paper-beta-regression-for-modelling-rates-and-proportions","type":"paper","name":"Beta Regression for Modelling Rates and Proportions","description":"Proposed regression with beta-distributed responses for bounded (0,1) outcomes. Handles natural heteroskedasticity of rate data\u2014variance highest near 0.5, decreasing toward boundaries. Linear regression on rates produces nonsensical predictions outside [0,1]. Essential for CTR, conversion rates, retention rates. Implemented in R's betareg package.","category":"Statistics > Generalized Linear Models","url":"https://www.tandfonline.com/doi/abs/10.1080/0266476042000214501"},{"id":"paper-regression-based-tests-for-overdispersion-in-the-poisson-model","type":"paper","name":"Regression-Based Tests for Overdispersion in the Poisson Model","description":"Developed practical regression-based tests for overdispersion requiring only mean-variance specification. The optimal test reduces to a simple t-test from auxiliary OLS regression. Before fitting negative binomial for overdispersed counts, use this test to formally reject Poisson. Implemented in R's AER package via dispersiontest().","category":"Statistics > Generalized Linear Models","url":"https://www.sciencedirect.com/science/article/abs/pii/030440769090014K"},{"id":"paper-random-effects-models-for-longitudinal-data","type":"paper","name":"Random-Effects Models for Longitudinal Data","description":"Won 2021 International Prize in Statistics. Unified empirical Bayes and ML via EM algorithm for unbalanced longitudinal data with subject-specific random effects. Solves the 'users have different numbers of sessions' problem\u2014models user heterogeneity while borrowing strength across users through partial pooling.","category":"Statistics > Mixed Effects & Multilevel Models","url":"https://www.jstor.org/stable/2529876"},{"id":"paper-recovery-of-inter-block-information-when-block-sizes-are-unequal","type":"paper","name":"Recovery of Inter-Block Information when Block Sizes are Unequal","description":"Invented Restricted Maximum Likelihood (REML), which accounts for degrees of freedom lost to estimating fixed effects. Now the default estimation method in virtually every mixed model software. Critical for unbiased variance component estimates, especially important for power analysis in A/B testing.","category":"Statistics > Mixed Effects & Multilevel Models","url":"https://www.jstor.org/stable/2334389"},{"id":"paper-that-blup-is-a-good-thing:-the-estimation-of-random-effects","type":"paper","name":"That BLUP is a Good Thing: The Estimation of Random Effects","description":"Unified BLUP (Best Linear Unbiased Prediction) theory\u2014showing it's the same as Kalman filtering, kriging, and credibility theory. Explains why shrinkage toward the grand mean is optimal: users with little data shrink toward population mean, users with abundant data reflect their own history.","category":"Statistics > Mixed Effects & Multilevel Models","url":"https://projecteuclid.org/journals/statistical-science/volume-6/issue-1/That-BLUP-is-a-Good-Thing--The-Estimation-of/10.1214/ss/1177011926.full"},{"id":"paper-fitting-linear-mixed-effects-models-using-lme4","type":"paper","name":"Fitting Linear Mixed-Effects Models Using lme4","description":"One of the most cited statistical papers in history (~75,000 citations). Documents lme4's computational algorithms and formula syntax: (1|user_id) for random intercepts, (treatment|user_id) for random slopes, (1|user_id) + (1|market) for crossed effects. The implementation guide for mixed models in R.","category":"Statistics > Mixed Effects & Multilevel Models","url":"https://www.jstatsoft.org/article/view/v067i01"},{"id":"paper-on-the-pooling-of-time-series-and-cross-section-data","type":"paper","name":"On the Pooling of Time Series and Cross Section Data","description":"Bridges econometrics and biostatistics: proves fixed effects equals random effects when you include group means as covariates. The 'Mundlak approach' offers a compromise\u2014random effects for efficiency plus cluster means to allow correlation between effects and regressors. Critical for choosing between plm and lmer.","category":"Statistics > Mixed Effects & Multilevel Models","url":"https://www.jstor.org/stable/1913646"},{"id":"paper-controlling-the-false-discovery-rate:-a-practical-and-powerful-approach-to-multiple-testing","type":"paper","name":"Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing","description":"One of the most-cited statistics papers ever (~100,000 citations). Introduced FDR as alternative to FWER\u2014controls expected proportion of false discoveries among rejections. The BH step-up procedure is now default in experimentation platforms at Google, Netflix, Meta. Essential when testing 500 experiments or 20 metrics per A/B test.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://www.jstor.org/stable/2346101"},{"id":"paper-a-simple-sequentially-rejective-multiple-test-procedure","type":"paper","name":"A Simple Sequentially Rejective Multiple Test Procedure","description":"Dominant method for FWER control when you cannot tolerate any false positives. Step-down approach uniformly more powerful than Bonferroni with same guarantee, no dependence assumptions required. The right choice for guardrail metrics (revenue, latency, crash rates) where a single false positive could ship a harmful feature.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://www.jstor.org/stable/4615733"},{"id":"paper-a-direct-approach-to-false-discovery-rates","type":"paper","name":"A Direct Approach to False Discovery Rates","description":"Introduced q-values\u2014the FDR analogue of p-values. A q-value tells you the minimum FDR threshold at which a test becomes significant. Also introduced \u03c0\u2080 estimation (proportion of true nulls), which can boost power up to 8\u00d7 compared to BH when many tests are truly non-null.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://www.jstor.org/stable/3088784"},{"id":"paper-the-control-of-the-false-discovery-rate-in-multiple-testing-under-dependency","type":"paper","name":"The Control of the False Discovery Rate in Multiple Testing Under Dependency","description":"Proves BH controls FDR under positive regression dependence (PRDS), covering most real-world cases. For arbitrary dependence, provides the BY correction guaranteeing FDR control under any correlation structure. Essential since A/B test metrics are correlated, user segments overlap, and experimental units cluster.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-4/The-control-of-the-false-discovery-rate-in-multiple-testing/10.1214/aos/1013699998.full"},{"id":"paper-large-scale-simultaneous-hypothesis-testing:-the-choice-of-a-null-hypothesis","type":"paper","name":"Large-Scale Simultaneous Hypothesis Testing: The Choice of a Null Hypothesis","description":"Introduced empirical null and local FDR (lfdr). When testing thousands of hypotheses, the theoretical null N(0,1) may be miscalibrated. Estimating null from data corrects for systematic biases. Local FDR assigns each experiment a 'probability of being noise'\u2014essential for prioritizing follow-up in large experimentation portfolios.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://www.jstor.org/stable/27590386"},{"id":"paper-controlling-the-false-discovery-rate-via-knockoffs","type":"paper","name":"Controlling the False Discovery Rate via Knockoffs","description":"FDR control for variable selection in regression\u2014where traditional p-values are unreliable due to correlated predictors. Constructs 'fake' knockoff variables mimicking correlation structure but independent of outcome. Enables FDR-controlled claims about which variables matter, not just whether there's signal. Bridge between multiple testing and high-dimensional regression.","category":"Statistics > Multiple Testing & False Discovery Rate","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-43/issue-5/Controlling-the-false-discovery-rate-via-knockoffs/10.1214/15-AOS1337.full"},{"id":"paper-a-generalization-of-sampling-without-replacement-from-a-finite-universe","type":"paper","name":"A Generalization of Sampling Without Replacement from a Finite Universe","description":"Introduced the Horvitz-Thompson estimator: \u0176 = \u03a3(Y\u1d62/\u03c0\u1d62). Works for any probability sampling design by inverse probability weighting. This is the same math underlying propensity score weighting in causal inference\u2014survey statisticians solved IPW in 1952; causal inference borrowed it three decades later.","category":"Statistics > Survey Sampling & Weighted Estimation","url":"https://www.jstor.org/stable/2280784"},{"id":"paper-calibration-estimators-in-survey-sampling","type":"paper","name":"Calibration Estimators in Survey Sampling","description":"Unified decades of ad-hoc weighting methods\u2014post-stratification, raking, regression estimation\u2014under a single calibration framework. Weights minimize distance from design weights while matching known population totals. Foundation behind every 'weight to Census' adjustment in commercial panels and platform surveys.","category":"Statistics > Survey Sampling & Weighted Estimation","url":"https://www.jstor.org/stable/2290268"},{"id":"paper-on-the-two-different-aspects-of-the-representative-method:-the-method-of-stratified-sampling-a","type":"paper","name":"On the Two Different Aspects of the Representative Method: The Method of Stratified Sampling and the Method of Purposive Selection","description":"Proved random probability sampling beats purposive 'representative' selection. Derived optimal allocation formula for stratified sampling: sample proportional to N\u2095 \u00d7 S\u2095 (stratum size \u00d7 stratum SD). Establishes why design-based inference via randomization provides the foundation for valid uncertainty quantification.","category":"Statistics > Survey Sampling & Weighted Estimation","url":"https://www.jstor.org/stable/2342192"},{"id":"paper-poststratification-into-many-categories-using-hierarchical-logistic-regression","type":"paper","name":"Poststratification into Many Categories Using Hierarchical Logistic Regression","description":"Introduced MRP (Multilevel Regression with Poststratification) for small-area estimation when many cells are sparse. Borrows strength across similar cells via hierarchical model, then poststratifies to population proportions. Enables valid estimation for small subgroups from biased opt-in samples\u2014validated by accurate election forecasts from Xbox data that was 93% male.","category":"Statistics > Survey Sampling & Weighted Estimation","url":"https://www150.statcan.gc.ca/n1/en/pub/12-001-x/1997002/article/3616-eng.pdf"},{"id":"paper-doubly-robust-inference-with-nonprobability-survey-samples","type":"paper","name":"Doubly Robust Inference with Nonprobability Survey Samples","description":"Doubly robust estimators for convenience samples with unknown selection mechanisms\u2014the default for tech company data. Consistent if either propensity model or outcome model is correctly specified. Bridges survey sampling and causal inference, showing survey propensity weights and causal IPW solve mathematically identical problems.","category":"Statistics > Survey Sampling & Weighted Estimation","url":"https://www.tandfonline.com/doi/abs/10.1080/01621459.2019.1677241"},{"id":"paper-limiting-forms-of-the-frequency-distribution-of-the-largest-or-smallest-member-of-a-sample","type":"paper","name":"Limiting Forms of the Frequency Distribution of the Largest or Smallest Member of a Sample","description":"Proves that maxima of i.i.d. samples converge to exactly three distribution types\u2014Gumbel (light tails), Fr\u00e9chet (heavy tails), and Weibull (bounded tails). This 'three types theorem' is the foundation of all EVT. Every anomaly detector, VaR model, and tail risk estimator builds on this elegant result.","category":"Statistics > Extreme Value Theory","url":"https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/limiting-forms-of-the-frequency-distribution-of-the-largest-or-smallest-member-of-a-sample/D9F2E08BF5539E47E0CDEE35B4DC4C62"},{"id":"paper-statistical-inference-using-extreme-order-statistics","type":"paper","name":"Statistical Inference Using Extreme Order Statistics","description":"Introduced GPD (Generalized Pareto Distribution) and Peaks-Over-Threshold methodology. Exceedances beyond any sufficiently high threshold follow GPD regardless of original distribution. POT uses all extreme observations rather than just block maxima, enabling anomaly detection with 10-100x fewer observations. Foundation of SPOT, DSPOT, and all modern streaming EVT.","category":"Statistics > Extreme Value Theory","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-3/issue-1/Statistical-Inference-Using-Extreme-Order-Statistics/10.1214/aos/1176343003.full"},{"id":"paper-models-for-exceedances-over-high-thresholds","type":"paper","name":"Models for Exceedances Over High Thresholds","description":"THE implementation guide for POT modeling. Complete toolkit: MLE for GPD parameters, threshold selection via mean residual life plots, diagnostic methods, handling temporal dependence. Every EVT software package (R's extRemes, Python's scipy.stats) implements methods from this paper. Answers: How to choose threshold? How to validate model?","category":"Statistics > Extreme Value Theory","url":"https://www.jstor.org/stable/2345667"},{"id":"paper-estimation-of-tail-related-risk-measures-for-heteroscedastic-financial-time-series:-an-extreme","type":"paper","name":"Estimation of Tail-Related Risk Measures for Heteroscedastic Financial Time Series: An Extreme Value Approach","description":"Solved EVT's limitation for time-varying volatility via two-stage GARCH-EVT: filter through GARCH to remove heteroscedasticity, then apply GPD to standardized residuals. First rigorous formulas for conditional VaR and Expected Shortfall satisfying Basel requirements. Same framework applies to tail latency, fraud detection, any metric with volatility clustering.","category":"Statistics > Extreme Value Theory","url":"https://www.sciencedirect.com/science/article/abs/pii/S0927539800000128"},{"id":"paper-anomaly-detection-in-streams-with-extreme-value-theory","type":"paper","name":"Anomaly Detection in Streams with Extreme Value Theory","description":"SPOT (Streaming Peaks-Over-Threshold) automatically detects anomalies in real-time with no manual threshold tuning\u2014threshold emerges from EVT theory. DSPOT extends to non-stationary streams with concept drift. O(1) per observation, no distributional assumptions. Applications: DDoS detection, equipment failures, fraud, latency spikes. Open-source Python code included.","category":"Statistics > Extreme Value Theory","url":"https://dl.acm.org/doi/10.1145/3097983.3098144"},{"id":"paper-probabilistic-models-for-some-intelligence-and-attainment-tests","type":"paper","name":"Probabilistic Models for Some Intelligence and Attainment Tests","description":"Introduced the one-parameter logistic (1PL/Rasch) model where response probability depends on person ability minus item difficulty. The 'specific objectivity' property enables comparing persons independent of which items they answered\u2014the theoretical cornerstone of all computer adaptive testing (CAT) and Duolingo-style assessments.","category":"Statistics > Item Response Theory","url":"https://press.uchicago.edu/ucp/books/book/chicago/P/bo5963223.html"},{"id":"paper-statistical-theories-of-mental-test-scores","type":"paper","name":"Statistical Theories of Mental Test Scores","description":"The 'bible of test theory'. Birnbaum's chapters introduced 2PL (adding discrimination \u03b1) and 3PL (adding guessing \u03b3) models. 2PL identifies which items best differentiate abilities\u2014high-discrimination items worth more for rankings. 3PL handles multiple-choice guessing and random baseline performance. The canonical model family for 50+ years.","category":"Statistics > Item Response Theory","url":"https://www.infoagepub.com/products/Statistical-Theories-of-Mental-Test-Scores"},{"id":"paper-machine-learning\u2013driven-language-assessment","type":"paper","name":"Machine Learning\u2013Driven Language Assessment","description":"How Duolingo English Test works at scale. Uses ML/NLP to estimate Rasch difficulty from item text\u2014skipping expensive human piloting. Achieves 0.96 internal consistency and r=0.77-0.78 with TOEFL/IELTS. Item exposure drops to 0.10% vs 20% in conventional CAT. Blueprint for building adaptive assessment without human norming.","category":"Statistics > Item Response Theory","url":"https://aclanthology.org/2020.tacl-1.16/"},{"id":"paper-\u03b2\u00b3-irt:-a-new-item-response-model-and-its-applications","type":"paper","name":"\u03b2\u00b3-IRT: A New Item Response Model and its Applications","description":"Extends IRT to continuous responses using Beta-distributed item characteristic curves. Treats ML model evaluation as psychometric problem: each test instance has latent difficulty, each model has latent ability. Identifies which benchmark examples genuinely discriminate strong from weak classifiers\u2014critical for efficient benchmarking.","category":"Statistics > Item Response Theory","url":"https://proceedings.mlr.press/v89/chen19b.html"},{"id":"paper-building-an-evaluation-scale-using-item-response-theory","type":"paper","name":"Building an Evaluation Scale using Item Response Theory","description":"First systematic application of IRT to NLP evaluation. Shows high accuracy \u2260 high ability when item difficulty ignored\u201480% on easy items may indicate lower ability than 70% on hard items. Foundation for IRT-based ML leaderboards accounting for difficulty. Directly applicable to crowdsourcing quality estimation.","category":"Statistics > Item Response Theory","url":"https://aclanthology.org/D16-1062/"},{"id":"paper-valid-post-selection-inference","type":"paper","name":"Valid Post-Selection Inference","description":"First practical PoSI framework for valid inference after arbitrary model selection. Key insight: treat as simultaneous inference by widening CIs to cover all 2^p possible coefficient estimates across submodels. Conservative but universally valid\u2014works regardless of whether selection used stepwise, lasso, AIC, or informal judgment.","category":"Statistics > Post-Selection Inference","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-41/issue-2/Valid-post-selection-inference/10.1214/12-AOS1077.full"},{"id":"paper-a-significance-test-for-the-lasso","type":"paper","name":"A Significance Test for the Lasso","description":"Breakthrough bringing p-values to lasso regression via covariance test statistic. Under null, test statistic follows Exp(1)\u2014though variables chosen adaptively, lasso shrinkage makes null distribution tractable. Works in high-dimensional settings (p > n). The first principled answer to 'which lasso-selected features are real.'","category":"Statistics > Post-Selection Inference","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-42/issue-2/A-significance-test-for-the-lasso/10.1214/13-AOS1175.full"},{"id":"paper-exact-post-selection-inference,-with-application-to-the-lasso","type":"paper","name":"Exact Post-Selection Inference, with Application to the Lasso","description":"THE foundational methods paper. Introduces polyhedral lemma: lasso selection event = response y falling into polyhedral set (Ay \u2264 b). Conditioning yields truncated Gaussian distribution for exact finite-sample CIs accounting for selection. No asymptotics required. Implemented in selectiveInference R package.","category":"Statistics > Post-Selection Inference","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-44/issue-3/Exact-post-selection-inference-with-application-to-the-lasso/10.1214/15-AOS1371.full"},{"id":"paper-statistical-learning-and-selective-inference","type":"paper","name":"Statistical Learning and Selective Inference","description":"Accessible PNAS entry point to the field. Poses the question: 'Having mined data to find potential associations, how do we properly assess their strength?' Illustrates methods for forward stepwise, lasso, PCA with worked examples. Connects selective inference to replication crisis\u2014cherry-picking requires higher significance bar.","category":"Statistics > Post-Selection Inference","url":"https://www.pnas.org/doi/10.1073/pnas.1507583112"},{"id":"paper-exact-post-selection-inference-for-sequential-regression-procedures","type":"paper","name":"Exact Post-Selection Inference for Sequential Regression Procedures","description":"Extends polyhedral framework to forward stepwise and LAR\u2014the most commonly used selection procedures. Proves these produce polyhedral selection events enabling exact conditional inference. Primary methods paper underlying selectiveInference R package: fs(), fsInf(), lar(), larInf(), fixedLassoInf().","category":"Statistics > Post-Selection Inference","url":"https://www.tandfonline.com/doi/abs/10.1080/01621459.2015.1108848"},{"id":"paper-controlled-experiments-on-the-web:-survey-and-practical-guide","type":"paper","name":"Controlled Experiments on the Web: Survey and Practical Guide","description":"THE foundational paper on web experimentation. Covers hypothesis testing, sample size, metrics, and common pitfalls. 2000+ citations.","category":"Experimentation > A/B Test Design & Analysis","url":"https://link.springer.com/article/10.1007/s10618-008-0114-1"},{"id":"paper-overlapping-experiment-infrastructure:-more,-better,-faster-experimentation","type":"paper","name":"Overlapping Experiment Infrastructure: More, Better, Faster Experimentation","description":"Google's infrastructure for running overlapping experiments, enabling hundreds of simultaneous tests without interference.","category":"Experimentation > A/B Test Design & Analysis","url":"https://research.google.com/pubs/archive/36500.pdf"},{"id":"paper-diagnosing-sample-ratio-mismatch-in-online-controlled-experiments:-a-taxonomy-and-rules-of-thu","type":"paper","name":"Diagnosing Sample Ratio Mismatch in Online Controlled Experiments: A Taxonomy and Rules of Thumb for Practitioners","description":"The definitive SRM paper from Microsoft/Booking.com\u2014provides taxonomy of causes and 10 diagnostic rules; ~6% of experiments exhibit SRM.","category":"Experimentation > A/B Test Design & Analysis","url":"https://dl.acm.org/doi/10.1145/3292500.3330722"},{"id":"paper-trustworthy-online-controlled-experiments:-five-puzzling-outcomes-explained","type":"paper","name":"Trustworthy Online Controlled Experiments: Five Puzzling Outcomes Explained","description":"Foundational Microsoft paper on experiment validity; coined OEC design principles and trustworthiness checks now industry standard.","category":"Experimentation > A/B Test Design & Analysis","url":"https://dl.acm.org/doi/10.1145/2339530.2339653"},{"id":"paper-a-dirty-dozen:-twelve-common-metric-interpretation-pitfalls-in-online-controlled-experiments","type":"paper","name":"A Dirty Dozen: Twelve Common Metric Interpretation Pitfalls in Online Controlled Experiments","description":"Essential guide to metric design\u2014introduces metric taxonomy (OEC, guardrail, diagnostic) with real experiment examples.","category":"Experimentation > A/B Test Design & Analysis","url":"https://dl.acm.org/doi/10.1145/3097983.3098024"},{"id":"paper-improving-the-sensitivity-of-online-controlled-experiments-by-utilizing-pre-experiment-data-(c","type":"paper","name":"Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data (CUPED)","description":"The CUPED method that uses pre-experiment covariates to dramatically reduce variance in experiment metrics.","category":"Experimentation > Variance Reduction","url":"https://robotics.stanford.edu/~ronnyk/2013-02CUPEDImprovingSensitivityOfControlledExperiments.pdf"},{"id":"paper-regression-adjustments-for-analyzing-randomized-experiments","type":"paper","name":"Regression Adjustments for Analyzing Randomized Experiments","description":"Shows how regression adjustment in randomized experiments yields valid inference even with heterogeneous treatment effects.","category":"Experimentation > Variance Reduction","url":"https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-1/Agnostic-notes-on-regression-adjustments-to-experimental-data--Reexamining/10.1214/12-AOAS583.full"},{"id":"paper-variance-reduction-in-randomized-experiments","type":"paper","name":"Variance Reduction in Randomized Experiments","description":"Optimal stratification and regression adjustment methods for experimental data with theoretical guarantees.","category":"Experimentation > Variance Reduction","url":"https://www.nber.org/papers/w24150"},{"id":"paper-machine-learning-for-variance-reduction-in-online-experiments","type":"paper","name":"Machine Learning for Variance Reduction in Online Experiments","description":"Introduces MLRATE\u2014extends CUPED to ML models via cross-fitting; achieved 70%+ variance reduction over difference-in-means at Meta.","category":"Experimentation > Variance Reduction","url":"https://proceedings.neurips.cc/paper/2021/hash/488b084119a1c7a4950f00706ec7ea16-Abstract.html"},{"id":"paper-adjusting-treatment-effect-estimates-by-post-stratification-in-randomized-experiments","type":"paper","name":"Adjusting Treatment Effect Estimates by Post-Stratification in Randomized Experiments","description":"Theoretical foundation for post-stratification; proves it's nearly as efficient as blocking with variance difference O(1/n\u00b2).","category":"Experimentation > Variance Reduction","url":"https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2012.01048.x"},{"id":"paper-improving-the-sensitivity-of-online-controlled-experiments:-case-studies-at-netflix","type":"paper","name":"Improving the Sensitivity of Online Controlled Experiments: Case Studies at Netflix","description":"Industry workhorse comparing stratification, post-stratification, and CUPED at scale; recommends post-assignment techniques.","category":"Experimentation > Variance Reduction","url":"https://dl.acm.org/doi/10.1145/2939672.2939733"},{"id":"paper-peeking-at-a-b-tests:-why-it-matters,-and-what-to-do-about-it","type":"paper","name":"Peeking at A/B Tests: Why It Matters, and What to Do About It","description":"Analyzes the peeking problem in A/B tests and introduces always-valid p-values for sequential testing.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2925568"},{"id":"paper-safe-testing","type":"paper","name":"Safe Testing","description":"E-values and safe anytime-valid inference that allows optional stopping while controlling type I error.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://arxiv.org/abs/1906.07801"},{"id":"paper-a-b-testing-with-fat-tails","type":"paper","name":"A/B Testing with Fat Tails","description":"Addresses the problem of highly variable metrics in experiments and proposes robust statistical methods.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://arxiv.org/abs/1901.04932"},{"id":"paper-a-multiple-testing-procedure-for-clinical-trials","type":"paper","name":"A Multiple Testing Procedure for Clinical Trials","description":"Foundational classic (3,200+ citations)\u2014established group sequential boundaries that all modern methods build upon.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://www.jstor.org/stable/2530245"},{"id":"paper-time-uniform,-nonparametric,-nonasymptotic-confidence-sequences","type":"paper","name":"Time-uniform, Nonparametric, Nonasymptotic Confidence Sequences","description":"Modern theoretical foundation for anytime-valid inference; backbone for GrowthBook, Spotify, and other industry tools.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-2/Time-uniform-nonparametric-nonasymptotic-confidence-sequences/10.1214/20-AOS1991.full"},{"id":"paper-continuous-monitoring-of-a-b-tests-without-pain:-optional-stopping-in-bayesian-testing","type":"paper","name":"Continuous Monitoring of A/B Tests without Pain: Optional Stopping in Bayesian Testing","description":"Rigorous theoretical grounding for Bayesian sequential testing with continuous monitoring; Microsoft's framework.","category":"Experimentation > Sequential & Adaptive Testing","url":"https://ieeexplore.ieee.org/document/7796895"},{"id":"paper-detecting-network-effects:-randomizing-over-randomized-experiments","type":"paper","name":"Detecting Network Effects: Randomizing Over Randomized Experiments","description":"Graph cluster randomization and design-based methods for detecting interference in network experiments.","category":"Experimentation > Interference & Spillovers","url":"https://arxiv.org/abs/1404.7530"},{"id":"paper-estimating-peer-effects-in-networks-with-peer-encouragement-designs","type":"paper","name":"Estimating Peer Effects in Networks with Peer Encouragement Designs","description":"Two-stage randomization design for identifying peer effects in social networks.","category":"Experimentation > Interference & Spillovers","url":"https://www.pnas.org/doi/10.1073/pnas.1511201113"},{"id":"paper-experimentation-in-two-sided-marketplaces","type":"paper","name":"Experimentation in Two-Sided Marketplaces","description":"Framework for experiments in marketplaces where treatment of one side affects the other.","category":"Experimentation > Interference & Spillovers","url":"https://arxiv.org/abs/2002.06875"},{"id":"paper-estimating-average-causal-effects-under-general-interference","type":"paper","name":"Estimating Average Causal Effects Under General Interference","description":"The seminal exposure mapping paper\u2014unified framework for design, exposure mapping, and estimands under network interference.","category":"Experimentation > Interference & Spillovers","url":"https://projecteuclid.org/journals/annals-of-applied-statistics/volume-11/issue-4/Estimating-average-causal-effects-under-general-interference-with-application-to/10.1214/16-AOAS1005.full"},{"id":"paper-design-and-analysis-of-bipartite-experiments-under-a-linear-exposure-response-model","type":"paper","name":"Design and Analysis of Bipartite Experiments Under a Linear Exposure-Response Model","description":"Essential for two-sided marketplaces\u2014introduces ERL estimator for buyer/seller and rider/driver experiment structures.","category":"Experimentation > Interference & Spillovers","url":"https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-17/issue-1/Design-and-analysis-of-bipartite-experiments-under-a-linear-exposure/10.1214/23-EJS2111.full"},{"id":"paper-a-review-of-spatial-causal-inference-methods-for-environmental-and-epidemiological-application","type":"paper","name":"A Review of Spatial Causal Inference Methods for Environmental and Epidemiological Applications","description":"Comprehensive review of spatial interference methods including geostatistical approaches for location-based spillovers.","category":"Experimentation > Interference & Spillovers","url":"https://onlinelibrary.wiley.com/doi/10.1111/insr.12452"},{"id":"paper-switchback-experiments-and-randomized-experiments-for-estimating-platform-level-effects","type":"paper","name":"Switchback Experiments and Randomized Experiments for Estimating Platform-Level Effects","description":"Design and analysis of switchback experiments for marketplace interventions at Airbnb.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3548162"},{"id":"paper-causal-impact:-a-new-approach-to-estimate-causal-effects","type":"paper","name":"Causal Impact: A New Approach to Estimate Causal Effects","description":"Google's Bayesian structural time-series approach for measuring impact of geo-level interventions.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://research.google/pubs/estimating-uncertainty-for-massive-data-streams/"},{"id":"paper-geolift:-open-source-solution-for-measuring-incremental-impact","type":"paper","name":"GeoLift: Open Source Solution for Measuring Incremental Impact","description":"Meta's open-source tool for geo-experiment design and measurement using synthetic control methods.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://github.com/facebookincubator/GeoLift"},{"id":"paper-design-and-analysis-of-switchback-experiments","type":"paper","name":"Design and Analysis of Switchback Experiments","description":"The definitive switchback paper\u2014optimal design under carryover effects with minimax formulation; used by Uber, Lyft, DoorDash.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2022.4386"},{"id":"paper-using-synthetic-controls:-feasibility,-data-requirements,-and-methodological-aspects","type":"paper","name":"Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects","description":"Authoritative methodological review from synthetic control's creator; called 'most important innovation in policy evaluation in 15 years'.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://www.aeaweb.org/articles?id=10.1257/jel.20191450"},{"id":"paper-trimmed-match-design-for-randomized-paired-geo-experiments","type":"paper","name":"Trimmed Match Design for Randomized Paired Geo Experiments","description":"Addresses power analysis for geo experiments with few heterogeneous regions; foundation for Google's Trimmed Match library.","category":"Experimentation > Switchback & Geo-Experiments","url":"https://arxiv.org/abs/2105.07060"},{"id":"paper-surrogate-index:-combining-short-term-proxies-to-estimate-long-term-treatment-effects","type":"paper","name":"Surrogate Index: Combining Short-Term Proxies to Estimate Long-Term Treatment Effects","description":"Framework for using short-term outcomes to predict long-term treatment effects in experiments.","category":"Experimentation > Long-run Effects & Surrogates","url":"https://www.nber.org/papers/w26463"},{"id":"paper-long-term-causal-inference-under-persistent-confounding-via-data-combination","type":"paper","name":"Long-term Causal Inference Under Persistent Confounding via Data Combination","description":"Methods for combining experimental and observational data to estimate persistent treatment effects.","category":"Experimentation > Long-run Effects & Surrogates","url":"https://arxiv.org/abs/2202.07234"},{"id":"paper-novelty-and-primacy:-a-long-term-estimator-for-online-experiments","type":"paper","name":"Novelty and Primacy: A Long-Term Estimator for Online Experiments","description":"First scalable method to estimate user-learning effects (novelty/primacy) via difference-in-differences across thousands of Microsoft experiments.","category":"Experimentation > Long-run Effects & Surrogates","url":"https://www.tandfonline.com/doi/full/10.1080/00401706.2021.2010114"},{"id":"paper-evaluating-the-surrogate-index-as-a-decision-making-tool-using-200-a-b-tests-at-netflix","type":"paper","name":"Evaluating the Surrogate Index as a Decision-Making Tool Using 200 A/B Tests at Netflix","description":"Largest empirical validation of surrogates\u201495% consistency between 14-day surrogate predictions and 63-day outcomes across 1,098 test arms.","category":"Experimentation > Long-run Effects & Surrogates","url":"https://arxiv.org/abs/2311.09857"},{"id":"paper-estimation-of-the-proportion-of-treatment-effect-explained-by-a-high-dimensional-surrogate","type":"paper","name":"Estimation of the Proportion of Treatment Effect Explained by a High-Dimensional Surrogate","description":"First rigorous method for high-dimensional surrogates where number of surrogates exceeds sample size; essential for multi-metric settings.","category":"Experimentation > Long-run Effects & Surrogates","url":"https://onlinelibrary.wiley.com/doi/10.1002/sim.9367"},{"id":"paper-the-central-role-of-the-propensity-score-in-observational-studies","type":"paper","name":"The Central Role of the Propensity Score in Observational Studies","description":"The foundational paper introducing propensity scores for causal inference in observational studies.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://academic.oup.com/biomet/article/70/1/41/240879"},{"id":"paper-matching-as-nonparametric-preprocessing-for-reducing-model-dependence","type":"paper","name":"Matching as Nonparametric Preprocessing for Reducing Model Dependence","description":"Best practices for matching methods and the MatchIt software implementation.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://gking.harvard.edu/publications/why-propensity-scores-should-not-be-used-formatching"},{"id":"paper-double-debiased-machine-learning-for-treatment-and-structural-parameters","type":"paper","name":"Double/Debiased Machine Learning for Treatment and Structural Parameters","description":"The double ML framework using cross-fitting to obtain valid inference with ML first-stage estimation.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://academic.oup.com/ectj/article/21/1/C1/5056401"},{"id":"paper-entropy-balancing-for-causal-effects:-a-multivariate-reweighting-method-to-produce-balanced-sa","type":"paper","name":"Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies","description":"Introduced entropy balancing, which achieves exact covariate balance through maximum entropy reweighting\u2014eliminating iterative propensity score model searching.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://www.cambridge.org/core/journals/political-analysis/article/entropy-balancing-for-causal-effects-a-multivariate-reweighting-method-to-produce-balanced-samples-in-observational-studies/164B3F1EC3C2F2D0C8B49C0FCAC0F1EC"},{"id":"paper-doubly-robust-estimation-in-missing-data-and-causal-inference-models","type":"paper","name":"Doubly Robust Estimation in Missing Data and Causal Inference Models","description":"Accessible exposition of the augmented IPW estimator, consistent if either propensity score or outcome model is correct\u2014the foundational 'doubly robust' property.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2005.00377.x"},{"id":"paper-semiparametric-efficiency-in-multivariate-regression-models-with-missing-data","type":"paper","name":"Semiparametric Efficiency in Multivariate Regression Models with Missing Data","description":"Foundational theoretical paper deriving semiparametric efficiency bounds and introducing the AIPW estimator class underlying all modern doubly robust methods.","category":"Observational Causal Inference > Matching & Propensity Scores","url":"https://www.jstor.org/stable/2291135"},{"id":"paper-what's-trending-in-difference-in-differences?-a-synthesis-of-the-recent-econometrics-literatur","type":"paper","name":"What's Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature","description":"Comprehensive review of modern DiD methods including staggered adoption and heterogeneous effects.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://arxiv.org/abs/2201.01194"},{"id":"paper-difference-in-differences-with-variation-in-treatment-timing","type":"paper","name":"Difference-in-Differences with Variation in Treatment Timing","description":"Decomposes two-way fixed effects estimators and reveals issues with staggered DiD designs.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://www.sciencedirect.com/science/article/pii/S0304407621001445"},{"id":"paper-difference-in-differences-with-multiple-time-periods","type":"paper","name":"Difference-in-Differences with Multiple Time Periods","description":"Group-time average treatment effects and aggregation methods for staggered DiD.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://www.sciencedirect.com/science/article/pii/S0304407620303948"},{"id":"paper-two-way-fixed-effects-estimators-with-heterogeneous-treatment-effects","type":"paper","name":"Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects","description":"Demonstrates TWFE regressions estimate weighted sums of ATEs with potentially negative weights\u2014proposing the DIDM estimator as solution.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20181169"},{"id":"paper-estimating-dynamic-treatment-effects-in-event-studies-with-heterogeneous-treatment-effects","type":"paper","name":"Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects","description":"Shows TWFE event-study coefficients are contaminated by effects from other periods, proposing an interaction-weighted estimator.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://www.sciencedirect.com/science/article/pii/S030440762030378X"},{"id":"paper-a-more-credible-approach-to-parallel-trends","type":"paper","name":"A More Credible Approach to Parallel Trends","description":"Formal sensitivity analysis for parallel trends violations\u2014implemented in the widely-used HonestDiD package.","category":"Observational Causal Inference > Difference-in-Differences","url":"https://academic.oup.com/restud/article/90/5/2555/7039335"},{"id":"paper-synthetic-control-methods-for-comparative-case-studies","type":"paper","name":"Synthetic Control Methods for Comparative Case Studies","description":"The foundational synthetic control paper with the California tobacco application.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap08746"},{"id":"paper-using-synthetic-controls:-feasibility,-data-requirements,-and-methodological-aspects-1","type":"paper","name":"Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects","description":"Practical guidance on when and how to apply synthetic control methods.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.aeaweb.org/articles?id=10.1257/jel.20191450"},{"id":"paper-synthetic-difference-in-differences","type":"paper","name":"Synthetic Difference in Differences","description":"Combines synthetic control and DiD for improved inference in panel data settings.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20190159"},{"id":"paper-matrix-completion-methods-for-causal-panel-data-models","type":"paper","name":"Matrix Completion Methods for Causal Panel Data Models","description":"Bridges matrix completion/ML with synthetic control using nuclear norm regularization\u2014handles staggered adoption and outperforms traditional SC.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1891924"},{"id":"paper-the-augmented-synthetic-control-method","type":"paper","name":"The Augmented Synthetic Control Method","description":"Extends synthetic control to settings where perfect pre-treatment fit is infeasible using ridge regression to de-bias estimates.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1929245"},{"id":"paper-synthetic-control-method:-inference,-sensitivity-analysis-and-confidence-sets","type":"paper","name":"Synthetic Control Method: Inference, Sensitivity Analysis and Confidence Sets","description":"Essential theoretical foundation for statistical inference in SC applications, extending permutation tests and constructing proper confidence sets.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.degruyter.com/document/doi/10.1515/jci-2016-0026/html"},{"id":"paper-synthetic-learner:-model-free-inference-on-treatments-over-time","type":"paper","name":"Synthetic Learner: Model-free inference on treatments over time","description":"Non-parametric algorithm for detecting treatment effects over time using synthetic controls with ML methods (Random Forest, Lasso, etc.) without assuming correct model specification.","category":"Observational Causal Inference > Synthetic Control","url":"https://www.sciencedirect.com/science/article/abs/pii/S0304407622001725"},{"id":"paper-identification-and-estimation-of-local-average-treatment-effects","type":"paper","name":"Identification and Estimation of Local Average Treatment Effects","description":"The LATE framework for interpreting IV estimates as effects on compliers.","category":"Observational Causal Inference > Instrumental Variables & LATE","url":"https://www.jstor.org/stable/2951620"},{"id":"paper-identification-of-causal-effects-using-instrumental-variables","type":"paper","name":"Identification of Causal Effects Using Instrumental Variables","description":"Defines the assumptions needed for IV and connects to potential outcomes framework.","category":"Observational Causal Inference > Instrumental Variables & LATE","url":"https://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476902"},{"id":"paper-testing-for-weak-instruments-in-linear-iv-regression","type":"paper","name":"Testing for Weak Instruments in Linear IV Regression","description":"Foundational framework for detecting weak instruments\u2014the origin of the 'first-stage F > 10' rule now required in all IV applications.","category":"Observational Causal Inference > Instrumental Variables & LATE","url":"https://www.cambridge.org/core/books/abs/identification-and-inference-for-econometric-models/testing-for-weak-instruments-in-linear-iv-regression/4A6D2D96F83269DBC9B8E7E2D8D02455"},{"id":"paper-quasi-experimental-shift-share-research-designs","type":"paper","name":"Quasi-Experimental Shift-Share Research Designs","description":"Modern econometric framework for Bartik instruments\u2014identification follows from quasi-random shock assignment rather than exogenous shares.","category":"Observational Causal Inference > Instrumental Variables & LATE","url":"https://academic.oup.com/restud/article/89/1/181/6294942"},{"id":"paper-judging-judge-fixed-effects","type":"paper","name":"Judging Judge Fixed Effects","description":"Develops nonparametric tests for exclusion and monotonicity in examiner IV designs\u2014essential for criminal justice, disability, and immigration research.","category":"Observational Causal Inference > Instrumental Variables & LATE","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20201860"},{"id":"paper-regression-discontinuity-designs-in-economics","type":"paper","name":"Regression Discontinuity Designs in Economics","description":"Comprehensive guide to RDD identification, estimation, and practical implementation.","category":"Observational Causal Inference > Regression Discontinuity","url":"https://www.aeaweb.org/articles?id=10.1257/jel.48.2.281"},{"id":"paper-a-practical-introduction-to-regression-discontinuity-designs","type":"paper","name":"A Practical Introduction to Regression Discontinuity Designs","description":"Modern implementation guide with rdrobust software for sharp and fuzzy RDD.","category":"Observational Causal Inference > Regression Discontinuity","url":"https://cattaneo.princeton.edu/books/Cattaneo-Idrobo-Titiunik_2019_CUP-Vol1.pdf"},{"id":"paper-manipulation-of-the-running-variable-in-the-regression-discontinuity-design:-a-density-test","type":"paper","name":"Manipulation of the Running Variable in the Regression Discontinuity Design: A Density Test","description":"Introduces the canonical density discontinuity test for detecting manipulation at the cutoff\u2014now a required falsification check in all RDD work.","category":"Observational Causal Inference > Regression Discontinuity","url":"https://www.sciencedirect.com/science/article/pii/S0304407607001133"},{"id":"paper-optimal-bandwidth-choice-for-the-regression-discontinuity-estimator","type":"paper","name":"Optimal Bandwidth Choice for the Regression Discontinuity Estimator","description":"Derives the MSE-optimal bandwidth for local linear RD estimation\u2014the first principled approach to bandwidth selection.","category":"Observational Causal Inference > Regression Discontinuity","url":"https://academic.oup.com/restud/article/79/3/933/1533189"},{"id":"paper-robust-nonparametric-confidence-intervals-for-regression-discontinuity-designs","type":"paper","name":"Robust Nonparametric Confidence Intervals for Regression-Discontinuity Designs","description":"Shows MSE-optimal bandwidths yield invalid conventional CIs and develops bias-corrected robust inference\u2014foundation for the rdrobust package.","category":"Observational Causal Inference > Regression Discontinuity","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA11757"},{"id":"paper-estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests","type":"paper","name":"Estimation and Inference of Heterogeneous Treatment Effects using Random Forests","description":"Causal forests for estimating conditional average treatment effects with valid confidence intervals.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839"},{"id":"paper-generic-machine-learning-inference-on-heterogeneous-treatment-effects-in-randomized-experiment","type":"paper","name":"Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments","description":"Framework for using any ML method to find heterogeneous effects with valid inference.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://arxiv.org/abs/1712.04802"},{"id":"paper-metalearners-for-estimating-heterogeneous-treatment-effects-using-machine-learning","type":"paper","name":"Metalearners for Estimating Heterogeneous Treatment Effects using Machine Learning","description":"Taxonomy of metalearners (S-learner, T-learner, X-learner) for CATE estimation.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://www.pnas.org/doi/10.1073/pnas.1804597116"},{"id":"paper-quasi-oracle-estimation-of-heterogeneous-treatment-effects","type":"paper","name":"Quasi-Oracle Estimation of Heterogeneous Treatment Effects","description":"Introduces the R-learner framework achieving quasi-oracle efficiency\u2014matching error bounds of an oracle knowing nuisance components.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://academic.oup.com/biomet/article/108/2/299/5911092"},{"id":"paper-towards-optimal-doubly-robust-estimation-of-heterogeneous-causal-effects","type":"paper","name":"Towards Optimal Doubly Robust Estimation of Heterogeneous Causal Effects","description":"Establishes model-free oracle inequalities for the DR-learner\u2014doubly robust CATE estimation achieves faster convergence rates.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-17/issue-2/Towards-optimal-doubly-robust-estimation-of-heterogeneous-causal-effects/10.1214/23-EJS2157.full"},{"id":"paper-policy-learning-with-observational-data","type":"paper","name":"Policy Learning With Observational Data","description":"Theoretical foundations for learning optimal treatment policies from observational data using doubly robust scores.","category":"Observational Causal Inference > Double ML & Heterogeneous Effects","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA15732"},{"id":"paper-sensitivity-analysis-in-observational-research:-introducing-the-e-value","type":"paper","name":"Sensitivity Analysis in Observational Research: Introducing the E-Value","description":"The E-value for quantifying sensitivity to unmeasured confounding.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://www.acpjournals.org/doi/10.7326/M16-2607"},{"id":"paper-making-sense-of-sensitivity:-extending-omitted-variable-bias","type":"paper","name":"Making Sense of Sensitivity: Extending Omitted Variable Bias","description":"Modern sensitivity analysis framework with intuitive benchmarking against observed covariates.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://www.tandfonline.com/doi/full/10.1111/rssb.12348"},{"id":"paper-nonparametric-bounds-on-treatment-effects","type":"paper","name":"Nonparametric Bounds on Treatment Effects","description":"Foundational paper establishing the partial identification paradigm\u2014showing what can be learned under minimal assumptions when point identification fails.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://www.jstor.org/stable/2006592"},{"id":"paper-training,-wages,-and-sample-selection:-estimating-sharp-bounds-on-treatment-effects","type":"paper","name":"Training, Wages, and Sample Selection: Estimating Sharp Bounds on Treatment Effects","description":"Developed the 'Lee bounds' trimming procedure for handling attrition under monotonicity\u2014now a standard robustness check for differential selection.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://academic.oup.com/restud/article/76/3/1071/1590596"},{"id":"paper-unobservable-selection-and-coefficient-stability:-theory-and-evidence","type":"paper","name":"Unobservable Selection and Coefficient Stability: Theory and Evidence","description":"Shows how to jointly use coefficient movements and R-squared changes to bound omitted variable bias\u2014the workhorse sensitivity analysis.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://www.tandfonline.com/doi/full/10.1080/07350015.2016.1227711"},{"id":"paper-selection-on-observed-and-unobserved-variables:-assessing-the-effectiveness-of-catholic-school","type":"paper","name":"Selection on Observed and Unobserved Variables: Assessing the Effectiveness of Catholic Schools","description":"Pioneered the insight that selection on observables guides selection on unobservables\u2014framework for assessing confounding needed to explain away effects.","category":"Observational Causal Inference > Sensitivity & Bounds","url":"https://www.journals.uchicago.edu/doi/10.1086/426036"},{"id":"paper-matrix-factorization-techniques-for-recommender-systems","type":"paper","name":"Matrix Factorization Techniques for Recommender Systems","description":"The definitive Netflix Prize paper establishing matrix factorization as the dominant CF paradigm.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://ieeexplore.ieee.org/document/5197422"},{"id":"paper-collaborative-filtering-for-implicit-feedback-datasets","type":"paper","name":"Collaborative Filtering for Implicit Feedback Datasets","description":"Foundational paper for implicit feedback (clicks, views); introduces confidence-weighted MF with ALS optimization.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://ieeexplore.ieee.org/document/4781121"},{"id":"paper-bpr:-bayesian-personalized-ranking-from-implicit-feedback","type":"paper","name":"BPR: Bayesian Personalized Ranking from Implicit Feedback","description":"Standard pairwise ranking loss for implicit feedback; BPR-OPT criterion ubiquitous in modern training.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://arxiv.org/abs/1205.2618"},{"id":"paper-factorization-meets-the-neighborhood","type":"paper","name":"Factorization Meets the Neighborhood","description":"Combines neighborhood and latent factor models; integrates user/item biases; essential for blending approaches.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://dl.acm.org/doi/10.1145/1401890.1401944"},{"id":"paper-probabilistic-matrix-factorization","type":"paper","name":"Probabilistic Matrix Factorization","description":"Introduced probabilistic treatment of MF that scales linearly with observations; handles Netflix-scale sparsity with automatic regularization via adaptive priors.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://papers.nips.cc/paper/2007/hash/d7322ed717dedf1eb4e6e52a37ea7bcd-Abstract.html"},{"id":"paper-factorization-machines","type":"paper","name":"Factorization Machines","description":"General predictor combining SVM flexibility with factorization model power; models all pairwise feature interactions in linear time. Subsumes SVD++, PITF, and specialized models.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://ieeexplore.ieee.org/document/5694074"},{"id":"paper-collaborative-filtering-with-temporal-dynamics","type":"paper","name":"Collaborative Filtering with Temporal Dynamics","description":"TimeSVD++ explicitly models drifting user preferences, item popularity evolution, and time-varying biases. Core component of Netflix Prize winning solution.","category":"Recommender Systems > Collaborative Filtering & Matrix Factorization","url":"https://dl.acm.org/doi/10.1145/1557019.1557072"},{"id":"paper-deep-neural-networks-for-youtube-recommendations","type":"paper","name":"Deep Neural Networks for YouTube Recommendations","description":"Seminal industry paper establishing two-stage deep learning (candidate generation + ranking) at billion-scale.","category":"Recommender Systems > Deep Recommenders","url":"https://research.google/pubs/deep-neural-networks-for-youtube-recommendations/"},{"id":"paper-embedding-based-retrieval-in-facebook-search","type":"paper","name":"Embedding-based Retrieval in Facebook Search","description":"Comprehensive industry paper on two-tower embedding models; covers hard negative mining, ANN indexing, production deployment.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/2006.11632"},{"id":"paper-self-attentive-sequential-recommendation-(sasrec)","type":"paper","name":"Self-Attentive Sequential Recommendation (SASRec)","description":"Applies self-attention to sequential recommendations; the Transformer foundation inspiring BERT4Rec and modern sequential models.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1808.09781"},{"id":"paper-bert4rec:-sequential-recommendation-with-bert","type":"paper","name":"BERT4Rec: Sequential Recommendation with BERT","description":"Adapts BERT's bidirectional self-attention with Cloze task for sequential predictions.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1904.06690"},{"id":"paper-neural-collaborative-filtering","type":"paper","name":"Neural Collaborative Filtering","description":"Replaces inner product with neural networks; introduces GMF+MLP framework (NeuMF); highly cited baseline.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1708.05031"},{"id":"paper-wide-&-deep-learning-for-recommender-systems","type":"paper","name":"Wide & Deep Learning for Recommender Systems","description":"Jointly trains wide linear models (memorization) with deep networks (generalization) using shared embeddings. Productionized on Google Play for 1B+ users; seminal industry paper establishing wide+deep paradigm.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1606.07792"},{"id":"paper-deepfm:-a-factorization-machine-based-neural-network-for-ctr-prediction","type":"paper","name":"DeepFM: A Factorization-Machine based Neural Network for CTR Prediction","description":"Combines FM component (low-order interactions) with deep component (high-order) via shared embeddings. Unlike Wide&Deep, requires no manual feature engineering. End-to-end training.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1703.04247"},{"id":"paper-deep-interest-network-for-click-through-rate-prediction","type":"paper","name":"Deep Interest Network for Click-Through Rate Prediction","description":"Attention mechanism adaptively learns user interest representations from behavioral history relative to candidate items\u2014solving fixed-length embedding bottleneck. Deployed on Alibaba main traffic.","category":"Recommender Systems > Deep Recommenders","url":"https://arxiv.org/abs/1706.06978"},{"id":"paper-recommendations-as-treatments:-debiasing-learning-and-evaluation","type":"paper","name":"Recommendations as Treatments: Debiasing Learning and Evaluation","description":"Foundational paper applying causal inference to recommenders; introduces IPS-based unbiased estimators.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"http://proceedings.mlr.press/v48/schnabel16.pdf"},{"id":"paper-unbiased-learning-to-rank-with-biased-feedback","type":"paper","name":"Unbiased Learning-to-Rank with Biased Feedback","description":"Addresses position bias in click data; propensity-weighted ranking SVM; essential for implicit feedback.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://arxiv.org/abs/1608.04468"},{"id":"paper-the-self-normalized-estimator-for-counterfactual-learning","type":"paper","name":"The Self-Normalized Estimator for Counterfactual Learning","description":"Introduces SNIPS reducing IPS variance without bias; widely used in production.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://papers.nips.cc/paper/2015/hash/39027dfad5138c9ca0c474d71db915c3-Abstract.html"},{"id":"paper-counterfactual-learning-and-evaluation-for-recommender-systems","type":"paper","name":"Counterfactual Learning and Evaluation for Recommender Systems","description":"Comprehensive tutorial covering IPS, SNIPS, Doubly Robust estimators with implementation guidance.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://dl.acm.org/doi/10.1145/3460231.3473320"},{"id":"paper-doubly-robust-joint-learning-for-recommendation-on-data-missing-not-at-random","type":"paper","name":"Doubly Robust Joint Learning for Recommendation on Data Missing Not at Random","description":"Combines imputation models with propensity scoring for unbiased performance estimation; theoretically principled doubly robust framework specifically for recommender systems with MNAR data.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://proceedings.mlr.press/v97/wang19n.html"},{"id":"paper-causal-embeddings-for-recommendation","type":"paper","name":"Causal Embeddings for Recommendation","description":"CausE optimizes recommendation policy for causal treatment effects (not just prediction) using domain adaptation to handle biased logged data. RecSys Best Paper Award.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://dl.acm.org/doi/10.1145/3240323.3240360"},{"id":"paper-the-deconfounded-recommender:-a-causal-inference-approach-to-recommendation","type":"paper","name":"The Deconfounded Recommender: A Causal Inference Approach to Recommendation","description":"Two-stage approach using substitute confounders from exposure modeling; addresses unobserved confounding in observational recommendation data from principled causal perspective.","category":"Recommender Systems > Causal Recommendations & Debiasing","url":"https://arxiv.org/abs/1808.06581"},{"id":"paper-topic-diversification-for-recommendation-lists","type":"paper","name":"Topic Diversification for Recommendation Lists","description":"Pioneering paper on balancing accuracy with diversity; introduces intra-list diversity metrics.","category":"Recommender Systems > Exploration & Diversity","url":"https://dl.acm.org/doi/10.1145/1060745.1060754"},{"id":"paper-exploring-the-filter-bubble","type":"paper","name":"Exploring the Filter Bubble","description":"First rigorous longitudinal study measuring filter bubble effects at individual level using MovieLens.","category":"Recommender Systems > Exploration & Diversity","url":"https://dl.acm.org/doi/10.1145/2566486.2568012"},{"id":"paper-blockbuster-culture's-next-rise-or-fall","type":"paper","name":"Blockbuster Culture's Next Rise or Fall","description":"Analyzes how recommenders affect aggregate sales diversity (long tail vs. blockbusters).","category":"Recommender Systems > Exploration & Diversity","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.1080.0974"},{"id":"paper-explore,-exploit,-and-explain","type":"paper","name":"Explore, Exploit, and Explain","description":"Spotify's production system combining contextual bandits for exploration with explainable recommendations.","category":"Recommender Systems > Exploration & Diversity","url":"https://dl.acm.org/doi/10.1145/3240323.3240354"},{"id":"paper-a-contextual-bandit-approach-to-personalized-news-article-recommendation","type":"paper","name":"A Contextual-Bandit Approach to Personalized News Article Recommendation","description":"Introduces LinUCB algorithm for contextual bandits; 12.5% CTR lift over context-free bandits on 33M+ Yahoo events. Foundational paper for bandit-based recommendations.","category":"Recommender Systems > Exploration & Diversity","url":"https://dl.acm.org/doi/10.1145/1772690.1772758"},{"id":"paper-an-empirical-evaluation-of-thompson-sampling","type":"paper","name":"An Empirical Evaluation of Thompson Sampling","description":"Comprehensive evaluation across display advertising and news recommendation demonstrating Thompson Sampling achieves state-of-the-art results; reignited practical interest in TS.","category":"Recommender Systems > Exploration & Diversity","url":"https://papers.nips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html"},{"id":"paper-calibrated-recommendations","type":"paper","name":"Calibrated Recommendations","description":"Shows accuracy-optimized recommenders crowd out users' lesser interests; proposes KL-divergence calibration metrics and efficient greedy re-ranking. Netflix research, RecSys Best Paper Nominee.","category":"Recommender Systems > Exploration & Diversity","url":"https://dl.acm.org/doi/10.1145/3240323.3240372"},{"id":"paper-dropoutnet:-addressing-cold-start-in-recommender-systems","type":"paper","name":"DropoutNet: Addressing Cold Start in Recommender Systems","description":"Uses dropout to force reliance on content features when collaborative signals unavailable; practical and widely adopted.","category":"Recommender Systems > Cold Start","url":"https://proceedings.neurips.cc/paper/2017/hash/dbd22ba3bd0df8f385bdac3e9f8be207-Abstract.html"},{"id":"paper-a-meta-learning-perspective-on-cold-start-recommendations","type":"paper","name":"A Meta-Learning Perspective on Cold-Start Recommendations","description":"Applies meta-learning to item cold-start; learns to adapt quickly from user history.","category":"Recommender Systems > Cold Start","url":"https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items"},{"id":"paper-collaborative-deep-learning-for-recommender-systems","type":"paper","name":"Collaborative Deep Learning for Recommender Systems","description":"Combines deep learning for content (stacked denoising autoencoders) with CF; influential hybrid approach.","category":"Recommender Systems > Cold Start","url":"https://dl.acm.org/doi/10.1145/2783258.2783273"},{"id":"paper-melu:-meta-learned-user-preference-estimator","type":"paper","name":"MeLU: Meta-Learned User Preference Estimator","description":"Applies MAML framework to user cold-start; learns initialization that quickly adapts to new users.","category":"Recommender Systems > Cold Start","url":"https://dl.acm.org/doi/10.1145/3292500.3330859"},{"id":"paper-from-zero-shot-learning-to-cold-start-recommendation","type":"paper","name":"From Zero-Shot Learning to Cold-Start Recommendation","description":"First paper framing cold-start as zero-shot learning problem; proposes Low-rank Linear Auto-Encoder (LLAE) addressing domain shift and spurious correlations. Novel theoretical connection enabling attribute-based recommendations for entirely new users.","category":"Recommender Systems > Cold Start","url":"https://ojs.aaai.org/index.php/AAAI/article/view/4324"},{"id":"paper-transfer-meta-framework-for-cross-domain-recommendation-to-cold-start-users","type":"paper","name":"Transfer-Meta Framework for Cross-domain Recommendation to Cold-Start Users","description":"State-of-the-art combining transfer learning and meta-learning for cross-domain cold start; uses source domain to warm-start target domain predictions for zero-interaction users.","category":"Recommender Systems > Cold Start","url":"https://dl.acm.org/doi/10.1145/3404835.3462832"},{"id":"paper-pinsage:-graph-convolutional-neural-networks-for-web-scale-recommender-systems","type":"paper","name":"PinSage: Graph Convolutional Neural Networks for Web-Scale Recommender Systems","description":"First billion-scale GCN deployment. Random-walk neighborhood sampling, curriculum training with hard negatives, MapReduce inference for Pinterest's 3B node graph. Seminal industrial GNN paper.","category":"Recommender Systems > Graph Neural Networks for Recommendations","url":"https://dl.acm.org/doi/10.1145/3219819.3219890"},{"id":"paper-neural-graph-collaborative-filtering","type":"paper","name":"Neural Graph Collaborative Filtering","description":"First to explicitly encode collaborative signal via high-order connectivity on user-item bipartite graphs through embedding propagation. Foundational theoretical framework for GNN-based CF.","category":"Recommender Systems > Graph Neural Networks for Recommendations","url":"https://dl.acm.org/doi/10.1145/3331184.3331267"},{"id":"paper-lightgcn:-simplifying-and-powering-graph-convolution-network-for-recommendation","type":"paper","name":"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation","description":"Demonstrates feature transformation and nonlinear activation contribute little to CF; proposes simplified GCN using only neighborhood aggregation\u201416% improvement over NGCF with simpler architecture.","category":"Recommender Systems > Graph Neural Networks for Recommendations","url":"https://dl.acm.org/doi/10.1145/3397271.3401063"},{"id":"paper-kgat:-knowledge-graph-attention-network-for-recommendation","type":"paper","name":"KGAT: Knowledge Graph Attention Network for Recommendation","description":"Unifies user-item interaction graphs with knowledge graphs via attention-based neighbor discrimination; enables more accurate, diverse, and explainable recommendations.","category":"Recommender Systems > Graph Neural Networks for Recommendations","url":"https://dl.acm.org/doi/10.1145/3292500.3330989"},{"id":"paper-modeling-task-relationships-in-multi-task-learning-with-multi-gate-mixture-of-experts","type":"paper","name":"Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts","description":"Task-specific gating networks over shared expert submodels; explicitly learns task relationships from data. Deployed at Google; widely adopted at Pinterest, LinkedIn, Meta.","category":"Recommender Systems > Multi-Task & Multi-Objective Learning","url":"https://dl.acm.org/doi/10.1145/3219819.3220007"},{"id":"paper-progressive-layered-extraction-(ple):-a-novel-multi-task-learning-model-for-personalized-recom","type":"paper","name":"Progressive Layered Extraction (PLE): A Novel Multi-Task Learning Model for Personalized Recommendations","description":"Addresses 'seesaw phenomenon' where improving one task hurts others; explicitly separates shared/task-specific experts with progressive routing. Achieved 2.23% lift at Tencent.","category":"Recommender Systems > Multi-Task & Multi-Objective Learning","url":"https://dl.acm.org/doi/10.1145/3383313.3412236"},{"id":"paper-entire-space-multi-task-model:-an-effective-approach-for-estimating-post-click-conversion-rate","type":"paper","name":"Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate","description":"Models CVR over entire impression space (not just clicks) to eliminate sample selection bias; jointly trains CTR and CTCVR with shared embeddings. Alibaba/Taobao deployment.","category":"Recommender Systems > Multi-Task & Multi-Objective Learning","url":"https://dl.acm.org/doi/10.1145/3209978.3210104"},{"id":"paper-a-pareto-efficient-algorithm-for-multiple-objective-optimization-in-e-commerce-recommendation","type":"paper","name":"A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation","description":"PE-LTR framework using coordinate descent with theoretical Pareto efficiency guarantees for balancing CTR and GMV. Alibaba e-commerce production system.","category":"Recommender Systems > Multi-Task & Multi-Objective Learning","url":"https://dl.acm.org/doi/10.1145/3298689.3347011"},{"id":"paper-top-k-off-policy-correction-for-a-reinforce-recommender-system","type":"paper","name":"Top-K Off-Policy Correction for a REINFORCE Recommender System","description":"Scales REINFORCE to YouTube production with millions of items; introduces top-K off-policy correction for learning from biased logged feedback. Seminal industry RL paper.","category":"Recommender Systems > Reinforcement Learning for Recommendations","url":"https://dl.acm.org/doi/10.1145/3289600.3290999"},{"id":"paper-slateq:-a-tractable-decomposition-for-reinforcement-learning-with-recommendation-sets","type":"paper","name":"SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets","description":"Value-based RL decomposition for slate recommendations; long-term slate value decomposes into tractable item-wise LTVs. YouTube production deployment solving combinatorial slate optimization.","category":"Recommender Systems > Reinforcement Learning for Recommendations","url":"https://www.ijcai.org/proceedings/2019/360"},{"id":"paper-deep-reinforcement-learning-for-list-wise-recommendations","type":"paper","name":"Deep Reinforcement Learning for List-wise Recommendations","description":"Actor-Critic framework capturing inter-item relationships in list recommendations; addresses sequential decision-making for e-commerce. JD.com application.","category":"Recommender Systems > Reinforcement Learning for Recommendations","url":"https://dl.acm.org/doi/10.1145/3240323.3240374"},{"id":"paper-pseudo-dyna-q:-a-reinforcement-learning-framework-for-interactive-recommendation","type":"paper","name":"Pseudo Dyna-Q: A Reinforcement Learning Framework for Interactive Recommendation","description":"Model-based RL using world models for recommendation; addresses data efficiency challenge of learning from limited online interactions.","category":"Recommender Systems > Reinforcement Learning for Recommendations","url":"https://dl.acm.org/doi/10.1145/3336191.3371801"},{"id":"paper-fairness-of-exposure-in-rankings","type":"paper","name":"Fairness of Exposure in Rankings","description":"Foundational framework for exposure-based fairness; develops efficient algorithms maximizing user utility while satisfying fairness constraints on content provider exposure. Applicable to job platforms, e-commerce, any two-sided marketplace.","category":"Recommender Systems > Fairness & Responsible Recommendations","url":"https://dl.acm.org/doi/10.1145/3219819.3220088"},{"id":"paper-towards-a-fair-marketplace:-counterfactual-evaluation-of-the-trade-off-between-relevance,-fair","type":"paper","name":"Towards a Fair Marketplace: Counterfactual Evaluation of the Trade-off between Relevance, Fairness & Satisfaction","description":"Studies relevance-fairness trade-offs in two-sided marketplaces; proposes counterfactual evaluation for balancing consumer and supplier objectives. Spotify production research.","category":"Recommender Systems > Fairness & Responsible Recommendations","url":"https://dl.acm.org/doi/10.1145/3269206.3272027"},{"id":"paper-controlling-fairness-and-bias-in-dynamic-learning-to-rank","type":"paper","name":"Controlling Fairness and Bias in Dynamic Learning-to-Rank","description":"Learning-to-rank enforcing merit-based fairness guarantees to item groups while accounting for selection bias in implicit feedback. Addresses fairness maintenance over time.","category":"Recommender Systems > Fairness & Responsible Recommendations","url":"https://dl.acm.org/doi/10.1145/3397271.3401100"},{"id":"paper-recommendations-and-their-impact-on-the-provider-side","type":"paper","name":"Recommendations and Their Impact on the Provider Side","description":"Comprehensive study of how recommendations affect content providers; examines supplier-side impacts and multi-stakeholder trade-offs. Spotify research.","category":"Recommender Systems > Fairness & Responsible Recommendations","url":"https://dl.acm.org/doi/10.1145/3298689.3347015"},{"id":"paper-offline-a-b-testing-for-recommender-systems","type":"paper","name":"Offline A/B Testing for Recommender Systems","description":"Counterfactual estimators for offline evaluation correlating with online A/B tests; addresses bias-variance tradeoffs in off-policy evaluation. Criteo production system enabling faster iteration.","category":"Recommender Systems > Evaluation Methodology","url":"https://dl.acm.org/doi/10.1145/3159652.3159687"},{"id":"paper-performance-of-recommender-algorithms-on-top-n-recommendation-tasks","type":"paper","name":"Performance of Recommender Algorithms on Top-N Recommendation Tasks","description":"Demonstrates RMSE optimization doesn't translate to top-N accuracy; establishes methodology for evaluating recommendation quality beyond prediction error metrics. Netflix context.","category":"Recommender Systems > Evaluation Methodology","url":"https://dl.acm.org/doi/10.1145/1864708.1864721"},{"id":"paper-are-we-really-making-much-progress?-a-worrying-analysis-of-recent-neural-recommendation-approa","type":"paper","name":"Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches","description":"Critical analysis showing many neural approaches don't outperform well-tuned baselines; emphasizes reproducibility and rigorous evaluation methodology. Essential for experimental design.","category":"Recommender Systems > Evaluation Methodology","url":"https://dl.acm.org/doi/10.1145/3298689.3347058"},{"id":"paper-from-ranknet-to-lambdarank-to-lambdamart:-an-overview","type":"paper","name":"From RankNet to LambdaRank to LambdaMART: An Overview","description":"Definitive reference unifying the RankNet family; LambdaMART remains the industry workhorse for gradient-boosted ranking.","category":"Search & Ranking > Learning to Rank","url":"https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/"},{"id":"paper-learning-to-rank-using-gradient-descent-(ranknet)","type":"paper","name":"Learning to Rank using Gradient Descent (RankNet)","description":"Foundational pairwise neural ranking using cross-entropy loss; won ICML Test of Time Award 2015.","category":"Search & Ranking > Learning to Rank","url":"https://www.microsoft.com/en-us/research/publication/learning-to-rank-using-gradient-descent/"},{"id":"paper-learning-to-rank:-from-pairwise-to-listwise-(listnet)","type":"paper","name":"Learning to Rank: From Pairwise to Listwise (ListNet)","description":"First listwise method using probability distributions over permutations; influenced all subsequent listwise methods.","category":"Search & Ranking > Learning to Rank","url":"https://dl.acm.org/doi/10.1145/1273496.1273513"},{"id":"paper-listwise-approach-to-learning-to-rank-(listmle)","type":"paper","name":"Listwise Approach to Learning to Rank (ListMLE)","description":"Foundational listwise LTR with theoretical analysis of listwise loss functions.","category":"Search & Ranking > Learning to Rank","url":"https://icml.cc/Conferences/2008/papers/167.pdf"},{"id":"paper-optimizing-search-engines-using-clickthrough-data","type":"paper","name":"Optimizing Search Engines using Clickthrough Data","description":"Seminal SVM-based pairwise LTR using click data for preference constraints; established click-based learning to rank paradigm.","category":"Search & Ranking > Learning to Rank","url":"https://dl.acm.org/doi/10.1145/775047.775067"},{"id":"paper-understanding-user-goals-in-web-search","type":"paper","name":"Understanding User Goals in Web Search","description":"Seminal taxonomy of query intent (navigational, informational, transactional); foundational framework still used today.","category":"Search & Ranking > Query Understanding","url":"https://dl.acm.org/doi/10.1145/988672.988675"},{"id":"paper-building-bridges-for-web-query-classification","type":"paper","name":"Building Bridges for Web Query Classification","description":"Foundational work on mapping queries to topic categories using intermediary data sources.","category":"Search & Ranking > Query Understanding","url":"https://dl.acm.org/doi/10.1145/1148170.1148196"},{"id":"paper-deep-search-query-intent-understanding","type":"paper","name":"Deep Search Query Intent Understanding","description":"Industrial-scale BERT-based intent classification for typeahead and search blending.","category":"Search & Ranking > Query Understanding","url":"https://arxiv.org/abs/2008.06759"},{"id":"paper-relevance-based-language-models","type":"paper","name":"Relevance-Based Language Models","description":"Foundational pseudo-relevance feedback method introducing RM3; widely used for query expansion in both traditional and neural retrieval.","category":"Search & Ranking > Query Understanding","url":"https://dl.acm.org/doi/10.1145/383952.384019"},{"id":"paper-context-sensitive-information-retrieval-using-implicit-feedback","type":"paper","name":"Context-Sensitive Information Retrieval Using Implicit Feedback","description":"Pioneered use of session context for query interpretation; demonstrated significant gains from implicit user feedback.","category":"Search & Ranking > Query Understanding","url":"https://dl.acm.org/doi/10.1145/1076034.1076049"},{"id":"paper-few-shot-generative-conversational-query-rewriting","type":"paper","name":"Few-Shot Generative Conversational Query Rewriting","description":"Modern neural query reformulation using GPT-2 for conversational settings; addresses context carryover in multi-turn search.","category":"Search & Ranking > Query Understanding","url":"https://dl.acm.org/doi/10.1145/3397271.3401130"},{"id":"paper-deep-neural-networks-for-youtube-recommendations-1","type":"paper","name":"Deep Neural Networks for YouTube Recommendations","description":"Landmark paper on watch-time optimization vs. clicks; explains freshness handling at scale.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://research.google/pubs/deep-neural-networks-for-youtube-recommendations/"},{"id":"paper-recommending-what-video-to-watch-next","type":"paper","name":"Recommending What Video to Watch Next","description":"Multi-objective ranking balancing engagement with satisfaction using multi-gate mixture-of-experts.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://dl.acm.org/doi/10.1145/3298689.3346997"},{"id":"paper-150-successful-ml-models:-6-lessons-at-booking.com","type":"paper","name":"150 Successful ML Models: 6 Lessons at Booking.com","description":"Influential industry paper on balancing business metrics vs. user value in production systems.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://dl.acm.org/doi/10.1145/3292500.3330744"},{"id":"paper-engagement,-user-satisfaction,-and-divisive-content-amplification","type":"paper","name":"Engagement, User Satisfaction, and Divisive Content Amplification","description":"Demonstrates empirically that engagement-based ranking underperforms for user satisfaction.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://academic.oup.com/pnasnexus/article/4/3/pgaf062/8052060"},{"id":"paper-modeling-dwell-time-to-predict-click-level-satisfaction","type":"paper","name":"Modeling Dwell Time to Predict Click-level Satisfaction","description":"Established context-dependent satisfaction thresholds beyond fixed dwell time cutoffs; showed satisfaction prediction requires query-document context.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://dl.acm.org/doi/10.1145/2556195.2556220"},{"id":"paper-beyond-clicks:-query-reformulation-as-a-predictor-of-search-satisfaction","type":"paper","name":"Beyond Clicks: Query Reformulation as a Predictor of Search Satisfaction","description":"Demonstrated satisfaction signals exist beyond clicks; query reformulation patterns predict user satisfaction better than clicks alone.","category":"Search & Ranking > Relevance vs. Engagement","url":"https://dl.acm.org/doi/10.1145/2505515.2505682"},{"id":"paper-an-experimental-comparison-of-click-position-bias-models","type":"paper","name":"An Experimental Comparison of Click Position-Bias Models","description":"Seminal empirical study establishing cascade model as best explanation for user examination behavior.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://dl.acm.org/doi/10.1145/1341531.1341545"},{"id":"paper-unbiased-learning-to-rank-with-biased-feedback-1","type":"paper","name":"Unbiased Learning-to-Rank with Biased Feedback","description":"Foundational counterfactual/IPS framework for unbiased LTR; propensity-weighted ranking SVM.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://arxiv.org/abs/1608.04468"},{"id":"paper-click-models-for-web-search","type":"paper","name":"Click Models for Web Search","description":"Comprehensive synthesis covering all major click models (PBM, DCM, DBN, UBM); essential reference.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://www.morganclaypool.com/doi/abs/10.2200/S00672ED1V01Y201509ICR046"},{"id":"paper-unbiased-ltr-with-unbiased-propensity-estimation-(dla)","type":"paper","name":"Unbiased LTR with Unbiased Propensity Estimation (DLA)","description":"Dual learning algorithm jointly training ranking and propensity models; widely used for production debiasing.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://dl.acm.org/doi/10.1145/3209978.3209986"},{"id":"paper-improving-deep-learning-for-airbnb-search","type":"paper","name":"Improving Deep Learning for Airbnb Search","description":"Practical industry case on position bias correction via dropout at inference; shows major production gains.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://arxiv.org/abs/2002.05515"},{"id":"paper-addressing-trust-bias-for-unbiased-learning-to-rank","type":"paper","name":"Addressing Trust Bias for Unbiased Learning-to-Rank","description":"First rigorous treatment of trust bias in ULTR framework; extends counterfactual work to account for users trusting higher-ranked results more.","category":"Search & Ranking > Position Bias & Debiasing","url":"https://dl.acm.org/doi/10.1145/3308558.3313697"},{"id":"paper-dense-passage-retrieval-for-open-domain-qa-(dpr)","type":"paper","name":"Dense Passage Retrieval for Open-Domain QA (DPR)","description":"Foundational dual-encoder dense retrieval; outperforms BM25 by 9-19%; established the dense retrieval paradigm.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://arxiv.org/abs/2004.04906"},{"id":"paper-colbert:-efficient-passage-search-via-late-interaction","type":"paper","name":"ColBERT: Efficient Passage Search via Late Interaction","description":"Introduced late interaction achieving near cross-encoder quality with bi-encoder speed.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://arxiv.org/abs/2004.12832"},{"id":"paper-passage-re-ranking-with-bert","type":"paper","name":"Passage Re-ranking with BERT","description":"Transformative demonstration of BERT for passage re-ranking; 27% improvement on MS MARCO.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://arxiv.org/abs/1901.04085"},{"id":"paper-real-time-personalization-using-embeddings-at-airbnb","type":"paper","name":"Real-time Personalization using Embeddings at Airbnb","description":"Best Paper Award. Production embedding system driving 99% of Airbnb conversions.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://dl.acm.org/doi/10.1145/3219819.3219885"},{"id":"paper-sentence-bert:-sentence-embeddings-using-siamese-networks","type":"paper","name":"Sentence-BERT: Sentence Embeddings using Siamese Networks","description":"Made BERT practical for dense retrieval with siamese architecture; widely used for semantic similarity.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://arxiv.org/abs/1908.10084"},{"id":"paper-splade:-sparse-lexical-and-expansion-model-for-first-stage-ranking","type":"paper","name":"SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking","description":"Learned sparse representations via MLM head with sparsity regularization; bridges gap between dense and sparse retrieval with interpretable term weights.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://dl.acm.org/doi/10.1145/3404835.3463098"},{"id":"paper-rocketqa:-an-optimized-training-approach-to-dense-passage-retrieval","type":"paper","name":"RocketQA: An Optimized Training Approach to Dense Passage Retrieval","description":"Critical training strategies for dense retrieval: cross-batch negatives, denoised hard negatives, knowledge distillation from cross-encoder. Baidu research.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://aclanthology.org/2021.naacl-main.466/"},{"id":"paper-approximate-nearest-neighbor-negative-contrastive-learning-for-dense-text-retrieval","type":"paper","name":"Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval","description":"Global hard negative mining via ANN index (ANCE); addresses limitation of in-batch negatives by refreshing hard negatives from evolving model.","category":"Search & Ranking > Semantic Search & Embeddings","url":"https://openreview.net/forum?id=zeFrfgyZln"},{"id":"paper-multi-stage-document-ranking-with-bert","type":"paper","name":"Multi-Stage Document Ranking with BERT","description":"Established BERT-based cross-encoder reranking paradigm with MonoBERT and duoBERT; 'Expando-Mono-Duo' design pattern for neural IR pipelines.","category":"Search & Ranking > Neural Ranking Models","url":"https://arxiv.org/abs/1910.14424"},{"id":"paper-from-doc2query-to-doctttttquery","type":"paper","name":"From doc2query to docTTTTTquery","description":"Neural document expansion via T5-generated queries; improves BM25 without runtime overhead by enriching documents at indexing time.","category":"Search & Ranking > Neural Ranking Models","url":"https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery-v2.pdf"},{"id":"paper-a-deep-relevance-matching-model-for-ad-hoc-retrieval","type":"paper","name":"A Deep Relevance Matching Model for Ad-hoc Retrieval","description":"Distinguished 'relevance matching' from 'semantic matching' in neural IR; histogram-based matching with term gating mechanism.","category":"Search & Ranking > Neural Ranking Models","url":"https://dl.acm.org/doi/10.1145/2983323.2983769"},{"id":"paper-end-to-end-neural-ad-hoc-ranking-with-kernel-pooling","type":"paper","name":"End-to-End Neural Ad-hoc Ranking with Kernel Pooling","description":"Pioneered end-to-end neural ranking with interpretable soft-match kernels (K-NRM); spawned KNRM variants used in production.","category":"Search & Ranking > Neural Ranking Models","url":"https://dl.acm.org/doi/10.1145/3077136.3080809"},{"id":"paper-unsupervised-corpus-aware-language-model-pre-training-for-dense-passage-retrieval","type":"paper","name":"Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval","description":"Pre-training specifically for dense retrieval via Condenser architecture; coCondenser adds corpus-aware contrastive objective for further gains.","category":"Search & Ranking > Neural Ranking Models","url":"https://aclanthology.org/2022.acl-long.203/"},{"id":"paper-realm:-retrieval-augmented-language-model-pre-training","type":"paper","name":"REALM: Retrieval-Augmented Language Model Pre-Training","description":"First end-to-end pre-training of retrieval + LM with backpropagation through retrieval; foundational architecture for knowledge-intensive tasks.","category":"Search & Ranking > Retrieval-Augmented Generation","url":"https://proceedings.mlr.press/v119/guu20a.html"},{"id":"paper-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks","type":"paper","name":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks","description":"THE paper that coined 'RAG'; combines pre-trained retriever with seq2seq generator for open-domain QA. Foundation for modern RAG systems.","category":"Search & Ranking > Retrieval-Augmented Generation","url":"https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html"},{"id":"paper-leveraging-passage-retrieval-with-generative-models-for-open-domain-question-answering","type":"paper","name":"Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering","description":"Fusion-in-Decoder (FiD) architecture enabling efficient scaling to 100+ passages; backbone of Atlas and subsequent RAG systems.","category":"Search & Ranking > Retrieval-Augmented Generation","url":"https://aclanthology.org/2021.eacl-main.74/"},{"id":"paper-transformer-memory-as-a-differentiable-search-index","type":"paper","name":"Transformer Memory as a Differentiable Search Index","description":"Generative retrieval paradigm (DSI): model memorizes corpus and generates document IDs directly; alternative to dense/sparse retrieve-then-rank.","category":"Search & Ranking > Retrieval-Augmented Generation","url":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/892840a6123b5ec99ebaab8be1530fba-Abstract-Conference.html"},{"id":"paper-cumulated-gain-based-evaluation-of-ir-techniques","type":"paper","name":"Cumulated Gain-Based Evaluation of IR Techniques","description":"Introduced DCG and NDCG; most widely used ranking metric enabling graded relevance evaluation.","category":"Search & Ranking > Evaluation Methods for IR","url":"https://dl.acm.org/doi/10.1145/582415.582418"},{"id":"paper-expected-reciprocal-rank-for-graded-relevance","type":"paper","name":"Expected Reciprocal Rank for Graded Relevance","description":"Cascade-based metric modeling user stopping behavior; primary TREC Web Track metric accounting for diminishing returns.","category":"Search & Ranking > Evaluation Methods for IR","url":"https://dl.acm.org/doi/10.1145/1645953.1646033"},{"id":"paper-ms-marco:-a-human-generated-machine-reading-comprehension-dataset","type":"paper","name":"MS MARCO: A Human Generated MAchine Reading COmprehension Dataset","description":"Large-scale passage ranking benchmark with 1M queries; enabled neural retrieval research and remains primary leaderboard.","category":"Search & Ranking > Evaluation Methods for IR","url":"https://arxiv.org/abs/1611.09268"},{"id":"paper-beir:-a-heterogeneous-benchmark-for-zero-shot-evaluation-of-information-retrieval-models","type":"paper","name":"BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models","description":"18-dataset benchmark testing out-of-distribution generalization; key finding that BM25 remains robust while dense models struggle on domain shift.","category":"Search & Ranking > Evaluation Methods for IR","url":"https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/65b9eea6e1cc6bb9f0cd2a47751a186f-Abstract-round2.html"},{"id":"paper-large-scale-validation-and-analysis-of-interleaved-search-evaluation","type":"paper","name":"Large-Scale Validation and Analysis of Interleaved Search Evaluation","description":"Definitive validation of interleaving as online A/B testing gold standard; demonstrated high agreement with editorial judgments at scale.","category":"Search & Ranking > Evaluation Methods for IR","url":"https://dl.acm.org/doi/10.1145/2094072.2094078"},{"id":"paper-personalizing-search-via-automated-analysis-of-interests-and-activities","type":"paper","name":"Personalizing Search via Automated Analysis of Interests and Activities","description":"Foundational personalization paper establishing paradigm for implicit user modeling from desktop and search history.","category":"Search & Ranking > Personalized & Conversational Search","url":"https://dl.acm.org/doi/10.1145/1076034.1076111"},{"id":"paper-modeling-the-impact-of-short--and-long-term-behavior-on-search-personalization","type":"paper","name":"Modeling the Impact of Short- and Long-Term Behavior on Search Personalization","description":"Established distinction between session-level and historical personalization signals; showed combination outperforms either alone.","category":"Search & Ranking > Personalized & Conversational Search","url":"https://dl.acm.org/doi/10.1145/2348283.2348312"},{"id":"paper-context-aware-ranking-in-web-search","type":"paper","name":"Context-Aware Ranking in Web Search","description":"Operationalized session and context signals in production LTR frameworks; showed how to integrate behavioral context into ranking features.","category":"Search & Ranking > Personalized & Conversational Search","url":"https://dl.acm.org/doi/10.1145/1835449.1835528"},{"id":"paper-trec-cast-2019:-the-conversational-assistance-track","type":"paper","name":"TREC CAsT 2019: The Conversational Assistance Track","description":"Defining benchmark for conversational IR with 80 dialogues over 38M passages; established evaluation methodology for multi-turn search.","category":"Search & Ranking > Personalized & Conversational Search","url":"https://dl.acm.org/doi/10.1145/3397271.3401206"},{"id":"paper-open-retrieval-conversational-question-answering","type":"paper","name":"Open-Retrieval Conversational Question Answering","description":"Open-domain retrieval for conversational QA; advances beyond simplified settings with ORConvQA dataset and baselines.","category":"Search & Ranking > Personalized & Conversational Search","url":"https://dl.acm.org/doi/10.1145/3397271.3401110"},{"id":"paper-the-use-of-mmr,-diversity-based-reranking-for-reordering-documents-and-producing-summaries","type":"paper","name":"The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries","description":"THE seminal diversification paper introducing Maximal Marginal Relevance (MMR) formula; balances relevance with novelty.","category":"Search & Ranking > Result Diversification","url":"https://dl.acm.org/doi/10.1145/290941.291025"},{"id":"paper-novelty-and-diversity-in-information-retrieval-evaluation","type":"paper","name":"Novelty and Diversity in Information Retrieval Evaluation","description":"Standard evaluation framework for diversity introducing \u03b1-nDCG; enabled TREC Web diversity track and systematic diversity research.","category":"Search & Ranking > Result Diversification","url":"https://dl.acm.org/doi/10.1145/1390334.1390446"},{"id":"paper-diversifying-search-results","type":"paper","name":"Diversifying Search Results","description":"Intent-aware diversification with formal coverage guarantees; models query as distribution over intents and optimizes expected coverage.","category":"Search & Ranking > Result Diversification","url":"https://dl.acm.org/doi/10.1145/1498759.1498766"},{"id":"paper-asymptotically-efficient-adaptive-allocation-rules","type":"paper","name":"Asymptotically Efficient Adaptive Allocation Rules","description":"Establishes the fundamental logarithmic regret lower bound; defines optimal exploration-exploitation tradeoff.","category":"Reinforcement Learning > Multi-Armed Bandits","url":"https://www.sciencedirect.com/science/article/pii/0196885885900028"},{"id":"paper-finite-time-analysis-of-the-multiarmed-bandit-problem","type":"paper","name":"Finite-time Analysis of the Multiarmed Bandit Problem","description":"Introduces UCB1 with finite-time regret bounds; the practical workhorse algorithm still widely deployed.","category":"Reinforcement Learning > Multi-Armed Bandits","url":"https://link.springer.com/article/10.1023/A:1013689704352"},{"id":"paper-regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems","type":"paper","name":"Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems","description":"Comprehensive survey unifying stochastic and adversarial bandits; essential theoretical reference.","category":"Reinforcement Learning > Multi-Armed Bandits","url":"https://www.nowpublishers.com/article/Details/MAL-024"},{"id":"paper-optimal-best-arm-identification-with-fixed-confidence","type":"paper","name":"Optimal Best Arm Identification with Fixed Confidence","description":"Establishes lower bounds and optimal algorithms for best-arm identification; key for A/B testing.","category":"Reinforcement Learning > Multi-Armed Bandits","url":"http://proceedings.mlr.press/v49/garivier16a.html"},{"id":"paper-on-the-complexity-of-best-arm-identification-in-multi-armed-bandit-models","type":"paper","name":"On the Complexity of Best-Arm Identification in Multi-Armed Bandit Models","description":"Characterizes the sample complexity of best-arm identification in fixed-budget and fixed-confidence settings.","category":"Reinforcement Learning > Multi-Armed Bandits","url":"https://jmlr.org/papers/v17/kaufman16a.html"},{"id":"paper-a-contextual-bandit-approach-to-personalized-news-article-recommendation-1","type":"paper","name":"A Contextual-Bandit Approach to Personalized News Article Recommendation","description":"Introduces LinUCB; deployed at Yahoo! with 33M events; foundational industry paper.","category":"Reinforcement Learning > Contextual Bandits","url":"https://arxiv.org/abs/1003.0146"},{"id":"paper-contextual-bandits-with-linear-payoff-functions","type":"paper","name":"Contextual Bandits with Linear Payoff Functions","description":"Rigorous theoretical analysis providing SupLinUCB algorithm.","category":"Reinforcement Learning > Contextual Bandits","url":"https://proceedings.mlr.press/v15/chu11a.html"},{"id":"paper-thompson-sampling-for-contextual-bandits-with-linear-payoffs","type":"paper","name":"Thompson Sampling for Contextual Bandits with Linear Payoffs","description":"First near-optimal regret bounds for Thompson Sampling in contextual settings.","category":"Reinforcement Learning > Contextual Bandits","url":"https://proceedings.mlr.press/v28/agrawal13.html"},{"id":"paper-taming-the-monster:-a-fast-and-simple-algorithm-for-contextual-bandits","type":"paper","name":"Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits","description":"Efficient algorithm handling large policy classes for practical implementation.","category":"Reinforcement Learning > Contextual Bandits","url":"https://proceedings.mlr.press/v32/agarwalb14.html"},{"id":"paper-neural-contextual-bandits-with-ucb-based-exploration","type":"paper","name":"Neural Contextual Bandits with UCB-based Exploration","description":"Extends contextual bandits to neural network function approximation; bridges deep learning and bandit theory.","category":"Reinforcement Learning > Contextual Bandits","url":"https://proceedings.mlr.press/v119/zhou20a.html"},{"id":"paper-beyond-ucb:-optimal-and-efficient-contextual-bandits-with-regression-oracles","type":"paper","name":"Beyond UCB: Optimal and Efficient Contextual Bandits with Regression Oracles","description":"SquareCB algorithm achieves optimal regret using only regression oracles; practical for complex function classes.","category":"Reinforcement Learning > Contextual Bandits","url":"https://proceedings.mlr.press/v119/foster20a.html"},{"id":"paper-a-tutorial-on-thompson-sampling","type":"paper","name":"A Tutorial on Thompson Sampling","description":"Definitive survey covering theory, applications, and extensions; essential practitioner reference.","category":"Reinforcement Learning > Thompson Sampling & Bayesian Bandits","url":"https://arxiv.org/abs/1707.02038"},{"id":"paper-an-empirical-evaluation-of-thompson-sampling-1","type":"paper","name":"An Empirical Evaluation of Thompson Sampling","description":"Demonstrates strong empirical performance; sparked renewed industry interest.","category":"Reinforcement Learning > Thompson Sampling & Bayesian Bandits","url":"https://papers.nips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html"},{"id":"paper-analysis-of-thompson-sampling-for-the-multi-armed-bandit-problem","type":"paper","name":"Analysis of Thompson Sampling for the Multi-armed Bandit Problem","description":"First proof of optimal O(\u221aKT log T) regret bounds.","category":"Reinforcement Learning > Thompson Sampling & Bayesian Bandits","url":"http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf"},{"id":"paper-learning-to-optimize-via-posterior-sampling","type":"paper","name":"Learning to Optimize via Posterior Sampling","description":"Theoretical foundations extending Thompson Sampling to general RL.","category":"Reinforcement Learning > Thompson Sampling & Bayesian Bandits","url":"https://pubsonline.informs.org/doi/10.1287/moor.2014.0650"},{"id":"paper-learning-to-optimize-via-information-directed-sampling","type":"paper","name":"Learning to Optimize via Information-Directed Sampling","description":"Generalizes Thompson Sampling using information ratio; provides tighter regret bounds for structured problems.","category":"Reinforcement Learning > Thompson Sampling & Bayesian Bandits","url":"https://pubsonline.informs.org/doi/10.1287/opre.2017.1663"},{"id":"paper-doubly-robust-policy-evaluation-and-learning","type":"paper","name":"Doubly Robust Policy Evaluation and Learning","description":"Introduces doubly robust estimator combining IPS and direct method; robust to model misspecification.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://arxiv.org/abs/1103.4601"},{"id":"paper-counterfactual-risk-minimization:-learning-from-logged-bandit-feedback","type":"paper","name":"Counterfactual Risk Minimization: Learning from Logged Bandit Feedback","description":"Principled framework for learning from logged data; widely used in industry.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://jmlr.org/papers/v16/swaminathan15a.html"},{"id":"paper-the-self-normalized-estimator-for-counterfactual-learning-1","type":"paper","name":"The Self-Normalized Estimator for Counterfactual Learning","description":"Addresses high variance in IPS with self-normalization for real systems.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://papers.nips.cc/paper/2015/hash/39027dfad5138c9ca0c474d71db915c3-Abstract.html"},{"id":"paper-optimal-and-adaptive-off-policy-evaluation-in-contextual-bandits","type":"paper","name":"Optimal and Adaptive Off-policy Evaluation in Contextual Bandits","description":"Minimax optimal bounds providing theoretical foundation for modern OPE.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://proceedings.mlr.press/v70/wang17a.html"},{"id":"paper-data-efficient-off-policy-policy-evaluation-for-reinforcement-learning","type":"paper","name":"Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning","description":"High-confidence bounds for off-policy evaluation; safety-critical applications in healthcare and education.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://proceedings.mlr.press/v48/thomasa16.html"},{"id":"paper-towards-optimal-off-policy-evaluation-for-reinforcement-learning","type":"paper","name":"Towards Optimal Off-Policy Evaluation for Reinforcement Learning","description":"Achieves minimax optimal rates for OPE in tabular MDPs; foundational theoretical result.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://arxiv.org/abs/1905.00360"},{"id":"paper-off-policy-evaluation-for-slate-recommendation","type":"paper","name":"Off-policy Evaluation for Slate Recommendation","description":"Extends OPE to slate/list recommendations; critical for search and recommendation systems.","category":"Reinforcement Learning > Off-Policy Evaluation","url":"https://papers.nips.cc/paper/2017/hash/5352696a9ca3397beb79f116f3a33991-Abstract.html"},{"id":"paper-offline-reinforcement-learning:-tutorial,-review,-and-perspectives-on-open-problems","type":"paper","name":"Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems","description":"Comprehensive tutorial defining the field's challenges and research directions.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/2005.01643"},{"id":"paper-off-policy-deep-reinforcement-learning-without-exploration-(bcq)","type":"paper","name":"Off-Policy Deep Reinforcement Learning without Exploration (BCQ)","description":"Identifies extrapolation error as core challenge; introduces Batch-Constrained Q-learning.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/1812.02900"},{"id":"paper-conservative-q-learning-for-offline-reinforcement-learning-(cql)","type":"paper","name":"Conservative Q-Learning for Offline Reinforcement Learning (CQL)","description":"Learns conservative Q-functions lower-bounding true value; SOTA on D4RL benchmarks.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/2006.04779"},{"id":"paper-d4rl:-datasets-for-deep-data-driven-reinforcement-learning","type":"paper","name":"D4RL: Datasets for Deep Data-Driven Reinforcement Learning","description":"Standard benchmark datasets enabling reproducible offline RL research.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/2004.07219"},{"id":"paper-decision-transformer:-reinforcement-learning-via-sequence-modeling","type":"paper","name":"Decision Transformer: Reinforcement Learning via Sequence Modeling","description":"Frames offline RL as sequence modeling using transformers; avoids bootstrapping entirely.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/2106.01345"},{"id":"paper-offline-reinforcement-learning-with-implicit-q-learning","type":"paper","name":"Offline Reinforcement Learning with Implicit Q-Learning","description":"Simple algorithm avoiding explicit policy constraint; strong performance on D4RL benchmarks.","category":"Reinforcement Learning > Batch/Offline RL","url":"https://arxiv.org/abs/2110.06169"},{"id":"paper-real-time-bidding-by-reinforcement-learning-in-display-advertising","type":"paper","name":"Real-Time Bidding by Reinforcement Learning in Display Advertising","description":"MDP framework for RTB with neural network value approximation for budget-constrained bidding.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://arxiv.org/abs/1701.02490"},{"id":"paper-deep-reinforcement-learning-for-sponsored-search-real-time-bidding","type":"paper","name":"Deep Reinforcement Learning for Sponsored Search Real-time Bidding","description":"DRL for sponsored search deployed at Alibaba scale; handles non-stationary environments.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://arxiv.org/abs/1803.00259"},{"id":"paper-budget-constrained-bidding-by-model-free-reinforcement-learning","type":"paper","name":"Budget Constrained Bidding by Model-free Reinforcement Learning","description":"Model-free RL for budget-constrained bidding with practical reward function design.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://arxiv.org/abs/1802.08365"},{"id":"paper-web-scale-bayesian-click-through-rate-prediction-for-sponsored-search","type":"paper","name":"Web-scale Bayesian Click-through Rate Prediction for Sponsored Search","description":"Thompson Sampling at web-scale in Bing; demonstrates industrial viability of Bayesian methods.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://www.microsoft.com/en-us/research/publication/web-scale-bayesian-click-through-rate-prediction-for-sponsored-search-advertising-in-microsofts-bing-search-engine/"},{"id":"paper-learning-in-repeated-auctions-with-budgets:-regret-minimization-and-equilibrium","type":"paper","name":"Learning in Repeated Auctions with Budgets: Regret Minimization and Equilibrium","description":"Regret bounds for bidding with budget constraints; foundational for pacing algorithms.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2018.3209"},{"id":"paper-optimal-auctions-through-deep-learning","type":"paper","name":"Optimal Auctions through Deep Learning","description":"Neural networks learn near-optimal auction mechanisms; connects ML and mechanism design.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://proceedings.mlr.press/v97/duetting19a.html"},{"id":"paper-contextual-bandits-with-cross-learning","type":"paper","name":"Contextual Bandits with Cross-Learning","description":"Learning across related auctions; critical for ad platforms with correlated contexts.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://proceedings.neurips.cc/paper/2019/hash/b5b03f06271f8917685d14cea7c6c50a-Abstract.html"},{"id":"paper-personalized-dynamic-pricing-with-machine-learning:-high-dimensional-features-and-heterogeneou","type":"paper","name":"Personalized Dynamic Pricing with Machine Learning: High-Dimensional Features and Heterogeneous Elasticity","description":"Combines ML feature learning with dynamic pricing; optimal regret in high dimensions.","category":"Reinforcement Learning > RL for Bidding & Pricing","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2020.3680"},{"id":"paper-top-k-off-policy-correction-for-a-reinforce-recommender-system-1","type":"paper","name":"Top-K Off-Policy Correction for a REINFORCE Recommender System","description":"Deployed at YouTube; addresses large action spaces in slate recommendation with off-policy correction.","category":"Reinforcement Learning > RL for Recommendations","url":"https://dl.acm.org/doi/10.1145/3289600.3290999"},{"id":"paper-slateq:-a-tractable-decomposition-for-reinforcement-learning-with-recommendation-sets-1","type":"paper","name":"SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets","description":"Decomposes slate Q-values for tractable optimization; deployed at Google.","category":"Reinforcement Learning > RL for Recommendations","url":"https://www.ijcai.org/proceedings/2019/360"},{"id":"paper-deep-reinforcement-learning-for-page-wise-recommendations","type":"paper","name":"Deep Reinforcement Learning for Page-wise Recommendations","description":"DRL for whole-page recommendations considering item interactions and user browsing patterns.","category":"Reinforcement Learning > RL for Recommendations","url":"https://dl.acm.org/doi/10.1145/3240323.3240374"},{"id":"paper-generative-adversarial-user-model-for-reinforcement-learning-based-recommendation-system","type":"paper","name":"Generative Adversarial User Model for Reinforcement Learning Based Recommendation System","description":"Learns user simulator for offline RL training; addresses exploration challenges in recommendations.","category":"Reinforcement Learning > RL for Recommendations","url":"https://proceedings.mlr.press/v97/chen19f.html"},{"id":"paper-reinforcement-learning-to-optimize-long-term-user-engagement-in-recommender-systems","type":"paper","name":"Reinforcement Learning to Optimize Long-term User Engagement in Recommender Systems","description":"Optimizes long-term user retention metrics beyond immediate clicks; deployed at JD.com.","category":"Reinforcement Learning > RL for Recommendations","url":"https://dl.acm.org/doi/10.1145/3292500.3330668"},{"id":"paper-constrained-policy-optimization","type":"paper","name":"Constrained Policy Optimization","description":"First practical algorithm for RL with safety constraints; foundational for safe RL.","category":"Reinforcement Learning > Safe & Constrained RL","url":"https://proceedings.mlr.press/v70/achiam17a.html"},{"id":"paper-safe-model-based-reinforcement-learning-with-stability-guarantees","type":"paper","name":"Safe Model-based Reinforcement Learning with Stability Guarantees","description":"Provides formal safety guarantees using Lyapunov functions; critical for robotics applications.","category":"Reinforcement Learning > Safe & Constrained RL","url":"https://papers.nips.cc/paper/2017/hash/766ebcd59621e305170616ba3d3dac32-Abstract.html"},{"id":"paper-benchmarking-safe-exploration-in-deep-reinforcement-learning","type":"paper","name":"Benchmarking Safe Exploration in Deep Reinforcement Learning","description":"OpenAI Safety Gym benchmark suite; standard evaluation for safe RL algorithms.","category":"Reinforcement Learning > Safe & Constrained RL","url":"https://cdn.openai.com/safexp-short.pdf"},{"id":"paper-deep-exploration-via-bootstrapped-dqn","type":"paper","name":"Deep Exploration via Bootstrapped DQN","description":"Posterior sampling for deep RL exploration; efficient exploration without explicit uncertainty.","category":"Reinforcement Learning > Exploration & Sample Efficiency","url":"https://papers.nips.cc/paper/2016/hash/8d8818c8e140c64c743113f563cf750f-Abstract.html"},{"id":"paper-unifying-count-based-exploration-and-intrinsic-motivation","type":"paper","name":"Unifying Count-Based Exploration and Intrinsic Motivation","description":"Pseudo-counts for exploration in high-dimensional spaces; breakthrough for sparse-reward problems.","category":"Reinforcement Learning > Exploration & Sample Efficiency","url":"https://papers.nips.cc/paper/2016/hash/afda332245e2af431fb7b672a68b659d-Abstract.html"},{"id":"paper-curiosity-driven-exploration-by-self-supervised-prediction","type":"paper","name":"Curiosity-driven Exploration by Self-supervised Prediction","description":"Intrinsic curiosity module using prediction error as exploration bonus; widely influential approach.","category":"Reinforcement Learning > Exploration & Sample Efficiency","url":"https://proceedings.mlr.press/v70/pathak17a.html"},{"id":"paper-model-based-reinforcement-learning-for-atari","type":"paper","name":"Model Based Reinforcement Learning for Atari","description":"SimPLe achieves 100x sample efficiency on Atari using learned world models.","category":"Reinforcement Learning > Exploration & Sample Efficiency","url":"https://arxiv.org/abs/1903.00374"},{"id":"paper-a-unified-game-theoretic-approach-to-multiagent-reinforcement-learning","type":"paper","name":"A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning","description":"PSRO framework unifying game theory and deep RL; foundational for competitive multi-agent systems.","category":"Reinforcement Learning > Multi-Agent & Game-Theoretic RL","url":"https://papers.nips.cc/paper/2017/hash/3323fe11e9595c09af38571f2756d3c5-Abstract.html"},{"id":"paper-learning-with-opponent-learning-awareness","type":"paper","name":"Learning with Opponent-Learning Awareness","description":"LOLA accounts for opponent adaptation during learning; key insight for non-stationary multi-agent settings.","category":"Reinforcement Learning > Multi-Agent & Game-Theoretic RL","url":"https://dl.acm.org/doi/10.5555/3237383.3237811"},{"id":"paper-grandmaster-level-in-starcraft-ii-using-multi-agent-reinforcement-learning","type":"paper","name":"Grandmaster level in StarCraft II using multi-agent reinforcement learning","description":"AlphaStar achieves grandmaster level; landmark result in complex multi-agent real-time strategy.","category":"Reinforcement Learning > Multi-Agent & Game-Theoretic RL","url":"https://www.nature.com/articles/s41586-019-1724-z"},{"id":"paper-superhuman-ai-for-multiplayer-poker","type":"paper","name":"Superhuman AI for multiplayer poker","description":"Pluribus beats top humans in 6-player poker; breakthrough in imperfect-information games.","category":"Reinforcement Learning > Multi-Agent & Game-Theoretic RL","url":"https://www.science.org/doi/10.1126/science.aay2400"},{"id":"paper-algorithms-for-inverse-reinforcement-learning","type":"paper","name":"Algorithms for Inverse Reinforcement Learning","description":"Foundational IRL paper formalizing reward extraction from observed optimal behavior.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://ai.stanford.edu/~ang/papers/icml00-irl.pdf"},{"id":"paper-apprenticeship-learning-via-inverse-reinforcement-learning","type":"paper","name":"Apprenticeship Learning via Inverse Reinforcement Learning","description":"Extends IRL to practical apprenticeship learning with feature expectation matching.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf"},{"id":"paper-maximum-entropy-inverse-reinforcement-learning","type":"paper","name":"Maximum Entropy Inverse Reinforcement Learning","description":"Resolves IRL ambiguity using maximum entropy principle; now the standard IRL formulation.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://cdn.aaai.org/AAAI/2008/AAAI08-227.pdf"},{"id":"paper-cooperative-inverse-reinforcement-learning","type":"paper","name":"Cooperative Inverse Reinforcement Learning","description":"Frames value alignment as cooperative game; foundational for AI safety.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://people.eecs.berkeley.edu/~russell/papers/russell-nips16-cirl.pdf"},{"id":"paper-bayesian-inverse-reinforcement-learning","type":"paper","name":"Bayesian Inverse Reinforcement Learning","description":"First Bayesian framework for IRL; provides posterior distributions over rewards capturing uncertainty.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://www.ijcai.org/Proceedings/07/Papers/416.pdf"},{"id":"paper-guided-cost-learning:-deep-inverse-optimal-control-via-policy-optimization","type":"paper","name":"Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization","description":"First deep IRL method learning arbitrary neural network cost functions; enabled learning from raw images.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://proceedings.mlr.press/v48/finn16.html"},{"id":"paper-inverse-reward-design","type":"paper","name":"Inverse Reward Design","description":"Treats designed rewards as noisy observations of true objectives; addresses reward hacking and negative side effects.","category":"Inverse RL & Preference Learning > Reward Inference from Behavior","url":"https://papers.nips.cc/paper/2017/hash/32fdab6559cdfa4f167f8c31b9199643-Abstract.html"},{"id":"paper-alvinn:-an-autonomous-land-vehicle-in-a-neural-network","type":"paper","name":"ALVINN: An Autonomous Land Vehicle in a Neural Network","description":"Pioneering behavioral cloning; first end-to-end neural network steering for autonomous vehicles.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://proceedings.neurips.cc/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf"},{"id":"paper-a-reduction-of-imitation-learning-to-no-regret-online-learning-(dagger)","type":"paper","name":"A Reduction of Imitation Learning to No-Regret Online Learning (DAgger)","description":"Solves distribution shift in behavioral cloning; reduces imitation to online learning with O(T) error.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://arxiv.org/abs/1011.0686"},{"id":"paper-generative-adversarial-imitation-learning-(gail)","type":"paper","name":"Generative Adversarial Imitation Learning (GAIL)","description":"GAN-style adversarial training directly learning policy without reward recovery.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://arxiv.org/abs/1606.03476"},{"id":"paper-learning-from-demonstration","type":"paper","name":"Learning from Demonstration","description":"Foundational work showing demonstrations accelerate RL; established paradigm for robot skill acquisition.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://papers.nips.cc/paper/1996/hash/68d13cf26c4b4f4f932e3eff990093ba-Abstract.html"},{"id":"paper-behavioral-cloning-from-observation","type":"paper","name":"Behavioral Cloning from Observation","description":"Learning from state-only observations without action labels; enables learning from video demonstrations.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://www.ijcai.org/proceedings/2018/687"},{"id":"paper-end-to-end-learning-for-self-driving-cars","type":"paper","name":"End to End Learning for Self-Driving Cars","description":"Industry-defining paper: CNNs mapping pixels to steering; achieved 98% autonomous driving in road tests.","category":"Inverse RL & Preference Learning > Imitation Learning","url":"https://arxiv.org/abs/1604.07316"},{"id":"paper-construction-of-a-utility-function-from-expenditure-data","type":"paper","name":"Construction of a Utility Function from Expenditure Data","description":"Foundational theorem: data is rationalizable iff it satisfies GARP; basis for computational revealed preference.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://ideas.repec.org/a/ier/iecrev/v8y1967i1p67-77.html"},{"id":"paper-the-nonparametric-approach-to-demand-analysis","type":"paper","name":"The Nonparametric Approach to Demand Analysis","description":"Makes Afriat computationally tractable; shows how to test and recover preferences nonparametrically.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://www.econometricsociety.org/publications/econometrica/1982/07/01/nonparametric-approach-demand-analysis"},{"id":"paper-revealed-preference-theory","type":"paper","name":"Revealed Preference Theory","description":"Comprehensive modern treatment covering GARP extensions, complexity, and mechanism design applications.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://www.cambridge.org/core/books/revealed-preference-theory/8B1F9B3F0C1B6E9B6B0B4B6B0B4B6B0B"},{"id":"paper-nonparametric-engel-curves-and-revealed-preference","type":"paper","name":"Nonparametric Engel Curves and Revealed Preference","description":"Combines revealed preference with nonparametric estimation; sharp bounds on counterfactual demands.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2008.00854.x"},{"id":"paper-conditional-logit-analysis-of-qualitative-choice-behavior","type":"paper","name":"Conditional Logit Analysis of Qualitative Choice Behavior","description":"Nobel Prize-winning random utility framework; foundation of discrete choice models used throughout tech.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf"},{"id":"paper-stochastic-choice-and-revealed-perturbed-utility","type":"paper","name":"Stochastic Choice and Revealed Perturbed Utility","description":"Axiomatic foundations for perturbed utility models; generalizes logit choice to capture bounded rationality.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA12660"},{"id":"paper-dynamic-random-utility","type":"paper","name":"Dynamic Random Utility","description":"Extends random utility to sequential choice with preference correlation; applicable to session-based user modeling.","category":"Inverse RL & Preference Learning > Revealed Preference at Scale","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA15456"},{"id":"paper-deep-reinforcement-learning-from-human-preferences","type":"paper","name":"Deep Reinforcement Learning from Human Preferences","description":"Foundational RLHF paper learning rewards from preference comparisons with ~1% feedback.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/1706.03741"},{"id":"paper-training-language-models-to-follow-instructions-with-human-feedback-(instructgpt)","type":"paper","name":"Training Language Models to Follow Instructions with Human Feedback (InstructGPT)","description":"1.3B InstructGPT outperforms 175B GPT-3 on human preferences; foundation for ChatGPT.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/2203.02155"},{"id":"paper-constitutional-ai:-harmlessness-from-ai-feedback","type":"paper","name":"Constitutional AI: Harmlessness from AI Feedback","description":"RLAIF using AI self-critique against constitutional principles; Claude's training methodology.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/2212.08073"},{"id":"paper-direct-preference-optimization-(dpo)","type":"paper","name":"Direct Preference Optimization (DPO)","description":"Eliminates reward model and RL loop; preference optimization via simple classification loss.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/2305.18290"},{"id":"paper-proximal-policy-optimization-algorithms","type":"paper","name":"Proximal Policy Optimization Algorithms","description":"Stable policy gradient algorithm with clipped objectives; THE optimizer underlying RLHF in all major LLMs.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/1707.06347"},{"id":"paper-learning-to-summarize-from-human-feedback","type":"paper","name":"Learning to Summarize from Human Feedback","description":"Demonstrated reward model + PPO pipeline for text; direct precursor to InstructGPT methodology.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/2009.01325"},{"id":"paper-a-general-theoretical-paradigm-to-understand-learning-from-human-preferences","type":"paper","name":"A General Theoretical Paradigm to Understand Learning from Human Preferences","description":"Unifies RLHF/DPO theoretically; Identity Preference Optimization fixes DPO overfitting issues.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://proceedings.mlr.press/v238/azar24a.html"},{"id":"paper-kto:-model-alignment-as-prospect-theoretic-optimization","type":"paper","name":"KTO: Model Alignment as Prospect Theoretic Optimization","description":"Aligns LLMs using binary good/bad signal via Kahneman-Tversky prospect theory; no preference pairs needed.","category":"Inverse RL & Preference Learning > Human Feedback & RLHF","url":"https://arxiv.org/abs/2402.01306"},{"id":"paper-interactively-optimizing-information-retrieval-systems-as-a-dueling-bandits-problem","type":"paper","name":"Interactively Optimizing Information Retrieval Systems as a Dueling Bandits Problem","description":"Introduced dueling bandits for pairwise preference learning; enables online learning without absolute labels.","category":"Inverse RL & Preference Learning > Preference Elicitation & Active Learning","url":"https://proceedings.mlr.press/v5/yue09a.html"},{"id":"paper-the-k-armed-dueling-bandits-problem","type":"paper","name":"The K-Armed Dueling Bandits Problem","description":"Extended dueling bandits to K arms with regret bounds; Interleaved Filter algorithm for search evaluation.","category":"Inverse RL & Preference Learning > Preference Elicitation & Active Learning","url":"https://www.sciencedirect.com/science/article/pii/S0022000012000256"},{"id":"paper-preference-based-online-learning-with-dueling-bandits:-a-survey","type":"paper","name":"Preference-based Online Learning with Dueling Bandits: A Survey","description":"Comprehensive 108-page survey of dueling bandits variants, algorithms, and applications.","category":"Inverse RL & Preference Learning > Preference Elicitation & Active Learning","url":"https://jmlr.org/papers/v22/18-546.html"},{"id":"paper-stagewise-safe-bayesian-optimization-with-gaussian-processes","type":"paper","name":"Stagewise Safe Bayesian Optimization with Gaussian Processes","description":"Safe preference-based optimization separating exploration from exploitation; applicable to clinical/robotics.","category":"Inverse RL & Preference Learning > Preference Elicitation & Active Learning","url":"https://proceedings.mlr.press/v80/sui18a.html"},{"id":"paper-counterfactual-risk-minimization:-learning-from-logged-bandit-feedback-1","type":"paper","name":"Counterfactual Risk Minimization: Learning from Logged Bandit Feedback","description":"Propensity-weighted learning from logged actions; foundation for offline policy learning in recommendations.","category":"Inverse RL & Preference Learning > Preference Elicitation & Active Learning","url":"https://www.jmlr.org/papers/v16/swaminathan15a.html"},{"id":"paper-an-experimental-comparison-of-click-position-bias-models-1","type":"paper","name":"An Experimental Comparison of Click Position-Bias Models","description":"Seminal click modeling paper; introduced cascade and position-based models; foundation for bias correction.","category":"Inverse RL & Preference Learning > Choice Modeling from Behavioral Data","url":"https://dl.acm.org/doi/10.1145/1341531.1341545"},{"id":"paper-a-dynamic-bayesian-network-click-model-for-web-search-ranking","type":"paper","name":"A Dynamic Bayesian Network Click Model for Web Search Ranking","description":"DBN click model capturing examination chains and satisfaction; enables unbiased relevance estimation.","category":"Inverse RL & Preference Learning > Choice Modeling from Behavioral Data","url":"https://dl.acm.org/doi/10.1145/1526709.1526711"},{"id":"paper-unbiased-learning-to-rank-with-biased-feedback-2","type":"paper","name":"Unbiased Learning-to-Rank with Biased Feedback","description":"Counterfactual framework for unbiased LTR; Propensity-Weighted Ranking SVM; highly influential for debiasing.","category":"Inverse RL & Preference Learning > Choice Modeling from Behavioral Data","url":"https://dl.acm.org/doi/10.1145/3018661.3018699"},{"id":"paper-click-models-for-web-search-1","type":"paper","name":"Click Models for Web Search","description":"Comprehensive survey of click models, estimation methods, and applications to search evaluation.","category":"Inverse RL & Preference Learning > Choice Modeling from Behavioral Data","url":"https://www.morganclaypool.com/doi/abs/10.2200/S00654ED1V01Y201507ICR043"},{"id":"paper-concrete-problems-in-ai-safety","type":"paper","name":"Concrete Problems in AI Safety","description":"Taxonomy of five safety problems: side effects, reward hacking, scalable oversight, safe exploration, distributional shift.","category":"Inverse RL & Preference Learning > Value Alignment & AI Safety","url":"https://arxiv.org/abs/1606.06565"},{"id":"paper-goal-misgeneralization-in-deep-reinforcement-learning","type":"paper","name":"Goal Misgeneralization in Deep Reinforcement Learning","description":"Demonstrates agents can pursue wrong goals even with correct specifications; distinct from reward hacking.","category":"Inverse RL & Preference Learning > Value Alignment & AI Safety","url":"https://arxiv.org/abs/2105.14111"},{"id":"paper-scaling-laws-for-reward-model-overoptimization","type":"paper","name":"Scaling Laws for Reward Model Overoptimization","description":"First systematic study of Goodhart's Law in RLHF; provides predictable scaling for safe optimization bounds.","category":"Inverse RL & Preference Learning > Value Alignment & AI Safety","url":"https://proceedings.mlr.press/v202/gao23h.html"},{"id":"paper-weak-to-strong-generalization:-eliciting-strong-capabilities-with-weak-supervision","type":"paper","name":"Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision","description":"Shows GPT-2 can supervise GPT-4; core empirical work on scalable oversight for superhuman AI alignment.","category":"Inverse RL & Preference Learning > Value Alignment & AI Safety","url":"https://arxiv.org/abs/2312.09390"},{"id":"paper-matrix-factorization-techniques-for-recommender-systems-1","type":"paper","name":"Matrix Factorization Techniques for Recommender Systems","description":"Netflix Prize winners' tutorial; latent factor models, implicit feedback, temporal dynamics; 14,000+ citations.","category":"Inverse RL & Preference Learning > Personalization & User Modeling","url":"https://ieeexplore.ieee.org/document/5197422"},{"id":"paper-collaborative-filtering-for-implicit-feedback-datasets-1","type":"paper","name":"Collaborative Filtering for Implicit Feedback Datasets","description":"Weighted matrix factorization for clicks/views; confidence-weighted preference learning; industry standard.","category":"Inverse RL & Preference Learning > Personalization & User Modeling","url":"https://ieeexplore.ieee.org/document/4781121"},{"id":"paper-bpr:-bayesian-personalized-ranking-from-implicit-feedback-1","type":"paper","name":"BPR: Bayesian Personalized Ranking from Implicit Feedback","description":"Pairwise ranking optimization from Bayesian principles; first method optimizing ranking directly for implicit data.","category":"Inverse RL & Preference Learning > Personalization & User Modeling","url":"https://arxiv.org/abs/1205.2618"},{"id":"paper-time-series-analysis:-forecasting-and-control","type":"paper","name":"Time Series Analysis: Forecasting and Control","description":"Foundational text establishing ARIMA and the Box-Jenkins approach to model identification.","category":"Forecasting > Time Series Foundations","url":"https://www.wiley.com/en-us/Time+Series+Analysis%3A+Forecasting+and+Control%2C+5th+Edition-p-9781118675021"},{"id":"paper-a-state-space-framework-for-automatic-forecasting-using-exponential-smoothing","type":"paper","name":"A State Space Framework for Automatic Forecasting using Exponential Smoothing","description":"Establishes ETS state space framework enabling model selection, prediction intervals, and likelihood calculation.","category":"Forecasting > Time Series Foundations","url":"https://robjhyndman.com/papers/hksg.pdf"},{"id":"paper-the-m3-competition:-results,-conclusions-and-implications","type":"paper","name":"The M3-Competition: Results, Conclusions and Implications","description":"Landmark 3,003-series competition establishing that simpler methods often outperform complex ones.","category":"Forecasting > Time Series Foundations","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207000000571"},{"id":"paper-the-m4-competition:-100,000-time-series-and-61-forecasting-methods","type":"paper","name":"The M4 Competition: 100,000 Time Series and 61 Forecasting Methods","description":"100,000 series showing hybrid statistical-ML methods dominate; pure ML underperformed.","category":"Forecasting > Time Series Foundations","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207018300785"},{"id":"paper-stl:-a-seasonal-trend-decomposition-procedure-based-on-loess","type":"paper","name":"STL: A Seasonal-Trend Decomposition Procedure Based on Loess","description":"Foundational decomposition method separating seasonal, trend, and remainder components using local regression.","category":"Forecasting > Time Series Foundations","url":"https://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/stl-a-seasonal-trend-decomposition-procedure-based-on-loess.pdf"},{"id":"paper-mstl:-a-seasonal-trend-decomposition-algorithm-for-time-series-with-multiple-seasonal-patterns","type":"paper","name":"MSTL: A Seasonal-Trend Decomposition Algorithm for Time Series with Multiple Seasonal Patterns","description":"Extension of STL handling multiple seasonal periods; essential for complex seasonality like hourly data.","category":"Forecasting > Time Series Foundations","url":"https://arxiv.org/abs/2107.13462"},{"id":"paper-strictly-proper-scoring-rules,-prediction,-and-estimation","type":"paper","name":"Strictly Proper Scoring Rules, Prediction, and Estimation","description":"Definitive treatment of proper scoring rules; introduces CRPS, energy score, interval score.","category":"Forecasting > Probabilistic Forecasting","url":"https://sites.stat.washington.edu/raftery/Research/PDF/Gneiting2007jasa.pdf"},{"id":"paper-regression-quantiles","type":"paper","name":"Regression Quantiles","description":"Introduced quantile regression for estimating conditional quantiles; foundation for distributional forecasting.","category":"Forecasting > Probabilistic Forecasting","url":"https://www.jstor.org/stable/1913643"},{"id":"paper-probabilistic-energy-forecasting:-global-energy-forecasting-competition-2014-and-beyond","type":"paper","name":"Probabilistic Energy Forecasting: Global Energy Forecasting Competition 2014 and Beyond","description":"GEFCom2014 establishing practical standards for probabilistic forecast evaluation.","category":"Forecasting > Probabilistic Forecasting","url":"https://ideas.repec.org/a/eee/intfor/v32y2016i3p896-913.html"},{"id":"paper-conformal-time-series-forecasting","type":"paper","name":"Conformal Time-series Forecasting","description":"Distribution-free prediction intervals with guaranteed coverage for time series; handles non-exchangeability.","category":"Forecasting > Probabilistic Forecasting","url":"https://arxiv.org/abs/2107.01709"},{"id":"paper-multivariate-probabilistic-time-series-forecasting-via-conditioned-normalizing-flows","type":"paper","name":"Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows","description":"Normalizing flows for flexible multivariate distributions in forecasting; captures complex dependencies.","category":"Forecasting > Probabilistic Forecasting","url":"https://arxiv.org/abs/2002.06103"},{"id":"paper-the-combination-of-forecasts","type":"paper","name":"The Combination of Forecasts","description":"Seminal paper showing combined forecasts yield lower MSE than individuals; foundation for ensemble methods.","category":"Forecasting > Hierarchical & Grouped Forecasting","url":"https://www.jstor.org/stable/3008764"},{"id":"paper-optimal-forecast-reconciliation-for-hierarchical-and-grouped-time-series-through-trace-minimiz","type":"paper","name":"Optimal Forecast Reconciliation for Hierarchical and Grouped Time Series Through Trace Minimization","description":"MinT optimal reconciliation method minimizing forecast variance; outperforms bottom-up and top-down.","category":"Forecasting > Hierarchical & Grouped Forecasting","url":"https://robjhyndman.com/publications/mint/"},{"id":"paper-chapter-4:-forecast-combinations","type":"paper","name":"Chapter 4: Forecast Combinations","description":"Authoritative review explaining why simple averages often beat optimal weights (estimation error, instability).","category":"Forecasting > Hierarchical & Grouped Forecasting","url":"https://www.sciencedirect.com/science/article/abs/pii/S1574070605010049"},{"id":"paper-forecast-reconciliation:-a-review","type":"paper","name":"Forecast Reconciliation: A Review","description":"Comprehensive review covering cross-sectional, temporal, and cross-temporal reconciliation.","category":"Forecasting > Hierarchical & Grouped Forecasting","url":"https://www.sciencedirect.com/science/article/pii/S0169207023001097"},{"id":"paper-cross-temporal-forecast-reconciliation:-optimal-combination-method-and-heuristic-algorithms","type":"paper","name":"Cross-temporal Forecast Reconciliation: Optimal Combination Method and Heuristic Algorithms","description":"Unified framework for simultaneous cross-sectional and temporal reconciliation; optimal point forecasts.","category":"Forecasting > Hierarchical & Grouped Forecasting","url":"https://www.sciencedirect.com/science/article/pii/S0169207022001005"},{"id":"paper-deepar:-probabilistic-forecasting-with-autoregressive-recurrent-networks","type":"paper","name":"DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks","description":"Amazon's global probabilistic forecasting model; pioneered cross-learning for scale-diverse series.","category":"Forecasting > Deep Learning for Forecasting","url":"https://arxiv.org/abs/1704.04110"},{"id":"paper-forecasting-at-scale-(prophet)","type":"paper","name":"Forecasting at Scale (Prophet)","description":"Meta's additive model with trend, seasonality, holidays; designed for analyst-in-the-loop forecasting.","category":"Forecasting > Deep Learning for Forecasting","url":"https://peerj.com/preprints/3190/"},{"id":"paper-n-beats:-neural-basis-expansion-analysis-for-interpretable-time-series-forecasting","type":"paper","name":"N-BEATS: Neural Basis Expansion Analysis for Interpretable Time Series Forecasting","description":"First pure DL model to beat M4 winner; interpretable version decomposes into trend and seasonality.","category":"Forecasting > Deep Learning for Forecasting","url":"https://arxiv.org/abs/1905.10437"},{"id":"paper-temporal-fusion-transformers-for-interpretable-multi-horizon-time-series-forecasting","type":"paper","name":"Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting","description":"Google's attention architecture handling static covariates, known future inputs, observed past-only features.","category":"Forecasting > Deep Learning for Forecasting","url":"https://arxiv.org/abs/1912.09363"},{"id":"paper-m5-accuracy-competition:-results,-findings,-and-conclusions","type":"paper","name":"M5 Accuracy Competition: Results, Findings, and Conclusions","description":"42,840 Walmart series; LightGBM and DL dominated; 22% improvement over best benchmark.","category":"Forecasting > Deep Learning for Forecasting","url":"https://www.sciencedirect.com/science/article/pii/S0169207021001874"},{"id":"paper-deep-state-space-models-for-time-series-forecasting","type":"paper","name":"Deep State Space Models for Time Series Forecasting","description":"Combines state space models with deep learning; enables interpretable components with neural flexibility.","category":"Forecasting > Deep Learning for Forecasting","url":"https://papers.nips.cc/paper/2018/hash/5cf68969fb67aa6082363a6d4e6468e2-Abstract.html"},{"id":"paper-informer:-beyond-efficient-transformer-for-long-sequence-time-series-forecasting","type":"paper","name":"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting","description":"AAAI Best Paper; ProbSparse attention achieving O(L log L) complexity for long sequences.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2012.07436"},{"id":"paper-autoformer:-decomposition-transformers-with-auto-correlation-for-long-term-series-forecasting","type":"paper","name":"Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting","description":"Novel auto-correlation mechanism replacing attention; built-in series decomposition improves interpretability.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2106.13008"},{"id":"paper-fedformer:-frequency-enhanced-decomposed-transformer-for-long-term-series-forecasting","type":"paper","name":"FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting","description":"Fourier-enhanced attention capturing global patterns in frequency domain with linear complexity.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2201.12740"},{"id":"paper-a-time-series-is-worth-64-words:-long-term-forecasting-with-transformers-(patchtst)","type":"paper","name":"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers (PatchTST)","description":"Patching time series like images; channel-independence achieving SOTA on long-term benchmarks.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2211.14730"},{"id":"paper-tsmixer:-an-all-mlp-architecture-for-time-series-forecasting","type":"paper","name":"TSMixer: An All-MLP Architecture for Time Series Forecasting","description":"Google's MLP-Mixer adaptation showing simple MLPs can match or beat transformers on forecasting.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2303.06053"},{"id":"paper-tsmixer:-lightweight-mlp-mixer-model-for-multivariate-time-series-forecasting","type":"paper","name":"TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting","description":"IBM's TSMixer variant with cross-variate mixing; strong M5 performance with fewer parameters.","category":"Forecasting > Transformers & MLPs for Forecasting","url":"https://arxiv.org/abs/2306.09364"},{"id":"paper-chronos:-learning-the-language-of-time-series","type":"paper","name":"Chronos: Learning the Language of Time Series","description":"Amazon's tokenized time series foundation model; zero-shot forecasting matching fine-tuned models.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2403.07815"},{"id":"paper-timegpt-1","type":"paper","name":"TimeGPT-1","description":"First commercial time series foundation model; API-based zero-shot forecasting for practitioners.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2310.03589"},{"id":"paper-lag-llama:-towards-foundation-models-for-probabilistic-time-series-forecasting","type":"paper","name":"Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting","description":"Open-source decoder-only foundation model for probabilistic forecasting; strong zero-shot transfer.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2310.08278"},{"id":"paper-moment:-a-family-of-open-time-series-foundation-models","type":"paper","name":"MOMENT: A Family of Open Time-series Foundation Models","description":"CMU's open foundation model supporting forecasting, classification, anomaly detection, and imputation.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2402.03885"},{"id":"paper-a-decoder-only-foundation-model-for-time-series-forecasting-(timesfm)","type":"paper","name":"A Decoder-Only Foundation Model for Time-Series Forecasting (TimesFM)","description":"Google's 200M parameter foundation model trained on 100B time points; strong zero-shot performance.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2310.10688"},{"id":"paper-unified-training-of-universal-time-series-forecasting-transformers-(moirai)","type":"paper","name":"Unified Training of Universal Time Series Forecasting Transformers (Moirai)","description":"Salesforce's multi-patch model handling variable frequencies and prediction lengths in single model.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2402.02592"},{"id":"paper-time-llm:-time-series-forecasting-by-reprogramming-large-language-models","type":"paper","name":"Time-LLM: Time Series Forecasting by Reprogramming Large Language Models","description":"Repurposing frozen LLMs for forecasting via prompt reprogramming; no time series pre-training needed.","category":"Forecasting > Foundation Models for Time Series","url":"https://arxiv.org/abs/2310.01728"},{"id":"paper-forecasting-and-stock-control-for-intermittent-demands","type":"paper","name":"Forecasting and Stock Control for Intermittent Demands","description":"Foundational method separating demand size from demand occurrence; basis for spare parts forecasting.","category":"Forecasting > Intermittent Demand Forecasting","url":"https://www.jstor.org/stable/3007885"},{"id":"paper-the-accuracy-of-intermittent-demand-estimates","type":"paper","name":"The Accuracy of Intermittent Demand Estimates","description":"SBA method correcting Croston's bias; widely adopted in supply chain software.","category":"Forecasting > Intermittent Demand Forecasting","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207003001152"},{"id":"paper-intermittent-demand-forecasting-with-context-aware-learning","type":"paper","name":"Intermittent Demand Forecasting with Context-Aware Learning","description":"TSB method explicitly modeling demand probability; improved coverage for slow-moving items.","category":"Forecasting > Intermittent Demand Forecasting","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207010000543"},{"id":"paper-gluonts:-probabilistic-and-neural-time-series-modeling-in-python","type":"paper","name":"GluonTS: Probabilistic and Neural Time Series Modeling in Python","description":"Amazon's open-source toolkit; includes intermittent demand models and extensive benchmarking.","category":"Forecasting > Intermittent Demand Forecasting","url":"https://arxiv.org/abs/1906.05264"},{"id":"paper-bayesian-online-changepoint-detection","type":"paper","name":"Bayesian Online Changepoint Detection","description":"Elegant Bayesian framework for online change point detection; foundational for streaming applications.","category":"Forecasting > Time Series Anomaly Detection","url":"https://arxiv.org/abs/0710.3742"},{"id":"paper-time-series-anomaly-detection-service-at-microsoft","type":"paper","name":"Time-Series Anomaly Detection Service at Microsoft","description":"Microsoft's production system using spectral residual and CNN; handles millions of time series.","category":"Forecasting > Time Series Anomaly Detection","url":"https://arxiv.org/abs/1906.03821"},{"id":"paper-robust-random-cut-forest-based-anomaly-detection-on-streams","type":"paper","name":"Robust Random Cut Forest Based Anomaly Detection on Streams","description":"Amazon's streaming anomaly detection algorithm; efficient updates and interpretable anomaly scores.","category":"Forecasting > Time Series Anomaly Detection","url":"http://proceedings.mlr.press/v48/guha16.html"},{"id":"paper-omnianomaly:-robust-anomaly-detection-for-multivariate-time-series-through-stochastic-recurren","type":"paper","name":"OmniAnomaly: Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network","description":"VAE-based approach for multivariate anomaly detection; captures temporal dependencies and normal patterns.","category":"Forecasting > Time Series Anomaly Detection","url":"https://dl.acm.org/doi/10.1145/3292500.3330672"},{"id":"paper-inferring-causal-impact-using-bayesian-structural-time-series-models-1","type":"paper","name":"Inferring Causal Impact Using Bayesian Structural Time-Series Models","description":"Google's CausalImpact for estimating causal effects from observational time series; widely used for attribution.","category":"Forecasting > Causal Impact & Intervention","url":"https://arxiv.org/abs/1506.00356"},{"id":"paper-synthetic-control-methods-for-comparative-case-studies-1","type":"paper","name":"Synthetic Control Methods for Comparative Case Studies","description":"Foundational synthetic control paper; 'most important innovation in evaluation literature in 15 years'.","category":"Forecasting > Causal Impact & Intervention","url":"https://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap08746"},{"id":"paper-using-synthetic-controls:-feasibility,-data-requirements,-and-methodological-aspects-2","type":"paper","name":"Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects","description":"Comprehensive methodological review covering feasibility, inference, and best practices.","category":"Forecasting > Causal Impact & Intervention","url":"https://www.aeaweb.org/content/file?id=12409"},{"id":"paper-predicting-the-present-with-bayesian-structural-time-series","type":"paper","name":"Predicting the Present with Bayesian Structural Time Series","description":"Google's BSTS framework for nowcasting with spike-and-slab regression for variable selection.","category":"Forecasting > Causal Impact & Intervention","url":"https://research.google/pubs/estimating-uncertainty-for-massive-data-streams/"},{"id":"paper-difference-in-differences-with-multiple-time-periods-1","type":"paper","name":"Difference-in-Differences with Multiple Time Periods","description":"Modern DiD handling staggered treatment timing and heterogeneous effects; doubly-robust estimator.","category":"Forecasting > Causal Impact & Intervention","url":"https://www.sciencedirect.com/science/article/abs/pii/S0304407620303948"},{"id":"paper-what's-trending-in-difference-in-differences?-a-synthesis-of-the-recent-econometrics-literatur-1","type":"paper","name":"What's Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature","description":"Comprehensive synthesis of modern DiD developments; essential guide to recent methodological advances.","category":"Forecasting > Causal Impact & Intervention","url":"https://www.sciencedirect.com/science/article/abs/pii/S0304407623001021"},{"id":"paper-orbit:-probabilistic-forecast-with-exponential-smoothing","type":"paper","name":"Orbit: Probabilistic Forecast with Exponential Smoothing","description":"Uber's Bayesian forecasting framework combining ETS with global models; production-ready with uncertainty.","category":"Forecasting > Production Forecasting Systems","url":"https://arxiv.org/abs/2004.08492"},{"id":"paper-forecasting-at-scale-(prophet)-1","type":"paper","name":"Forecasting at Scale (Prophet)","description":"Meta's production system enabling analysts to create reliable forecasts with domain knowledge.","category":"Forecasting > Production Forecasting Systems","url":"https://peerj.com/preprints/3190/"},{"id":"paper-demand-forecasting-at-alibaba:-practice-and-lessons-learned","type":"paper","name":"Demand Forecasting at Alibaba: Practice and Lessons Learned","description":"Large-scale demand forecasting system handling billions of SKUs; hierarchical and cross-learning approaches.","category":"Forecasting > Production Forecasting Systems","url":"https://dl.acm.org/doi/10.1145/3447548.3467193"},{"id":"paper-150-successful-machine-learning-models:-6-lessons-learned-at-booking.com","type":"paper","name":"150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com","description":"Practical lessons from production ML including forecasting; emphasizes offline-online gaps and iteration.","category":"Forecasting > Production Forecasting Systems","url":"https://dl.acm.org/doi/10.1145/3292500.3330744"},{"id":"paper-comparing-predictive-accuracy","type":"paper","name":"Comparing Predictive Accuracy","description":"The Diebold-Mariano test for forecast comparison; essential for model selection in production.","category":"Forecasting > Production Forecasting Systems","url":"https://www.jstor.org/stable/1392185"},{"id":"paper-rfm-analysis-for-customer-segmentation","type":"paper","name":"RFM Analysis for Customer Segmentation","description":"Recency-Frequency-Monetary framework still widely used in retail and e-commerce.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://www.amazon.com/Strategic-Database-Marketing-Arthur-Hughes/dp/0071351825"},{"id":"paper-customer-lifetime-value-segmentation","type":"paper","name":"Customer Lifetime Value Segmentation","description":"Probability models (BG/NBD) for CLV estimation enabling value-based segmentation.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://www.sciencedirect.com/science/article/abs/pii/S1094996809000024"},{"id":"paper-spotify's-discover-weekly:-machine-learning-meets-human-curation","type":"paper","name":"Spotify's Discover Weekly: Machine Learning Meets Human Curation","description":"Clustering taste profiles to power personalized playlists at scale.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://engineering.atspotify.com/2015/09/the-story-behind-discover-weekly/"},{"id":"paper-customer-lifetime-value:-modeling-and-recommendations","type":"paper","name":"Customer Lifetime Value: Modeling and Recommendations","description":"Framework for predicting individual-level CLV using past transaction data\u2014foundational for value-based marketing.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://www.jstor.org/stable/30162272"},{"id":"paper-counting-your-customers:-who-are-they-and-what-will-they-do-next?","type":"paper","name":"Counting Your Customers: Who Are They and What Will They Do Next?","description":"Pareto/NBD model for customer counting and transaction prediction\u2014still used at scale in industry.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://www.jstor.org/stable/2631608"},{"id":"paper-a-model-of-customer-lifetime-value","type":"paper","name":"A Model of Customer Lifetime Value","description":"Linking customer acquisition, retention, and expansion to CLV\u2014connects marketing spend to lifetime value.","category":"Clustering & Segmentation > Customer Segmentation","url":"https://www.jstor.org/stable/30040643"},{"id":"paper-algorithm-as-136:-a-k-means-clustering-algorithm","type":"paper","name":"Algorithm AS 136: A K-Means Clustering Algorithm","description":"Definitive k-means formulation with convergence guarantees\u2014still the default.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://www.jstor.org/stable/2346830"},{"id":"paper-hierarchical-grouping-to-optimize-an-objective-function","type":"paper","name":"Hierarchical Grouping to Optimize an Objective Function","description":"Ward's method for agglomerative clustering minimizing within-cluster variance.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://www.jstor.org/stable/2282967"},{"id":"paper-scalable-k-means++","type":"paper","name":"Scalable K-Means++","description":"Parallel k-means initialization achieving logarithmic rounds\u2014default in Spark MLlib.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://arxiv.org/abs/1203.6402"},{"id":"paper-a-density-based-algorithm-for-discovering-clusters-(dbscan)","type":"paper","name":"A Density-Based Algorithm for Discovering Clusters (DBSCAN)","description":"Density-based clustering finding arbitrarily shaped clusters and handling noise\u2014foundational for spatial clustering.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf"},{"id":"paper-birch:-an-efficient-data-clustering-method-for-very-large-databases","type":"paper","name":"BIRCH: An Efficient Data Clustering Method for Very Large Databases","description":"Hierarchical clustering using CF-trees for single-scan scalability\u2014enables clustering of millions of records.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://dl.acm.org/doi/10.1145/235968.233324"},{"id":"paper-optics:-ordering-points-to-identify-the-clustering-structure","type":"paper","name":"OPTICS: Ordering Points To Identify the Clustering Structure","description":"Density-based ordering producing cluster hierarchy without fixed epsilon\u2014extends DBSCAN for variable densities.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://dl.acm.org/doi/10.1145/304181.304187"},{"id":"paper-mean-shift:-a-robust-approach-toward-feature-space-analysis","type":"paper","name":"Mean Shift: A Robust Approach Toward Feature Space Analysis","description":"Non-parametric mode-seeking algorithm for clustering without specifying number of clusters.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://ieeexplore.ieee.org/document/1000236"},{"id":"paper-web-scale-k-means-clustering","type":"paper","name":"Web-Scale K-Means Clustering","description":"Mini-batch k-means enabling streaming updates\u2014Google's approach for web-scale clustering.","category":"Clustering & Segmentation > Classical Clustering Algorithms","url":"https://dl.acm.org/doi/10.1145/1772690.1772862"},{"id":"paper-finite-mixture-models","type":"paper","name":"Finite Mixture Models","description":"Comprehensive treatment of Gaussian and non-Gaussian mixture estimation.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://onlinelibrary.wiley.com/doi/book/10.1002/0471721182"},{"id":"paper-latent-class-analysis","type":"paper","name":"Latent Class Analysis","description":"Foundational discrete mixture model for categorical response patterns.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://www.amazon.com/Latent-Structure-Analysis-Paul-Lazarsfeld/dp/0395042488"},{"id":"paper-variational-inference-for-dirichlet-process-mixtures","type":"paper","name":"Variational Inference for Dirichlet Process Mixtures","description":"Scalable non-parametric Bayesian clustering without specifying K.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-1/Variational-inference-for-Dirichlet-process-mixtures/10.1214/06-BA104.full"},{"id":"paper-latent-dirichlet-allocation","type":"paper","name":"Latent Dirichlet Allocation","description":"Generative probabilistic model for topic modeling\u2014foundational for discovering latent topics in text collections.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://www.jmlr.org/papers/v3/blei03a.html"},{"id":"paper-hierarchical-dirichlet-processes","type":"paper","name":"Hierarchical Dirichlet Processes","description":"Non-parametric Bayesian approach for sharing clusters across grouped data\u2014automatic topic number selection.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://www.tandfonline.com/doi/abs/10.1198/016214506000000302"},{"id":"paper-model-based-clustering,-discriminant-analysis,-and-density-estimation","type":"paper","name":"Model-Based Clustering, Discriminant Analysis, and Density Estimation","description":"Gaussian mixture model framework with automatic model selection via BIC\u2014implemented in R's mclust package.","category":"Clustering & Segmentation > Model-Based Clustering","url":"https://www.tandfonline.com/doi/abs/10.1198/016214502760047131"},{"id":"paper-deep-embedded-clustering-(dec)","type":"paper","name":"Deep Embedded Clustering (DEC)","description":"Joint representation learning and clustering via autoencoders.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/1511.06335"},{"id":"paper-spectral-clustering-and-the-high-dimensional-stochastic-blockmodel","type":"paper","name":"Spectral Clustering and the High-Dimensional Stochastic Blockmodel","description":"Theoretical foundation for spectral methods in network/embedding clustering.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/1007.1684"},{"id":"paper-contrastive-clustering","type":"paper","name":"Contrastive Clustering","description":"Self-supervised contrastive objectives for cluster-friendly representations.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/2009.09687"},{"id":"paper-on-spectral-clustering:-analysis-and-an-algorithm","type":"paper","name":"On Spectral Clustering: Analysis and an Algorithm","description":"Foundational spectral clustering using Laplacian eigenvectors\u2014NeurIPS best paper, widely implemented.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://proceedings.neurips.cc/paper/2001/file/801272ee79cfde7fa5960571fee36b9b-Paper.pdf"},{"id":"paper-unsupervised-learning-of-visual-features-by-contrasting-cluster-assignments-(swav)","type":"paper","name":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments (SwAV)","description":"Self-supervised visual learning via online clustering\u2014state-of-the-art for unsupervised image representations.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/2006.09882"},{"id":"paper-scan:-learning-to-classify-images-without-labels","type":"paper","name":"SCAN: Learning to Classify Images without Labels","description":"Two-step unsupervised classification via representation learning then clustering\u2014strong ImageNet results.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/2005.12320"},{"id":"paper-variational-deep-embedding-(vade)","type":"paper","name":"Variational Deep Embedding (VaDE)","description":"VAE-based clustering combining variational autoencoders with GMM priors for end-to-end learning.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/1611.05148"},{"id":"paper-deep-clustering-for-unsupervised-learning-of-visual-features-(deepcluster)","type":"paper","name":"Deep Clustering for Unsupervised Learning of Visual Features (DeepCluster)","description":"Iterative clustering and CNN training for unsupervised feature learning\u2014Facebook AI's breakthrough.","category":"Clustering & Segmentation > Embedding-Based Clustering","url":"https://arxiv.org/abs/1807.05520"},{"id":"paper-heterogeneous-treatment-effects-and-optimal-targeting","type":"paper","name":"Heterogeneous Treatment Effects and Optimal Targeting","description":"Causal forests for estimating HTEs and deriving optimal targeting policies.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://arxiv.org/abs/1902.07409"},{"id":"paper-uplift-modeling-for-clinical-trial-data","type":"paper","name":"Uplift Modeling for Clinical Trial Data","description":"Foundational uplift/treatment-effect modeling enabling segment-specific interventions.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://link.springer.com/chapter/10.1007/978-3-642-31537-4_13"},{"id":"paper-personalization-at-spotify-using-cassandra","type":"paper","name":"Personalization at Spotify Using Cassandra","description":"Large-scale user segmentation powering real-time recommendations.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://engineering.atspotify.com/2015/01/personalization-at-spotify-using-cassandra/"},{"id":"paper-netflix-artwork-personalization","type":"paper","name":"Netflix Artwork Personalization","description":"Segment-based image selection improving engagement through visual personalization.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://netflixtechblog.com/artwork-personalization-c589f074ad76"},{"id":"paper-a-contextual-bandit-approach-to-personalized-news-article-recommendation-(linucb)","type":"paper","name":"A Contextual-Bandit Approach to Personalized News Article Recommendation (LinUCB)","description":"Linear UCB algorithm for personalization at Yahoo\u2014foundational contextual bandit for segment-based recommendations.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://arxiv.org/abs/1003.0146"},{"id":"paper-the-microsoft-decision-service","type":"paper","name":"The Microsoft Decision Service","description":"Production system for personalization via contextual bandits\u2014deployed across Microsoft products.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://arxiv.org/abs/1606.03966"},{"id":"paper-online-clustering-of-bandits","type":"paper","name":"Online Clustering of Bandits","description":"Dynamic user clustering for bandits\u2014learns segment structure while optimizing recommendations.","category":"Clustering & Segmentation > Segmentation for Targeting","url":"https://arxiv.org/abs/1401.8257"},{"id":"paper-million-song-dataset","type":"paper","name":"Million Song Dataset","description":"Benchmark dataset for music analysis enabling audio feature clustering research at scale.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://labrosa.ee.columbia.edu/millionsong/"},{"id":"paper-content-based-music-information-retrieval:-current-directions-and-future-challenges","type":"paper","name":"Content-Based Music Information Retrieval: Current Directions and Future Challenges","description":"Survey of audio feature extraction for music similarity and clustering\u2014foundational for MIR.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://ieeexplore.ieee.org/document/995066"},{"id":"paper-wavenet:-a-generative-model-for-raw-audio","type":"paper","name":"WaveNet: A Generative Model for Raw Audio","description":"Deep generative model for audio\u2014enables learned audio embeddings for clustering.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://arxiv.org/abs/1609.03499"},{"id":"paper-librosa:-audio-and-music-signal-analysis-in-python","type":"paper","name":"librosa: Audio and Music Signal Analysis in Python","description":"Standard Python library for audio feature extraction\u2014MFCCs, spectrograms for clustering.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://librosa.org/doc/latest/index.html"},{"id":"paper-automatic-tagging-using-deep-convolutional-neural-networks","type":"paper","name":"Automatic Tagging Using Deep Convolutional Neural Networks","description":"CNN for music auto-tagging enabling tag-based clustering and organization.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://arxiv.org/abs/1606.00298"},{"id":"paper-spotify's-audio-features-and-track-analysis","type":"paper","name":"Spotify's Audio Features and Track Analysis","description":"Audio analysis API powering playlist generation and music clustering at scale.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://developer.spotify.com/documentation/web-api/reference/get-audio-features"},{"id":"paper-music-genre-classification-with-the-million-song-dataset","type":"paper","name":"Music Genre Classification with the Million Song Dataset","description":"Benchmark for genre classification\u2014evaluates clustering approaches on real music data.","category":"Clustering & Segmentation > Music & Audio Clustering","url":"https://ismir2012.ismir.net/event/papers/505_ISMIR_2012.pdf"},{"id":"paper-deep-neural-networks-for-youtube-recommendations-2","type":"paper","name":"Deep Neural Networks for YouTube Recommendations","description":"Two-tower architecture for video clustering and candidate generation at YouTube scale.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://dl.acm.org/doi/10.1145/2959100.2959190"},{"id":"paper-the-netflix-recommender-system:-algorithms,-business-value,-and-innovation","type":"paper","name":"The Netflix Recommender System: Algorithms, Business Value, and Innovation","description":"Overview of Netflix's recommendation system including movie clustering and personalization.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://dl.acm.org/doi/10.1145/2843948"},{"id":"paper-youtube-8m:-a-large-scale-video-classification-benchmark","type":"paper","name":"YouTube-8M: A Large-Scale Video Classification Benchmark","description":"8 million videos with labels for video understanding\u2014benchmark for video clustering research.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://arxiv.org/abs/1609.08675"},{"id":"paper-embarrassingly-shallow-autoencoders-for-sparse-data-(ease)","type":"paper","name":"Embarrassingly Shallow Autoencoders for Sparse Data (EASE)","description":"Simple but effective collaborative filtering for movie recommendations\u2014Netflix competition winner approach.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://arxiv.org/abs/1905.03375"},{"id":"paper-matrix-factorization-techniques-for-recommender-systems-2","type":"paper","name":"Matrix Factorization Techniques for Recommender Systems","description":"Netflix Prize winning approach using latent factors\u2014foundational for content clustering.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://ieeexplore.ieee.org/document/5197422"},{"id":"paper-variational-autoencoders-for-collaborative-filtering","type":"paper","name":"Variational Autoencoders for Collaborative Filtering","description":"VAE-based collaborative filtering\u2014Netflix research on implicit feedback clustering.","category":"Clustering & Segmentation > Video & Movie Clustering","url":"https://arxiv.org/abs/1802.05814"},{"id":"paper-player-modeling-in-video-games","type":"paper","name":"Player Modeling in Video Games","description":"Survey of player modeling techniques including behavior clustering and segmentation.","category":"Clustering & Segmentation > Game & UGC Clustering","url":"https://ieeexplore.ieee.org/document/6518186"},{"id":"paper-predicting-player-churn-in-video-games-using-survival-analysis-and-clustering","type":"paper","name":"Predicting Player Churn in Video Games Using Survival Analysis and Clustering","description":"Combining survival models with player clusters for churn prediction in games.","category":"Clustering & Segmentation > Game & UGC Clustering","url":"https://ieeexplore.ieee.org/document/7317943"},{"id":"paper-analyzing-user-behavior-in-mmorpgs","type":"paper","name":"Analyzing User Behavior in MMORPGs","description":"Foundational study of player motivations and behavioral clustering in online games.","category":"Clustering & Segmentation > Game & UGC Clustering","url":"https://dl.acm.org/doi/10.1145/1178477.1178541"},{"id":"paper-deep-learning-for-video-game-content-generation","type":"paper","name":"Deep Learning for Video Game Content Generation","description":"Survey of ML for game content\u2014includes UGC clustering and content organization.","category":"Clustering & Segmentation > Game & UGC Clustering","url":"https://arxiv.org/abs/2012.00724"},{"id":"paper-game-data-mining","type":"paper","name":"Game Data Mining","description":"Comprehensive guide to mining game data including player segmentation techniques.","category":"Clustering & Segmentation > Game & UGC Clustering","url":"https://link.springer.com/book/10.1007/978-3-319-77638-3"},{"id":"paper-a-dirichlet-multinomial-mixture-model-based-approach-for-short-text-clustering-(gsdmm)","type":"paper","name":"A Dirichlet Multinomial Mixture Model-based Approach for Short Text Clustering (GSDMM)","description":"Collapsed Gibbs sampling for short text clustering\u2014handles sparse, short documents like tweets.","category":"Clustering & Segmentation > Text & Document Clustering","url":"https://dl.acm.org/doi/10.1145/2623330.2623715"},{"id":"paper-sentence-bert:-sentence-embeddings-using-siamese-bert-networks","type":"paper","name":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks","description":"Efficient sentence embeddings for semantic similarity\u2014enables fast document clustering.","category":"Clustering & Segmentation > Text & Document Clustering","url":"https://arxiv.org/abs/1908.10084"},{"id":"paper-self-training-with-contrastive-clustering-for-short-text-clustering-(stc2)","type":"paper","name":"Self-Training with Contrastive Clustering for Short Text Clustering (STC2)","description":"State-of-the-art short text clustering combining contrastive learning with self-training.","category":"Clustering & Segmentation > Text & Document Clustering","url":"https://arxiv.org/abs/2107.06123"},{"id":"paper-a-survey-of-text-clustering-algorithms","type":"paper","name":"A Survey of Text Clustering Algorithms","description":"Comprehensive survey of document clustering methods from TF-IDF to neural approaches.","category":"Clustering & Segmentation > Text & Document Clustering","url":"https://link.springer.com/chapter/10.1007/978-1-4614-3223-4_4"},{"id":"paper-unifying-visual-embeddings-for-visual-search-at-pinterest","type":"paper","name":"Unifying Visual Embeddings for Visual Search at Pinterest","description":"Multi-task visual embeddings for image clustering and similarity search at Pinterest scale.","category":"Clustering & Segmentation > Visual Content Clustering","url":"https://arxiv.org/abs/1908.01707"},{"id":"paper-deep-residual-learning-for-image-recognition-(resnet)","type":"paper","name":"Deep Residual Learning for Image Recognition (ResNet)","description":"ResNet architecture enabling powerful visual features for image clustering.","category":"Clustering & Segmentation > Visual Content Clustering","url":"https://arxiv.org/abs/1512.03385"},{"id":"paper-learning-transferable-visual-models-from-natural-language-supervision-(clip)","type":"paper","name":"Learning Transferable Visual Models From Natural Language Supervision (CLIP)","description":"Vision-language model enabling zero-shot image clustering via text descriptions.","category":"Clustering & Segmentation > Visual Content Clustering","url":"https://arxiv.org/abs/2103.00020"},{"id":"paper-pinterest-visual-search:-the-evolution-and-beyond","type":"paper","name":"Pinterest Visual Search: The Evolution and Beyond","description":"Evolution of visual search and image clustering at Pinterest\u2014practical lessons at scale.","category":"Clustering & Segmentation > Visual Content Clustering","url":"https://medium.com/pinterest-engineering/the-evolution-of-pinterest-visual-search-3d3b7d0f8f39"},{"id":"paper-the-theory-and-practice-of-revenue-management","type":"paper","name":"The Theory and Practice of Revenue Management","description":"The definitive textbook on revenue management covering pricing, capacity control, and overbooking.","category":"Pricing > Dynamic Pricing & Revenue Management","url":"https://www.springer.com/gp/book/9781402077012"},{"id":"paper-dynamic-pricing-in-the-presence-of-inventory-considerations","type":"paper","name":"Dynamic Pricing in the Presence of Inventory Considerations","description":"Framework for dynamic pricing with finite inventory and strategic consumers.","category":"Pricing > Dynamic Pricing & Revenue Management","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1080.0918"},{"id":"paper-pricing-and-revenue-optimization","type":"paper","name":"Pricing and Revenue Optimization","description":"Comprehensive practitioner's guide to pricing strategy and optimization techniques.","category":"Pricing > Dynamic Pricing & Revenue Management","url":"https://www.sup.org/books/title/?id=24833"},{"id":"paper-optimal-dynamic-pricing-of-inventories-with-stochastic-demand-over-finite-horizons","type":"paper","name":"Optimal Dynamic Pricing of Inventories with Stochastic Demand over Finite Horizons","description":"The foundational paper for dynamic pricing theory\u2014establishes intensity control formulation, proves optimality of monotonically decreasing prices. 4,000+ citations.","category":"Pricing > Dynamic Pricing & Revenue Management","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.40.8.999"},{"id":"paper-a-multiproduct-dynamic-pricing-problem-and-its-applications-to-network-yield-management","type":"paper","name":"A Multiproduct Dynamic Pricing Problem and Its Applications to Network Yield Management","description":"Extends dynamic pricing to multiple products sharing capacity constraints\u2014the theoretical foundation for airline network revenue management and cloud computing.","category":"Pricing > Dynamic Pricing & Revenue Management","url":"https://pubsonline.informs.org/doi/10.1287/opre.45.1.24"},{"id":"paper-clearance-pricing-and-inventory-policies-for-retail-chains","type":"paper","name":"Clearance Pricing and Inventory Policies for Retail Chains","description":"Multi-location markdown optimization balancing store-level heterogeneity.","category":"Pricing > Markdown & Clearance","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.44.3.285"},{"id":"paper-dynamic-pricing-with-a-prior-on-market-response","type":"paper","name":"Dynamic Pricing with a Prior on Market Response","description":"Bayesian approach to learning demand while optimizing markdown paths.","category":"Pricing > Markdown & Clearance","url":"https://pubsonline.informs.org/doi/abs/10.1287/opre.1080.0647"},{"id":"paper-the-value-of-fast-fashion:-quick-response,-enhanced-design,-and-strategic-consumer-behavior","type":"paper","name":"The Value of Fast Fashion: Quick Response, Enhanced Design, and Strategic Consumer Behavior","description":"The definitive paper on fast fashion economics\u2014models how Zara-style systems mitigate strategic consumer behavior and reduce markdowns.","category":"Pricing > Markdown & Clearance","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.1100.1303"},{"id":"paper-coordinating-clearance-markdown-sales-of-seasonal-products-in-retail-chains","type":"paper","name":"Coordinating Clearance Markdown Sales of Seasonal Products in Retail Chains","description":"Foundational paper on multi-store clearance optimization using stochastic dynamic programming with real Falabella case study.","category":"Pricing > Markdown & Clearance","url":"https://pubsonline.informs.org/doi/10.1287/opre.46.5.609"},{"id":"paper-dynamic-pricing-and-learning:-historical-origins,-current-research,-and-new-directions","type":"paper","name":"Dynamic Pricing and Learning: Historical Origins, Current Research, and New Directions","description":"The definitive survey on explore-exploit pricing literature\u2014synthesizes OR/MS, economics, marketing, and CS covering regret bounds and bandit connections.","category":"Pricing > Markdown & Clearance","url":"https://www.sciencedirect.com/science/article/pii/S1876735415000021"},{"id":"paper-dynamic-pricing-and-matching-in-ride-hailing-platforms","type":"paper","name":"Dynamic Pricing and Matching in Ride-Hailing Platforms","description":"Joint optimization of pricing and matching in two-sided rideshare markets.","category":"Pricing > Surge & Real-time Pricing","url":"https://papers.nips.cc/paper/2019/hash/1b0f27d6c6eb67f90ade2f58521a1f0d-Abstract.html"},{"id":"paper-surge-pricing-solves-the-wild-goose-chase","type":"paper","name":"Surge Pricing Solves the Wild Goose Chase","description":"Empirical analysis of Uber's surge pricing showing welfare improvements from reduced search frictions.","category":"Pricing > Surge & Real-time Pricing","url":"https://dl.acm.org/doi/10.1145/3033274.3085098"},{"id":"paper-the-value-of-flexible-work:-evidence-from-uber-drivers","type":"paper","name":"The Value of Flexible Work: Evidence from Uber Drivers","description":"Estimates labor supply elasticity and value of flexibility using Uber driver data.","category":"Pricing > Surge & Real-time Pricing","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/702171"},{"id":"paper-economics-of-a-bottleneck","type":"paper","name":"Economics of a Bottleneck","description":"The workhorse model for dynamic congestion pricing theory\u2014operationalized Vickrey's bottleneck concept with endogenous departure decisions and time-varying tolls.","category":"Pricing > Surge & Real-time Pricing","url":"https://www.sciencedirect.com/science/article/pii/009411909090028L"},{"id":"paper-platform-competition-in-two-sided-markets","type":"paper","name":"Platform Competition in Two-Sided Markets","description":"The foundational paper on two-sided market pricing\u2014derives optimal price allocation explaining why platforms price asymmetrically across sides.","category":"Pricing > Surge & Real-time Pricing","url":"https://onlinelibrary.wiley.com/doi/10.1162/154247603322493212"},{"id":"paper-competition-in-two-sided-markets","type":"paper","name":"Competition in Two-Sided Markets","description":"Introduces the competitive bottlenecks framework where one side multi-homes\u2014explains monopoly power over access to single-homing customers.","category":"Pricing > Surge & Real-time Pricing","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1756-2171.2006.tb00037.x"},{"id":"paper-personalized-pricing-and-consumer-welfare","type":"paper","name":"Personalized Pricing and Consumer Welfare","description":"Analyzes welfare effects of machine learning-based personalized pricing.","category":"Pricing > Personalized Pricing","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/722220"},{"id":"paper-algorithmic-pricing-and-competition","type":"paper","name":"Algorithmic Pricing and Competition","description":"How algorithmic pricing affects competition and market outcomes.","category":"Pricing > Personalized Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20220701"},{"id":"paper-customer-poaching-and-brand-switching","type":"paper","name":"Customer Poaching and Brand Switching","description":"The seminal paper on behavior-based price discrimination\u2014foundational duopoly model showing how firms use purchase history to discriminate. 2,000+ citations.","category":"Pricing > Personalized Pricing","url":"https://onlinelibrary.wiley.com/doi/10.1111/1756-2171.00034"},{"id":"paper-the-economics-of-privacy","type":"paper","name":"The Economics of Privacy","description":"The definitive JEL survey on privacy and personal data economics\u2014covers consumer tracking, welfare implications, and regulatory frameworks.","category":"Pricing > Personalized Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/jel.54.2.442"},{"id":"paper-approximating-purchase-propensities-and-reservation-prices-from-broad-consumer-tracking","type":"paper","name":"Approximating Purchase Propensities and Reservation Prices from Broad Consumer Tracking","description":"Key paper demonstrating ML enables first-degree price discrimination\u2014shows big data increases potential profits by 14.55% vs 0.14% from demographics alone.","category":"Pricing > Personalized Pricing","url":"https://onlinelibrary.wiley.com/doi/10.1111/iere.12441"},{"id":"paper-automobile-prices-in-market-equilibrium-(blp)","type":"paper","name":"Automobile Prices in Market Equilibrium (BLP)","description":"The foundational random coefficients discrete choice model for demand estimation.","category":"Pricing > Demand Estimation & Elasticity","url":"https://www.jstor.org/stable/2171802"},{"id":"paper-empirical-models-of-consumer-behavior","type":"paper","name":"Empirical Models of Consumer Behavior","description":"Practical guide to implementing BLP-style demand models with market-level data.","category":"Pricing > Demand Estimation & Elasticity","url":"https://www.annualreviews.org/doi/abs/10.1146/annurev-economics-111809-125118"},{"id":"paper-pyblp:-blp-demand-estimation-in-python","type":"paper","name":"pyBLP: BLP Demand Estimation in Python","description":"Modern implementation and extensions of BLP with diagnostics and best practices.","category":"Pricing > Demand Estimation & Elasticity","url":"https://pyblp.readthedocs.io/"},{"id":"paper-estimating-discrete-choice-models-of-product-differentiation","type":"paper","name":"Estimating Discrete-Choice Models of Product Differentiation","description":"The foundational paper introducing the critical inversion technique for demand estimation\u2014enables estimation with IVs despite endogenous prices.","category":"Pricing > Demand Estimation & Elasticity","url":"https://onlinelibrary.wiley.com/doi/10.2307/2555829"},{"id":"paper-differentiated-products-demand-systems-from-a-combination-of-micro-and-macro-data:-the-new-car","type":"paper","name":"Differentiated Products Demand Systems from a Combination of Micro and Macro Data: The New Car Market","description":"Pioneered combining micro-level consumer data with aggregate market shares\u2014foundation for modern 'micro moments' approaches in pyBLP.","category":"Pricing > Demand Estimation & Elasticity","url":"https://www.journals.uchicago.edu/doi/10.1086/379939"},{"id":"paper-dynamic-online-pricing-with-incomplete-information-using-multi-armed-bandit-experiments","type":"paper","name":"Dynamic Online Pricing with Incomplete Information Using Multi-Armed Bandit Experiments","description":"The workhorse paper for online price experimentation\u2014extends MAB algorithms to incorporate microeconomic choice theory. 43% profit improvements.","category":"Pricing > Demand Estimation & Elasticity","url":"https://pubsonline.informs.org/doi/10.1287/mksc.2018.1129"},{"id":"paper-dynamic-pricing-without-knowing-the-demand-function:-risk-bounds-and-near-optimal-algorithms","type":"paper","name":"Dynamic Pricing Without Knowing the Demand Function: Risk Bounds and Near-Optimal Algorithms","description":"Field-defining paper establishing theoretical framework for dynamic pricing with demand learning. Pioneered regret-based analysis with \u221aT regret bounds.","category":"Pricing > Price Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/opre.1090.0764"},{"id":"paper-simultaneously-learning-and-optimizing-using-controlled-variance-pricing","type":"paper","name":"Simultaneously Learning and Optimizing Using Controlled Variance Pricing","description":"Introduces elegant Controlled Variance Pricing (CVP) policy with 'taboo interval' for exploration. Achieves logarithmic regret while being highly implementable.","category":"Pricing > Price Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2013.1788"},{"id":"paper-online-network-revenue-management-using-thompson-sampling","type":"paper","name":"Online Network Revenue Management Using Thompson Sampling","description":"Bridges bandit algorithms and practical pricing by applying Thompson sampling to network revenue management with inventory constraints. Validated at Rue La La.","category":"Pricing > Price Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/opre.2018.1755"},{"id":"paper-dynamic-pricing-and-demand-learning-with-limited-price-experimentation","type":"paper","name":"Dynamic Pricing and Demand Learning with Limited Price Experimentation","description":"Models settings where sellers can make at most m price changes. Characterizes optimal regret as O(log^m T). Includes real implementation at Groupon.","category":"Pricing > Price Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/opre.2017.1629"},{"id":"paper-feature-based-dynamic-pricing","type":"paper","name":"Feature-Based Dynamic Pricing","description":"Pioneering work on contextual pricing where products have feature vectors. Uses ellipsoid method to achieve O(d\u00b2 log d) regret. Winner of 2024 Revenue Management Prize.","category":"Pricing > Price Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2019.3485"},{"id":"paper-a-disneyland-dilemma:-two-part-tariffs-for-a-mickey-mouse-monopoly","type":"paper","name":"A Disneyland Dilemma: Two-Part Tariffs for a Mickey Mouse Monopoly","description":"Foundational paper on two-part tariffs. Should Disneyland charge high admission with free rides, or free entry with high per-ride prices? 600+ citations.","category":"Pricing > Subscription & Nonlinear Pricing","url":"https://www.jstor.org/stable/1880564"},{"id":"paper-multiproduct-nonlinear-pricing","type":"paper","name":"Multiproduct Nonlinear Pricing","description":"Extends nonlinear pricing theory to multidimensional screening with multiple products. Foundational for product line design.","category":"Pricing > Subscription & Nonlinear Pricing","url":"https://www.jstor.org/stable/2171924"},{"id":"paper-nonlinear-pricing-with-random-participation","type":"paper","name":"Nonlinear Pricing with Random Participation","description":"Landmark paper showing that sufficiently intense competition eliminates quality distortions, yielding efficient 'cost-plus-fee' pricing.","category":"Pricing > Subscription & Nonlinear Pricing","url":"https://academic.oup.com/restud/article/69/1/277/1584052"},{"id":"paper-selling-to-overconfident-consumers","type":"paper","name":"Selling to Overconfident Consumers","description":"Field-defining paper on behavioral pricing and three-part tariffs. Shows consumer overconfidence explains cell phone plan structures. Uses real cellular billing data.","category":"Pricing > Subscription & Nonlinear Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/aer.99.5.1770"},{"id":"paper-freemium-as-optimal-menu-pricing","type":"paper","name":"Freemium as Optimal Menu Pricing","description":"Rigorous foundations for freemium models (Spotify, YouTube). Shows optimal menu consists of exactly two services\u2014ad-supported free and ad-free premium.","category":"Pricing > Subscription & Nonlinear Pricing","url":"https://www.sciencedirect.com/science/article/pii/S0167718718301395"},{"id":"paper-artificial-intelligence,-algorithmic-pricing,-and-collusion","type":"paper","name":"Artificial Intelligence, Algorithmic Pricing, and Collusion","description":"Field-defining paper showing Q-learning algorithms autonomously learn supracompetitive prices without communication, sustaining collusion through punishment strategies.","category":"Pricing > Algorithmic Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20190623"},{"id":"paper-autonomous-algorithmic-collusion:-q-learning-under-sequential-pricing","type":"paper","name":"Autonomous Algorithmic Collusion: Q-learning Under Sequential Pricing","description":"Extends Calvano et al. to sequential (Stackelberg) pricing environments, showing Q-learning converges to collusive equilibria even with turn-taking.","category":"Pricing > Algorithmic Pricing","url":"https://onlinelibrary.wiley.com/doi/10.1111/1756-2171.12383"},{"id":"paper-competition-in-pricing-algorithms","type":"paper","name":"Competition in Pricing Algorithms","description":"Shows pricing algorithms generate supracompetitive prices through competitive equilibrium\u2014no collusion required. Uses high-frequency empirical data from online retailers.","category":"Pricing > Algorithmic Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/mic.20210027"},{"id":"paper-the-economics-of-privacy-1","type":"paper","name":"The Economics of Privacy","description":"Definitive JEL survey on privacy economics\u2014essential for understanding personalized pricing and price discrimination enabled by algorithmic data collection.","category":"Pricing > Algorithmic Pricing","url":"https://www.aeaweb.org/articles?id=10.1257/jel.54.2.442"},{"id":"paper-sustainable-and-unchallenged-algorithmic-tacit-collusion","type":"paper","name":"Sustainable and Unchallenged Algorithmic Tacit Collusion","description":"Leading competition law analysis explaining the legal gap: tacit collusion is harmful but lawful under current antitrust frameworks.","category":"Pricing > Algorithmic Pricing","url":"https://scholarlycommons.law.northwestern.edu/njtip/vol17/iss2/1/"},{"id":"paper-a-tutorial-on-thompson-sampling-1","type":"paper","name":"A Tutorial on Thompson Sampling","description":"Definitive reference on Thompson sampling covering Bernoulli bandits, product recommendation, assortment optimization, and RL in MDPs.","category":"Pricing > RL for Pricing","url":"https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf"},{"id":"paper-thompson-sampling-for-contextual-bandits-with-linear-payoffs-1","type":"paper","name":"Thompson Sampling for Contextual Bandits with Linear Payoffs","description":"First theoretical regret guarantees for contextual Thompson Sampling. Proves \u00d5(d\u221aT) regret bounds. Novel martingale-based analysis became the template for subsequent work.","category":"Pricing > RL for Pricing","url":"https://proceedings.mlr.press/v28/agrawal13.html"},{"id":"paper-dynamic-pricing-under-a-general-parametric-choice-model","type":"paper","name":"Dynamic Pricing Under a General Parametric Choice Model","description":"Shows \u0398(\u221aT) regret for general parametric demand with MLE estimation. Important bridge between econometric demand estimation and online learning theory.","category":"Pricing > RL for Pricing","url":"https://pubsonline.informs.org/doi/10.1287/opre.1120.1057"},{"id":"paper-reinforcement-learning-applied-to-airline-revenue-management","type":"paper","name":"Reinforcement Learning Applied to Airline Revenue Management","description":"Landmark industry application from Amadeus. Demonstrates deep RL for airline pricing that learns directly from customer interactions without demand forecasting.","category":"Pricing > RL for Pricing","url":"https://link.springer.com/article/10.1057/s41272-020-00228-4"},{"id":"paper-customer-churn-prediction:-a-survey","type":"paper","name":"Customer Churn Prediction: A Survey","description":"Comprehensive survey of churn prediction methods and evaluation metrics.","category":"Subscriptions & Retention > Churn Prediction & Prevention","url":"https://www.sciencedirect.com/science/article/pii/S0957417412002357"},{"id":"paper-churn-prediction-in-mobile-social-games:-towards-a-complete-assessment-using-survival-ensemble","type":"paper","name":"Churn Prediction in Mobile Social Games: Towards a Complete Assessment Using Survival Ensembles","description":"Survival analysis approach to churn with right-censoring and dynamic hazards.","category":"Subscriptions & Retention > Churn Prediction & Prevention","url":"https://ieeexplore.ieee.org/document/7837911"},{"id":"paper-counting-your-customers:-who-are-they-and-what-will-they-do-next?-(bg-nbd)","type":"paper","name":"Counting Your Customers: Who Are They and What Will They Do Next? (BG/NBD)","description":"The BG/NBD model for customer lifetime value with transaction data.","category":"Subscriptions & Retention > Lifetime Value Estimation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1040.0098"},{"id":"paper-'counting-your-customers'-the-easy-way:-an-alternative-to-the-pareto-nbd-model","type":"paper","name":"'Counting Your Customers' the Easy Way: An Alternative to the Pareto/NBD Model","description":"Simplified BG/NBD model that maintains predictive accuracy with easier estimation.","category":"Subscriptions & Retention > Lifetime Value Estimation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1040.0098"},{"id":"paper-customer-base-valuation-in-a-contractual-setting:-the-perils-of-ignoring-heterogeneity","type":"paper","name":"Customer-Base Valuation in a Contractual Setting: The Perils of Ignoring Heterogeneity","description":"Shifted-Beta-Geometric model for subscription businesses with discrete renewal periods.","category":"Subscriptions & Retention > Lifetime Value Estimation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1090.0502"},{"id":"paper-freemium-as-a-marketing-strategy","type":"paper","name":"Freemium as a Marketing Strategy","description":"Structural model of freemium conversion analyzing optimal feature restriction.","category":"Subscriptions & Retention > Free-to-Paid Conversion","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1748824"},{"id":"paper-making-freemium-work","type":"paper","name":"Making Freemium Work","description":"Practitioner framework for freemium strategy and conversion optimization.","category":"Subscriptions & Retention > Free-to-Paid Conversion","url":"https://hbr.org/2014/05/making-freemium-work"},{"id":"paper-does-retaining-customers-pay-off?","type":"paper","name":"Does Retaining Customers Pay Off?","description":"Empirical analysis of the relationship between customer tenure and profitability.","category":"Subscriptions & Retention > Renewal & Cancellation Dynamics","url":"https://sloanreview.mit.edu/article/the-mismanagement-of-customer-loyalty/"},{"id":"paper-the-effects-of-customer-satisfaction-on-customer-spending","type":"paper","name":"The Effects of Customer Satisfaction on Customer Spending","description":"Links satisfaction metrics to retention and share of wallet outcomes.","category":"Subscriptions & Retention > Renewal & Cancellation Dynamics","url":"https://journals.sagepub.com/doi/abs/10.1177/1094670508315953"},{"id":"paper-a-behavior-model-for-persuasive-design","type":"paper","name":"A Behavior Model for Persuasive Design","description":"Foundational paper introducing the Fogg Behavior Model: Behavior = Motivation \u00d7 Ability \u00d7 Trigger. The academic framework underlying 'Hooked' and most digital habit formation research. Over 4,500 citations; essential conceptual foundation for product designers.","category":"Subscriptions & Retention > Engagement & Habit Formation","url":"https://dl.acm.org/doi/abs/10.1145/1541948.1541999"},{"id":"paper-does-gamification-work?-\u2014-a-literature-review-of-empirical-studies-on-gamification","type":"paper","name":"Does Gamification Work? \u2014 A Literature Review of Empirical Studies on Gamification","description":"Seminal literature review establishing empirical evidence framework for gamification effects. Finds gamification provides positive effects on engagement but is highly context-dependent. Over 4,000 citations; the definitive academic synthesis on gamification.","category":"Subscriptions & Retention > Engagement & Habit Formation","url":"https://ieeexplore.ieee.org/document/6758978"},{"id":"paper-measuring-the-impact-of-crowdsourcing-features-on-mobile-app-user-engagement-and-retention:-a-","type":"paper","name":"Measuring the Impact of Crowdsourcing Features on Mobile App User Engagement and Retention: A Randomized Field Experiment","description":"Rigorous RCT examining how user-generated content features affect app engagement. Finds content submission reduces session-ending hazard by 11% and app abandonment by 14%. Methodological gold standard for engagement research.","category":"Subscriptions & Retention > Engagement & Habit Formation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.3960"},{"id":"paper-digital-interventions-and-habit-formation-in-educational-technology","type":"paper","name":"Digital Interventions and Habit Formation in Educational Technology","description":"Large-scale randomized experiment (10,000 learners) showing contest-based interventions increase engagement by 45% and create persistent habit formation effects (75% higher engagement 12 weeks post-intervention). Cutting-edge field experimental evidence from leading economists.","category":"Subscriptions & Retention > Engagement & Habit Formation","url":"https://arxiv.org/abs/2310.10850"},{"id":"paper-empirical-support-for-a-causal-relationship-between-gamification-and-learning-outcomes","type":"paper","name":"Empirical Support for a Causal Relationship Between Gamification and Learning Outcomes","description":"Provides causal evidence linking gamification to outcomes mediated by behavioral changes. Validates Landers' theory of gamified learning with empirical evidence\u2014important for understanding mechanism design.","category":"Subscriptions & Retention > Engagement & Habit Formation","url":"https://dl.acm.org/doi/abs/10.1145/3173574.3173885"},{"id":"paper-customer-attrition-analysis-for-financial-services-using-proportional-hazard-models","type":"paper","name":"Customer Attrition Analysis for Financial Services Using Proportional Hazard Models","description":"Comprehensive Cox proportional hazards application to customer churn with time-varying covariates. Demonstrates how demographic, environmental, and behavioral variables predict retention. Over 600 citations; foundational for survival analysis in marketing.","category":"Subscriptions & Retention > Survival Analysis for Subscriptions","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221703001068"},{"id":"paper-how-to-project-customer-retention","type":"paper","name":"How to Project Customer Retention","description":"Develops the shifted-beta-geometric (sBG) probability model for contractual settings. Accounts for customer heterogeneity in retention rates and provides forecasts for tenure, lifetime value, and customer base valuation. Essential methodology for subscription businesses.","category":"Subscriptions & Retention > Survival Analysis for Subscriptions","url":"https://www.sciencedirect.com/science/article/abs/pii/S1094996806700329"},{"id":"paper-a-competing-risks-model-based-on-latent-dirichlet-allocation-for-predicting-churn-reasons","type":"paper","name":"A Competing Risks Model Based on Latent Dirichlet Allocation for Predicting Churn Reasons","description":"Novel competing risks survival model predicting both churn propensity and churn reason. Incorporates text analytics (LDA) from customer service transcripts to distinguish service-provider-driven versus competitor-driven churn. Modern integration of NLP with survival analysis.","category":"Subscriptions & Retention > Survival Analysis for Subscriptions","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167923621000543"},{"id":"paper-random-survival-forests-with-competing-risks-framework","type":"paper","name":"Random Survival Forests with Competing Risks Framework","description":"Combines machine learning (random forests) with competing risks methodology. Computes distinct risk profiles for different churn causes and identifies relationships between risks and customer behavior for targeted interventions.","category":"Subscriptions & Retention > Survival Analysis for Subscriptions","url":"https://www.tandfonline.com/doi/abs/10.1080/01605682.2020.1843982"},{"id":"paper-manage-marketing-by-the-customer-equity-test","type":"paper","name":"Manage Marketing by the Customer Equity Test","description":"Introduces the customer equity concept and decision calculus for balancing acquisition versus retention spending. Origins of viewing customers as assets. Over 1,000 citations; bridges practitioner and academic perspectives.","category":"Subscriptions & Retention > Customer Base Analysis & Cohort Methods","url":"https://hbr.org/1996/07/manage-marketing-by-the-customer-equity-test"},{"id":"paper-return-on-marketing:-using-customer-equity-to-focus-marketing-strategy","type":"paper","name":"Return on Marketing: Using Customer Equity to Focus Marketing Strategy","description":"Unified strategic framework enabling marketing options to be traded off based on projected financial return, operationalized as change in customer equity. Key contribution linking marketing decisions to shareholder value through customer equity.","category":"Subscriptions & Retention > Customer Base Analysis & Cohort Methods","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkg.68.1.109.24030"},{"id":"paper-valuing-customers","type":"paper","name":"Valuing Customers","description":"Demonstrates how CLV can value firms including high-growth firms with negative earnings. Shows 1% improvement in retention improves firm value by 3-7%, while margin improvement yields only ~1% increase. Validated on Amazon, eBay, Capital One, E*Trade data.","category":"Subscriptions & Retention > Customer Base Analysis & Cohort Methods","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkr.41.1.7.25084"},{"id":"paper-social-effects-on-customer-retention","type":"paper","name":"Social Effects on Customer Retention","description":"Landmark study using data from 1 million cellular customers showing exposure to a defecting neighbor increases churn hazard by 80%. Establishes that social contagion affects retention similarly to adoption. Foundational paper for network effects on churn.","category":"Subscriptions & Retention > Network Effects on Retention","url":"https://journals.sagepub.com/doi/abs/10.1509/jm.75.6.24"},{"id":"paper-social-interactions-in-customer-churn-decisions:-the-impact-of-relationship-directionality","type":"paper","name":"Social Interactions in Customer Churn Decisions: The Impact of Relationship Directionality","description":"Extends social effects research by analyzing directed networks. Finds that only contacts the customer initiates communication with influence churn decisions. Demonstrates importance of relationship directionality and recency of neighbor churn.","category":"Subscriptions & Retention > Network Effects on Retention","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167811613000487"},{"id":"paper-exploring-peer-effects-associated-with-user-retention-in-a-socially-connected-business","type":"paper","name":"Exploring Peer Effects Associated with User Retention in a Socially Connected Business","description":"Uses gym membership data to study bidirectional peer effects in usage and churn. When high-centrality users churn, cascade effects increase average un-subscription by 7.2% within 6 months. Provides targeting guidance: short-term strategies should target low-centrality users; long-term should target high-centrality.","category":"Subscriptions & Retention > Network Effects on Retention","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2023.1459"},{"id":"paper-in-pursuit-of-enhanced-customer-retention-management:-review,-key-issues,-and-future-direction","type":"paper","name":"In Pursuit of Enhanced Customer Retention Management: Review, Key Issues, and Future Directions","description":"Comprehensive review from 12 leading CRM scholars covering social connectivity's role in retention. Synthesizes literature on network externalities in multiplayer gaming, communications, and shared services. Identifies research frontier for network-oriented retention.","category":"Subscriptions & Retention > Network Effects on Retention","url":"https://link.springer.com/article/10.1007/s40547-017-0080-0"},{"id":"paper-internet-advertising-and-the-generalized-second-price-auction","type":"paper","name":"Internet Advertising and the Generalized Second-Price Auction","description":"Analysis of the GSP auction used by Google and the gap from VCG efficiency.","category":"Advertising > Ad Auctions (GSP, VCG)","url":"https://www.aeaweb.org/articles?id=10.1257/aer.97.1.242"},{"id":"paper-position-auctions","type":"paper","name":"Position Auctions","description":"Equilibrium analysis of position auctions with symmetric Nash equilibrium characterization.","category":"Advertising > Ad Auctions (GSP, VCG)","url":"https://www.sciencedirect.com/science/article/pii/S016726810600158X"},{"id":"paper-auctions-and-bidding:-a-guide-for-computer-scientists","type":"paper","name":"Auctions and Bidding: A Guide for Computer Scientists","description":"Comprehensive survey of auction theory and mechanism design for practitioners.","category":"Advertising > Ad Auctions (GSP, VCG)","url":"https://dl.acm.org/doi/10.1145/1922649.1922653"},{"id":"paper-counterspeculation,-auctions,-and-competitive-sealed-tenders","type":"paper","name":"Counterspeculation, Auctions, and Competitive Sealed Tenders","description":"Nobel Prize-winning paper establishing truthful bidding in second-price sealed-bid auctions\u2014the theoretical bedrock for all VCG mechanisms and modern ad auctions. ~8,000 citations.","category":"Advertising > Ad Auctions (GSP, VCG)","url":"https://www.jstor.org/stable/2977633"},{"id":"paper-optimal-auction-design","type":"paper","name":"Optimal Auction Design","description":"Derives revenue-maximizing auctions and optimal reserve prices via 'virtual value' concept. Essential for understanding how platforms set reserve prices. ~6,400 citations.","category":"Advertising > Ad Auctions (GSP, VCG)","url":"https://pubsonline.informs.org/doi/abs/10.1287/moor.6.1.58"},{"id":"paper-budget-management-strategies-in-repeated-auctions","type":"paper","name":"Budget Management Strategies in Repeated Auctions","description":"Optimal budget pacing strategies for advertisers in repeated auctions.","category":"Advertising > Autobidding & Budget Pacing","url":"https://dl.acm.org/doi/10.1145/2764468.2764484"},{"id":"paper-autobidding-with-constraints","type":"paper","name":"Autobidding with Constraints","description":"Value-maximizing autobidding under budget and ROI constraints.","category":"Advertising > Autobidding & Budget Pacing","url":"https://arxiv.org/abs/1912.10336"},{"id":"paper-from-first-price-auctions-to-incentive-compatible-auctions","type":"paper","name":"From First-Price Auctions to Incentive-Compatible Auctions","description":"Mechanism design for autobidders and the transition to first-price auctions.","category":"Advertising > Autobidding & Budget Pacing","url":"https://arxiv.org/abs/2103.07012"},{"id":"paper-learning-in-repeated-auctions-with-budgets:-regret-minimization-and-equilibrium-1","type":"paper","name":"Learning in Repeated Auctions with Budgets: Regret Minimization and Equilibrium","description":"Introduces adaptive pacing strategies with asymptotic optimality proofs; shows these form approximate Nash equilibrium. The reference paper for budget pacing algorithms at Google/Meta.","category":"Advertising > Autobidding & Budget Pacing","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2018.3093"},{"id":"paper-multiplicative-pacing-equilibria-in-auction-markets","type":"paper","name":"Multiplicative Pacing Equilibria in Auction Markets","description":"Formalizes pacing equilibrium as game-theoretic solution concept for autobidding; proves existence when platforms use multiplicative bid scaling.","category":"Advertising > Autobidding & Budget Pacing","url":"https://pubsonline.informs.org/doi/abs/10.1287/opre.2021.2165"},{"id":"paper-pacing-equilibrium-in-first-price-auction-markets","type":"paper","name":"Pacing Equilibrium in First Price Auction Markets","description":"Theoretical justification for industry's transition to first-price auctions (Google 2019); proves unique equilibrium and efficient computation via Eisenberg-Gale program.","category":"Advertising > Autobidding & Budget Pacing","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2022.4387"},{"id":"paper-measuring-ad-effectiveness-using-geo-experiments","type":"paper","name":"Measuring Ad Effectiveness Using Geo Experiments","description":"Google's framework for measuring incremental ad impact using geographic experiments.","category":"Advertising > Attribution & Incrementality","url":"https://research.google/pubs/pub38355/"},{"id":"paper-ghost-ads:-improving-the-economics-of-measuring-online-ad-effectiveness","type":"paper","name":"Ghost Ads: Improving the Economics of Measuring Online Ad Effectiveness","description":"Novel methodology for measuring ad lift without holdout using predicted ad exposure.","category":"Advertising > Attribution & Incrementality","url":"https://www.aeaweb.org/articles?id=10.1257/jep.31.2.163"},{"id":"paper-challenges-and-opportunities-in-media-mix-modeling","type":"paper","name":"Challenges and Opportunities in Media Mix Modeling","description":"Google's approach to marketing mix modeling with Bayesian methods.","category":"Advertising > Attribution & Incrementality","url":"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45998.pdf"},{"id":"paper-consumer-heterogeneity-and-paid-search-effectiveness:-a-large-scale-field-experiment","type":"paper","name":"Consumer Heterogeneity and Paid Search Effectiveness: A Large-Scale Field Experiment","description":"Landmark eBay experiment showing paid search ROI vastly overestimated\u201499.5% of brand keyword traffic substitutes to organic. Demonstrates critical importance of experiments over observational methods. ~800 citations.","category":"Advertising > Attribution & Incrementality","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA12423"},{"id":"paper-the-unfavorable-economics-of-measuring-the-returns-to-advertising","type":"paper","name":"The Unfavorable Economics of Measuring the Returns to Advertising","description":"Analyzes 25 large RCTs ($2.8M spend) showing massive sample sizes needed for reliable ad measurement due to individual sales volatility (CV of 10). Explains why selection bias is 'crippling.' ~700 citations.","category":"Advertising > Attribution & Incrementality","url":"https://academic.oup.com/qje/article-abstract/130/4/1941/1916234"},{"id":"paper-a-comparison-of-approaches-to-advertising-measurement:-evidence-from-big-field-experiments-at-","type":"paper","name":"A Comparison of Approaches to Advertising Measurement: Evidence from Big Field Experiments at Facebook","description":"Compares RCTs to observational methods using 15 Facebook experiments (1.6B impressions). Demonstrates observational methods consistently fail even with rich behavioral data. ~500 citations.","category":"Advertising > Attribution & Incrementality","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2018.1135"},{"id":"paper-tv-advertising-effectiveness-and-profitability:-generalizable-results-from-288-brands","type":"paper","name":"TV Advertising Effectiveness and Profitability: Generalizable Results from 288 Brands","description":"Border-strategy identification across 288 brands finds TV ad elasticity of ~0.025\u2014much lower than prior estimates; 80%+ of brands show negative marginal ROI.","category":"Advertising > Attribution & Incrementality","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA17674"},{"id":"paper-a-large-scale-benchmark-for-uplift-modeling","type":"paper","name":"A Large Scale Benchmark for Uplift Modeling","description":"Criteo's uplift modeling benchmark and methods for targeting persuadables.","category":"Advertising > Targeting & Lookalikes","url":"https://dl.acm.org/doi/10.1145/3219819.3219822"},{"id":"paper-targeting-online-display-ads:-comparing-segment-based-and-individual-based-targeting","type":"paper","name":"Targeting Online Display Ads: Comparing Segment-Based and Individual-Based Targeting","description":"Compares effectiveness of behavioral vs. segment-based ad targeting.","category":"Advertising > Targeting & Lookalikes","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1120.0768"},{"id":"paper-an-experimental-investigation-of-the-effects-of-retargeted-advertising:-the-role-of-frequency-","type":"paper","name":"An Experimental Investigation of the Effects of Retargeted Advertising: The Role of Frequency and Timing","description":"Large-scale RCT showing retargeting increases website returns by 14.6%, with effectiveness decaying over time (33% of impact on day 1) and advertising complementarities across weeks.","category":"Advertising > Targeting & Lookalikes","url":"https://journals.sagepub.com/doi/abs/10.1177/0022243718813987"},{"id":"paper-targeting-and-privacy-in-mobile-advertising","type":"paper","name":"Targeting and Privacy in Mobile Advertising","description":"Unified framework combining ML-based targeting with auction models; shows efficient targeting improves CTR by 66.8% over current practice, with implications for privacy regulation.","category":"Advertising > Targeting & Lookalikes","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2020.1235"},{"id":"paper-personalization-in-email-marketing:-the-role-of-noninformative-advertising-content","type":"paper","name":"Personalization in Email Marketing: The Role of Noninformative Advertising Content","description":"Field experiments showing adding recipient names increases open rates by 20%, sales leads by 31%\u2014even though names are non-informative. Gary Lilien Prize Finalist.","category":"Advertising > Targeting & Lookalikes","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2017.1066"},{"id":"paper-the-long-and-the-short-of-it:-balancing-short-and-long-term-marketing-strategies","type":"paper","name":"The Long and the Short of It: Balancing Short and Long-Term Marketing Strategies","description":"IPA research on optimal balance between brand building and activation.","category":"Advertising > Brand vs. Performance","url":"https://www.ipa.co.uk/knowledge/publications/the-long-and-the-short-of-it/"},{"id":"paper-online-display-advertising:-targeting-and-obtrusiveness","type":"paper","name":"Online Display Advertising: Targeting and Obtrusiveness","description":"Trade-offs between ad targeting precision and user annoyance.","category":"Advertising > Brand vs. Performance","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1100.0583"},{"id":"paper-digital-advertising-and-consumer-price-search","type":"paper","name":"Digital Advertising and Consumer Price Search","description":"How digital advertising affects consumer search behavior and market outcomes.","category":"Advertising > Brand vs. Performance","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4239"},{"id":"paper-how-well-does-advertising-work?-generalizations-from-meta-analysis-of-brand-advertising-elasti","type":"paper","name":"How Well Does Advertising Work? Generalizations from Meta-Analysis of Brand Advertising Elasticities","description":"Definitive meta-analysis of 751 short-term and 402 long-term advertising elasticities from 56 studies (1960-2008). Average short-term elasticity: 0.12; long-term: 0.24. ~440 citations.","category":"Advertising > Brand vs. Performance","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkr.48.3.457"},{"id":"paper-how-tv-advertising-works:-a-meta-analysis-of-389-real-world-split-cable-tv-advertising-experim","type":"paper","name":"How TV Advertising Works: A Meta-Analysis of 389 Real World Split Cable TV Advertising Experiments","description":"Classic BehaviorScan meta-analysis showing only ~50% of TV ad weight tests had positive sales effects; established that copy/strategy changes matter more than budget increases. Foundational paper.","category":"Advertising > Brand vs. Performance","url":"https://journals.sagepub.com/doi/abs/10.1177/002224379503200202"},{"id":"paper-privacy-regulation-and-online-advertising","type":"paper","name":"Privacy Regulation and Online Advertising","description":"Foundational empirical paper showing EU privacy regulation (ePrivacy Directive) reduced display ad effectiveness by 65% in changing purchase intent. ~2,500 citations.","category":"Advertising > Privacy & Ad Effectiveness","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1100.1246"},{"id":"paper-the-effect-of-privacy-regulation-on-the-data-industry:-empirical-evidence-from-gdpr","type":"paper","name":"The Effect of Privacy Regulation on the Data Industry: Empirical Evidence from GDPR","description":"Shows GDPR's opt-in led to 12.5% drop in tracked consumers, but remaining consumers are more valuable\u2014demonstrating 'privacy externalities' where privacy-conscious consumers make opt-in consumers more predictable.","category":"Advertising > Privacy & Ad Effectiveness","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/1756-2171.12453"},{"id":"paper-privacy-and-market-concentration:-intended-and-unintended-consequences-of-the-gdpr","type":"paper","name":"Privacy and Market Concentration: Intended and Unintended Consequences of the GDPR","description":"Panel data on 27,000+ websites shows GDPR reduced vendor use by 15% but increased market concentration by 17%\u2014large platforms (Google, Facebook) gained share as small vendors dropped.","category":"Advertising > Privacy & Ad Effectiveness","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2023.4709"},{"id":"paper-the-economic-consequences-of-apple's-app-tracking-transparency","type":"paper","name":"The Economic Consequences of Apple's App Tracking Transparency","description":"Quantifies ATT's economic effects: 37% reduction in CTR for Meta's conversion-optimized ads; firms with higher Meta dependence experienced 37% revenue decline. Smaller e-commerce firms disproportionately harmed.","category":"Advertising > Privacy & Ad Effectiveness","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4627585"},{"id":"paper-economic-consequences-of-online-tracking-restrictions","type":"paper","name":"Economic Consequences of Online Tracking Restrictions","description":"Studies 128M ad impressions over 2.5 years; average cookie lifetime is 279 days with \u20ac2.52 value. One-year cookie restrictions would cost \u20ac904M annually in Europe. IJRM Best Article Award 2024.","category":"Advertising > Privacy & Ad Effectiveness","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167811623000691"},{"id":"paper-online-display-advertising-markets:-a-literature-review-and-future-directions","type":"paper","name":"Online Display Advertising Markets: A Literature Review and Future Directions","description":"Comprehensive literature review organizing display advertising research by ecosystem agents (advertisers, publishers, intermediaries). Essential reading for understanding the programmatic landscape. ~200 citations.","category":"Advertising > Real-Time Bidding & Programmatic","url":"https://pubsonline.informs.org/doi/abs/10.1287/isre.2019.0902"},{"id":"paper-repeated-auctions-with-budgets-in-ad-exchanges:-approximations-and-design","type":"paper","name":"Repeated Auctions with Budgets in Ad Exchanges: Approximations and Design","description":"Introduces Fluid Mean Field Equilibrium (FMFE) framework for budget-constrained advertisers; provides prescriptions for reserve prices and impression allocation. ~500 citations.","category":"Advertising > Real-Time Bidding & Programmatic","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2014.1965"},{"id":"paper-real-time-bidding-in-online-display-advertising","type":"paper","name":"Real-Time Bidding in Online Display Advertising","description":"Game-theoretic model showing symmetric advertisers use asymmetric strategies; publishers should maintain reservation contracts alongside RTB for revenue optimization.","category":"Advertising > Real-Time Bidding & Programmatic","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2017.1083"},{"id":"paper-first-price-auctions-in-online-display-advertising","type":"paper","name":"First-Price Auctions in Online Display Advertising","description":"Explains industry shift from second-price to first-price auctions as direct economic consequence of header bidding adoption, not trust issues. Analyzes waterfalling vs. header bidding mechanisms.","category":"Advertising > Real-Time Bidding & Programmatic","url":"https://journals.sagepub.com/doi/abs/10.1177/00222437211019677"},{"id":"paper-market-provision-of-broadcasting:-a-welfare-analysis","type":"paper","name":"Market Provision of Broadcasting: A Welfare Analysis","description":"Foundational two-sided market model for advertising-financed media; analyzes when equilibrium advertising levels are socially optimal. The theoretical foundation for attention economics. ~680 citations.","category":"Advertising > Attention & Viewability","url":"https://academic.oup.com/restud/article-abstract/72/4/947/1586451"},{"id":"paper-how-viewer-tuning,-presence,-and-attention-respond-to-ad-content-and-predict-brand-search-lift","type":"paper","name":"How Viewer Tuning, Presence, and Attention Respond to Ad Content and Predict Brand Search Lift","description":"First study distinguishing TV ad viewability from actual viewing using passive measurement; finds 30% of TV ads play to empty rooms. Demonstrates attention metrics predict brand search lift better than tuning data.","category":"Advertising > Attention & Viewability","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2022.1370"},{"id":"paper-television-advertising-and-online-word-of-mouth:-an-empirical-investigation-of-social-tv-activ","type":"paper","name":"Television Advertising and Online Word-of-Mouth: An Empirical Investigation of Social TV Activity","description":"Examines 'Social TV'\u2014joint consumption of TV and social media production. TV advertising impacts online WOM volume for both brands and programs. ~200 citations.","category":"Advertising > Attention & Viewability","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2016.1002"},{"id":"paper-sponsorship-disclosure-and-consumer-deception:-experimental-evidence-from-native-advertising","type":"paper","name":"Sponsorship Disclosure and Consumer Deception: Experimental Evidence from Native Advertising","description":"Field experiments on how native advertising disclosure affects consumer behavior; provides causal evidence on tension between ad effectiveness and consumer deception in native formats.","category":"Advertising > Attention & Viewability","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2018.1125"},{"id":"paper-the-dynamics-of-viral-marketing","type":"paper","name":"The Dynamics of Viral Marketing","description":"Empirical analysis of viral cascades on a retailer's recommendation network; foundational for understanding k-factor and referral mechanics.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://www.cs.cmu.edu/~jure/pubs/viral-tweb.pdf"},{"id":"paper-effects-of-word-of-mouth-versus-traditional-marketing","type":"paper","name":"Effects of Word-of-Mouth Versus Traditional Marketing","description":"VAR model showing WOM elasticity is 20-30x higher than traditional marketing channels.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://www.anderson.ucla.edu/documents/areas/fac/marketing/bucklin_effects.pdf"},{"id":"paper-a-multi-stage-model-of-word-of-mouth-influence","type":"paper","name":"A Multi-Stage Model of Word-of-Mouth Influence","description":"Decomposes viral influence across awareness, interest, and decision stages; practical framework for campaign design.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167811608000414"},{"id":"paper-referral-programs-and-customer-value","type":"paper","name":"Referral Programs and Customer Value","description":"Referred customers are 16% more valuable with higher margins and retention. Foundational empirical study on referral program economics. ~1,600 citations.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkg.75.1.46"},{"id":"paper-seeding-strategies-for-viral-marketing:-an-empirical-comparison","type":"paper","name":"Seeding Strategies for Viral Marketing: An Empirical Comparison","description":"Field experiments show hub/bridge seeding outperforms random targeting for viral campaigns. ~1,400 citations.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkg.75.6.55"},{"id":"paper-creating-social-contagion-through-viral-product-design:-a-randomized-trial-of-peer-influence-i","type":"paper","name":"Creating Social Contagion Through Viral Product Design: A Randomized Trial of Peer Influence in Networks","description":"Randomized trial on 1.4M Facebook users; passive-broadcast generates 246% more contagion than active-personalized messaging. ~1,800 citations.","category":"Marketing & Growth > Acquisition & Referrals","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1421"},{"id":"paper-network-externalities,-competition,-and-compatibility","type":"paper","name":"Network Externalities, Competition, and Compatibility","description":"Seminal formalization of direct/indirect network effects and compatibility choice; 6,800+ citations.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://idv.sinica.edu.tw/kongpin/teaching/io/KatzShapiro1.pdf"},{"id":"paper-a-theory-of-interdependent-demand-for-a-communications-service","type":"paper","name":"A Theory of Interdependent Demand for a Communications Service","description":"Original network effects paper introducing critical mass concept for telecommunications.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://www.jstor.org/stable/3003378"},{"id":"paper-systems-competition-and-network-effects","type":"paper","name":"Systems Competition and Network Effects","description":"Accessible synthesis on network effects, installed base dynamics, and platform competition.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://www.aeaweb.org/articles?id=10.1257/jep.8.2.93"},{"id":"paper-standardization,-compatibility,-and-innovation","type":"paper","name":"Standardization, Compatibility, and Innovation","description":"Introduces 'excess inertia' and coordination failure; explains why inferior standards persist.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://www.jstor.org/stable/2555617"},{"id":"paper-platform-competition-in-two-sided-markets-1","type":"paper","name":"Platform Competition in Two-Sided Markets","description":"THE foundational two-sided markets paper; pricing structure, chicken-and-egg dynamics. ~8,000 citations.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://academic.oup.com/jeea/article-abstract/1/4/990/2280902"},{"id":"paper-competition-in-two-sided-markets-1","type":"paper","name":"Competition in Two-Sided Markets","description":"Introduces competitive bottlenecks\u2014when one side multi-homes, platforms compete fiercely on single-homers. ~4,500 citations.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-2171.2006.tb00037.x"},{"id":"paper-chicken-and-egg:-competition-among-intermediation-service-providers","type":"paper","name":"Chicken and Egg: Competition Among Intermediation Service Providers","description":"Formalizes platform launch problem; divide-and-conquer strategies for entrants. ~1,800 citations.","category":"Marketing & Growth > Network Effects & Viral Growth","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/1756-2171.00022"},{"id":"paper-how-promotions-work","type":"paper","name":"How Promotions Work","description":"14 empirical generalizations about promotion effects (brand switching, stockpiling, category expansion); most-cited promotion paper.","category":"Marketing & Growth > Promotions & Discounts","url":"https://pubsonline.informs.org/doi/10.1287/mksc.14.3.G122"},{"id":"paper-the-different-faces-of-coupon-elasticity","type":"paper","name":"The Different Faces of Coupon Elasticity","description":"Econometric model for coupon effects showing self/cross-coupon elasticities; practical for optimization.","category":"Marketing & Growth > Promotions & Discounts","url":"https://www.sciencedirect.com/science/article/abs/pii/S0022435905000023"},{"id":"paper-how-price-promotions-work:-a-review","type":"paper","name":"How Price Promotions Work: A Review","description":"Comprehensive update to 1995 generalizations; bridges academic research with practitioner insights.","category":"Marketing & Growth > Promotions & Discounts","url":"https://www.sciencedirect.com/science/article/abs/pii/S2452261919300061"},{"id":"paper-the-long-term-impact-of-promotion-and-advertising-on-consumer-brand-choice","type":"paper","name":"The Long-Term Impact of Promotion and Advertising on Consumer Brand Choice","description":"8-year panel showing promotions increase price sensitivity while eroding brand equity. ~2,500 citations.","category":"Marketing & Growth > Promotions & Discounts","url":"https://journals.sagepub.com/doi/abs/10.1177/002224379703400205"},{"id":"paper-a-price-discrimination-theory-of-coupons","type":"paper","name":"A Price Discrimination Theory of Coupons","description":"Foundational theory: coupons as self-selection price discrimination devices. ~1,800 citations.","category":"Marketing & Growth > Promotions & Discounts","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.3.2.128"},{"id":"paper-bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects-1","type":"paper","name":"Bayesian Methods for Media Mix Modeling with Carryover and Shape Effects","description":"Foundational Google paper introducing Bayesian MMM with adstock/saturation curves; basis for LightweightMMM.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://research.google/pubs/bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects/"},{"id":"paper-geo-level-bayesian-hierarchical-media-mix-modeling","type":"paper","name":"Geo-Level Bayesian Hierarchical Media Mix Modeling","description":"Extends Bayesian MMM to geo-level data; provides tighter credible intervals and reduces targeting bias.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://research.google/pubs/pub46000/"},{"id":"paper-robyn:-continuous-&-semi-automated-mmm","type":"paper","name":"Robyn: Continuous & Semi-Automated MMM","description":"Technical documentation for Meta's open-source Robyn; covers ridge regression, evolutionary optimization, calibration.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://arxiv.org/abs/2403.14674"},{"id":"paper-media-mix-model-calibration-with-bayesian-priors","type":"paper","name":"Media Mix Model Calibration With Bayesian Priors","description":"Methods for calibrating MMM with experiment results; bridges MMM and incrementality testing.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://research.google/pubs/media-mix-model-calibration-with-bayesian-priors/"},{"id":"paper-the-persistence-of-marketing-effects-on-sales","type":"paper","name":"The Persistence of Marketing Effects on Sales","description":"Introduces persistence modeling via unit-roots and impulse response; distinguishes short-term from permanent effects. ~2,200 citations.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.14.1.1"},{"id":"paper-how-budget-allocation-relates-to-productivity-in-marketing-spending:-an-international-comparis","type":"paper","name":"How Budget Allocation Relates to Productivity in Marketing Spending: An International Comparison","description":"INFORMS Practice Prize winner; 1-4% profit improvement from optimized allocation vs. heuristics. ~650 citations.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1110.0665"},{"id":"paper-effect-of-sales-promotion-on-purchasing-behavior-on-promotional-and-non-promotional-days","type":"paper","name":"Effect of Sales Promotion on Purchasing Behavior on Promotional and Non-Promotional Days","description":"Promotions have virtually no permanent effects\u2014short-term ROI metrics mislead. ~1,200 citations.","category":"Marketing & Growth > Marketing Mix Modeling","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkr.39.4.421.19114"},{"id":"paper-differential-response-analysis","type":"paper","name":"Differential Response Analysis","description":"Original uplift paper introducing the 'Persuadables' segmentation framework (Persuadables, Sure Things, Lost Causes, Sleeping Dogs).","category":"Marketing & Growth > Uplift Modeling","url":"https://stochasticsolutions.com/papers.html"},{"id":"paper-using-control-groups-to-target-on-predicted-lift","type":"paper","name":"Using Control Groups to Target on Predicted Lift","description":"Introduces Qini curves for uplift model evaluation; practitioner-focused methodology comparison.","category":"Marketing & Growth > Uplift Modeling","url":"https://www.research.ed.ac.uk/en/publications/using-control-groups-to-target-on-predicted-lift-building-and-ass"},{"id":"paper-estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests-1","type":"paper","name":"Estimation and Inference of Heterogeneous Treatment Effects using Random Forests","description":"Causal forests for HTE estimation with valid confidence intervals; foundation for grf package; 2000+ citations.","category":"Marketing & Growth > Uplift Modeling","url":"https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839"},{"id":"paper-decision-trees-for-uplift-modeling","type":"paper","name":"Decision Trees for Uplift Modeling","description":"Adapts information theory for uplift decision trees; extends to multiple treatments; widely implemented.","category":"Marketing & Growth > Uplift Modeling","url":"https://link.springer.com/article/10.1007/s10115-011-0434-0"},{"id":"paper-metalearners-for-estimating-heterogeneous-treatment-effects-using-machine-learning-1","type":"paper","name":"Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning","description":"Introduces S-learner, T-learner, and X-learner; optimal for imbalanced treatment groups. ~1,100 citations.","category":"Marketing & Growth > Uplift Modeling","url":"https://www.pnas.org/doi/abs/10.1073/pnas.1804597116"},{"id":"paper-double-debiased-machine-learning-for-treatment-and-structural-parameters-1","type":"paper","name":"Double/Debiased Machine Learning for Treatment and Structural Parameters","description":"Foundation for causal ML\u2014Neyman-orthogonal scores + cross-fitting enable root-n consistent inference. ~4,000 citations.","category":"Marketing & Growth > Uplift Modeling","url":"https://academic.oup.com/ectj/article-abstract/21/1/C1/5056401"},{"id":"paper-towards-optimal-doubly-robust-estimation-of-heterogeneous-causal-effects-1","type":"paper","name":"Towards Optimal Doubly Robust Estimation of Heterogeneous Causal Effects","description":"DR-learner with minimax optimality bounds for heterogeneous effects. ~100+ citations.","category":"Marketing & Growth > Uplift Modeling","url":"https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-17/issue-2/Towards-optimal-doubly-robust-estimation-of-heterogeneous-causal-effects/10.1214/23-EJS2157.short"},{"id":"paper-attributing-conversions-in-a-multichannel-online-marketing-environment:-an-empirical-model-and","type":"paper","name":"Attributing Conversions in a Multichannel Online Marketing Environment: An Empirical Model and a Field Experiment","description":"Bayesian multi-touch attribution with carryover/spillover across funnel stages; AMA/MSI Paul Root Award. ~600 citations.","category":"Marketing & Growth > Customer Journey & Funnel Analytics","url":"https://journals.sagepub.com/doi/abs/10.1509/jmr.13.0050"},{"id":"paper-understanding-customer-experience-throughout-the-customer-journey","type":"paper","name":"Understanding Customer Experience Throughout the Customer Journey","description":"Seminal conceptual framework for touchpoints across pre-purchase, purchase, post-purchase. ~3,500 citations.","category":"Marketing & Growth > Customer Journey & Funnel Analytics","url":"https://journals.sagepub.com/doi/abs/10.1509/jm.15.0420"},{"id":"paper-challenges-and-opportunities-in-multichannel-customer-management","type":"paper","name":"Challenges and Opportunities in Multichannel Customer Management","description":"Foundational 5-challenge framework for omnichannel research. ~2,000 citations.","category":"Marketing & Growth > Customer Journey & Funnel Analytics","url":"https://journals.sagepub.com/doi/abs/10.1177/1094670506293559"},{"id":"paper-mapping-the-customer-journey:-lessons-learned-from-graph-based-online-attribution-modeling","type":"paper","name":"Mapping the Customer Journey: Lessons Learned from Graph-Based Online Attribution Modeling","description":"Markov chain attribution showing substantial divergence from last-click heuristics. ~350 citations.","category":"Marketing & Growth > Customer Journey & Funnel Analytics","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167811616300039"},{"id":"paper-trustworthy-online-controlled-experiments:-a-practical-guide-to-a-b-testing","type":"paper","name":"Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing","description":"Foundational best practices from thousands of experiments at Microsoft/Amazon; OEC design, validity threats. ~1,200 citations.","category":"Marketing & Growth > A/B Testing & Experimentation","url":"https://dl.acm.org/doi/abs/10.1145/2339530.2339653"},{"id":"paper-graph-cluster-randomization:-network-exposure-to-multiple-universes","type":"paper","name":"Graph Cluster Randomization: Network Exposure to Multiple Universes","description":"Handles network interference via cluster randomization; exponentially lower variance under spillovers. ~600 citations.","category":"Marketing & Growth > A/B Testing & Experimentation","url":"https://dl.acm.org/doi/abs/10.1145/2487575.2487695"},{"id":"paper-an-empirical-evaluation-of-thompson-sampling-2","type":"paper","name":"An Empirical Evaluation of Thompson Sampling","description":"Establishes Thompson Sampling as practical standard for explore-exploit in ad optimization. ~1,500 citations.","category":"Marketing & Growth > A/B Testing & Experimentation","url":"https://papers.nips.cc/paper_files/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html"},{"id":"paper-always-valid-inference:-continuous-monitoring-of-a-b-tests","type":"paper","name":"Always Valid Inference: Continuous Monitoring of A/B Tests","description":"Defines always-valid p-values maintaining validity regardless of peeking; solves continuous monitoring problem. ~400 citations.","category":"Marketing & Growth > A/B Testing & Experimentation","url":"https://pubsonline.informs.org/doi/abs/10.1287/opre.2021.2135"},{"id":"paper-inferring-causal-impact-using-bayesian-structural-time-series-models-2","type":"paper","name":"Inferring Causal Impact Using Bayesian Structural Time-Series Models","description":"CausalImpact methodology for geo-experiments when individual randomization impossible. ~1,400 citations.","category":"Marketing & Growth > A/B Testing & Experimentation","url":"https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-1/Inferring-causal-impact-using-Bayesian-structural-time-series-models/10.1214/14-AOAS788.full"},{"id":"paper-the-endowed-progress-effect:-how-artificial-advancement-increases-effort","type":"paper","name":"The Endowed Progress Effect: How Artificial Advancement Increases Effort","description":"Artificial progress (pre-stamped cards) significantly increases completion; foundational loyalty psychology. ~1,800 citations.","category":"Marketing & Growth > Loyalty Programs & CRM","url":"https://academic.oup.com/jcr/article-abstract/32/4/504/1796392"},{"id":"paper-the-mismanagement-of-customer-loyalty","type":"paper","name":"The Mismanagement of Customer Loyalty","description":"Framework identifying controllable CLV drivers; outperforms RFM models. ~2,400 citations.","category":"Marketing & Growth > Loyalty Programs & CRM","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkg.67.1.77.18595"},{"id":"paper-do-loyalty-programs-really-enhance-behavioral-loyalty?-an-empirical-analysis-accounting-for-se","type":"paper","name":"Do Loyalty Programs Really Enhance Behavioral Loyalty? An Empirical Analysis Accounting for Self-Selecting Members","description":"IV correction shows 86% of apparent LP effect disappears when controlling for self-selection. ~900 citations.","category":"Marketing & Growth > Loyalty Programs & CRM","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167811606000668"},{"id":"paper-long-term-impact-of-loyalty-programs-on-consumer-purchase-behavior-and-loyalty","type":"paper","name":"Long-Term Impact of Loyalty Programs on Consumer Purchase Behavior and Loyalty","description":"Heterogeneous effects: heavy buyers don't change; light buyers benefit most from programs. ~1,400 citations.","category":"Marketing & Growth > Loyalty Programs & CRM","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkg.71.4.019"},{"id":"paper-the-effect-of-word-of-mouth-on-sales:-online-book-reviews","type":"paper","name":"The Effect of Word of Mouth on Sales: Online Book Reviews","description":"Causal evidence reviews affect sales; 1-star reviews hurt more than 5-star help. ~4,500 citations.","category":"Marketing & Growth > Content & Social Media Marketing","url":"https://journals.sagepub.com/doi/abs/10.1509/jmkr.43.3.345"},{"id":"paper-what-makes-online-content-viral?","type":"paper","name":"What Makes Online Content Viral?","description":"High-arousal emotions (awe, anger) increase sharing; positive content more viral. ~3,500 citations.","category":"Marketing & Growth > Content & Social Media Marketing","url":"https://journals.sagepub.com/doi/abs/10.1509/jmr.10.0353"},{"id":"paper-using-online-conversations-to-study-word-of-mouth-communication","type":"paper","name":"Using Online Conversations to Study Word-of-Mouth Communication","description":"WOM dispersion (not volume) predicts growth; conversations across communities matter most. ~2,200 citations.","category":"Marketing & Growth > Content & Social Media Marketing","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.1040.0071"},{"id":"paper-influencer-marketing-effectiveness","type":"paper","name":"Influencer Marketing Effectiveness","description":"5,800+ campaigns: originality, follower size, sponsor salience enhance effectiveness; inverted-U for activity. ~300 citations.","category":"Marketing & Growth > Content & Social Media Marketing","url":"https://journals.sagepub.com/doi/abs/10.1177/00222429221102889"},{"id":"paper-platform-competition-in-two-sided-markets-2","type":"paper","name":"Platform Competition in Two-Sided Markets","description":"Foundational theory introducing price structure vs. price level distinction for platforms.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://academic.oup.com/jeea/article/1/4/990/2280902"},{"id":"paper-two-sided-markets:-a-progress-report","type":"paper","name":"Two-Sided Markets: A Progress Report","description":"Comprehensive survey defining two-sidedness by price structure; multi-homing analysis.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-2171.2006.tb00036.x"},{"id":"paper-competition-in-two-sided-markets-2","type":"paper","name":"Competition in Two-Sided Markets","description":"Three canonical models (monopoly, single-homing, competitive bottlenecks); workhorse for policy analysis.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1756-2171.2006.tb00037.x"},{"id":"paper-chicken-and-egg:-competition-among-intermediation-service-providers-1","type":"paper","name":"Chicken and Egg: Competition Among Intermediation Service Providers","description":"Addresses startup problem and price competition; divide-and-conquer strategies.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://www.jstor.org/stable/1593720"},{"id":"paper-a-price-theory-of-multi-sided-platforms","type":"paper","name":"A Price Theory of Multi-Sided Platforms","description":"The theoretical gold standard for platform pricing; introduces Spence distortion showing platforms internalize network effects only for marginal users. Essential for welfare analysis.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://www.aeaweb.org/articles?id=10.1257/aer.100.4.1642"},{"id":"paper-pricing-and-commitment-by-two-sided-platforms","type":"paper","name":"Pricing and Commitment by Two-Sided Platforms","description":"Studies sequential arrival of sides and commitment decisions; key for understanding multi-homing dynamics and platform timing strategies.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-2171.2006.tb00035.x"},{"id":"paper-platform-envelopment","type":"paper","name":"Platform Envelopment","description":"Explains how tech giants expand across adjacent platform markets through bundling; foundational for understanding winner-take-all dynamics.","category":"Matching & Marketplaces > Two-Sided Markets","url":"https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.935"},{"id":"paper-nobel-prize-scientific-background:-dmp-model","type":"paper","name":"Nobel Prize Scientific Background: DMP Model","description":"Comprehensive summary of canonical search-matching theory; matching function, wage bargaining, unemployment dynamics.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://www.nobelprize.org/uploads/2018/06/advanced-economicsciences2010.pdf"},{"id":"paper-equilibrium-unemployment-theory","type":"paper","name":"Equilibrium Unemployment Theory","description":"Definitive textbook treatment of DMP model; the practitioner's reference for labor market search.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://mitpress.mit.edu/9780262161879/equilibrium-unemployment-theory/"},{"id":"paper-looking-into-the-black-box:-a-survey-of-the-matching-function","type":"paper","name":"Looking into the Black Box: A Survey of the Matching Function","description":"Empirical estimation of aggregate matching functions; bridges theory and data.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://www.aeaweb.org/articles?id=10.1257/jel.39.2.390"},{"id":"paper-job-creation-and-job-destruction","type":"paper","name":"Job Creation and Job Destruction","description":"Introduces endogenous job destruction into search framework; stochastic equilibrium model.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://academic.oup.com/restud/article/61/3/397/1523034"},{"id":"paper-inefficient-hiring-in-entry-level-labor-markets","type":"paper","name":"Inefficient Hiring in Entry-Level Labor Markets","description":"Field experiment on Upwork (oDesk) demonstrating information frictions cause inefficient unemployment; first rigorous platform labor experiment.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://www.aeaweb.org/articles?id=10.1257/aer.104.11.3565"},{"id":"paper-landing-the-first-job:-the-value-of-intermediaries-in-online-hiring","type":"paper","name":"Landing the First Job: The Value of Intermediaries in Online Hiring","description":"Uses Upwork data to quantify how platform certification helps inexperienced workers overcome reputation gaps and find first jobs.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://academic.oup.com/restud/article/83/2/810/2461352"},{"id":"paper-monopsony-in-online-labor-markets","type":"paper","name":"Monopsony in Online Labor Markets","description":"Amazon Mechanical Turk experiments find substantial monopsony power (labor supply elasticity ~0.1) facing individual requesters.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://www.aeaweb.org/articles?id=10.1257/aeri.20180150"},{"id":"paper-who-benefits-from-online-gig-economy-platforms?","type":"paper","name":"Who Benefits from Online Gig Economy Platforms?","description":"Upwork analysis showing workers capture surplus because demand-side search frictions reduce direct competition between workers.","category":"Matching & Marketplaces > Search & Matching Frictions","url":"https://www.nber.org/papers/w29031"},{"id":"paper-college-admissions-and-the-stability-of-marriage","type":"paper","name":"College Admissions and the Stability of Marriage","description":"Introduces deferred acceptance algorithm and stability concept; foundation of market design.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://web.stanford.edu/~alroth/papers/GaleandShapley.revised.IJGT.pdf"},{"id":"paper-kidney-exchange","type":"paper","name":"Kidney Exchange","description":"Applies mechanism design to organ allocation; created real kidney exchange programs; saves thousands of lives.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://www.nber.org/papers/w10002"},{"id":"paper-the-redesign-of-the-matching-market-for-american-physicians","type":"paper","name":"The Redesign of the Matching Market for American Physicians","description":"Engineering economics: redesigning NRMP; demonstrates stability matters empirically.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://web.stanford.edu/~alroth/papers/rothperansonAER.PDF"},{"id":"paper-matching-and-pricing-in-ride-hailing:-wild-goose-chases","type":"paper","name":"Matching and Pricing in Ride Hailing: Wild Goose Chases","description":"Shows ride-hailing prone to matching failures; explains why surge pricing is necessary.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2022.00096"},{"id":"paper-clearing-matching-markets-efficiently:-informative-signals-and-match-recommendations","type":"paper","name":"Clearing Matching Markets Efficiently: Informative Signals and Match Recommendations","description":"Shows platforms can facilitate efficient market clearing through targeted recommendations; reduces wasted applications and improves welfare for both sides.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2019.3468"},{"id":"paper-pricing-in-ride-sharing-platforms:-a-queueing-theoretic-approach","type":"paper","name":"Pricing in Ride-Sharing Platforms: A Queueing-Theoretic Approach","description":"Foundational queueing model for Uber/Lyft showing dynamic pricing is robust to uncertainty; establishes theoretical foundation for surge pricing.","category":"Matching & Marketplaces > Matching Algorithms","url":"https://dl.acm.org/doi/10.1145/2764468.2764527"},{"id":"paper-trust-among-strangers-in-internet-transactions","type":"paper","name":"Trust Among Strangers in Internet Transactions","description":"First rigorous empirical analysis of online reputation (eBay); documents extreme positive bias.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://presnick.people.si.umich.edu/papers/ebayNBER/index.html"},{"id":"paper-the-value-of-reputation-on-ebay:-a-controlled-experiment","type":"paper","name":"The Value of Reputation on eBay: A Controlled Experiment","description":"Field experiment proving ~8% reputation premium; gold standard methodology.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://link.springer.com/article/10.1007/s10683-006-4309-2"},{"id":"paper-fake-it-till-you-make-it:-reputation,-competition,-and-yelp-review-fraud","type":"paper","name":"Fake It Till You Make It: Reputation, Competition, and Yelp Review Fraud","description":"Documents incentives for fake reviews; 16% of Yelp reviews suspicious; competition drives fraud.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2015.2304"},{"id":"paper-reciprocity-and-unveiling-in-two-sided-reputation-systems","type":"paper","name":"Reciprocity and Unveiling in Two-Sided Reputation Systems","description":"Airbnb experiment showing bilateral reviews cause reciprocity/retaliation bias.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2020.1260"},{"id":"paper-the-limits-of-reputation-in-platform-markets:-an-empirical-analysis-and-field-experiment","type":"paper","name":"The Limits of Reputation in Platform Markets: An Empirical Analysis and Field Experiment","description":"eBay analysis showing reputation mechanisms suffer from reputational externalities and silent dissatisfaction bias; introduces 'Effective Percent Positive' measure.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://www.nber.org/papers/w20830"},{"id":"paper-promotional-reviews:-an-empirical-investigation-of-online-review-manipulation","type":"paper","name":"Promotional Reviews: An Empirical Investigation of Online Review Manipulation","description":"First rigorous fake review identification comparing TripAdvisor vs. Expedia; shows independent hotels strategically post fake reviews of competitors.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://www.aeaweb.org/articles?id=10.1257/aer.104.8.2421"},{"id":"paper-asymmetric-information,-adverse-selection-and-online-disclosure:-the-case-of-ebay-motors","type":"paper","name":"Asymmetric Information, Adverse Selection and Online Disclosure: The Case of eBay Motors","description":"Classic on voluntary disclosure in online markets; shows sellers reveal private information to reduce adverse selection in used car sales.","category":"Matching & Marketplaces > Reputation & Reviews","url":"https://www.aeaweb.org/articles?id=10.1257/aer.101.4.1535"},{"id":"paper-using-big-data-to-estimate-consumer-surplus:-the-case-of-uber","type":"paper","name":"Using Big Data to Estimate Consumer Surplus: The Case of Uber","description":"Uses surge pricing variation to estimate demand; $6.8B consumer surplus; RDD methodology.","category":"Matching & Marketplaces > Congestion & Rationing","url":"https://www.nber.org/papers/w22627"},{"id":"paper-who-benefits-from-surge-pricing?","type":"paper","name":"Who Benefits from Surge Pricing?","description":"Structural model of surge pricing welfare; riders gain, drivers lose; distributional analysis.","category":"Matching & Marketplaces > Congestion & Rationing","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA19106"},{"id":"paper-overbooking-with-substitutable-inventory-classes","type":"paper","name":"Overbooking with Substitutable Inventory Classes","description":"Optimal overbooking with multiple fare classes; airline revenue management workhorse.","category":"Matching & Marketplaces > Congestion & Rationing","url":"https://business.columbia.edu/sites/default/files-efs/pubfiles/3916/overbooking.pdf"},{"id":"paper-managing-congestion-in-matching-markets","type":"paper","name":"Managing Congestion in Matching Markets","description":"Shows restricting visibility reduces wasted applications and improves welfare for both sides; directly applicable to Upwork, dating apps, Airbnb.","category":"Matching & Marketplaces > Congestion & Rationing","url":"https://pubsonline.informs.org/doi/10.1287/msom.2020.0907"},{"id":"paper-design-of-lotteries-and-wait-lists-for-affordable-housing-allocation","type":"paper","name":"Design of Lotteries and Wait-Lists for Affordable Housing Allocation","description":"Proves equivalence of independent lotteries and penalty-waitlists; applicable to any platform managing queues for scarce resources.","category":"Matching & Marketplaces > Congestion & Rationing","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2019.3311"},{"id":"paper-an-analysis-of-the-labor-market-for-uber's-driver-partners-in-the-united-states","type":"paper","name":"An Analysis of the Labor Market for Uber's Driver-Partners in the United States","description":"First comprehensive Uber labor market analysis using administrative and survey data; foundational descriptive paper on gig work.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://journals.sagepub.com/doi/10.1177/0019793917717222"},{"id":"paper-the-value-of-flexible-work:-evidence-from-uber-drivers-1","type":"paper","name":"The Value of Flexible Work: Evidence from Uber Drivers","description":"Estimates drivers earn more than twice the surplus they would in rigid arrangements; seminal flexibility valuation paper.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://www.journals.uchicago.edu/doi/10.1086/702171"},{"id":"paper-uber-versus-taxi:-a-driver's-eye-view","type":"paper","name":"Uber versus Taxi: A Driver's Eye View","description":"Field experiment showing rideshare drivers strongly prefer proportional commission over fixed taxi leases; finds intertemporal substitution elasticity ~1.2.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://www.aeaweb.org/articles?id=10.1257/app.20190655"},{"id":"paper-the-gender-earnings-gap-in-the-gig-economy:-evidence-from-over-a-million-rideshare-drivers","type":"paper","name":"The Gender Earnings Gap in the Gig Economy: Evidence from over a Million Rideshare Drivers","description":"Documents 7% gender gap among Uber drivers entirely explained by experience, preferences, and driving speed\u2014not discrimination.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://academic.oup.com/restud/article/88/5/2210/6154047"},{"id":"paper-valuing-alternative-work-arrangements","type":"paper","name":"Valuing Alternative Work Arrangements","description":"Field experiment finding average worker WTP 20% of wages to avoid employer-set schedules; explains gig work appeal.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20161500"},{"id":"paper-the-rise-and-nature-of-alternative-work-arrangements-in-the-united-states,-1995-2015","type":"paper","name":"The Rise and Nature of Alternative Work Arrangements in the United States, 1995-2015","description":"Documents alternative work growth from 10.7% to 15.8% of workforce; contextualizes gig economy scale and trends.","category":"Matching & Marketplaces > Gig Economy & Platform Labor","url":"https://journals.sagepub.com/doi/10.1177/0019793918820008"},{"id":"paper-the-role-of-surge-pricing-on-a-service-platform-with-self-scheduling-capacity","type":"paper","name":"The Role of Surge Pricing on a Service Platform with Self-Scheduling Capacity","description":"Foundational theory showing surge pricing benefits all stakeholders by better utilizing flexible capacity; explains when dynamic pricing is welfare-improving.","category":"Matching & Marketplaces > Dynamic Pricing in Marketplaces","url":"https://pubsonline.informs.org/doi/10.1287/msom.2017.0618"},{"id":"paper-artificial-intelligence,-algorithmic-pricing,-and-collusion-1","type":"paper","name":"Artificial Intelligence, Algorithmic Pricing, and Collusion","description":"Demonstrates Q-learning algorithms autonomously learn collusive strategies; major antitrust implications for platform pricing.","category":"Matching & Marketplaces > Dynamic Pricing in Marketplaces","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20190623"},{"id":"paper-algorithmic-pricing-and-competition:-empirical-evidence-from-the-german-retail-gasoline-market","type":"paper","name":"Algorithmic Pricing and Competition: Empirical Evidence from the German Retail Gasoline Market","description":"First large-scale empirical analysis finding margins increased 28% when both competitors adopted pricing algorithms.","category":"Matching & Marketplaces > Dynamic Pricing in Marketplaces","url":"https://www.journals.uchicago.edu/doi/10.1086/726906"},{"id":"paper-why-marketplace-experimentation-is-harder-than-it-seems:-the-role-of-test-control-interference","type":"paper","name":"Why Marketplace Experimentation is Harder than it Seems: The Role of Test-Control Interference","description":"First paper documenting naive A/B testing overstates treatment effects by ~2x due to general equilibrium effects; eBay data, launched this literature.","category":"Matching & Marketplaces > Marketplace Design & Experimentation","url":"https://dl.acm.org/doi/10.1145/2600057.2602837"},{"id":"paper-the-econometrics-of-randomized-experiments","type":"paper","name":"The Econometrics of Randomized Experiments","description":"Comprehensive treatment of experimental design including interference; essential methodology paper for platform economists.","category":"Matching & Marketplaces > Marketplace Design & Experimentation","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169721817300076"},{"id":"paper-interference,-bias,-and-variance-in-two-sided-marketplace-experimentation:-guidance-for-platfo","type":"paper","name":"Interference, Bias, and Variance in Two-Sided Marketplace Experimentation: Guidance for Platforms","description":"Characterizes when to randomize on supply vs. demand side; practical guidance for platforms running experiments.","category":"Matching & Marketplaces > Marketplace Design & Experimentation","url":"https://dl.acm.org/doi/10.1145/3485447.3512063"},{"id":"paper-reducing-interference-bias-in-online-marketplace-experiments-using-cluster-randomization","type":"paper","name":"Reducing Interference Bias in Online Marketplace Experiments Using Cluster Randomization","description":"Meta-experiment on Airbnb empirically measuring interference bias magnitude; bridges theory and practice for marketplace experiments.","category":"Matching & Marketplaces > Marketplace Design & Experimentation","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2023.4748"},{"id":"paper-search,-matching,-and-the-role-of-digital-marketplace-design-in-enabling-trade:-evidence-from-","type":"paper","name":"Search, Matching, and the Role of Digital Marketplace Design in Enabling Trade: Evidence from Airbnb","description":"Shows 42% of booking inquiries rejected by hosts; platform search design critically affects transaction volume and market thickness.","category":"Matching & Marketplaces > Marketplace Design & Experimentation","url":"https://andreyfradkin.com/assets/Fradkin_JMP.pdf"},{"id":"paper-responses-to-entry-in-multi-sided-markets:-the-impact-of-craigslist-on-local-newspapers","type":"paper","name":"Responses to Entry in Multi-Sided Markets: The Impact of Craigslist on Local Newspapers","description":"Exploits Craigslist's staggered entry; landmark empirical paper on platform competition and displacement effects.","category":"Matching & Marketplaces > Platform Competition & Strategy","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2013.1823"},{"id":"paper-competing-with-complementors:-an-empirical-look-at-amazon.com","type":"paper","name":"Competing with Complementors: An Empirical Look at Amazon.com","description":"Amazon Marketplace data showing Amazon targets successful product spaces for entry; essential for self-preferencing debates.","category":"Matching & Marketplaces > Platform Competition & Strategy","url":"https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.2932"},{"id":"paper-the-rise-of-the-sharing-economy:-estimating-the-impact-of-airbnb-on-the-hotel-industry","type":"paper","name":"The Rise of the Sharing Economy: Estimating the Impact of Airbnb on the Hotel Industry","description":"Estimates 8-10% causal impact on hotel revenue in Austin; shows sharing economy disruption dynamics and incumbent responses.","category":"Matching & Marketplaces > Platform Competition & Strategy","url":"https://journals.sagepub.com/doi/10.1509/jmr.15.0204"},{"id":"paper-trust-and-disintermediation:-evidence-from-an-online-freelance-marketplace","type":"paper","name":"Trust and Disintermediation: Evidence from an Online Freelance Marketplace","description":"RCT showing enhanced trust increases hiring but also disintermediation when trust is sufficiently high; platform design tradeoff.","category":"Matching & Marketplaces > Platform Competition & Strategy","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2020.3583"},{"id":"paper-technology-and-disintermediation-in-online-marketplaces","type":"paper","name":"Technology and Disintermediation in Online Marketplaces","description":"Uses China Skype blockade as natural experiment; finds restricting communication reduces disintermediation by 18%.","category":"Matching & Marketplaces > Platform Competition & Strategy","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2023.4872"},{"id":"paper-consumer-price-search-and-platform-design-in-internet-commerce","type":"paper","name":"Consumer Price Search and Platform Design in Internet Commerce","description":"Uses eBay browsing data to show narrowing consumer choice sets can paradoxically strengthen seller competition and lower prices.","category":"Matching & Marketplaces > Information Design in Marketplaces","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20171218"},{"id":"paper-the-welfare-effects-of-peer-entry:-the-case-of-airbnb-and-the-accommodation-industry","type":"paper","name":"The Welfare Effects of Peer Entry: The Case of Airbnb and the Accommodation Industry","description":"Structural model quantifying welfare: consumer surplus $41/night, host surplus $26/night; benefits concentrated during peak demand.","category":"Matching & Marketplaces > Information Design in Marketplaces","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20180260"},{"id":"paper-peer-to-peer-markets","type":"paper","name":"Peer-to-Peer Markets","description":"Comprehensive framework covering search, matching, pricing, and reputation in peer platforms; essential survey paper.","category":"Matching & Marketplaces > Information Design in Marketplaces","url":"https://www.annualreviews.org/doi/10.1146/annurev-economics-080315-015334"},{"id":"paper-counterspeculation,-auctions,-and-competitive-sealed-tenders-1","type":"paper","name":"Counterspeculation, Auctions, and Competitive Sealed Tenders","description":"Introduces second-price sealed-bid (Vickrey) auction; establishes truthful bidding as dominant strategy.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://cramton.umd.edu/market-design-papers/vickrey-counterspeculation-auctions-and-competitive-sealed-tenders.pdf"},{"id":"paper-optimal-auction-design-1","type":"paper","name":"Optimal Auction Design","description":"Characterizes revenue-maximizing auctions; introduces virtual valuations and optimal reserves; Nobel Prize work.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://pubsonline.informs.org/doi/10.1287/moor.6.1.58"},{"id":"paper-optimal-auctions","type":"paper","name":"Optimal Auctions","description":"Independently proves revenue equivalence theorem; shows optimal reserve prices increase revenue.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://www.jstor.org/stable/1803481"},{"id":"paper-a-theory-of-auctions-and-competitive-bidding","type":"paper","name":"A Theory of Auctions and Competitive Bidding","description":"Introduces affiliated values and linkage principle; shows English auctions reduce winner's curse.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://www.cs.princeton.edu/courses/archive/spr10/cos444/papers/milgrom_weber82.pdf"},{"id":"paper-auctions-versus-negotiations","type":"paper","name":"Auctions Versus Negotiations","description":"Demonstrates one additional bidder in simple auction outperforms optimally-designed negotiation; establishes competition's fundamental value in asymmetric settings.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://www.jstor.org/stable/2118262"},{"id":"paper-a-theory-of-auctions-and-competitive-bidding,-ii","type":"paper","name":"A Theory of Auctions and Competitive Bidding, II","description":"Extends affiliated values to common value settings with asymmetric information; essential for understanding winner's curse in display advertising.","category":"Mechanism Design & Auctions > Auction Theory Foundations","url":"https://www.researchgate.net/publication/4902022_A_Theory_of_Auctions_and_Competitive_Bidding_II"},{"id":"paper-putting-auction-theory-to-work","type":"paper","name":"Putting Auction Theory to Work","description":"Practitioner's guide to designing real auctions; details SMRA for spectrum auctions; Nobel Prize foundation.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://www.cambridge.org/core/books/putting-auction-theory-to-work/B90B5B93ED4C65BC22ACA0DF9D97C3C7"},{"id":"paper-the-lovely-but-lonely-vickrey-auction","type":"paper","name":"The Lovely but Lonely Vickrey Auction","description":"Explains why VCG rarely used in practice; introduces practical alternatives for combinatorial settings.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://milgrom.people.stanford.edu/wp-content/uploads/2005/12/Lovely-but-Lonely-Vickrey-Auction-072404a.pdf"},{"id":"paper-combinatorial-auctions","type":"paper","name":"Combinatorial Auctions","description":"Comprehensive treatment of package bidding, winner determination, and spectrum auction design.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://mitpress.mit.edu/9780262033428/combinatorial-auctions/"},{"id":"paper-incentives-in-teams","type":"paper","name":"Incentives in Teams","description":"Generalizes incentive-compatible mechanisms with transfers; completes theoretical foundation for VCG.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://www.jstor.org/stable/1914085"},{"id":"paper-an-efficient-ascending-bid-auction-for-multiple-objects","type":"paper","name":"An Efficient Ascending-Bid Auction for Multiple Objects","description":"Proposes 'clinching' auction achieving Vickrey outcomes dynamically while preserving privacy; eliminates demand reduction in uniform-price settings. Adopted in Treasury and spectrum auctions.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://www.jstor.org/stable/3592838"},{"id":"paper-core-selecting-package-auctions","type":"paper","name":"Core-Selecting Package Auctions","description":"Introduces mechanisms generating competitive revenues while minimizing shill-bidding incentives; theoretical foundation for FCC combinatorial clock auction payment rules.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://link.springer.com/article/10.1007/s00182-007-0100-7"},{"id":"paper-clock-auctions-and-radio-spectrum-reallocation","type":"paper","name":"Clock Auctions and Radio Spectrum Reallocation","description":"Develops deferred-acceptance clock auctions with strategy-proof properties; directly applied to FCC Incentive Auction ($19.8B, 2016-17). Nobel Prize-awarded work.","category":"Mechanism Design & Auctions > Multi-unit & Combinatorial Auctions","url":"https://www.journals.uchicago.edu/doi/10.1086/704074"},{"id":"paper-learning-in-repeated-auctions-with-budgets","type":"paper","name":"Learning in Repeated Auctions with Budgets","description":"Introduces adaptive pacing strategies for budget-constrained bidders; proves regret bounds; foundational for ad auction budget management.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2921446"},{"id":"paper-repeated-auctions-with-budgets-in-ad-exchanges","type":"paper","name":"Repeated Auctions with Budgets in Ad Exchanges","description":"Analyzes fluid approximations for budget-constrained repeated auctions; practical design principles.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2014.2022"},{"id":"paper-budget-management-strategies-in-repeated-auctions-1","type":"paper","name":"Budget Management Strategies in Repeated Auctions","description":"Compares pacing, throttling, and probabilistic strategies; Google research on platform budget management.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://pubsonline.informs.org/doi/10.1287/opre.2020.2017"},{"id":"paper-auto-bidding-auctions-in-the-presence-of-user-costs","type":"paper","name":"Auto-bidding Auctions in the Presence of User Costs","description":"Analyzes VCG with value-maximizing autobidders; shows cost multipliers improve welfare.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://research.google/pubs/autobidding-auctions-in-the-presence-of-user-costs/"},{"id":"paper-pacing-equilibrium-in-first-price-auction-markets-1","type":"paper","name":"Pacing Equilibrium in First Price Auction Markets","description":"Proves first-price auctions with budget pacing guarantee equilibrium uniqueness and efficient computation; theoretical foundation for industry's second-to-first price transition.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2021.4001"},{"id":"paper-multiplicative-pacing-equilibria-in-auction-markets-1","type":"paper","name":"Multiplicative Pacing Equilibria in Auction Markets","description":"Foundational paper proving existence of pacing equilibria for budget-constrained bidders; connects repeated auctions to competitive equilibrium theory.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://pubsonline.informs.org/doi/10.1287/opre.2021.2135"},{"id":"paper-the-landscape-of-auto-bidding-auctions:-value-versus-utility-maximization","type":"paper","name":"The Landscape of Auto-Bidding Auctions: Value Versus Utility Maximization","description":"Compares value-maximizing versus utility-maximizing autobidders; shows first-best revenue achievable with value-maximizers. Essential for understanding modern autobidding platforms.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://dl.acm.org/doi/10.1145/3465456.3467590"},{"id":"paper-optimal-mechanisms-for-value-maximizers-with-budget-constraints-via-target-clipping","type":"paper","name":"Optimal Mechanisms for Value Maximizers with Budget Constraints via Target Clipping","description":"Extends autobidding theory to budget-constrained value maximizers; proposes clipping mechanisms achieving near-optimal revenue.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://dl.acm.org/doi/10.1145/3485447.3512052"},{"id":"paper-a-field-guide-to-personalized-reserve-prices","type":"paper","name":"A Field Guide to Personalized Reserve Prices","description":"Practical algorithms for learning optimal reserve prices at Google scale; bridges theory and deployed systems.","category":"Mechanism Design & Auctions > Dynamic Auctions & Repeated Games","url":"https://dl.acm.org/doi/10.1145/2872427.2883029"},{"id":"paper-college-admissions-and-the-stability-of-marriage-1","type":"paper","name":"College Admissions and the Stability of Marriage","description":"Introduces deferred acceptance algorithm; proves existence of stable matchings; Nobel Prize foundation.","category":"Mechanism Design & Auctions > Market Design","url":"https://sites.math.washington.edu/~billey/classes/562.winter.2018/articles/Gale.Shapley.pdf"},{"id":"paper-school-choice:-a-mechanism-design-approach","type":"paper","name":"School Choice: A Mechanism Design Approach","description":"Applies matching theory to school choice; shows Boston mechanism is manipulable; proposes strategy-proof alternatives.","category":"Mechanism Design & Auctions > Market Design","url":"https://www.aeaweb.org/articles?id=10.1257/000282803321455354"},{"id":"paper-kidney-exchange-1","type":"paper","name":"Kidney Exchange","description":"Designs kidney exchange clearinghouses using top trading cycles; Nobel Prize application.","category":"Mechanism Design & Auctions > Market Design","url":"https://www.nber.org/papers/w10002"},{"id":"paper-changing-the-boston-school-choice-mechanism","type":"paper","name":"Changing the Boston School Choice Mechanism","description":"Documents Boston's switch to deferred acceptance; empirical evidence on strategic behavior.","category":"Mechanism Design & Auctions > Market Design","url":"https://www.nber.org/papers/w11965"},{"id":"paper-course-match:-a-large-scale-implementation-of-approximate-competitive-equilibrium-from-equal-i","type":"paper","name":"Course Match: A Large-Scale Implementation of Approximate Competitive Equilibrium from Equal Incomes","description":"Reports deployment of A-CEEI mechanism at Wharton (1,700 students, 350 courses); solves billions of mixed-integer programs. Definitive paper on scaling market design.","category":"Mechanism Design & Auctions > Market Design","url":"https://pubsonline.informs.org/doi/10.1287/opre.2016.1544"},{"id":"paper-commitment-on-volunteer-crowdsourcing-platforms:-implications-for-growth-and-engagement","type":"paper","name":"Commitment on Volunteer Crowdsourcing Platforms: Implications for Growth and Engagement","description":"Studies optimal adoption policies on matching platforms using Food Rescue U.S. data; shows commitment mechanisms' impacts on growth versus engagement.","category":"Mechanism Design & Auctions > Market Design","url":"https://pubsonline.informs.org/doi/10.1287/msom.2022.0222"},{"id":"paper-course-allocation-by-proxy-auction","type":"paper","name":"Course Allocation by Proxy Auction","description":"Proposes proxy bidding countering strategic gaming in course allocation; key insight for automated assignment systems.","category":"Mechanism Design & Auctions > Market Design","url":"https://link.springer.com/chapter/10.1007/978-3-642-17572-5_46"},{"id":"paper-strategic-information-transmission","type":"paper","name":"Strategic Information Transmission","description":"Foundational cheap talk model; shows partition equilibria arise with interest misalignment.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://www.jstor.org/stable/1913390"},{"id":"paper-bayesian-persuasion","type":"paper","name":"Bayesian Persuasion","description":"Introduces information design framework; characterizes sender-optimal signals via concavification; transformed the field.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://www.aeaweb.org/articles?id=10.1257/aer.101.6.2590"},{"id":"paper-competition-in-persuasion","type":"paper","name":"Competition in Persuasion","description":"Extends Bayesian persuasion to multiple senders; shows competition increases information revelation.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://academic.oup.com/restud/article/84/1/300/2669964"},{"id":"paper-information-design:-a-unified-perspective","type":"paper","name":"Information Design: A Unified Perspective","description":"Comprehensive survey connecting Bayesian persuasion, mechanism design, and correlated equilibrium.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://www.aeaweb.org/articles?id=10.1257/jel.20181489"},{"id":"paper-first-price-auctions-with-general-information-structures:-implications-for-bidding-and-revenue","type":"paper","name":"First-Price Auctions with General Information Structures: Implications for Bidding and Revenue","description":"Characterizes equilibrium bidding across all possible information structures in first-price auctions; derives robust revenue bounds regardless of bidder information.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA13958"},{"id":"paper-optimal-information-disclosure-in-classic-auctions","type":"paper","name":"Optimal Information Disclosure in Classic Auctions","description":"Characterizes revenue-maximizing information: reveal low values (increase competition) but pool high values. Provides rationale for conflation strategies in digital advertising.","category":"Mechanism Design & Auctions > Information Design & Signaling","url":"https://www.aeaweb.org/articles?id=10.1257/aeri.20210689"},{"id":"paper-internet-advertising-and-the-generalized-second-price-auction:-selling-billions-of-dollars-wor","type":"paper","name":"Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords","description":"First rigorous analysis of GSP mechanism used by Google/Yahoo; proves GSP lacks dominant strategy but identifies 'locally envy-free' equilibrium.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://www.jstor.org/stable/4132849"},{"id":"paper-position-auctions-1","type":"paper","name":"Position Auctions","description":"Independent equilibrium analysis of search auctions; introduces quality-weighted ranking (bid \u00d7 CTR); validates theory with Google data.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://link.springer.com/article/10.1007/s00182-006-0029-7"},{"id":"paper-sponsored-search-auctions","type":"paper","name":"Sponsored Search Auctions","description":"Authoritative survey integrating mechanism design, optimization, and ML perspectives on ad auctions.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://www.cambridge.org/core/books/algorithmic-game-theory/sponsored-search-auctions/D6A4B3C8F45C3E8A9D1B2A6F5C4D3E2A"},{"id":"paper-reserve-prices-in-internet-advertising-auctions:-a-field-experiment","type":"paper","name":"Reserve Prices in Internet Advertising Auctions: A Field Experiment","description":"First large-scale field experiment applying Myerson optimal auction theory to sponsored search at Yahoo; demonstrates ~12% revenue increase from optimized reserves.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://www.journals.uchicago.edu/doi/10.1086/718916"},{"id":"paper-optimal-real-time-bidding-for-display-advertising","type":"paper","name":"Optimal Real-Time Bidding for Display Advertising","description":"Formulates RTB as functional optimization; derives optimal bidding functions under budget constraints. Foundational for DSP bidding strategies.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://dl.acm.org/doi/10.1145/2623330.2623633"},{"id":"paper-reserve-price-optimization-for-first-price-auctions-in-display-advertising","type":"paper","name":"Reserve Price Optimization for First Price Auctions in Display Advertising","description":"Addresses industry's second-to-first price transition; proposes gradient-based reserve optimization validated on Google Ad Exchange data.","category":"Mechanism Design & Auctions > Sponsored Search & Display Ad Auctions","url":"https://proceedings.mlr.press/v139/feng21d.html"},{"id":"paper-algorithmic-mechanism-design","type":"paper","name":"Algorithmic Mechanism Design","description":"Foundational paper coining the field; establishes computational complexity constraints on mechanism design through scheduling problems where VCG fails.","category":"Mechanism Design & Auctions > Algorithmic Game Theory & Computational Mechanism Design","url":"https://www.sciencedirect.com/science/article/pii/S0899825601907086"},{"id":"paper-simple-versus-optimal-mechanisms","type":"paper","name":"Simple versus Optimal Mechanisms","description":"Proves simple mechanisms (Vickrey with anonymous reserves) achieve constant-factor approximation to optimal revenue; establishes simplicity-optimality tradeoff paradigm.","category":"Mechanism Design & Auctions > Algorithmic Game Theory & Computational Mechanism Design","url":"https://dl.acm.org/doi/10.1145/1566374.1566407"},{"id":"paper-multi-parameter-mechanism-design-and-sequential-posted-pricing","type":"paper","name":"Multi-Parameter Mechanism Design and Sequential Posted Pricing","description":"Introduces sequential posted pricing as approximation to optimal multi-dimensional revenue; connects prophet inequalities to mechanism design.","category":"Mechanism Design & Auctions > Algorithmic Game Theory & Computational Mechanism Design","url":"https://dl.acm.org/doi/10.1145/1806689.1806733"},{"id":"paper-optimal-multi-dimensional-mechanism-design:-reducing-revenue-to-welfare-maximization","type":"paper","name":"Optimal Multi-Dimensional Mechanism Design: Reducing Revenue to Welfare Maximization","description":"Fundamental reduction showing every mechanism implementable as distribution over virtual VCG rules. FOCS Test of Time Award.","category":"Mechanism Design & Auctions > Algorithmic Game Theory & Computational Mechanism Design","url":"https://ieeexplore.ieee.org/document/6375305"},{"id":"paper-matroid-prophet-inequalities","type":"paper","name":"Matroid Prophet Inequalities","description":"Generalizes prophet inequality to matroid constraints; first efficient constant-approximations for multi-parameter settings.","category":"Mechanism Design & Auctions > Algorithmic Game Theory & Computational Mechanism Design","url":"https://dl.acm.org/doi/10.1145/2213977.2214013"},{"id":"paper-a-price-theory-of-multi-sided-platforms-1","type":"paper","name":"A Price Theory of Multi-Sided Platforms","description":"General theory of monopoly platform pricing showing how platforms internalize network externalities only at the margin; foundational for understanding platform fee structures.","category":"Mechanism Design & Auctions > Platform Mechanism Design","url":"https://www.jstor.org/stable/27871251"},{"id":"paper-two-sided-platforms:-product-variety-and-pricing-structures","type":"paper","name":"Two-Sided Platforms: Product Variety and Pricing Structures","description":"Models platform pricing when consumers value variety; shows variable fees trade off producer innovation against platform holdup.","category":"Mechanism Design & Auctions > Platform Mechanism Design","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1530-9134.2009.00238.x"},{"id":"paper-multi-sided-platforms","type":"paper","name":"Multi-Sided Platforms","description":"Comprehensive theory of firm choice between vertical integration and platform modes; directly applicable to Uber, Airbnb marketplace design.","category":"Mechanism Design & Auctions > Platform Mechanism Design","url":"https://link.springer.com/article/10.1007/s00182-015-0478-9"},{"id":"paper-online-labor-markets","type":"paper","name":"Online Labor Markets","description":"Explores platform creators' choices of price structure, price level, and investment in online labor markets; early theoretical treatment of gig economy mechanism design.","category":"Mechanism Design & Auctions > Platform Mechanism Design","url":"https://link.springer.com/chapter/10.1007/978-3-642-17572-5_42"},{"id":"paper-equilibrium-effects-of-pay-transparency","type":"paper","name":"Equilibrium Effects of Pay Transparency","description":"Demonstrates transparency reduces worker bargaining power in platform/gig markets using event-study of state transparency laws; essential for platform wage-setting policy.","category":"Mechanism Design & Auctions > Platform Mechanism Design","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA18709"},{"id":"paper-mechanism-design-via-differential-privacy","type":"paper","name":"Mechanism Design via Differential Privacy","description":"Seminal paper showing differential privacy ensures approximate dominant-strategy truthfulness under arbitrary utilities; introduces the exponential mechanism.","category":"Mechanism Design & Auctions > Privacy-Preserving & Differential Privacy Mechanisms","url":"https://ieeexplore.ieee.org/document/4389483"},{"id":"paper-selling-privacy-at-auction","type":"paper","name":"Selling Privacy at Auction","description":"Initiates study of data markets through differential privacy lens; shows optimal designs are variants of multi-unit procurement auctions compensating data owners for privacy loss.","category":"Mechanism Design & Auctions > Privacy-Preserving & Differential Privacy Mechanisms","url":"https://dl.acm.org/doi/10.1145/1993574.1993592"},{"id":"paper-privacy-and-mechanism-design","type":"paper","name":"Privacy and Mechanism Design","description":"Comprehensive survey showing differential privacy provides tools for controlling mechanism stability and designing truthful mechanisms without money.","category":"Mechanism Design & Auctions > Privacy-Preserving & Differential Privacy Mechanisms","url":"https://dl.acm.org/doi/10.1145/2509413.2509428"},{"id":"paper-deconstructing-amazon-ec2-spot-instance-pricing","type":"paper","name":"Deconstructing Amazon EC2 Spot Instance Pricing","description":"Reverse-engineers AWS spot pricing revealing hidden dynamic reserve mechanism rather than market-driven prices; critical insights for cloud users and providers.","category":"Mechanism Design & Auctions > Cloud & Computing Resource Auctions","url":"https://dl.acm.org/doi/10.1145/2465529.2465530"},{"id":"paper-cloud-pricing:-the-spot-market-strikes-back","type":"paper","name":"Cloud Pricing: The Spot Market Strikes Back","description":"Combines queuing theory and game theory analyzing when spot instances alongside fixed-price are profitable; accounts for cannibalization and preemption costs.","category":"Mechanism Design & Auctions > Cloud & Computing Resource Auctions","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2021.4178"},{"id":"paper-an-online-auction-framework-for-dynamic-resource-provisioning-in-cloud-computing","type":"paper","name":"An Online Auction Framework for Dynamic Resource Provisioning in Cloud Computing","description":"First online combinatorial auction for cloud handling dynamic arrivals; addresses revenue maximization and truthfulness jointly.","category":"Mechanism Design & Auctions > Cloud & Computing Resource Auctions","url":"https://dl.acm.org/doi/10.1145/2637364.2592003"},{"id":"paper-on-the-cluster-admission-problem-for-cloud-computing","type":"paper","name":"On the Cluster Admission Problem for Cloud Computing","description":"Proposes admission control policies matching heterogeneous workloads to cloud resources via MDPs and information elicitation; significantly improves cluster utilization.","category":"Mechanism Design & Auctions > Cloud & Computing Resource Auctions","url":"https://www.jair.org/index.php/jair/article/view/12359"},{"id":"paper-estimating-discrete-choice-models-of-product-differentiation-1","type":"paper","name":"Estimating Discrete-Choice Models of Product Differentiation","description":"Introduces market share inversion mapping observed shares to mean utilities, enabling IV estimation with aggregate data.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://www.jstor.org/stable/2555829"},{"id":"paper-automobile-prices-in-market-equilibrium","type":"paper","name":"Automobile Prices in Market Equilibrium","description":"The canonical 'BLP' paper: random coefficients logit with unobserved product characteristics and endogenous prices.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://www.jstor.org/stable/2171802"},{"id":"paper-a-practitioner's-guide-to-estimation-of-random-coefficients-logit-models-of-demand","type":"paper","name":"A Practitioner's Guide to Estimation of Random-Coefficients Logit Models of Demand","description":"Essential implementation guide clarifying BLP algorithms and computational practice.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1430-9134.2000.00513.x"},{"id":"paper-identification-in-differentiated-products-markets-using-market-level-data","type":"paper","name":"Identification in Differentiated Products Markets Using Market Level Data","description":"Rigorous nonparametric identification foundations establishing when demand is identified.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://www.econometricsociety.org/doi/10.3982/ECTA10135"},{"id":"paper-best-practices-for-differentiated-products-demand-estimation-with-pyblp","type":"paper","name":"Best Practices for Differentiated Products Demand Estimation with PyBLP","description":"Modern best practices with open-source Python implementation; addresses numerical stability and optimal instruments.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://chrisconlon.github.io/site/pyblp.pdf"},{"id":"paper-valuing-new-goods-in-a-model-with-complementarity:-online-newspapers","type":"paper","name":"Valuing New Goods in a Model with Complementarity: Online Newspapers","description":"Extends discrete choice to allow complementarity between products; estimates substitution between print and online news using Washington Post data. Essential for digital goods where products may be complements rather than substitutes.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://www.jstor.org/stable/30034408"},{"id":"paper-estimating-demand-for-mobile-applications-in-the-new-economy","type":"paper","name":"Estimating Demand for Mobile Applications in the New Economy","description":"BLP-style random coefficients nested logit for iOS and Android app stores; estimates $33.6 billion annual consumer surplus from mobile apps and quantifies in-app purchase and advertising effects.","category":"Structural Estimation > Demand Estimation (BLP)","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2013.1805"},{"id":"paper-entry-and-competition-in-concentrated-markets","type":"paper","name":"Entry and Competition in Concentrated Markets","description":"Foundational ordered probit entry model using threshold ratios to infer competitive effects from market structure.","category":"Structural Estimation > Entry & Competition","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/261786"},{"id":"paper-estimation-of-a-model-of-entry-in-the-airline-industry","type":"paper","name":"Estimation of a Model of Entry in the Airline Industry","description":"Methods for estimating discrete games with multiple equilibria; foundation for airline entry applications.","category":"Structural Estimation > Entry & Competition","url":"https://www.jstor.org/stable/2951571"},{"id":"paper-empirical-models-of-entry-and-market-structure","type":"paper","name":"Empirical Models of Entry and Market Structure","description":"Authoritative survey covering static and dynamic entry models with identification and estimation methods.","category":"Structural Estimation > Entry & Competition","url":"https://www.sciencedirect.com/science/article/pii/S1573448X07030296"},{"id":"paper-market-structure-and-multiple-equilibria-in-airline-markets","type":"paper","name":"Market Structure and Multiple Equilibria in Airline Markets","description":"Inference methods for entry games with multiple equilibria using partial identification.","category":"Structural Estimation > Entry & Competition","url":"https://www.econometricsociety.org/doi/10.3982/ECTA5368"},{"id":"paper-the-welfare-effects-of-peer-entry:-the-case-of-airbnb-and-the-accommodation-industry-1","type":"paper","name":"The Welfare Effects of Peer Entry: The Case of Airbnb and the Accommodation Industry","description":"Structural model of competition between 'flexible' peer suppliers (Airbnb) and 'dedicated' sellers (hotels). Finds Airbnb generated $41 consumer surplus per room-night with welfare gains concentrated during capacity-constrained periods.","category":"Structural Estimation > Entry & Competition","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20180260"},{"id":"paper-what-happens-when-wal-mart-comes-to-town:-an-empirical-analysis-of-the-discount-retailing-indu","type":"paper","name":"What Happens When Wal-Mart Comes to Town: An Empirical Analysis of the Discount Retailing Industry","description":"Develops computational methods for large-scale entry games; tractable approach for markets with many potential entrants relevant to platform expansion analysis.","category":"Structural Estimation > Entry & Competition","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1468-0262.2008.00854.x"},{"id":"paper-optimal-replacement-of-gmc-bus-engines:-an-empirical-model-of-harold-zurcher","type":"paper","name":"Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher","description":"Foundational paper introducing nested fixed point (NFXP) algorithm and conditional independence assumptions.","category":"Structural Estimation > Dynamic Structural Models","url":"https://www.econometricsociety.org/publications/econometrica/1987/09/01/optimal-replacement-gmc-bus-engines-empirical-model-harold"},{"id":"paper-conditional-choice-probabilities-and-the-estimation-of-dynamic-models","type":"paper","name":"Conditional Choice Probabilities and the Estimation of Dynamic Models","description":"Revolutionary CCP approach expressing value functions as functions of observable choice probabilities.","category":"Structural Estimation > Dynamic Structural Models","url":"https://academic.oup.com/restud/article-abstract/60/3/497/1570375"},{"id":"paper-sequential-estimation-of-dynamic-discrete-games","type":"paper","name":"Sequential Estimation of Dynamic Discrete Games","description":"Extends CCP to dynamic games; introduces nested pseudo-likelihood addressing computational challenges.","category":"Structural Estimation > Dynamic Structural Models","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2007.00731.x"},{"id":"paper-conditional-choice-probability-estimation-of-dynamic-discrete-choice-models-with-unobserved-he","type":"paper","name":"Conditional Choice Probability Estimation of Dynamic Discrete Choice Models with Unobserved Heterogeneity","description":"Integrates unobserved heterogeneity into CCP estimators using EM algorithm.","category":"Structural Estimation > Dynamic Structural Models","url":"https://www.econometricsociety.org/doi/10.3982/ECTA7743"},{"id":"paper-practical-methods-for-estimation-of-dynamic-discrete-choice-models","type":"paper","name":"Practical Methods for Estimation of Dynamic Discrete Choice Models","description":"Excellent practical guide bridging theory and implementation.","category":"Structural Estimation > Dynamic Structural Models","url":"https://www.annualreviews.org/doi/abs/10.1146/annurev-economics-111809-125038"},{"id":"paper-changing-their-tune:-how-consumers'-adoption-of-online-streaming-affects-music-consumption-and","type":"paper","name":"Changing Their Tune: How Consumers' Adoption of Online Streaming Affects Music Consumption and Discovery","description":"Studies consumption dynamics using individual listening histories across streaming platforms; finds streaming adoption increases quantity and diversity of music consumption.","category":"Structural Estimation > Dynamic Structural Models","url":"https://pubsonline.informs.org/doi/10.1287/mksc.2017.1051"},{"id":"paper-state-dependence-and-alternative-explanations-for-consumer-inertia","type":"paper","name":"State Dependence and Alternative Explanations for Consumer Inertia","description":"Separates structural state dependence from heterogeneity using household scanner data; essential for understanding subscription stickiness and switching costs in digital services.","category":"Structural Estimation > Dynamic Structural Models","url":"https://www.jstor.org/stable/25651509"},{"id":"paper-optimal-nonparametric-estimation-of-first-price-auctions","type":"paper","name":"Optimal Nonparametric Estimation of First-Price Auctions","description":"The foundational 'GPV' paper introducing nonparametric bid inversion to recover private value distributions.","category":"Structural Estimation > Auction Estimation","url":"https://ideas.repec.org/a/ecm/emetrp/v68y2000i3p525-574.html"},{"id":"paper-identification-of-standard-auction-models","type":"paper","name":"Identification of Standard Auction Models","description":"Establishes nonparametric identification conditions for major auction formats.","category":"Structural Estimation > Auction Estimation","url":"https://www.econometricsociety.org/doi/10.1111/1468-0262.00315"},{"id":"paper-nonparametric-approaches-to-auctions","type":"paper","name":"Nonparametric Approaches to Auctions","description":"Comprehensive handbook chapter; authoritative survey of identification and estimation.","category":"Structural Estimation > Auction Estimation","url":"https://www.sciencedirect.com/science/article/pii/S1573448X07060603"},{"id":"paper-identification-and-estimation-of-auction-models-with-unobserved-heterogeneity","type":"paper","name":"Identification and Estimation of Auction Models with Unobserved Heterogeneity","description":"Addresses unobserved auction heterogeneity using multiplicative structure; widely applied in procurement.","category":"Structural Estimation > Auction Estimation","url":"https://academic.oup.com/restud/article-abstract/78/1/293/1534722"},{"id":"paper-an-empirical-perspective-on-auctions","type":"paper","name":"An Empirical Perspective on Auctions","description":"Applied survey covering auction theory testing and structural estimation in practice.","category":"Structural Estimation > Auction Estimation","url":"https://www.sciencedirect.com/science/article/pii/S1573448X07030326"},{"id":"paper-internet-advertising-and-the-generalized-second-price-auction:-selling-billions-of-dollars-wor-1","type":"paper","name":"Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords","description":"Foundational analysis of GSP auction mechanism used by Google and Yahoo; characterizes equilibria and proves revenue equivalence under complete information. Required reading for ad auction design.","category":"Structural Estimation > Auction Estimation","url":"https://www.jstor.org/stable/4132849"},{"id":"paper-a-structural-model-of-sponsored-search-advertising-auctions","type":"paper","name":"A Structural Model of Sponsored Search Advertising Auctions","description":"Structural econometric methods for estimating bidder valuations in sponsored search auctions; bridges GSP theory with empirical estimation of ad auction data.","category":"Structural Estimation > Auction Estimation","url":"https://www.gsb.stanford.edu/faculty-research/working-papers/structural-model-sponsored-search-advertising-auctions"},{"id":"paper-the-dynamics-of-productivity-in-the-telecommunications-equipment-industry","type":"paper","name":"The Dynamics of Productivity in the Telecommunications Equipment Industry","description":"Foundational control function approach using investment to proxy for unobserved productivity.","category":"Structural Estimation > Production & Cost Estimation","url":"https://www.jstor.org/stable/2171831"},{"id":"paper-estimating-production-functions-using-inputs-to-control-for-unobservables","type":"paper","name":"Estimating Production Functions Using Inputs to Control for Unobservables","description":"Uses intermediate inputs as proxy; more widely applicable than OP due to data availability.","category":"Structural Estimation > Production & Cost Estimation","url":"https://academic.oup.com/restud/article-abstract/70/2/317/1586618"},{"id":"paper-identification-properties-of-recent-production-function-estimators","type":"paper","name":"Identification Properties of Recent Production Function Estimators","description":"Resolves functional dependence problems in OP/LP; the 'ACF' estimator is now standard practice.","category":"Structural Estimation > Production & Cost Estimation","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA13408"},{"id":"paper-markups-and-firm-level-export-status","type":"paper","name":"Markups and Firm-Level Export Status","description":"Combines production function and markup estimation; highly influential applied methodology.","category":"Structural Estimation > Production & Cost Estimation","url":"https://www.aeaweb.org/articles?id=10.1257/aer.102.6.2437"},{"id":"paper-on-the-identification-of-gross-output-production-functions","type":"paper","name":"On the Identification of Gross Output Production Functions","description":"Resolves identification issues with gross output using nonparametric IV methods.","category":"Structural Estimation > Production & Cost Estimation","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/707736"},{"id":"paper-two-sided-markets:-a-progress-report-1","type":"paper","name":"Two-Sided Markets: A Progress Report","description":"Canonical theoretical framework defining two-sided markets where price structure (not just level) matters; establishes concepts of membership fees, usage fees, and indirect network effects.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://www.jstor.org/stable/25046325"},{"id":"paper-competition-between-networks:-a-study-of-the-market-for-yellow-pages","type":"paper","name":"Competition Between Networks: A Study of the Market for Yellow Pages","description":"First rigorous structural estimation of cross-side network effects in two-sided markets; estimates simultaneous equations for consumer demand, advertiser demand, and publisher pricing.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://academic.oup.com/restud/article/71/2/483/1600219"},{"id":"paper-a-price-theory-of-multi-sided-platforms-2","type":"paper","name":"A Price Theory of Multi-Sided Platforms","description":"General theory of monopoly platform pricing showing platforms internalize only marginal users' externalities (Spence distortion). Essential for understanding market power measurement in platform markets.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://www.jstor.org/stable/27871251"},{"id":"paper-identification-of-peer-effects-through-social-networks","type":"paper","name":"Identification of Peer Effects Through Social Networks","description":"Provides necessary and sufficient conditions for identifying peer effects using network structure; shows how intransitive networks solve Manski's reflection problem.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://www.sciencedirect.com/science/article/pii/S0304407609000335"},{"id":"paper-distinguishing-influence-based-contagion-from-homophily-driven-diffusion-in-dynamic-networks","type":"paper","name":"Distinguishing Influence-Based Contagion from Homophily-Driven Diffusion in Dynamic Networks","description":"Uses 27.4 million Yahoo users to separate peer influence from selection; shows previous methods overestimate influence by 300-700%. Essential methodology for network effect identification.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://www.pnas.org/doi/10.1073/pnas.0908800106"},{"id":"paper-evidence-on-learning-and-network-externalities-in-the-diffusion-of-home-computers","type":"paper","name":"Evidence on Learning and Network Externalities in the Diffusion of Home Computers","description":"Early empirical paper distinguishing network externalities from learning spillovers using geographic variation; finds effects tied to email/internet use, supporting communication network hypothesis.","category":"Structural Estimation > Platform & Network Effects Estimation","url":"https://www.jstor.org/stable/3555107"},{"id":"paper-the-welfare-effects-of-bundling-in-multichannel-television-markets","type":"paper","name":"The Welfare Effects of Bundling in Multichannel Television Markets","description":"Full industry structural model combining viewership, demand, pricing, bundling, and Nash bargaining between distributors and content providers. Finds unbundling raises negotiated input costs 103%.","category":"Structural Estimation > Digital Goods, Streaming & Content Markets","url":"https://www.jstor.org/stable/23287153"},{"id":"paper-as-streaming-reaches-flood-stage,-does-it-stimulate-or-depress-music-sales?","type":"paper","name":"As Streaming Reaches Flood Stage, Does it Stimulate or Depress Music Sales?","description":"Uses Spotify growth to estimate streaming's market impact; finds 137 streams displace 1 track sale but streaming also displaces piracy, making it approximately revenue-neutral.","category":"Structural Estimation > Digital Goods, Streaming & Content Markets","url":"https://www.sciencedirect.com/science/article/pii/S016771871730133X"},{"id":"paper-music-for-a-song:-an-empirical-look-at-uniform-pricing-and-its-alternatives","type":"paper","name":"Music for a Song: An Empirical Look at Uniform Pricing and Its Alternatives","description":"Estimates willingness-to-pay for digital songs and simulates revenue under alternative pricing (bundling, two-part tariffs); finds bundling raises revenue 16-33% over uniform pricing.","category":"Structural Estimation > Digital Goods, Streaming & Content Markets","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1467-6451.2011.00451.x"},{"id":"paper-the-effect-of-file-sharing-on-record-sales:-an-empirical-analysis","type":"paper","name":"The Effect of File Sharing on Record Sales: An Empirical Analysis","description":"Most-cited digital piracy paper using matched file-sharing and sales data; uses German school holidays as instrument. Established the empirical agenda for piracy research.","category":"Structural Estimation > Digital Goods, Streaming & Content Markets","url":"https://www.journals.uchicago.edu/doi/10.1086/511995"},{"id":"paper-piracy-and-copyright-enforcement-mechanisms","type":"paper","name":"Piracy and Copyright Enforcement Mechanisms","description":"Authoritative synthesis reviewing piracy displacement effects, creative incentives, and enforcement effectiveness. Essential methodological guide for digital content research.","category":"Structural Estimation > Digital Goods, Streaming & Content Markets","url":"https://www.journals.uchicago.edu/doi/10.1086/675819"},{"id":"paper-consumer-surplus-in-the-digital-economy:-estimating-the-value-of-increased-product-variety-at-","type":"paper","name":"Consumer Surplus in the Digital Economy: Estimating the Value of Increased Product Variety at Online Booksellers","description":"First rigorous estimation of 'Long Tail' welfare gains; shows Amazon variety benefits were 7-10x larger than price competition gains. Foundational paper quantifying why e-commerce matters.","category":"Structural Estimation > E-commerce & Online Retail","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.49.11.1580.20580"},{"id":"paper-search,-obfuscation,-and-price-elasticities-on-the-internet","type":"paper","name":"Search, Obfuscation, and Price Elasticities on the Internet","description":"Explains the price dispersion puzzle\u2014why dispersion persists despite low online search costs. Shows retailers strategically make search harder through add-on pricing and complex fees.","category":"Structural Estimation > E-commerce & Online Retail","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA5708"},{"id":"paper-testing-models-of-consumer-search-using-data-on-web-browsing-and-purchasing-behavior","type":"paper","name":"Testing Models of Consumer Search Using Data on Web Browsing and Purchasing Behavior","description":"Uses clickstream data to directly observe search sequences; rejects standard sequential search in favor of fixed sample size model. Methodological benchmark for structural search estimation.","category":"Structural Estimation > E-commerce & Online Retail","url":"https://www.aeaweb.org/articles?id=10.1257/aer.102.6.2955"},{"id":"paper-consumer-price-search-and-platform-design-in-internet-commerce-1","type":"paper","name":"Consumer Price Search and Platform Design in Internet Commerce","description":"Equilibrium model of search and price competition on eBay; quantifies platform design trade-offs between match quality and price competition using detailed browsing data.","category":"Structural Estimation > E-commerce & Online Retail","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20161492"},{"id":"paper-auctions-versus-posted-prices-in-online-markets","type":"paper","name":"Auctions versus Posted Prices in Online Markets","description":"Explains eBay's shift from auctions to posted prices by estimating demand trade-offs between price discovery and convenience using millions of seller experiments.","category":"Structural Estimation > E-commerce & Online Retail","url":"https://www.journals.uchicago.edu/doi/10.1086/696569"},{"id":"paper-using-price-distributions-to-estimate-search-costs","type":"paper","name":"Using Price Distributions to Estimate Search Costs","description":"Foundational methodology for backing out search cost distributions from equilibrium prices; underlies virtually all subsequent empirical search estimation.","category":"Structural Estimation > Search, Advertising & Attention","url":"https://www.jstor.org/stable/25046317"},{"id":"paper-the-power-of-rankings:-quantifying-the-effect-of-rankings-on-online-consumer-search-and-purcha","type":"paper","name":"The Power of Rankings: Quantifying the Effect of Rankings on Online Consumer Search and Purchase Decisions","description":"Uses Expedia field experiment to causally identify position effects ($1.92/position); gold-standard paper on ranking effects in digital platforms. Bass Outstanding Dissertation Award winner.","category":"Structural Estimation > Search, Advertising & Attention","url":"https://pubsonline.informs.org/doi/10.1287/mksc.2017.1072"},{"id":"paper-advertising,-consumer-awareness,-and-choice:-evidence-from-the-u.s.-banking-industry","type":"paper","name":"Advertising, Consumer Awareness, and Choice: Evidence from the U.S. Banking Industry","description":"Integrates costly search with endogenous consideration set formation; shows advertising shifts awareness rather than preferences, increasing competition.","category":"Structural Estimation > Search, Advertising & Attention","url":"https://www.jstor.org/stable/26248992"},{"id":"paper-what-makes-them-click:-empirical-analysis-of-consumer-demand-for-search-advertising","type":"paper","name":"What Makes Them Click: Empirical Analysis of Consumer Demand for Search Advertising","description":"Canonical consumer-side structural model of sponsored search using Bing data; finds 51% more clicks would occur without ad competition. Essential for understanding attention allocation.","category":"Structural Estimation > Search, Advertising & Attention","url":"https://www.aeaweb.org/articles?id=10.1257/mic.20130153"},{"id":"paper-double-debiased-machine-learning-for-treatment-and-structural-parameters-2","type":"paper","name":"Double/Debiased Machine Learning for Treatment and Structural Parameters","description":"Foundational framework for using ML to estimate nuisance parameters while preserving valid inference on structural parameters through orthogonal scores and cross-fitting.","category":"Structural Estimation > Machine Learning & Structural Estimation","url":"https://academic.oup.com/ectj/article/21/1/C1/5056401"},{"id":"paper-estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests-2","type":"paper","name":"Estimation and Inference of Heterogeneous Treatment Effects using Random Forests","description":"Develops causal forests for heterogeneous treatment effect estimation with valid confidence intervals. Critical for personalization, targeting, and A/B test analysis.","category":"Structural Estimation > Machine Learning & Structural Estimation","url":"https://www.tandfonline.com/doi/10.1080/01621459.2017.1319839"},{"id":"paper-deep-iv:-a-flexible-approach-for-counterfactual-prediction","type":"paper","name":"Deep IV: A Flexible Approach for Counterfactual Prediction","description":"Deep learning framework for instrumental variables; two-stage neural network approach for demand estimation with price endogeneity. Bridges deep learning with core BLP problem.","category":"Structural Estimation > Machine Learning & Structural Estimation","url":"https://proceedings.mlr.press/v70/hartford17a.html"},{"id":"paper-deep-neural-networks-for-estimation-and-inference","type":"paper","name":"Deep Neural Networks for Estimation and Inference","description":"Rigorous theoretical foundations proving deep nets can be used as first-step estimators in semiparametric inference; provides convergence bounds validating neural networks for causal inference.","category":"Structural Estimation > Machine Learning & Structural Estimation","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA16901"},{"id":"paper-conditional-logit-analysis-of-qualitative-choice-behavior-1","type":"paper","name":"Conditional Logit Analysis of Qualitative Choice Behavior","description":"Foundational paper deriving multinomial logit from random utility maximization; established modern discrete choice.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf"},{"id":"paper-automobile-prices-in-market-equilibrium-1","type":"paper","name":"Automobile Prices in Market Equilibrium","description":"Random coefficients demand with market-level data; workhorse for IO and empirical demand.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://ideas.repec.org/a/ecm/emetrp/v63y1995i4p841-90.html"},{"id":"paper-mixed-mnl-models-for-discrete-response","type":"paper","name":"Mixed MNL Models for Discrete Response","description":"Proves mixed logit approximates any random utility model; establishes simulation-based estimation.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://onlinelibrary.wiley.com/doi/abs/10.1002/1099-1255(200009/10)15:5%3C447::AID-JAE570%3E3.0.CO;2-1"},{"id":"paper-discrete-choice-methods-with-simulation-(2nd-ed.)","type":"paper","name":"Discrete Choice Methods with Simulation (2nd ed.)","description":"The definitive textbook covering logit variants and simulation methods; essential practitioner reference.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://eml.berkeley.edu/books/train1201.pdf"},{"id":"paper-valuing-new-goods-in-a-model-with-complementarity:-online-newspapers-1","type":"paper","name":"Valuing New Goods in a Model with Complementarity: Online Newspapers","description":"Mixed logit applied to digital products; estimates substitution between print and online news with cannibalization implications.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://www.jstor.org/stable/30034408"},{"id":"paper-what-drives-media-slant?-evidence-from-u.s.-daily-newspapers","type":"paper","name":"What Drives Media Slant? Evidence from U.S. Daily Newspapers","description":"Discrete choice demand model incorporating ideological content; demonstrates how consumer preferences drive product differentiation in information markets.","category":"Choice Models & Dynamic Choice > Discrete Choice (Logit, Mixed Logit)","url":"https://onlinelibrary.wiley.com/doi/10.3982/ECTA7195"},{"id":"paper-an-evaluation-cost-model-of-consideration-sets","type":"paper","name":"An Evaluation Cost Model of Consideration Sets","description":"Foundational model of consideration set formation as cost-benefit tradeoff.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://www.semanticscholar.org/paper/An-Evaluation-Cost-Model-of-Consideration-Sets-Hauser-Wernerfelt/200a6a2227cb565da7227e90092bd67e3d595fb0"},{"id":"paper-limited-information-and-advertising-in-the-u.s.-personal-computer-industry","type":"paper","name":"Limited Information and Advertising in the U.S. Personal Computer Industry","description":"Embeds limited information into BLP-style demand; shows advertising affects consideration sets.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA4158"},{"id":"paper-revealed-attention","type":"paper","name":"Revealed Attention","description":"Axiomatic foundation for choice with limited attention; introduces 'attention filters'.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://econweb.umd.edu/~masatlioglu/Revealed%20Attention.pdf"},{"id":"paper-costly-information-acquisition:-experimental-analysis-of-a-boundedly-rational-model","type":"paper","name":"Costly Information Acquisition: Experimental Analysis of a Boundedly Rational Model","description":"Experimental evidence on directed cognition and bounded rationality in search.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://www.aeaweb.org/articles?id=10.1257/aer.96.4.1043"},{"id":"paper-the-power-of-rankings:-quantifying-the-effect-of-rankings-on-online-consumer-search-and-purcha-1","type":"paper","name":"The Power of Rankings: Quantifying the Effect of Rankings on Online Consumer Search and Purchase Decisions","description":"Uses Expedia field experiment to causally identify position effects; shows rankings affect search behavior but not purchase conditional on search.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://pubsonline.informs.org/doi/10.1287/mksc.2017.1072"},{"id":"paper-quantifying-search-and-switching-costs-in-the-u.s.-auto-insurance-industry","type":"paper","name":"Quantifying Search and Switching Costs in the U.S. Auto Insurance Industry","description":"Develops integrated model of simultaneous search and switching costs using consideration set data; methodological template for separating search from switching frictions.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://www.jstor.org/stable/43551529"},{"id":"paper-product-differentiation,-search-costs,-and-competition-in-the-mutual-fund-industry:-a-case-stu","type":"paper","name":"Product Differentiation, Search Costs, and Competition in the Mutual Fund Industry: A Case Study of S&P 500 Index Funds","description":"Models search frictions for financially homogeneous products; explains fund proliferation and fee dispersion via information costs.","category":"Choice Models & Dynamic Choice > Consideration Sets & Attention","url":"https://www.jstor.org/stable/25098694"},{"id":"paper-optimal-replacement-of-gmc-bus-engines","type":"paper","name":"Optimal Replacement of GMC Bus Engines","description":"Introduces NFXP algorithm for dynamic discrete choice; establishes the structural framework.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://www.researchgate.net/publication/4815002_Optimal_Replacement_of_GMC_Bus_Engines_An_Empirical_Model_of_Harold_Zurcher"},{"id":"paper-conditional-choice-probabilities-and-the-estimation-of-dynamic-models-1","type":"paper","name":"Conditional Choice Probabilities and the Estimation of Dynamic Models","description":"CCP estimation recovering value functions without solving the full DP problem.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://academic.oup.com/restud/article-abstract/60/3/497/1570375"},{"id":"paper-structural-estimation-of-markov-decision-processes","type":"paper","name":"Structural Estimation of Markov Decision Processes","description":"Comprehensive survey of dynamic discrete choice methods and computational issues.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://www.sciencedirect.com/science/article/pii/S1573441205800205"},{"id":"paper-conditional-choice-probability-estimation-with-unobserved-heterogeneity","type":"paper","name":"Conditional Choice Probability Estimation with Unobserved Heterogeneity","description":"Extends CCP to unobserved heterogeneity; introduces 'finite dependence' for tractability.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://www.comlabgames.com/ramiller/ccp_econometrica.pdf"},{"id":"paper-dynamics-of-consumer-demand-for-new-durable-goods","type":"paper","name":"Dynamics of Consumer Demand for New Durable Goods","description":"DDC with forward-looking consumers, heterogeneity, and repeat purchases; estimated on digital camcorder data\u2014template for tech durable goods.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://www.journals.uchicago.edu/doi/10.1086/664717"},{"id":"paper-intertemporal-price-discrimination-with-forward-looking-consumers:-application-to-the-us-marke","type":"paper","name":"Intertemporal Price Discrimination with Forward-Looking Consumers: Application to the US Market for Console Video-Games","description":"Dynamic pricing with strategic consumers anticipating price declines; Markov-perfect equilibrium applied to video game consoles.","category":"Choice Models & Dynamic Choice > Dynamic Discrete Choice","url":"https://link.springer.com/article/10.1007/s11129-007-9027-x"},{"id":"paper-measuring-the-implications-of-sales-and-consumer-inventory-behavior","type":"paper","name":"Measuring the Implications of Sales and Consumer Inventory Behavior","description":"Structural model showing static demand estimates overstate own-price elasticities by 30% due to stockpiling.","category":"Choice Models & Dynamic Choice > Intertemporal Substitution","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00721.x"},{"id":"paper-intertemporal-price-discrimination-in-storable-goods-markets","type":"paper","name":"Intertemporal Price Discrimination in Storable Goods Markets","description":"Models optimal pricing when consumers stockpile; sales capture 25-30% of price discrimination profits.","category":"Choice Models & Dynamic Choice > Intertemporal Substitution","url":"https://www.aeaweb.org/articles?id=10.1257/aer.103.7.2722"},{"id":"paper-brand-and-quantity-choice-dynamics-under-price-uncertainty","type":"paper","name":"Brand and Quantity Choice Dynamics Under Price Uncertainty","description":"Dynamic structural model with Bayesian learning and forward-looking stockpiling behavior.","category":"Choice Models & Dynamic Choice > Intertemporal Substitution","url":"https://link.springer.com/article/10.1023/A:1024569421506"},{"id":"paper-binge-watching-and-advertising","type":"paper","name":"Binge Watching and Advertising","description":"Models streaming video consumption dynamics\u2014session continuation, series switching, and inter-session timing; first rigorous treatment of binge-watching economics using Hulu data.","category":"Choice Models & Dynamic Choice > Intertemporal Substitution","url":"https://journals.sagepub.com/doi/10.1509/jm.15.0108"},{"id":"paper-nudge:-improving-decisions-about-health,-wealth,-and-happiness","type":"paper","name":"Nudge: Improving Decisions About Health, Wealth, and Happiness","description":"Foundational book introducing 'libertarian paternalism' and choice architecture.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://psycnet.apa.org/record/2008-03730-000"},{"id":"paper-the-power-of-suggestion:-inertia-in-401(k)-participation-and-savings-behavior","type":"paper","name":"The Power of Suggestion: Inertia in 401(k) Participation and Savings Behavior","description":"Auto-enrollment increases 401(k) participation from 49% to 86%; canonical default effects evidence.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://academic.oup.com/qje/article-abstract/116/4/1149/1903159"},{"id":"paper-save-more-tomorrow:-using-behavioral-economics-to-increase-employee-saving","type":"paper","name":"Save More Tomorrow: Using Behavioral Economics to Increase Employee Saving","description":"Commitment device increasing savings from 3.5% to 13.6% in 40 months.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/262131"},{"id":"paper-optimal-defaults-and-active-decisions","type":"paper","name":"Optimal Defaults and Active Decisions","description":"Theoretical framework for optimal default design under heterogeneous preferences.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC2798815/"},{"id":"paper-do-defaults-save-lives?","type":"paper","name":"Do Defaults Save Lives?","description":"Organ donation rates dramatically higher in opt-out countries; demonstrates default power beyond savings.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://www.science.org/doi/10.1126/science.1091721"},{"id":"paper-the-welfare-effects-of-social-media","type":"paper","name":"The Welfare Effects of Social Media","description":"Large-scale RCT deactivating Facebook; finds deactivation increases well-being and reduces news consumption\u2014questions platform welfare measurement.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20190658"},{"id":"paper-digital-addiction","type":"paper","name":"Digital Addiction","description":"Economic model of digital addiction with habit formation and self-control; estimates 31% of social media use attributable to self-control problems.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://www.aeaweb.org/articles?id=10.1257/aer.20210867"},{"id":"paper-privacy-regulation-and-online-advertising-1","type":"paper","name":"Privacy Regulation and Online Advertising","description":"Studies EU privacy directive's effects; shows opt-in defaults reduced ad effectiveness by 65%\u2014demonstrates default effects in digital advertising markets.","category":"Choice Models & Dynamic Choice > Choice Architecture & Nudges","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.1100.1246"},{"id":"paper-optimal-search-for-the-best-alternative","type":"paper","name":"Optimal Search for the Best Alternative","description":"The 'Pandora's Box' paper introducing reservation value rule for optimal sequential search\u2014theoretical foundation for all empirical search models.","category":"Choice Models & Dynamic Choice > Search & Sequential Choice","url":"https://onlinelibrary.wiley.com/doi/10.2307/1912562"},{"id":"paper-using-price-distributions-to-estimate-search-costs-1","type":"paper","name":"Using Price Distributions to Estimate Search Costs","description":"Develops methodology to estimate search cost distributions from equilibrium price data alone; identification from search model restrictions.","category":"Choice Models & Dynamic Choice > Search & Sequential Choice","url":"https://www.jstor.org/stable/25046317"},{"id":"paper-testing-models-of-consumer-search-using-data-on-web-browsing-and-purchasing-behavior-1","type":"paper","name":"Testing Models of Consumer Search Using Data on Web Browsing and Purchasing Behavior","description":"Uses e-commerce clickstream data to test sequential vs. fixed-sample search; estimates search costs in online book market.","category":"Choice Models & Dynamic Choice > Search & Sequential Choice","url":"https://www.aeaweb.org/articles?id=10.1257/aer.102.6.2955"},{"id":"paper-the-probit-choice-model-under-sequential-search-with-an-application-to-online-retailing","type":"paper","name":"The Probit Choice Model Under Sequential Search with an Application to Online Retailing","description":"Tractable probit search model combining Weitzman's framework with demand estimation; applied to Amazon camcorder data.","category":"Choice Models & Dynamic Choice > Search & Sequential Choice","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2016.2507"},{"id":"paper-decision-making-under-uncertainty:-capturing-dynamic-brand-choice-processes-in-turbulent-consu","type":"paper","name":"Decision-Making Under Uncertainty: Capturing Dynamic Brand Choice Processes in Turbulent Consumer Goods Markets","description":"Seminal paper introducing Bayesian learning for consumer choice under quality uncertainty; consumers update beliefs from experience and advertising signals.","category":"Choice Models & Dynamic Choice > Learning & Experimentation in Choice","url":"https://pubsonline.informs.org/doi/10.1287/mksc.15.1.1"},{"id":"paper-empirically-distinguishing-informative-and-prestige-effects-of-advertising","type":"paper","name":"Empirically Distinguishing Informative and Prestige Effects of Advertising","description":"Clever identification strategy separating informative from prestige advertising effects using experience goods; informative ads affect inexperienced consumers differently.","category":"Choice Models & Dynamic Choice > Learning & Experimentation in Choice","url":"https://www.jstor.org/stable/2692307"},{"id":"paper-a-dynamic-model-of-brand-choice-when-price-and-advertising-signal-product-quality","type":"paper","name":"A Dynamic Model of Brand Choice When Price and Advertising Signal Product Quality","description":"Integrates multiple quality signals (price, advertising frequency, content, experience) into unified Bayesian framework; shows promotions can erode brand equity.","category":"Choice Models & Dynamic Choice > Learning & Experimentation in Choice","url":"https://pubsonline.informs.org/doi/10.1287/mksc.1070.0327"},{"id":"paper-learning-models:-an-assessment-of-progress,-challenges-and-new-developments","type":"paper","name":"Learning Models: An Assessment of Progress, Challenges and New Developments","description":"Comprehensive survey covering identification, estimation, and extensions including forgetting and social learning\u2014essential methodological reference.","category":"Choice Models & Dynamic Choice > Learning & Experimentation in Choice","url":"https://pubsonline.informs.org/doi/10.1287/mksc.1120.0755"},{"id":"paper-blockbuster-culture's-next-rise-or-fall:-the-impact-of-recommender-systems-on-sales-diversity","type":"paper","name":"Blockbuster Culture's Next Rise or Fall: The Impact of Recommender Systems on Sales Diversity","description":"Shows collaborative filtering exhibits popularity bias through rich-get-richer effects; recommendations can reduce, not increase, sales diversity.","category":"Choice Models & Dynamic Choice > Recommendation Systems & Algorithmic Choice","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.1080.0974"},{"id":"paper-will-the-global-village-fracture-into-tribes?-recommender-systems-and-their-effects-on-consume","type":"paper","name":"Will the Global Village Fracture into Tribes? Recommender Systems and Their Effects on Consumer Fragmentation","description":"Contrary to fragmentation fears, finds personalization increases commonality across consumers through volume and mix effects.","category":"Choice Models & Dynamic Choice > Recommendation Systems & Algorithmic Choice","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2013.1808"},{"id":"paper-do-recommender-systems-manipulate-consumer-preferences?-a-study-of-anchoring-effects","type":"paper","name":"Do Recommender Systems Manipulate Consumer Preferences? A Study of Anchoring Effects","description":"Experiments show recommendations serve as anchors influencing users' own preference ratings; creates feedback loops affecting future recommendations.","category":"Choice Models & Dynamic Choice > Recommendation Systems & Algorithmic Choice","url":"https://pubsonline.informs.org/doi/10.1287/isre.2013.0497"},{"id":"paper-understanding-echo-chambers-and-filter-bubbles:-the-impact-of-social-media-on-diversification-","type":"paper","name":"Understanding Echo Chambers and Filter Bubbles: The Impact of Social Media on Diversification and Partisan Shifts in News Consumption","description":"Using 4+ years of browsing data from 200,000+ U.S. adults, finds differentiated platform effects: Facebook increases diversity but partisan shift; Twitter shows minimal effects.","category":"Choice Models & Dynamic Choice > Recommendation Systems & Algorithmic Choice","url":"https://misq.umn.edu/understanding-echo-chambers-and-filter-bubbles-the-impact-of-social-media-on-diversification-and-partisan-shifts-in-news-consumption.html"},{"id":"paper-algorithmic-effects-on-the-diversity-of-consumption-on-spotify","type":"paper","name":"Algorithmic Effects on the Diversity of Consumption on Spotify","description":"Field experiments show consumption diversity correlates with retention, yet algorithmic recommendations push toward less diverse listening\u2014identifies core platform design tension.","category":"Choice Models & Dynamic Choice > Recommendation Systems & Algorithmic Choice","url":"https://dl.acm.org/doi/10.1145/3366423.3380281"},{"id":"paper-competition-when-consumers-have-switching-costs:-an-overview-with-applications-to-industrial-o","type":"paper","name":"Competition When Consumers Have Switching Costs: An Overview with Applications to Industrial Organization, Macroeconomics, and International Trade","description":"Seminal survey establishing theoretical framework for how switching costs create market share dependence and affect competitive dynamics.","category":"Choice Models & Dynamic Choice > Switching Costs & Platform Lock-in","url":"https://academic.oup.com/restud/article/62/4/515/1577097"},{"id":"paper-state-dependence-and-alternative-explanations-for-consumer-inertia-1","type":"paper","name":"State Dependence and Alternative Explanations for Consumer Inertia","description":"Demonstrates identification of structural state dependence from spurious heterogeneity using flexible semi-parametric methods; distinguishes true loyalty from heterogeneity.","category":"Choice Models & Dynamic Choice > Switching Costs & Platform Lock-in","url":"https://www.jstor.org/stable/25651509"},{"id":"paper-adverse-selection-and-inertia-in-health-insurance-markets:-when-nudging-hurts","type":"paper","name":"Adverse Selection and Inertia in Health Insurance Markets: When Nudging Hurts","description":"Quantifies massive switching costs ($2,000+) using natural experiment; shows reducing inertia can backfire by exacerbating adverse selection.","category":"Choice Models & Dynamic Choice > Switching Costs & Platform Lock-in","url":"https://www.aeaweb.org/articles?id=10.1257/aer.103.7.2643"},{"id":"paper-competition-in-two-sided-markets-3","type":"paper","name":"Competition in Two-Sided Markets","description":"Foundational model distinguishing single-homing from multi-homing; introduces 'competitive bottlenecks' explaining platform lock-in dynamics.","category":"Choice Models & Dynamic Choice > Switching Costs & Platform Lock-in","url":"https://www.jstor.org/stable/25046346"},{"id":"paper-a-simple-model-of-herd-behavior","type":"paper","name":"A Simple Model of Herd Behavior","description":"Classic model where rational agents ignore private information and follow predecessors, leading to potentially inefficient herding cascades.","category":"Choice Models & Dynamic Choice > Social Influence & Peer Effects","url":"https://www.jstor.org/stable/2118364"},{"id":"paper-a-theory-of-fads,-fashion,-custom,-and-cultural-change-as-informational-cascades","type":"paper","name":"A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades","description":"Introduces informational cascades where optimal behavior is to follow predecessors; explains fragility of mass behaviors and sudden social shifts.","category":"Choice Models & Dynamic Choice > Social Influence & Peer Effects","url":"https://www.journals.uchicago.edu/doi/10.1086/261849"},{"id":"paper-identification-of-endogenous-social-effects:-the-reflection-problem","type":"paper","name":"Identification of Endogenous Social Effects: The Reflection Problem","description":"Foundational econometrics paper showing why peer effects cannot be identified from behavioral data alone\u2014the 'reflection problem' from simultaneity.","category":"Choice Models & Dynamic Choice > Social Influence & Peer Effects","url":"https://academic.oup.com/restud/article/60/3/531/1570385"},{"id":"paper-creating-social-contagion-through-viral-product-design:-a-randomized-trial-of-peer-influence-i-1","type":"paper","name":"Creating Social Contagion Through Viral Product Design: A Randomized Trial of Peer Influence in Networks","description":"Landmark RCT with 1.4 million Facebook users identifying causal peer influence; passive-broadcast features generate 246% increase in peer adoption.","category":"Choice Models & Dynamic Choice > Social Influence & Peer Effects","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.1110.1421"},{"id":"paper-financial-ratios,-discriminant-analysis-and-the-prediction-of-corporate-bankruptcy","type":"paper","name":"Financial Ratios, Discriminant Analysis and the Prediction of Corporate Bankruptcy","description":"The Z-score model using MDA; 10,000+ citations and still the benchmark for bankruptcy prediction.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1968.tb00843.x"},{"id":"paper-financial-ratios-and-the-probabilistic-prediction-of-bankruptcy","type":"paper","name":"Financial Ratios and the Probabilistic Prediction of Bankruptcy","description":"Introduced logistic regression to default prediction; established logit as industry workhorse.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://www.jstor.org/stable/2490395"},{"id":"paper-on-the-pricing-of-corporate-debt:-the-risk-structure-of-interest-rates","type":"paper","name":"On the Pricing of Corporate Debt: The Risk Structure of Interest Rates","description":"Structural model treating equity as call option; foundation for KMV/Moody's EDF.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1974.tb03058.x"},{"id":"paper-credit-rationing-in-markets-with-imperfect-information","type":"paper","name":"Credit Rationing in Markets with Imperfect Information","description":"Explains equilibrium credit rationing from adverse selection; essential for lending market theory.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://www.jstor.org/stable/1802787"},{"id":"paper-xgboost:-a-scalable-tree-boosting-system","type":"paper","name":"XGBoost: A Scalable Tree Boosting System","description":"Dominant ML algorithm for credit scoring; consistently outperforms logistic regression.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://arxiv.org/abs/1603.02754"},{"id":"paper-benchmarking-state-of-the-art-classification-algorithms-for-credit-scoring:-an-update-of-resea","type":"paper","name":"Benchmarking State-of-the-Art Classification Algorithms for Credit Scoring: An Update of Research","description":"Definitive benchmark comparing 41 classifiers across 8 datasets; establishes that ensemble methods outperform logistic regression.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://www.sciencedirect.com/science/article/pii/S037722171500543X"},{"id":"paper-consumer-credit-risk-models-via-machine-learning-algorithms","type":"paper","name":"Consumer Credit-Risk Models Via Machine-Learning Algorithms","description":"First major paper showing transaction data + ML dramatically improves default prediction; estimates 6-25% cost savings.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://www.sciencedirect.com/science/article/pii/S0378426610002372"},{"id":"paper-risk-and-risk-management-in-the-credit-card-industry","type":"paper","name":"Risk and Risk Management in the Credit Card Industry","description":"Uses account-level data from 6 major US banks; finds substantial heterogeneity\u2014no single model works for all.","category":"Credit & Lending > Credit Scoring & Risk Models","url":"https://www.sciencedirect.com/science/article/pii/S0378426616300681"},{"id":"paper-mortgage-lending-in-boston:-interpreting-hmda-data","type":"paper","name":"Mortgage Lending in Boston: Interpreting HMDA Data","description":"Seminal Boston Fed study documenting lending discrimination; foundational for fair lending enforcement.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://www.jstor.org/stable/2118254"},{"id":"paper-consumer-lending-discrimination-in-the-fintech-era","type":"paper","name":"Consumer-Lending Discrimination in the FinTech Era","description":"Latinx/African-American borrowers pay 7.9 bps more; FinTech reduces but doesn't eliminate discrimination.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://www.nber.org/papers/w25943"},{"id":"paper-predictably-unequal?-the-effects-of-machine-learning-on-credit-markets","type":"paper","name":"Predictably Unequal? The Effects of Machine Learning on Credit Markets","description":"ML models create distributional impacts favoring advantaged groups even without using race.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3072038"},{"id":"paper-how-costly-is-noise?-data-and-disparities-in-consumer-credit","type":"paper","name":"How Costly is Noise? Data and Disparities in Consumer Credit","description":"Credit scores are noisier for minority borrowers; quantifies how data disparities translate to lending disparities.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3504921"},{"id":"paper-inherent-trade-offs-in-the-fair-determination-of-risk-scores","type":"paper","name":"Inherent Trade-Offs in the Fair Determination of Risk Scores","description":"Proves impossibility of satisfying calibration and error rate parity simultaneously\u2014THE foundational fairness theorem.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://arxiv.org/abs/1609.05807"},{"id":"paper-fair-prediction-with-disparate-impact:-a-study-of-bias-in-recidivism-prediction-instruments","type":"paper","name":"Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments","description":"Independently derives impossibility result with explicit disparate impact focus; addressed ProPublica/COMPAS controversy.","category":"Credit & Lending > Fair Lending & Disparate Impact","url":"https://www.liebertpub.com/doi/10.1089/big.2016.0047"},{"id":"paper-the-failure-of-competition-in-the-credit-card-market","type":"paper","name":"The Failure of Competition in the Credit Card Market","description":"Documented sticky credit card rates; introduced adverse selection explanations establishing the field.","category":"Credit & Lending > Pricing Credit Products","url":"https://econ.umd.edu/sites/www.econ.umd.edu/files/pubs/aerhigh.pdf"},{"id":"paper-adverse-selection-in-the-credit-card-market","type":"paper","name":"Adverse Selection in the Credit Card Market","description":"First direct evidence of adverse selection using randomized solicitations.","category":"Credit & Lending > Pricing Credit Products","url":"https://jfhoude.wiscweb.wisc.edu/wp-content/uploads/sites/769/2019/09/Asubel_wp1999.pdf"},{"id":"paper-estimating-welfare-in-insurance-markets-using-variation-in-prices","type":"paper","name":"Estimating Welfare in Insurance Markets Using Variation in Prices","description":"Demand-and-cost curve framework for analyzing selection; widely applied to credit markets.","category":"Credit & Lending > Pricing Credit Products","url":"https://www.nber.org/papers/w13839"},{"id":"paper-selection-in-insurance-markets:-theory-and-empirics-in-pictures","type":"paper","name":"Selection in Insurance Markets: Theory and Empirics in Pictures","description":"Intuitive graphical framework for understanding selection and welfare in credit/insurance.","category":"Credit & Lending > Pricing Credit Products","url":"https://www.aeaweb.org/articles?id=10.1257/jep.25.1.115"},{"id":"paper-time-to-default-in-credit-scoring-using-survival-analysis:-a-benchmark-study","type":"paper","name":"Time to Default in Credit Scoring Using Survival Analysis: A Benchmark Study","description":"Benchmark comparing survival methods for WHEN default occurs\u2014critical for IFRS 9 and lifetime expected credit loss.","category":"Credit & Lending > Pricing Credit Products","url":"https://www.tandfonline.com/doi/abs/10.1080/01605682.2017.1390527"},{"id":"paper-an-empirical-analysis-of-personal-bankruptcy-and-delinquency","type":"paper","name":"An Empirical Analysis of Personal Bankruptcy and Delinquency","description":"Landmark study finding increased default propensity independent of risk composition; suggests declining stigma.","category":"Credit & Lending > Collections & Recovery","url":"https://www.nber.org/papers/w8409"},{"id":"paper-what-do-we-know-about-loss-given-default?","type":"paper","name":"What Do We Know About Loss Given Default?","description":"Comprehensive LGD estimation review; go-to reference for Basel II/III recovery models.","category":"Credit & Lending > Collections & Recovery","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=525702"},{"id":"paper-losscalc:-model-for-predicting-loss-given-default","type":"paper","name":"LossCalc: Model for Predicting Loss Given Default","description":"Industry-standard LGD model using debt type, seniority, and macro factors.","category":"Credit & Lending > Collections & Recovery","url":"http://www.rogermstein.com/wp-content/uploads/losscalc.pdf"},{"id":"paper-measuring-lgd-on-commercial-loans:-an-18-year-internal-study","type":"paper","name":"Measuring LGD on Commercial Loans: An 18-Year Internal Study","description":"JPMorgan Chase's 18-year study of 3,761 defaults establishing key LGD drivers.","category":"Credit & Lending > Collections & Recovery","url":"https://www.researchgate.net/publication/228217633_Measuring_LGD_on_Commercial_Loans_An_18-Year_Internal_Study"},{"id":"paper-behavior-revealed-in-mobile-phone-usage-predicts-credit-repayment","type":"paper","name":"Behavior Revealed in Mobile Phone Usage Predicts Credit Repayment","description":"Mobile behavioral data outperforms credit bureaus for thin-file borrowers; foundational fintech paper.","category":"Credit & Lending > Alternative Data","url":"https://academic.oup.com/wber/article/34/3/618/5622690"},{"id":"paper-invisible-primes:-fintech-lending-with-alternative-data","type":"paper","name":"Invisible Primes: Fintech Lending with Alternative Data","description":"Alternative data identifies 'invisible primes' overlooked by traditional scores.","category":"Credit & Lending > Alternative Data","url":"https://www.nber.org/papers/w29840"},{"id":"paper-predicting-poverty-and-wealth-from-mobile-phone-metadata","type":"paper","name":"Predicting Poverty and Wealth from Mobile Phone Metadata","description":"Mobile metadata predicts socioeconomic status; opened mobile-based credit scoring in developing countries.","category":"Credit & Lending > Alternative Data","url":"https://science.sciencemag.org/content/350/6264/1073"},{"id":"paper-use-of-alternative-data-in-credit-process","type":"paper","name":"Use of Alternative Data in Credit Process","description":"Documents 45 million 'credit invisible' Americans; foundational regulatory framework.","category":"Credit & Lending > Alternative Data","url":"https://www.consumerfinance.gov/about-us/newsroom/cfpb-explores-impact-alternative-data-credit-access-consumers-who-are-credit-invisible/"},{"id":"paper-on-the-rise-of-fintechs:-credit-scoring-using-digital-footprints","type":"paper","name":"On the Rise of FinTechs: Credit Scoring Using Digital Footprints","description":"Digital footprints (device, email domain, typing) match credit bureau accuracy; foundational fintech credit study.","category":"Credit & Lending > Alternative Data","url":"https://academic.oup.com/rfs/article/33/7/2845/5568311"},{"id":"paper-smote:-synthetic-minority-over-sampling-technique","type":"paper","name":"SMOTE: Synthetic Minority Over-sampling Technique","description":"The foundational imbalanced-learning method used in virtually every fraud detection system.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://arxiv.org/abs/1106.1813"},{"id":"paper-statistical-fraud,-credit-and-claim-risk:-a-review","type":"paper","name":"Statistical Fraud, Credit and Claim Risk: A Review","description":"Authoritative taxonomy of fraud detection methods; still cited for conceptual foundations.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://projecteuclid.org/journals/statistical-science/volume-17/issue-3/Statistical-Fraud-Detection--A-Review/10.1214/ss/1042727940.full"},{"id":"paper-anomaly-detection:-a-survey","type":"paper","name":"Anomaly Detection: A Survey","description":"Definitive survey covering statistical, ML, and proximity-based anomaly methods.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://dl.acm.org/doi/10.1145/1541880.1541882"},{"id":"paper-credit-card-fraud,-credit-and-claim-risk:-a-realistic-modeling-and-a-novel-learning-strategy","type":"paper","name":"Credit Card Fraud, Credit and Claim Risk: A Realistic Modeling and a Novel Learning Strategy","description":"Addresses realistic fraud detection challenges: class imbalance, concept drift, and delayed feedback.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://ieeexplore.ieee.org/document/8038008"},{"id":"paper-feature-engineering-strategies-for-credit-card-fraud,-credit-and-claim-risk","type":"paper","name":"Feature Engineering Strategies for Credit Card Fraud, Credit and Claim Risk","description":"Transaction aggregation features improve fraud detection by 40%; widely adopted in industry.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://www.sciencedirect.com/science/article/abs/pii/S0957417415008276"},{"id":"paper-graph-based-anomaly-detection-and-description:-a-survey","type":"paper","name":"Graph-Based Anomaly Detection and Description: A Survey","description":"Survey on using graph structure to detect fraud rings and coordinated attacks.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://link.springer.com/article/10.1007/s10618-014-0365-y"},{"id":"paper-apate:-a-novel-approach-for-automated-credit-card-transaction-fraud,-credit-and-claim-risk-usi","type":"paper","name":"APATE: A Novel Approach for Automated Credit Card Transaction Fraud, Credit and Claim Risk Using Network-Based Extensions","description":"Network propagation improves fraud detection by leveraging transaction graph structure.","category":"Credit & Lending > Fraud, Credit and Claim Risk & Anomaly Detection","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167923615001645"},{"id":"paper-nesting-classical-actuarial-models-into-neural-networks","type":"paper","name":"Nesting Classical Actuarial Models into Neural Networks","description":"Embedding GLMs into neural networks improves insurance pricing while maintaining interpretability.","category":"Credit & Lending > Insurance Claims & Actuarial ML","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3320525"},{"id":"paper-data-driven-binning-for-insurance-tariffs","type":"paper","name":"Data Driven Binning for Insurance Tariffs","description":"Evolutionary trees optimize premium segmentation while respecting regulatory constraints.","category":"Credit & Lending > Insurance Claims & Actuarial ML","url":"https://www.tandfonline.com/doi/abs/10.1080/03461238.2018.1429300"},{"id":"paper-detecting-insurance-fraud-using-supervised-and-unsupervised-machine-learning","type":"paper","name":"Detecting Insurance Fraud Using Supervised and Unsupervised Machine Learning","description":"Comprehensive comparison of fraud detection methods for insurance claims.","category":"Credit & Lending > Insurance Claims & Actuarial ML","url":"https://link.springer.com/article/10.1057/s41270-022-00166-y"},{"id":"paper-claims-frequency-modeling-using-telematics-car-driving-data","type":"paper","name":"Claims Frequency Modeling Using Telematics Car Driving Data","description":"Telematics data (speed, braking) improves claims prediction; foundational usage-based insurance paper.","category":"Credit & Lending > Insurance Claims & Actuarial ML","url":"https://www.tandfonline.com/doi/abs/10.1080/03461238.2018.1523068"},{"id":"paper-neural-networks-applied-to-chain-ladder-reserving","type":"paper","name":"Neural Networks Applied to Chain-Ladder Reserving","description":"Neural networks improve reserve estimation over traditional chain-ladder methods.","category":"Credit & Lending > Insurance Claims & Actuarial ML","url":"https://www.cambridge.org/core/journals/european-actuarial-journal/article/neural-networks-applied-to-chainladder-reserving/A8B05E22D5F29F0AC35E76D8A76FE946"},{"id":"paper-the-dynamics-of-seller-reputation:-evidence-from-ebay","type":"paper","name":"The Dynamics of Seller Reputation: Evidence from eBay","description":"Foundational empirical study of reputation dynamics and their impact on seller behavior.","category":"Credit & Lending > Safety & Trust Scoring on Platforms","url":"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6451.2010.00405.x"},{"id":"paper-the-limits-of-reputation-in-platform-markets:-an-empirical-analysis-and-field-experiment-1","type":"paper","name":"The Limits of Reputation in Platform Markets: An Empirical Analysis and Field Experiment","description":"Field experiment showing reputation inflation and limits of feedback systems.","category":"Credit & Lending > Safety & Trust Scoring on Platforms","url":"https://www.nber.org/papers/w20830"},{"id":"paper-reputation-and-feedback-systems-in-online-platform-markets","type":"paper","name":"Reputation and Feedback Systems in Online Platform Markets","description":"Comprehensive survey of reputation system design and effectiveness in platforms.","category":"Credit & Lending > Safety & Trust Scoring on Platforms","url":"https://www.annualreviews.org/doi/abs/10.1146/annurev-economics-080315-015325"},{"id":"paper-the-value-of-reputation-information:-evidence-from-a-natural-experiment","type":"paper","name":"The Value of Reputation Information: Evidence from a Natural Experiment","description":"Natural experiment measuring the causal impact of reputation visibility on market outcomes.","category":"Credit & Lending > Safety & Trust Scoring on Platforms","url":"https://www.nber.org/papers/w23373"},{"id":"paper-a-unified-approach-to-interpreting-model-predictions-(shap)","type":"paper","name":"A Unified Approach to Interpreting Model Predictions (SHAP)","description":"SHAP values unify feature attribution methods; now standard for credit model explanations.","category":"Credit & Lending > Explainability & Regulatory ML","url":"https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html"},{"id":"paper-'why-should-i-trust-you?':-explaining-the-predictions-of-any-classifier-(lime)","type":"paper","name":"'Why Should I Trust You?': Explaining the Predictions of Any Classifier (LIME)","description":"Local interpretable explanations for any black-box model; widely used for adverse action notices.","category":"Credit & Lending > Explainability & Regulatory ML","url":"https://arxiv.org/abs/1602.04938"},{"id":"paper-stop-explaining-black-box-machine-learning-models-for-high-stakes-decisions-and-use-interpreta","type":"paper","name":"Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead","description":"Argues interpretable models match black-box accuracy for credit; influential regulatory perspective.","category":"Credit & Lending > Explainability & Regulatory ML","url":"https://www.nature.com/articles/s42256-019-0048-x"},{"id":"paper-intelligible-models-for-healthcare:-predicting-pneumonia-risk-and-hospital-30-day-readmission-","type":"paper","name":"Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission (GA\u00b2M)","description":"Generalized additive models with interactions; template for interpretable credit scoring.","category":"Credit & Lending > Explainability & Regulatory ML","url":"https://dl.acm.org/doi/10.1145/2783258.2788613"},{"id":"paper-a-survey-on-concept-drift-adaptation","type":"paper","name":"A Survey on Concept Drift Adaptation","description":"Comprehensive survey on detecting and adapting to changing data distributions in credit.","category":"Credit & Lending > Real-time Decisioning & Deployment","url":"https://dl.acm.org/doi/10.1145/2523813"},{"id":"paper-selection-bias-in-credit-scorecard-evaluation","type":"paper","name":"Selection Bias in Credit Scorecard Evaluation","description":"Identifies sample selection bias in scorecard validation; essential for production monitoring.","category":"Credit & Lending > Real-time Decisioning & Deployment","url":"https://www.tandfonline.com/doi/abs/10.1057/jors.2013.55"},{"id":"paper-reject-inference-methods-in-credit-scoring:-a-systematic-review-and-new-approaches","type":"paper","name":"Reject Inference Methods in Credit Scoring: A Systematic Review and New Approaches","description":"Reviews and advances reject inference methods for handling missing data from declined applications.","category":"Credit & Lending > Real-time Decisioning & Deployment","url":"https://www.sciencedirect.com/science/article/abs/pii/S037872062100178X"},{"id":"paper-streaming-active-learning-strategies-for-real-life-credit-card-fraud,-credit-and-claim-risk","type":"paper","name":"Streaming Active Learning Strategies for Real-Life Credit Card Fraud, Credit and Claim Risk","description":"Active learning reduces labeling costs for streaming fraud detection systems.","category":"Credit & Lending > Real-time Decisioning & Deployment","url":"https://ieeexplore.ieee.org/document/8457256"},{"id":"paper-isolation-forest","type":"paper","name":"Isolation Forest","description":"Tree-based anomaly isolation achieving O(n log n) complexity; the industry standard for fraud detection.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://ieeexplore.ieee.org/document/4781136"},{"id":"paper-lof:-identifying-density-based-local-outliers","type":"paper","name":"LOF: Identifying Density-Based Local Outliers","description":"Introduced Local Outlier Factor assigning continuous 'degree of outlierness' for variable-density anomaly detection.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/335191.335388"},{"id":"paper-anomaly-detection:-a-survey-1","type":"paper","name":"Anomaly Detection: A Survey","description":"Comprehensive taxonomy covering classification, nearest-neighbor, clustering, and statistical approaches; 8,000+ citations.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/1541880.1541882"},{"id":"paper-isolation-based-anomaly-detection","type":"paper","name":"Isolation-Based Anomaly Detection","description":"Extended journal version with theoretical analysis; handles high-dimensional masking and swamping effects.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/2133360.2133363"},{"id":"paper-estimating-the-support-of-a-high-dimensional-distribution-(one-class-svm)","type":"paper","name":"Estimating the Support of a High-Dimensional Distribution (One-Class SVM)","description":"One-class SVM for novelty detection; foundational method for fraud detection when only normal data is available.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://direct.mit.edu/neco/article/13/7/1443/6579"},{"id":"paper-deep-learning-for-anomaly-detection:-a-review","type":"paper","name":"Deep Learning for Anomaly Detection: A Review","description":"Comprehensive survey of deep learning anomaly detection; covers autoencoders, GANs, and self-supervised approaches.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/3439950"},{"id":"paper-a-survey-of-credit-card-fraud,-credit-and-claim-risk-techniques:-data-and-technique-oriented-p","type":"paper","name":"A Survey of Credit Card Fraud, Credit and Claim Risk Techniques: Data and Technique Oriented Perspective","description":"Survey comparing neural networks, genetic algorithms, and expert systems for credit card fraud detection.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://www.sciencedirect.com/science/article/abs/pii/S1566253507000863"},{"id":"paper-credit-card-fraud,-credit-and-claim-risk:-a-realistic-modeling-and-a-novel-learning-strategy-1","type":"paper","name":"Credit Card Fraud, Credit and Claim Risk: A Realistic Modeling and a Novel Learning Strategy","description":"Addresses realistic fraud challenges: extreme class imbalance, concept drift, and delayed feedback loops.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://ieeexplore.ieee.org/document/8038008"},{"id":"paper-fraud,-credit-and-claim-risk-in-healthcare-claims-using-machine-learning:-a-systematic-review","type":"paper","name":"Fraud, Credit and Claim Risk in Healthcare Claims Using Machine Learning: A Systematic Review","description":"Comprehensive review analyzing ML techniques for health insurance fraud over two decades.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://www.sciencedirect.com/science/article/pii/S0933365724003038"},{"id":"paper-insurance-fraud,-credit-and-claim-risk:-a-statistically-validated-network-approach","type":"paper","name":"Insurance Fraud, Credit and Claim Risk: A Statistically Validated Network Approach","description":"Network-based approach using statistically validated networks to detect coordinated fraud rings.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://onlinelibrary.wiley.com/doi/10.1111/jori.12421"},{"id":"paper-detecting-insurance-fraud-using-supervised-and-unsupervised-machine-learning-1","type":"paper","name":"Detecting Insurance Fraud Using Supervised and Unsupervised Machine Learning","description":"Field experiment showing supervised and unsupervised methods are complements, not substitutes.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://onlinelibrary.wiley.com/doi/10.1111/jori.12427"},{"id":"paper-oddball:-spotting-anomalies-in-weighted-graphs","type":"paper","name":"OddBall: Spotting Anomalies in Weighted Graphs","description":"Detects anomalies in weighted graphs using egonet features; foundational for fraud ring detection.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://www.cs.cmu.edu/~lakoglu/papers/pakdd10.pdf"},{"id":"paper-fraudar:-bounding-graph-fraud-in-the-face-of-camouflage","type":"paper","name":"FRAUDAR: Bounding Graph Fraud in the Face of Camouflage","description":"Detects dense subgraphs even when fraudsters add random edges to camouflage; handles lockstep behavior.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/2939672.2939747"},{"id":"paper-heterogeneous-graph-neural-networks-for-malicious-account-detection","type":"paper","name":"Heterogeneous Graph Neural Networks for Malicious Account Detection","description":"GEM model using heterogeneous graphs (users, devices, transactions) for Alipay fraud detection.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/3269206.3272010"},{"id":"paper-netwalk:-a-flexible-deep-embedding-approach-for-anomaly-detection-in-dynamic-networks","type":"paper","name":"NetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks","description":"Dynamic network embeddings for streaming anomaly detection; updates in O(1) per edge.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://dl.acm.org/doi/10.1145/3219819.3220024"},{"id":"paper-botrgcn:-twitter-bot-detection-with-relational-graph-convolutional-networks","type":"paper","name":"BotRGCN: Twitter Bot Detection with Relational Graph Convolutional Networks","description":"Relational GCN exploiting follower/friend graphs achieves SOTA on bot detection benchmarks.","category":"Trust & Safety > Fraud, Credit and Claim Risk","url":"https://arxiv.org/abs/2106.13092"},{"id":"paper-online-human-bot-interactions:-detection,-estimation,-and-characterization","type":"paper","name":"Online Human-Bot Interactions: Detection, Estimation, and Characterization","description":"Foundational Botometer paper; random forest on 1,000+ features estimating 9-15% of Twitter accounts are bots.","category":"Trust & Safety > Spam & Abuse","url":"https://ojs.aaai.org/index.php/ICWSM/article/view/14871"},{"id":"paper-the-rise-of-social-bots","type":"paper","name":"The Rise of Social Bots","description":"Seminal paper defining social bots, detection challenges, and policy implications for platform manipulation.","category":"Trust & Safety > Spam & Abuse","url":"https://dl.acm.org/doi/10.1145/2818717"},{"id":"paper-botometer-101:-social-bot-practicum-for-computational-social-scientists","type":"paper","name":"Botometer 101: Social Bot Practicum for Computational Social Scientists","description":"Practitioner guide for Botometer v4 with CAP scores, threshold selection, and case study methodology.","category":"Trust & Safety > Spam & Abuse","url":"https://link.springer.com/article/10.1007/s42001-022-00177-5"},{"id":"paper-scalable-and-generalizable-social-bot-detection-through-data-selection","type":"paper","name":"Scalable and Generalizable Social Bot Detection through Data Selection","description":"Addresses cross-dataset generalization using ensemble of specialized classifiers.","category":"Trust & Safety > Spam & Abuse","url":"https://ojs.aaai.org/index.php/AAAI/article/view/5460"},{"id":"paper-fake-it-till-you-make-it:-reputation,-competition,-and-yelp-review-fraud-1","type":"paper","name":"Fake It Till You Make It: Reputation, Competition, and Yelp Review Fraud","description":"First large-scale study of fake reviews; 16% of Yelp reviews flagged as fake, increasing with competition.","category":"Trust & Safety > Spam & Abuse","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2015.2304"},{"id":"paper-promotional-reviews:-an-empirical-investigation-of-online-review-manipulation-1","type":"paper","name":"Promotional Reviews: An Empirical Investigation of Online Review Manipulation","description":"Compares TripAdvisor vs Expedia reviews; finds review manipulation concentrated among independent hotels.","category":"Trust & Safety > Spam & Abuse","url":"https://www.aeaweb.org/articles?id=10.1257/aer.104.8.2421"},{"id":"paper-a-survey-on-fake-review-detection-techniques","type":"paper","name":"A Survey on Fake Review Detection Techniques","description":"Comprehensive survey covering linguistic, behavioral, and graph-based fake review detection methods.","category":"Trust & Safety > Spam & Abuse","url":"https://dl.acm.org/doi/10.1145/3577018"},{"id":"paper-automated-hate-speech-detection-and-the-problem-of-offensive-language","type":"paper","name":"Automated Hate Speech Detection and the Problem of Offensive Language","description":"Foundational 3-class dataset (hate/offensive/neither) with 24K labeled tweets; standard benchmark.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://arxiv.org/abs/1703.04009"},{"id":"paper-a-new-generation-of-perspective-api:-efficient-multilingual-character-level-transformers","type":"paper","name":"A New Generation of Perspective API: Efficient Multilingual Character-level Transformers","description":"Technical architecture behind Google Jigsaw's Perspective API; handles obfuscation, code-switching, multilingual toxicity.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://arxiv.org/abs/2202.11176"},{"id":"paper-measuring-and-mitigating-unintended-bias-in-text-classification","type":"paper","name":"Measuring and Mitigating Unintended Bias in Text Classification","description":"Develops methods for measuring unintended identity-term bias in toxicity classifiers; foundational for fair ML.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://dl.acm.org/doi/10.1145/3278721.3278729"},{"id":"paper-hatexplain:-a-benchmark-dataset-for-explainable-hate-speech-detection","type":"paper","name":"HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection","description":"First benchmark with rationale annotations for explainable hate speech detection across 20K posts.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://arxiv.org/abs/2012.10289"},{"id":"paper-automatic-detection-of-cyberbullying-in-social-media-text","type":"paper","name":"Automatic Detection of Cyberbullying in Social Media Text","description":"Multi-label cyberbullying detection with fine-grained categories; benchmark on Dutch social media.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0203794"},{"id":"paper-internet-argument-corpus-2.0:-an-sql-schema-for-dialogic-social-media-and-the-corpora-to-go-wi","type":"paper","name":"Internet Argument Corpus 2.0: An SQL Schema for Dialogic Social Media and the Corpora to Go with It","description":"Studies how subreddit norms shape behavior; users posting in banned communities post less toxic content after ban.","category":"Trust & Safety > Content Moderation & Toxicity","url":"https://dl.acm.org/doi/10.1145/3359294"},{"id":"paper-data-breaches,-phishing,-or-malware?-understanding-the-risks-of-stolen-credentials","type":"paper","name":"Data Breaches, Phishing, or Malware? Understanding the Risks of Stolen Credentials","description":"Google study on account hijacking vectors; SMS verification blocks 100% of automated bots and 96% of bulk phishing.","category":"Trust & Safety > Account Security & Identity","url":"https://dl.acm.org/doi/10.1145/3133956.3134067"},{"id":"paper-risk-based-authentication:-practical-deployments-and-research-challenges","type":"paper","name":"Risk-Based Authentication: Practical Deployments and Research Challenges","description":"Analyzes RBA deployments at Google, Microsoft, Amazon; develops measurement framework.","category":"Trust & Safety > Account Security & Identity","url":"https://riskbasedauthentication.org/publications/"},{"id":"paper-selective-graph-attention-networks-for-account-takeover-detection","type":"paper","name":"Selective Graph Attention Networks for Account Takeover Detection","description":"Graph neural networks modeling account-device-transaction relationships for ATO detection.","category":"Trust & Safety > Account Security & Identity","url":"https://ieeexplore.ieee.org/document/8637408"},{"id":"paper-deepauth:-deep-learning-based-authentication-for-anomaly-detection","type":"paper","name":"DeepAuth: Deep Learning Based Authentication for Anomaly Detection","description":"Deep learning approach combining behavioral biometrics with session features for continuous authentication.","category":"Trust & Safety > Account Security & Identity","url":"https://ieeexplore.ieee.org/document/9342831"},{"id":"paper-framing-the-underground-economy:-an-ecosystem-of-underground-market-sellers-and-operators","type":"paper","name":"Framing the Underground Economy: An Ecosystem of Underground Market Sellers and Operators","description":"Maps the underground economy of stolen accounts; traces supply chain from compromise to monetization.","category":"Trust & Safety > Account Security & Identity","url":"https://dl.acm.org/doi/10.1145/2815675.2815707"},{"id":"paper-who-let-the-trolls-out?-towards-understanding-state-sponsored-trolls","type":"paper","name":"Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls","description":"Characterizes Russian IRA troll activity across platforms; develops detection methodology.","category":"Trust & Safety > Coordinated Manipulation & Information Operations","url":"https://dl.acm.org/doi/10.1145/3292522.3326016"},{"id":"paper-disinformation-as-collaborative-work:-surfacing-the-participatory-nature-of-strategic-informat","type":"paper","name":"Disinformation as Collaborative Work: Surfacing the Participatory Nature of Strategic Information Operations","description":"Framework for understanding information operations as collaborative work; case study of 2016 election.","category":"Trust & Safety > Coordinated Manipulation & Information Operations","url":"https://dl.acm.org/doi/10.1145/3359229"},{"id":"paper-characterizing-twitter-users-who-engage-with-russian-internet-research-agency","type":"paper","name":"Characterizing Twitter Users Who Engage with Russian Internet Research Agency","description":"Analysis of 14M tweets by IRA; identifies patterns distinguishing troll engagement from organic users.","category":"Trust & Safety > Coordinated Manipulation & Information Operations","url":"https://arxiv.org/abs/1812.05969"},{"id":"paper-exploring-content-and-design-techniques-in-coordinated-manipulation:-a-survey","type":"paper","name":"Exploring Content and Design Techniques in Coordinated Manipulation: A Survey","description":"Comprehensive taxonomy of manipulation techniques across platforms and actor types.","category":"Trust & Safety > Coordinated Manipulation & Information Operations","url":"https://arxiv.org/abs/2105.04282"},{"id":"paper-abusive-language-detection-in-online-user-content","type":"paper","name":"Abusive Language Detection in Online User Content","description":"Yahoo system combining n-grams, syntactic, and semantic features; production-scale abuse detection.","category":"Trust & Safety > Abuse Detection in Human Interaction","url":"https://dl.acm.org/doi/10.1145/2872427.2883062"},{"id":"paper-deep-learning-for-detecting-harassment-in-social-media","type":"paper","name":"Deep Learning for Detecting Harassment in Social Media","description":"CNN and RNN architectures for harassment detection; analyzes temporal patterns in abuse.","category":"Trust & Safety > Abuse Detection in Human Interaction","url":"https://dl.acm.org/doi/10.1145/3041021.3054223"},{"id":"paper-ex-machina:-personal-attacks-seen-at-scale","type":"paper","name":"Ex Machina: Personal Attacks Seen at Scale","description":"Wikipedia personal attack corpus with 100K+ labeled comments; crowdsourcing methodology for abuse annotation.","category":"Trust & Safety > Abuse Detection in Human Interaction","url":"https://dl.acm.org/doi/10.1145/3038912.3052591"},{"id":"paper-deep-learning-for-user-comment-moderation","type":"paper","name":"Deep Learning for User Comment Moderation","description":"RNN with attention for comment moderation; deployed at Greek news organization.","category":"Trust & Safety > Abuse Detection in Human Interaction","url":"https://arxiv.org/abs/1705.09899"},{"id":"paper-what-is-privacy-worth?","type":"paper","name":"What Is Privacy Worth?","description":"Experiments showing people value privacy but underestimate risks; foundational behavioral privacy study.","category":"Trust & Safety > Privacy & Data Misuse","url":"https://www.journals.uchicago.edu/doi/abs/10.1086/671754"},{"id":"paper-the-economics-of-privacy-2","type":"paper","name":"The Economics of Privacy","description":"JEL survey covering market structure, price discrimination, and welfare effects of privacy regulation.","category":"Trust & Safety > Privacy & Data Misuse","url":"https://www.aeaweb.org/articles?id=10.1257/jel.54.2.442"},{"id":"paper-differential-privacy","type":"paper","name":"Differential Privacy","description":"Foundational paper defining differential privacy; mathematical framework for privacy-preserving computation.","category":"Trust & Safety > Privacy & Data Misuse","url":"https://link.springer.com/chapter/10.1007/11787006_1"},{"id":"paper-the-cost-of-annoying-ads","type":"paper","name":"The Cost of Annoying Ads","description":"Studies tradeoff between ad intrusiveness and platform revenue; privacy implications of targeting.","category":"Trust & Safety > Privacy & Data Misuse","url":"https://www.nber.org/papers/w23489"},{"id":"paper-the-truck-dispatching-problem","type":"paper","name":"The Truck Dispatching Problem","description":"The original VRP paper; introduced linear programming formulation for fleet routing from depot to customers.","category":"Logistics & Operations > Routing & Dispatch","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.6.1.80"},{"id":"paper-scheduling-of-vehicles-from-a-central-depot-to-a-number-of-delivery-points","type":"paper","name":"Scheduling of Vehicles from a Central Depot to a Number of Delivery Points","description":"Introduced the 'savings algorithm'\u2014still the most widely used VRP heuristic in commercial routing software.","category":"Logistics & Operations > Routing & Dispatch","url":"https://www.jstor.org/stable/168156"},{"id":"paper-dynamic-pricing-and-matching-in-ride-hailing-platforms-1","type":"paper","name":"Dynamic Pricing and Matching in Ride-Hailing Platforms","description":"Uber research on matching algorithms and dynamic pricing; batching and bipartite matching for real-time dispatch.","category":"Logistics & Operations > Routing & Dispatch","url":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3258234"},{"id":"paper-fifty-years-of-vehicle-routing","type":"paper","name":"Fifty Years of Vehicle Routing","description":"Authoritative survey from Dantzig-Ramser through modern metaheuristics.","category":"Logistics & Operations > Routing & Dispatch","url":"https://link.springer.com/article/10.1007/s13676-013-0020-6"},{"id":"paper-or-tools'-vehicle-routing-solver:-a-generic-constraint-programming-solver-with-heuristic-searc","type":"paper","name":"OR-Tools' Vehicle Routing Solver: A Generic Constraint-Programming Solver with Heuristic Search","description":"Google's open-source production solver powering Cloud optimization APIs; handles complex industrial constraints at scale.","category":"Logistics & Operations > Routing & Dispatch","url":"https://developers.google.com/optimization/routing"},{"id":"paper-an-effective-implementation-of-the-lin-kernighan-traveling-salesman-heuristic","type":"paper","name":"An Effective Implementation of the Lin-Kernighan Traveling Salesman Heuristic","description":"Industry-standard LKH heuristic holding records on all large benchmark instances; extended as LKH-3 for CVRP variants.","category":"Logistics & Operations > Routing & Dispatch","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221799002842"},{"id":"paper-ride-hailing-order-dispatching-at-didi-via-reinforcement-learning","type":"paper","name":"Ride-Hailing Order Dispatching at DiDi via Reinforcement Learning","description":"Production RL system matching tens of millions of daily rides; won NeurIPS 2018 Best Demo Award.","category":"Logistics & Operations > Routing & Dispatch","url":"https://arxiv.org/abs/2006.00543"},{"id":"paper-a-tutorial-on-column-generation-and-branch-and-price-for-vehicle-routing","type":"paper","name":"A Tutorial on Column Generation and Branch-and-Price for Vehicle Routing","description":"Foundational exact method tutorial underpinning state-of-the-art solvers for fleet planning.","category":"Logistics & Operations > Routing & Dispatch","url":"https://link.springer.com/article/10.1007/s10288-010-0130-z"},{"id":"paper-alibaba-vehicle-routing-algorithms-enable-rapid-pick-and-delivery","type":"paper","name":"Alibaba Vehicle Routing Algorithms Enable Rapid Pick and Delivery","description":"Production algorithms enabling 30-minute grocery delivery across Alibaba subsidiaries in China. Franz Edelman Award finalist.","category":"Logistics & Operations > Routing & Dispatch","url":"https://pubsonline.informs.org/doi/10.1287/inte.2022.1130"},{"id":"paper-2021-amazon-last-mile-routing-research-challenge:-data-set","type":"paper","name":"2021 Amazon Last Mile Routing Research Challenge: Data Set","description":"First large-scale public real-world routing dataset (9,184 routes); catalyzed ML + TSP research combining driver tacit knowledge.","category":"Logistics & Operations > Routing & Dispatch","url":"https://pubsonline.informs.org/doi/10.1287/trsc.2022.1173"},{"id":"paper-optimal-policies-for-a-multi-echelon-inventory-problem","type":"paper","name":"Optimal Policies for a Multi-Echelon Inventory Problem","description":"Introduced 'echelon inventory' concept; proved optimal base-stock policies for serial supply chains.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.4.475"},{"id":"paper-foundations-of-stochastic-inventory-theory","type":"paper","name":"Foundations of Stochastic Inventory Theory","description":"Definitive textbook on newsvendor, (s,S) policies, and dynamic inventory systems.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://www.sup.org/books/title/?id=4627"},{"id":"paper-optimizing-strategic-safety-stock-placement-in-supply-chains","type":"paper","name":"Optimizing Strategic Safety Stock Placement in Supply Chains","description":"Guaranteed-service model for safety stock optimization; deployed in SAP, Kinaxis, and enterprise software.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://pubsonline.informs.org/doi/10.1287/msom.2.1.68.23267"},{"id":"paper-the-evolution-of-amazon's-inventory-planning-system","type":"paper","name":"The Evolution of Amazon's Inventory Planning System","description":"Amazon's multi-echelon system with Lagrangian decomposition for real-time optimization across 175+ fulfillment centers.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://www.amazon.science/latest-news/the-evolution-of-amazons-inventory-planning-system"},{"id":"paper-alibaba-realizes-millions-in-cost-savings-through-integrated-demand-forecasting-and-inventory-","type":"paper","name":"Alibaba Realizes Millions in Cost Savings Through Integrated Demand Forecasting and Inventory Management","description":"Deep learning + simulation-optimization generating $42M+ annual savings in inventory and shrinkage costs. Franz Edelman Award finalist.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://pubsonline.informs.org/doi/10.1287/inte.2023.1165"},{"id":"paper-jd.com-improves-fulfillment-efficiency-with-integrated-assortment-planning-and-inventory-alloc","type":"paper","name":"JD.com Improves Fulfillment Efficiency with Integrated Assortment Planning and Inventory Allocation","description":"End-to-end algorithm improving local fulfillment rates by 0.54% across millions of weekly orders in two-echelon distribution. Franz Edelman Award finalist.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://pubsonline.informs.org/doi/10.1287/inte.2024.1301"},{"id":"paper-optimal-picking-policies-in-e-commerce-warehouses","type":"paper","name":"Optimal Picking Policies in E-Commerce Warehouses","description":"State-of-the-art picker routing for mixed-shelves warehouses; exact real-time algorithms for high-SKU e-commerce facilities.","category":"Logistics & Operations > Inventory & Fulfillment","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2022.4448"},{"id":"paper-deepar:-probabilistic-forecasting-with-autoregressive-recurrent-networks-1","type":"paper","name":"DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks","description":"Foundational Amazon paper powering SageMaker and Amazon Forecast; ~15% accuracy improvement over classical methods via global RNN.","category":"Logistics & Operations > Supply Chain Demand Forecasting","url":"https://arxiv.org/abs/1704.04110"},{"id":"paper-m5-accuracy-competition:-results,-findings,-and-conclusions-1","type":"paper","name":"M5 Accuracy Competition: Results, Findings, and Conclusions","description":"Landmark Walmart competition (42,840 time series) proving LightGBM ensembles outperform traditional statistical methods at retail scale.","category":"Logistics & Operations > Supply Chain Demand Forecasting","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207021001874"},{"id":"paper-m5-uncertainty-competition:-results,-findings-and-conclusions","type":"paper","name":"M5 Uncertainty Competition: Results, Findings and Conclusions","description":"Companion competition on probabilistic forecasting; winning methods combined LightGBM + DeepAR for intermittent demand quantiles.","category":"Logistics & Operations > Supply Chain Demand Forecasting","url":"https://www.sciencedirect.com/science/article/abs/pii/S0169207021001886"},{"id":"paper-temporal-fusion-transformers-for-interpretable-multi-horizon-time-series-forecasting-1","type":"paper","name":"Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting","description":"Attention-based architecture achieving 7% lower P50, 9% lower P90 losses; combines performance with interpretable variable importance.","category":"Logistics & Operations > Supply Chain Demand Forecasting","url":"https://arxiv.org/abs/1912.09363"},{"id":"paper-probabilistic-demand-forecasting-with-graph-neural-networks","type":"paper","name":"Probabilistic Demand Forecasting with Graph Neural Networks","description":"GraphDeepAR integrating GNN encoder with probabilistic decoder; captures inter-article relationships for improved retail forecasting.","category":"Logistics & Operations > Supply Chain Demand Forecasting","url":"https://www.amazon.science/publications/probabilistic-demand-forecasting-with-graph-neural-networks"},{"id":"paper-eta-prediction-with-graph-neural-networks-in-google-maps","type":"paper","name":"ETA Prediction with Graph Neural Networks in Google Maps","description":"Deployed GNN for Google Maps ETA; reduced negative outcomes by 40%+ in major cities.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://arxiv.org/abs/2108.11482"},{"id":"paper-deepeta:-how-uber-predicts-arrival-times-using-deep-learning","type":"paper","name":"DeepETA: How Uber Predicts Arrival Times Using Deep Learning","description":"Uber's production ETA using Transformers for tabular data; highest QPS system at Uber.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://www.uber.com/blog/deepeta-how-uber-predicts-arrival-times/"},{"id":"paper-diffusion-convolutional-recurrent-neural-network-(dcrnn)","type":"paper","name":"Diffusion Convolutional Recurrent Neural Network (DCRNN)","description":"Foundational spatiotemporal traffic forecasting combining graph convolutions with sequence models.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://arxiv.org/abs/1707.01926"},{"id":"paper-deepeta:-a-spatial-temporal-sequential-neural-network-model-for-package-delivery","type":"paper","name":"DeepETA: A Spatial-Temporal Sequential Neural Network Model for Package Delivery","description":"Deployed serving 100+ million packages/day; achieved 13.8% RMSE improvement using spatial-temporal LSTM with attention.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://ojs.aaai.org/index.php/AAAI/article/view/3856"},{"id":"paper-a-deep-learning-method-for-route-and-time-prediction-in-food-delivery","type":"paper","name":"A Deep Learning Method for Route and Time Prediction in Food Delivery","description":"First joint route-and-time prediction for food delivery; transformer architecture handling 34.9 million orders/day on Meituan.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://dl.acm.org/doi/10.1145/3447548.3467068"},{"id":"paper-heteta:-heterogeneous-information-network-embedding-for-eta","type":"paper","name":"HetETA: Heterogeneous Information Network Embedding for ETA","description":"Heterogeneous graph neural networks modeling road networks as multi-relational graphs; establishes importance of graph representations.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://dl.acm.org/doi/10.1145/3394486.3403294"},{"id":"paper-real-time-delivery-time-forecasting-and-promising-in-online-retailing","type":"paper","name":"Real-Time Delivery Time Forecasting and Promising in Online Retailing","description":"First data-driven framework predicting delivery time distributions (not point estimates); tested on JD.com showing 6.1% sales improvement.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://pubsonline.informs.org/doi/10.1287/msom.2022.1081"},{"id":"paper-a-survey-on-service-route-and-time-prediction-in-instant-delivery","type":"paper","name":"A Survey on Service Route and Time Prediction in Instant Delivery","description":"Comprehensive survey covering Cainiao, JD, Meituan, GrabFood systems; taxonomizes by task type, architecture, and learning paradigm.","category":"Logistics & Operations > ETA & Delivery Prediction","url":"https://ieeexplore.ieee.org/document/10323156"},{"id":"paper-telephone-call-centers:-tutorial,-review,-and-research-prospects","type":"paper","name":"Telephone Call Centers: Tutorial, Review, and Research Prospects","description":"Definitive survey on call center operations; directly applicable to gig economy capacity planning.","category":"Logistics & Operations > Capacity Planning","url":"https://faculty.wharton.upenn.edu/wp-content/uploads/2012/04/Gans-Koole-Mandelbaum-CCReview.pdf"},{"id":"paper-heavy-traffic-limits-for-queues-with-many-exponential-servers","type":"paper","name":"Heavy-Traffic Limits for Queues with Many Exponential Servers","description":"Foundational heavy-traffic theory; introduced QED regime balancing service quality with utilization.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/abs/10.1287/opre.29.3.567"},{"id":"paper-the-effects-of-uber's-surge-pricing:-a-case-study","type":"paper","name":"The Effects of Uber's Surge Pricing: A Case Study","description":"Natural experiment (NYE outage) showing dynamic pricing equilibrates supply/demand in real-time.","category":"Logistics & Operations > Capacity Planning","url":"https://www.uber.com/blog/research/the-effects-of-ubers-surge-pricing-a-case-study/"},{"id":"paper-dynamic-pricing-in-a-labor-market:-surge-pricing-and-flexible-work-on-the-uber-platform","type":"paper","name":"Dynamic Pricing in a Labor Market: Surge Pricing and Flexible Work on the Uber Platform","description":"Studies driver labor supply response using 25 million Uber trips.","category":"Logistics & Operations > Capacity Planning","url":"https://www.anderson.ucla.edu/faculty/keith.chen/papers/SurgeAndFlexibleWork_WorkingPaper.pdf"},{"id":"paper-the-role-of-surge-pricing-on-a-service-platform-with-self-scheduling-capacity-1","type":"paper","name":"The Role of Surge Pricing on a Service Platform with Self-Scheduling Capacity","description":"Foundational theory showing surge pricing achieves near-optimal profits with self-scheduling workers; directly informs Uber/Lyft design.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/msom.2017.0618"},{"id":"paper-the-impact-of-behavioral-and-economic-drivers-on-gig-economy-workers","type":"paper","name":"The Impact of Behavioral and Economic Drivers on Gig Economy Workers","description":"Rigorous econometric study showing incentive reallocation can increase capacity by 22% without additional cost.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/msom.2023.1193"},{"id":"paper-spatial-pricing-in-ride-sharing-networks","type":"paper","name":"Spatial Pricing in Ride-Sharing Networks","description":"Characterizes optimal spatial pricing; introduces 'balancedness' concept for demand patterns and driver positioning incentives.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/opre.2018.1800"},{"id":"paper-matching-and-pricing-in-ride-hailing:-wild-goose-chases-and-how-to-solve-them","type":"paper","name":"Matching and Pricing in Ride Hailing: Wild Goose Chases and How to Solve Them","description":"Developed at Uber showing surge pricing solves 'wild goose chase' matching failures better than matching adjustments alone.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2023.4843"},{"id":"paper-driver-surge-pricing","type":"paper","name":"Driver Surge Pricing","description":"Proves multiplicative surge is not incentive-compatible; proposes additive surge mechanism deployed by Uber.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/mnsc.2021.4241"},{"id":"paper-dynamic-pricing-and-matching-for-two-sided-queues","type":"paper","name":"Dynamic Pricing and Matching for Two-Sided Queues","description":"Rigorous queueing-theoretic model; develops fluid-based max-weight matching achieving \u221a\u03b7 optimality rate.","category":"Logistics & Operations > Capacity Planning","url":"https://pubsonline.informs.org/doi/10.1287/opre.2022.2266"},{"id":"paper-challenges-and-opportunities-in-crowdsourced-delivery-planning-and-operations","type":"paper","name":"Challenges and Opportunities in Crowdsourced Delivery Planning and Operations","description":"Authoritative survey on DoorDash, Instacart, Uber Eats covering matching, pricing, and gig economy logistics.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://link.springer.com/article/10.1007/s10288-021-00500-2"},{"id":"paper-crowdsourced-delivery:-a-review-of-platforms-and-academic-literature","type":"paper","name":"Crowdsourced Delivery: A Review of Platforms and Academic Literature","description":"Comprehensive review classifying platforms by scheduling mechanism.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://www.sciencedirect.com/science/article/abs/pii/S0305048320306915"},{"id":"paper-algorithm-for-robotic-picking-in-amazon-fulfillment-centers","type":"paper","name":"Algorithm for Robotic Picking in Amazon Fulfillment Centers","description":"Reduced drive distance by 62% and saved $500M+; demonstrates OR impact at scale.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://pubsonline.informs.org/doi/10.1287/inte.2022.1143"},{"id":"paper-the-flying-sidekick-traveling-salesman-problem:-optimization-of-drone-assisted-parcel-delivery","type":"paper","name":"The Flying Sidekick Traveling Salesman Problem: Optimization of Drone-Assisted Parcel Delivery","description":"Foundational FSTSP model for truck-drone tandem delivery; inspired by Amazon Prime Air, Google Wing, and DHL drone programs.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://www.sciencedirect.com/science/article/abs/pii/S0968090X15000297"},{"id":"paper-the-multiple-flying-sidekicks-traveling-salesman-problem:-parcel-delivery-with-multiple-drones","type":"paper","name":"The Multiple Flying Sidekicks Traveling Salesman Problem: Parcel Delivery with Multiple Drones","description":"Extends to multiple heterogeneous drones; MILP and heuristics for 100+ customers with 4+ drones.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://www.sciencedirect.com/science/article/abs/pii/S0968090X19301251"},{"id":"paper-crowdsourced-delivery\u2014a-dynamic-pickup-and-delivery-problem-with-ad-hoc-drivers","type":"paper","name":"Crowdsourced Delivery\u2014A Dynamic Pickup and Delivery Problem with Ad Hoc Drivers","description":"Rolling horizon optimization for Amazon Flex-style platforms; shows 37% vehicle-mile savings vs. dedicated fleets.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://pubsonline.informs.org/doi/10.1287/trsc.2018.0855"},{"id":"paper-time-slot-management-in-attended-home-delivery","type":"paper","name":"Time Slot Management in Attended Home Delivery","description":"Seminal paper on tactical time-slot design for e-grocers; developed with Albert.nl; 237+ citations in last-mile literature.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://pubsonline.informs.org/doi/10.1287/trsc.1100.0346"},{"id":"paper-crowdsourcing-last-mile-deliveries","type":"paper","name":"Crowdsourcing Last-Mile Deliveries","description":"First analytical study of crowdsourcing with guaranteed time windows; robust queueing for Amazon Flex-style operations.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://pubsonline.informs.org/doi/10.1287/msom.2021.1040"},{"id":"paper-flexible-time-window-management-for-attended-home-deliveries","type":"paper","name":"Flexible Time Window Management for Attended Home Deliveries","description":"Mixed long/short delivery windows; tested with German e-grocer AllyouneedFresh data.","category":"Logistics & Operations > Last-Mile Optimization","url":"https://www.sciencedirect.com/science/article/abs/pii/S0305048319304712"},{"id":"paper-coordinating-hundreds-of-cooperative,-autonomous-vehicles-in-warehouses","type":"paper","name":"Coordinating Hundreds of Cooperative, Autonomous Vehicles in Warehouses","description":"THE Kiva paper by its three co-inventors; describes multi-robot coordination that Amazon acquired for $775M and scaled to 500,000+ robots.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://ojs.aaai.org/index.php/aimagazine/article/view/2082"},{"id":"paper-estimating-performance-in-a-robotic-mobile-fulfillment-system","type":"paper","name":"Estimating Performance in a Robotic Mobile Fulfillment System","description":"Highly-cited queueing network model for Amazon-style RMFS; foundational for warehouse layout optimization and throughput analysis.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221717303144"},{"id":"paper-design-and-control-of-warehouse-order-picking:-a-literature-review","type":"paper","name":"Design and Control of Warehouse Order Picking: A Literature Review","description":"THE canonical survey (3,000+ citations) covering layout, storage assignment, routing, batching, and zoning.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221706006175"},{"id":"paper-decision-rules-for-robotic-mobile-fulfillment-systems","type":"paper","name":"Decision Rules for Robotic Mobile Fulfillment Systems","description":"Simulation-based evaluation of practical decision rules for order assignment and pod selection in Kiva-style warehouses.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://link.springer.com/article/10.1007/s12063-018-0132-6"},{"id":"paper-analysis-and-observations-from-the-first-amazon-picking-challenge","type":"paper","name":"Analysis and Observations from the First Amazon Picking Challenge","description":"Survey of 26 teams in Amazon's manipulation challenge; synthesizes perception, motion planning, and grasp planning lessons.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://ieeexplore.ieee.org/document/7759115"},{"id":"paper-warehousing-in-the-e-commerce-era:-a-survey","type":"paper","name":"Warehousing in the E-Commerce Era: A Survey","description":"Modern survey covering order batching, wave planning, RMFS, scattered storage, and returns processing for e-commerce.","category":"Logistics & Operations > Warehouse Robotics & Automation","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221718308476"},{"id":"paper-the-electric-vehicle-routing-problem-with-time-windows-and-recharging-stations","type":"paper","name":"The Electric Vehicle-Routing Problem with Time Windows and Recharging Stations","description":"THE foundational EVRP paper (1,000+ citations) introducing charging constraints into last-mile routing; established benchmark instances.","category":"Logistics & Operations > Fleet Electrification & Green Logistics","url":"https://pubsonline.informs.org/doi/10.1287/trsc.2013.0490"},{"id":"paper-the-pollution-routing-problem","type":"paper","name":"The Pollution-Routing Problem","description":"Foundation for green vehicle routing (1,500+ citations); models CO2 as function of speed, load, distance for cost-environment tradeoffs.","category":"Logistics & Operations > Fleet Electrification & Green Logistics","url":"https://www.sciencedirect.com/science/article/abs/pii/S019126151100024X"},{"id":"paper-routing-a-mixed-fleet-of-electric-and-conventional-vehicles","type":"paper","name":"Routing a Mixed Fleet of Electric and Conventional Vehicles","description":"Addresses practical fleet electrification decisions; optimizes routing for mixed fleets with realistic energy consumption models.","category":"Logistics & Operations > Fleet Electrification & Green Logistics","url":"https://www.sciencedirect.com/science/article/abs/pii/S0377221715000563"},{"id":"paper-ups-orion:-on-road-integrated-optimization-and-navigation","type":"paper","name":"UPS ORION: On-Road Integrated Optimization and Navigation","description":"Franz Edelman Award winner; industry-deployed system saving $300-400M annually, reducing 100M miles, 10M gallons fuel, 100,000 metric tons CO2.","category":"Logistics & Operations > Fleet Electrification & Green Logistics","url":"https://pubsonline.informs.org/doi/10.1287/inte.2016.0853"},{"id":"paper-calibrating-noise-to-sensitivity-in-private-data-analysis","type":"paper","name":"Calibrating Noise to Sensitivity in Private Data Analysis","description":"Foundational paper introducing \u03b5-differential privacy, Laplace mechanism, and noise calibration to sensitivity.","category":"Privacy > Differential Privacy","url":"https://link.springer.com/chapter/10.1007/11681878_14"},{"id":"paper-the-algorithmic-foundations-of-differential-privacy","type":"paper","name":"The Algorithmic Foundations of Differential Privacy","description":"The definitive textbook covering DP techniques, composition, mechanism design, and ML applications.","category":"Privacy > Differential Privacy","url":"https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf"},{"id":"paper-rappor:-randomized-aggregatable-privacy-preserving-ordinal-response","type":"paper","name":"RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response","description":"Google's practical local DP system deployed in Chrome with longitudinal privacy guarantees.","category":"Privacy > Differential Privacy","url":"https://arxiv.org/abs/1407.6981"},{"id":"paper-deep-learning-with-differential-privacy","type":"paper","name":"Deep Learning with Differential Privacy","description":"Introduces DP-SGD algorithm and moments accountant for training neural networks with formal DP guarantees.","category":"Privacy > Differential Privacy","url":"https://arxiv.org/abs/1607.00133"},{"id":"paper-the-composition-theorem-for-differential-privacy","type":"paper","name":"The Composition Theorem for Differential Privacy","description":"Proves optimal composition bounds for differential privacy; essential for privacy budget management.","category":"Privacy > Differential Privacy","url":"https://proceedings.mlr.press/v37/kairouz15.pdf"},{"id":"paper-r\u00e9nyi-differential-privacy","type":"paper","name":"R\u00e9nyi Differential Privacy","description":"Defines RDP using R\u00e9nyi divergence; cleaner composition analysis used in TensorFlow Privacy.","category":"Privacy > Differential Privacy","url":"https://arxiv.org/abs/1702.07476"},{"id":"paper-amplification-by-shuffling:-from-local-to-central-differential-privacy-via-anonymity","type":"paper","name":"Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity","description":"Proves shuffle model bridges local/central DP gap; deployed in Apple and Google systems.","category":"Privacy > Differential Privacy","url":"https://arxiv.org/abs/1811.12469"},{"id":"paper-privacy-amplification-by-subsampling:-tight-analyses-via-couplings-and-divergences","type":"paper","name":"Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences","description":"Unified framework for subsampling privacy amplification; essential for DP-SGD analysis.","category":"Privacy > Differential Privacy","url":"https://arxiv.org/abs/1807.01647"},{"id":"paper-gaussian-differential-privacy","type":"paper","name":"Gaussian Differential Privacy","description":"f-DP and GDP with lossless composition via CLT; modern privacy accounting foundation.","category":"Privacy > Differential Privacy","url":"https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12454"},{"id":"paper-communication-efficient-learning-of-deep-networks-from-decentralized-data","type":"paper","name":"Communication-Efficient Learning of Deep Networks from Decentralized Data","description":"Seminal paper introducing Federated Learning and FedAvg algorithm; enables ML without raw data collection.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1602.05629"},{"id":"paper-practical-secure-aggregation-for-privacy-preserving-machine-learning","type":"paper","name":"Practical Secure Aggregation for Privacy-Preserving Machine Learning","description":"Cryptographic protocol for aggregating model updates without seeing individual contributions.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1611.04482"},{"id":"paper-federated-learning:-strategies-for-improving-communication-efficiency","type":"paper","name":"Federated Learning: Strategies for Improving Communication Efficiency","description":"Introduces structured updates and sketching to reduce communication costs in federated settings.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1610.05492"},{"id":"paper-scaffold:-stochastic-controlled-averaging-for-federated-learning","type":"paper","name":"SCAFFOLD: Stochastic Controlled Averaging for Federated Learning","description":"Control variates for client drift under heterogeneity; tight convergence guarantees for non-IID data.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1910.06378"},{"id":"paper-learning-differentially-private-recurrent-language-models","type":"paper","name":"Learning Differentially Private Recurrent Language Models","description":"User-level DP for federated learning; production deployment in Gboard next-word prediction.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1710.06963"},{"id":"paper-ditto:-fair-and-robust-federated-learning-through-personalization","type":"paper","name":"Ditto: Fair and Robust Federated Learning Through Personalization","description":"Personalized FL addressing fairness and robustness via local regularization toward global model.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/2012.04221"},{"id":"paper-advances-and-open-problems-in-federated-learning","type":"paper","name":"Advances and Open Problems in Federated Learning","description":"Definitive 210-page survey defining cross-device/cross-silo taxonomy and 50+ open problems.","category":"Privacy > Federated Learning","url":"https://arxiv.org/abs/1912.04977"},{"id":"paper-rappor:-randomized-aggregatable-privacy-preserving-ordinal-response-1","type":"paper","name":"RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response","description":"Foundation for privacy-preserving telemetry with local DP guarantees for aggregate statistics.","category":"Privacy > Privacy-Preserving Measurement","url":"https://arxiv.org/abs/1407.6981"},{"id":"paper-scalable-private-learning-with-pate","type":"paper","name":"Scalable Private Learning with PATE","description":"Scaled PATE framework with GNMax aggregation; achieves strong privacy (\u03b5 < 1) while maintaining utility.","category":"Privacy > Privacy-Preserving Measurement","url":"https://arxiv.org/abs/1802.08908"},{"id":"paper-semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data-(pate)","type":"paper","name":"Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data (PATE)","description":"Private Aggregation of Teacher Ensembles; enables privacy-preserving ML via knowledge transfer.","category":"Privacy > Privacy-Preserving Measurement","url":"https://research.google/pubs/pub45828/"},{"id":"paper-interoperable-private-attribution:-a-proposal","type":"paper","name":"Interoperable Private Attribution: A Proposal","description":"MPC + DP protocol for cross-site attribution without user tracking; W3C Privacy CG proposal by Meta/Mozilla.","category":"Privacy > Privacy-Preserving Measurement","url":"https://eprint.iacr.org/2023/437"},{"id":"paper-ibex:-privacy-preserving-ad-conversion-tracking-and-bidding","type":"paper","name":"Ibex: Privacy-Preserving Ad Conversion Tracking and Bidding","description":"Encrypted conversion measurement and oblivious real-time bidding using MPC and secret sharing.","category":"Privacy > Privacy-Preserving Measurement","url":"https://dl.acm.org/doi/10.1145/3548606.3560651"},{"id":"paper-modeling-tabular-data-using-conditional-gan-(ctgan)","type":"paper","name":"Modeling Tabular Data using Conditional GAN (CTGAN)","description":"State-of-the-art GAN for synthetic tabular data; handles mixed types with mode-specific normalization.","category":"Privacy > Synthetic Data","url":"https://arxiv.org/pdf/1907.00503"},{"id":"paper-semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data-(pate)-1","type":"paper","name":"Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data (PATE)","description":"PATE enables training on synthetic/unlabeled data with DP guarantees transferred from teacher ensemble.","category":"Privacy > Synthetic Data","url":"https://research.google/pubs/pub45828/"},{"id":"paper-pate-gan:-generating-synthetic-data-with-differential-privacy-guarantees","type":"paper","name":"PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees","description":"Combines PATE framework with GANs for DP synthetic data generation.","category":"Privacy > Synthetic Data","url":"https://openreview.net/forum?id=S1zk9iRqF7"},{"id":"paper-privbayes:-private-data-release-via-bayesian-networks","type":"paper","name":"PrivBayes: Private Data Release via Bayesian Networks","description":"Bayesian network approach to DP synthesis; widely deployed baseline for synthetic data.","category":"Privacy > Synthetic Data","url":"https://dl.acm.org/doi/10.1145/3134428"},{"id":"paper-winning-the-nist-contest:-a-scalable-approach-to-dp-synthetic-data","type":"paper","name":"Winning the NIST Contest: A Scalable Approach to DP Synthetic Data","description":"MST/Private-PGM marginal-based synthesis that won NIST DP synthetic data competition.","category":"Privacy > Synthetic Data","url":"https://journalprivacyconfidentiality.org/index.php/jpc/article/view/776"},{"id":"paper-k-anonymity:-a-model-for-protecting-privacy","type":"paper","name":"k-Anonymity: A Model for Protecting Privacy","description":"Foundational paper introducing k-anonymity; each record indistinguishable from k-1 others on quasi-identifiers.","category":"Privacy > Anonymization & De-identification","url":"https://dl.acm.org/doi/10.1142/S0218488502001648"},{"id":"paper-robust-de-anonymization-of-large-sparse-datasets-(netflix)","type":"paper","name":"Robust De-anonymization of Large Sparse Datasets (Netflix)","description":"Landmark attack demonstrating re-identification of Netflix users; showed k-anonymity fails on high-dimensional data.","category":"Privacy > Anonymization & De-identification","url":"https://arxiv.org/abs/cs/0610105"},{"id":"paper-\u2113-diversity:-privacy-beyond-k-anonymity","type":"paper","name":"\u2113-Diversity: Privacy Beyond k-Anonymity","description":"Extends k-anonymity by requiring diversity in sensitive attributes; defends against homogeneity attacks.","category":"Privacy > Anonymization & De-identification","url":"https://dl.acm.org/doi/10.1145/1217299.1217302"},{"id":"paper-t-closeness:-privacy-beyond-k-anonymity-and-\u2113-diversity","type":"paper","name":"t-Closeness: Privacy Beyond k-Anonymity and \u2113-Diversity","description":"Requires sensitive attribute distribution in each equivalence class be close to overall distribution.","category":"Privacy > Anonymization & De-identification","url":"https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf"},{"id":"paper-identity-inference-of-genomic-data-using-long-range-familial-searches","type":"paper","name":"Identity Inference of Genomic Data Using Long-Range Familial Searches","description":"Shows 60% of European-descent Americans re-identifiable via genetic genealogy databases like GEDmatch.","category":"Privacy > Anonymization & De-identification","url":"https://www.science.org/doi/10.1126/science.aau4832"},{"id":"paper-how-to-generate-and-exchange-secrets","type":"paper","name":"How to Generate and Exchange Secrets","description":"Garbled circuits for secure two-party computation; foundational 2PC technique enabling oblivious computation.","category":"Privacy > Secure Computation & MPC","url":"https://ieeexplore.ieee.org/document/4568207"},{"id":"paper-how-to-play-any-mental-game-(gmw-protocol)","type":"paper","name":"How to Play Any Mental Game (GMW Protocol)","description":"GMW protocol proving completeness of secure MPC with honest majority; any function computable securely.","category":"Privacy > Secure Computation & MPC","url":"https://dl.acm.org/doi/10.1145/28395.28420"},{"id":"paper-completeness-theorems-for-non-cryptographic-fault-tolerant-distributed-computation-(bgw)","type":"paper","name":"Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation (BGW)","description":"BGW protocol for information-theoretic MPC; 2023 Dijkstra Prize winner for seminal distributed computing paper.","category":"Privacy > Secure Computation & MPC","url":"https://dl.acm.org/doi/10.1145/62212.62213"},{"id":"paper-fully-homomorphic-encryption-using-ideal-lattices","type":"paper","name":"Fully Homomorphic Encryption Using Ideal Lattices","description":"First FHE construction enabling arbitrary computation on encrypted data; breakthrough cryptographic result.","category":"Privacy > Secure Computation & MPC","url":"https://dl.acm.org/doi/10.1145/1536414.1536440"},{"id":"paper-practical-multi-party-private-set-intersection-from-symmetric-key-techniques","type":"paper","name":"Practical Multi-party Private Set Intersection from Symmetric-Key Techniques","description":"Practical multi-party PSI using OPPRF; deployed for privacy-preserving ad matching and contact discovery.","category":"Privacy > Secure Computation & MPC","url":"https://dl.acm.org/doi/10.1145/3133956.3134065"},{"id":"paper-privacy-regulation-and-online-advertising-2","type":"paper","name":"Privacy Regulation and Online Advertising","description":"EU privacy directive reduced ad effectiveness by 65%; first major empirical study of privacy regulation impact.","category":"Privacy > Privacy Economics & Regulation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1100.1246"},{"id":"paper-the-short-run-effects-of-gdpr-on-technology-venture-investment","type":"paper","name":"The Short-Run Effects of GDPR on Technology Venture Investment","description":"GDPR reduced EU tech venture investment by ~26%; rigorous diff-in-diff analysis of regulation effects.","category":"Privacy > Privacy Economics & Regulation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2020.1271"},{"id":"paper-privacy-protection-and-technology-diffusion:-the-case-of-electronic-medical-records","type":"paper","name":"Privacy Protection and Technology Diffusion: The Case of Electronic Medical Records","description":"State privacy laws reduced EMR adoption by 24%; pioneering regulation-innovation tradeoff study.","category":"Privacy > Privacy Economics & Regulation","url":"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1090.1014"},{"id":"paper-membership-inference-attacks-against-machine-learning-models","type":"paper","name":"Membership Inference Attacks Against Machine Learning Models","description":"Foundational paper introducing shadow model-based membership inference; spawned entire research area.","category":"Privacy > ML Privacy Attacks","url":"https://arxiv.org/abs/1610.05820"},{"id":"paper-model-inversion-attacks-that-exploit-confidence-information-and-basic-countermeasures","type":"paper","name":"Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures","description":"Demonstrated recovery of training faces from facial recognition confidence scores; motivates output privacy.","category":"Privacy > ML Privacy Attacks","url":"https://dl.acm.org/doi/10.1145/2810103.2813677"},{"id":"paper-extracting-training-data-from-large-language-models","type":"paper","name":"Extracting Training Data from Large Language Models","description":"First demonstration of verbatim training data extraction from GPT-2 including PII; motivated LLM safety research.","category":"Privacy > ML Privacy Attacks","url":"https://arxiv.org/abs/2012.07805"},{"id":"paper-deep-leakage-from-gradients","type":"paper","name":"Deep Leakage from Gradients","description":"Gradient inversion reconstructs pixel-perfect training images from gradients; motivated secure aggregation.","category":"Privacy > ML Privacy Attacks","url":"https://arxiv.org/abs/1906.08935"},{"id":"paper-exploiting-unintended-feature-leakage-in-collaborative-learning","type":"paper","name":"Exploiting Unintended Feature Leakage in Collaborative Learning","description":"Property inference attacks on federated learning; passive and active variants extract sensitive attributes.","category":"Privacy > ML Privacy Attacks","url":"https://arxiv.org/abs/1805.04049"},{"id":"paper-private-information-retrieval","type":"paper","name":"Private Information Retrieval","description":"Foundational PIR paper; proves single-server IT-PIR impossible sub-linearly, introduces multi-server PIR.","category":"Privacy > PIR & Anonymous Systems","url":"https://dl.acm.org/doi/10.1145/293347.293350"},{"id":"paper-untraceable-electronic-mail,-return-addresses,-and-digital-pseudonyms","type":"paper","name":"Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms","description":"Introduces mix networks; first practical solution to traffic analysis enabling anonymous communication.","category":"Privacy > PIR & Anonymous Systems","url":"https://dl.acm.org/doi/10.1145/358549.358563"},{"id":"paper-tor:-the-second-generation-onion-router","type":"paper","name":"Tor: The Second-Generation Onion Router","description":"Design of Tor with perfect forward secrecy, directory servers, hidden services; deployed to millions.","category":"Privacy > PIR & Anonymous Systems","url":"https://www.usenix.org/conference/13th-usenix-security-symposium/tor-second-generation-onion-router"},{"id":"paper-improving-the-robustness-of-private-information-retrieval","type":"paper","name":"Improving the Robustness of Private Information Retrieval","description":"Byzantine-robust multi-server PIR; first practical open-source PIR implementation (Percy++).","category":"Privacy > PIR & Anonymous Systems","url":"https://ieeexplore.ieee.org/document/4223220"},{"id":"paper-secureml:-a-system-for-scalable-privacy-preserving-machine-learning","type":"paper","name":"SecureML: A System for Scalable Privacy-Preserving Machine Learning","description":"First practical MPC-based neural network training system; enables ML on private data from multiple parties.","category":"Privacy > Privacy-Preserving ML","url":"https://ieeexplore.ieee.org/document/7958569"},{"id":"paper-slalom:-fast,-verifiable-and-private-execution-of-neural-networks-in-trusted-hardware","type":"paper","name":"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware","description":"Efficient DNN execution in Intel SGX with cryptographic verification of correct computation.","category":"Privacy > Privacy-Preserving ML","url":"https://arxiv.org/abs/1806.03287"},{"id":"paper-delphi:-a-cryptographic-inference-service-for-neural-networks","type":"paper","name":"Delphi: A Cryptographic Inference Service for Neural Networks","description":"22\u00d7 faster secure inference via ML-crypto co-design; hybrid HE + garbled circuits approach.","category":"Privacy > Privacy-Preserving ML","url":"https://www.usenix.org/conference/usenixsecurity20/presentation/mishra"},{"id":"paper-iron:-private-inference-on-transformers","type":"paper","name":"Iron: Private Inference on Transformers","description":"First efficient 2PC framework for BERT/GPT inference; specialized protocols for Softmax and GELU.","category":"Privacy > Privacy-Preserving ML","url":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/f8e1bda1c3e6fdf9b5bc5c9d7f5f9cd4-Abstract-Conference.html"},{"id":"paper-hedonic-prices-and-implicit-markets:-product-differentiation-in-pure-competition","type":"paper","name":"Hedonic Prices and Implicit Markets: Product Differentiation in Pure Competition","description":"Theoretical foundation for all hedonic pricing models; every AVM derives from this framework.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.jstor.org/stable/1830899"},{"id":"paper-the-efficiency-of-the-market-for-single-family-homes","type":"paper","name":"The Efficiency of the Market for Single-Family Homes","description":"Original Case-Shiller methodology establishing weighted repeat-sales indices used in S&P/Case-Shiller and FHFA.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.aeaweb.org/articles?id=10.1257/aer.79.1.125"},{"id":"paper-housing-dynamics","type":"paper","name":"Housing Dynamics","description":"Models serial correlation in house prices (momentum at 1-year, mean reversion at 5+ years); explains forecasting difficulty.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.nber.org/papers/w12787"},{"id":"paper-how-much-is-the-view-from-the-window-worth?-machine-learning-driven-hedonic-pricing-model","type":"paper","name":"How Much is the View from the Window Worth? Machine Learning-Driven Hedonic Pricing Model","description":"25% accuracy improvement by integrating image and text data with interpretable SHAP-based ML for AVMs.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.sciencedirect.com/science/article/pii/S0148296322000741"},{"id":"paper-why-is-intermediating-houses-so-difficult?-evidence-from-ibuyers","type":"paper","name":"Why is Intermediating Houses so Difficult? Evidence from iBuyers","description":"Definitive analysis of Opendoor and Zillow Offers; quantifies adverse selection vs. liquidity tradeoffs in iBuying.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.nber.org/papers/w28252"},{"id":"paper-the-effect-of-home-sharing-on-house-prices-and-rents:-evidence-from-airbnb","type":"paper","name":"The Effect of Home-Sharing on House Prices and Rents: Evidence from Airbnb","description":"IV strategy on nationwide Airbnb data; 1% listing increase \u2192 0.018% rent increase via supply reallocation.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2020.1227"},{"id":"paper-do-short-term-rental-platforms-affect-housing-markets?-evidence-from-airbnb-in-barcelona","type":"paper","name":"Do Short-Term Rental Platforms Affect Housing Markets? Evidence from Airbnb in Barcelona","description":"Rigorous event-study finding Airbnb increased Barcelona rents 1.9% and prices 4.6%.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.sciencedirect.com/science/article/pii/S0094119019300774"},{"id":"paper-housing-market-expectations","type":"paper","name":"Housing Market Expectations","description":"Comprehensive survey on household price expectation formation; documents extrapolation and social network effects.","category":"Spatial & Geo > Real Estate & Proptech","url":"https://www.nber.org/papers/w29909"},{"id":"paper-kernel-density-estimation","type":"paper","name":"Kernel Density Estimation","description":"Foundational non-parametric density estimation underpinning demand heatmaps.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://www.taylorfrancis.com/books/mono/10.1201/9781315140919/density-estimation-statistics-data-analysis-silverman"},{"id":"paper-geographically-weighted-regression","type":"paper","name":"Geographically Weighted Regression","description":"Local regression allowing coefficients to vary spatially\u2014key for heterogeneous demand.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://onlinelibrary.wiley.com/doi/book/10.1002/9781118786352"},{"id":"paper-deep-gravity:-large-scale-origin-destination-flows","type":"paper","name":"Deep Gravity: Large-Scale Origin-Destination Flows","description":"Neural network predicting mobility flows, outperforming classic gravity models.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://www.nature.com/articles/s41467-021-24803-0"},{"id":"paper-understanding-uber-demand","type":"paper","name":"Understanding Uber Demand","description":"Uber's real-time geospatial demand prediction powering surge and dispatch.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://www.uber.com/blog/demand-and-surge-pricing/"},{"id":"paper-eta-prediction-with-graph-neural-networks-in-google-maps-1","type":"paper","name":"ETA Prediction with Graph Neural Networks in Google Maps","description":"Production GNN that reduced negative ETA outcomes by 40%+ in cities like Sydney; deployed at scale.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://dl.acm.org/doi/10.1145/3459637.3481916"},{"id":"paper-diffusion-convolutional-recurrent-neural-network:-data-driven-traffic-forecasting","type":"paper","name":"Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting","description":"Foundational spatiotemporal GNN with 5,000+ citations; models traffic as diffusion on road graphs.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://arxiv.org/abs/1707.01926"},{"id":"paper-a-review-of-self-exciting-spatio-temporal-point-processes-and-their-applications","type":"paper","name":"A Review of Self-Exciting Spatio-Temporal Point Processes and Their Applications","description":"Definitive Hawkes process review for modeling clustered demand in surge pricing and fraud detection.","category":"Spatial & Geo > Geospatial Demand Modeling","url":"https://projecteuclid.org/journals/statistical-science/volume-33/issue-3/A-Review-of-Self-Exciting-Spatio-Temporal-Point-Processes-and/10.1214/17-STS629.full"},{"id":"paper-maximum-coverage-location-problem","type":"paper","name":"Maximum Coverage Location Problem","description":"Seminal optimization formulation for facility siting under coverage constraints.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://link.springer.com/article/10.1007/BF01942293"},{"id":"paper-spatial-interaction-models","type":"paper","name":"Spatial Interaction Models","description":"Entropy-maximization derivation of gravity and retail models.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://journals.sagepub.com/doi/10.1068/a030001"},{"id":"paper-starbucks-store-locator-with-machine-learning","type":"paper","name":"Starbucks Store Locator with Machine Learning","description":"ML-driven site selection combining foot traffic, demographics, and competition.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://stories.starbucks.com/stories/2019/how-starbucks-uses-data-to-site-new-stores/"},{"id":"paper-competitive-location-models:-a-review","type":"paper","name":"Competitive Location Models: A Review","description":"Authoritative review covering Hotelling spatial competition, gravity-based capture models, and location games.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://www.sciencedirect.com/science/article/pii/S037722172301003X"},{"id":"paper-geo-spotting:-mining-online-location-based-services-for-optimal-retail-store-placement","type":"paper","name":"Geo-Spotting: Mining Online Location-Based Services for Optimal Retail Store Placement","description":"Pioneering ML site selection using Foursquare data with gradient boosted trees; foundational for location analytics.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://dl.acm.org/doi/10.1145/2487575.2487616"},{"id":"paper-facility-location-under-uncertainty:-a-review","type":"paper","name":"Facility Location Under Uncertainty: A Review","description":"Canonical review of stochastic and robust facility location for warehouse network design.","category":"Spatial & Geo > Location Choice & Site Selection","url":"https://www.tandfonline.com/doi/abs/10.1080/07408170500216480"},{"id":"paper-spatial-econometrics:-methods-and-models","type":"paper","name":"Spatial Econometrics: Methods and Models","description":"Definitive textbook: spatial lag/error models, Moran's I, and inference.","category":"Spatial & Geo > Spatial Econometrics","url":"https://link.springer.com/book/10.1007/978-94-015-7799-1"},{"id":"paper-a-spatial-cliff-ord-type-model-with-heteroskedastic-innovations","type":"paper","name":"A Spatial Cliff-Ord-Type Model with Heteroskedastic Innovations","description":"Robust GMM estimation for spatial autoregressions\u2014standard in applied work.","category":"Spatial & Geo > Spatial Econometrics","url":"https://www.sciencedirect.com/science/article/abs/pii/S0304407609001870"},{"id":"paper-pysal:-a-python-library-for-spatial-analysis","type":"paper","name":"PySAL: A Python Library for Spatial Analysis","description":"Open-source library implementing spatial weights, autocorrelation, regression.","category":"Spatial & Geo > Spatial Econometrics","url":"https://pysal.org/pysal/"},{"id":"paper-spatial-spillovers-in-airbnb-pricing","type":"paper","name":"Spatial Spillovers in Airbnb Pricing","description":"Demonstrates spatial lag effects in short-term rental markets using hedonic models.","category":"Spatial & Geo > Spatial Econometrics","url":"https://www.sciencedirect.com/science/article/abs/pii/S0094119020300310"},{"id":"paper-gmm-estimation-with-cross-sectional-dependence","type":"paper","name":"GMM Estimation with Cross Sectional Dependence","description":"Foundational paper on spatial HAC standard errors ('Conley SEs'); industry-standard correction.","category":"Spatial & Geo > Spatial Econometrics","url":"https://www.sciencedirect.com/science/article/pii/S0304407698000840"},{"id":"paper-estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests-3","type":"paper","name":"Estimation and Inference of Heterogeneous Treatment Effects using Random Forests","description":"Causal forests for heterogeneous treatment effects with valid confidence intervals; implemented in grf and EconML.","category":"Spatial & Geo > Spatial Econometrics","url":"https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1319839"},{"id":"paper-geographic-boundaries-as-regression-discontinuities","type":"paper","name":"Geographic Boundaries as Regression Discontinuities","description":"Foundational geographic RDD methodology addressing boundary selection and spatial inference.","category":"Spatial & Geo > Spatial Econometrics","url":"https://www.cambridge.org/core/journals/political-analysis/article/geographic-boundaries-as-regression-discontinuities/89E13E84E67DADAB8F67F88E9D5BFAED"},{"id":"paper-libpostal:-international-address-parsing","type":"paper","name":"libpostal: International Address Parsing","description":"NLP library parsing addresses in 60+ languages\u2014widely used in ride-sharing and logistics.","category":"Spatial & Geo > Mapping & Geocoding","url":"https://github.com/openvenues/libpostal"},{"id":"paper-h3:-uber's-hexagonal-hierarchical-spatial-index","type":"paper","name":"H3: Uber's Hexagonal Hierarchical Spatial Index","description":"Hexagonal grid system enabling efficient geospatial joins and aggregations.","category":"Spatial & Geo > Mapping & Geocoding","url":"https://www.uber.com/blog/h3/"},{"id":"paper-placekey:-a-universal-place-identifier","type":"paper","name":"Placekey: A Universal Place Identifier","description":"Standardized POI identifier joining disparate datasets without address matching.","category":"Spatial & Geo > Mapping & Geocoding","url":"https://www.placekey.io/"},{"id":"paper-bing-geocoding","type":"paper","name":"Bing Geocoding","description":"Production geocoding system at Bing scale; covers parsing, candidate generation, and ranking pipeline.","category":"Spatial & Geo > Mapping & Geocoding","url":"https://dl.acm.org/doi/10.1145/2820783.2820828"},{"id":"paper-probabilistic-record-linkage-and-a-method-to-calculate-the-positive-predictive-value","type":"paper","name":"Probabilistic Record Linkage and a Method to Calculate the Positive Predictive Value","description":"HMM-based address parsing and record linkage; foundational for modern address normalization.","category":"Spatial & Geo > Mapping & Geocoding","url":"https://link.springer.com/article/10.1023/A:1020576411898"},{"id":"paper-understanding-individual-human-mobility-patterns","type":"paper","name":"Understanding Individual Human Mobility Patterns","description":"Large-scale mobile-phone analysis revealing power-law travel distributions.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.nature.com/articles/nature06958"},{"id":"paper-the-universal-visitation-law-of-human-mobility","type":"paper","name":"The Universal Visitation Law of Human Mobility","description":"Unifying framework explaining visitation frequency to locations across cities.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.nature.com/articles/s41586-021-03480-9"},{"id":"paper-deepmove:-predicting-human-mobility","type":"paper","name":"DeepMove: Predicting Human Mobility","description":"Attention-based RNN capturing periodicity and transition patterns in check-ins.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://dl.acm.org/doi/10.1145/3178876.3186058"},{"id":"paper-google-mobility-reports","type":"paper","name":"Google Mobility Reports","description":"Aggregated mobility trends by place category\u2014used globally for pandemic response.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.google.com/covid19/mobility/"},{"id":"paper-safegraph-foot-traffic-data","type":"paper","name":"SafeGraph Foot Traffic Data","description":"Panel-based POI visit data enabling offline-to-online attribution and demand studies.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.safegraph.com/products/places"},{"id":"paper-fear,-lockdown,-and-diversion:-comparing-drivers-of-pandemic-economic-decline","type":"paper","name":"Fear, Lockdown, and Diversion: Comparing Drivers of Pandemic Economic Decline","description":"Uses smartphone mobility to show voluntary behavioral changes dwarfed lockdown effects on foot traffic.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.sciencedirect.com/science/article/pii/S0047272720301754"},{"id":"paper-creating-synthetic-baseline-populations","type":"paper","name":"Creating Synthetic Baseline Populations","description":"Iterative Proportional Fitting (IPF) to generate representative synthetic populations for microsimulation.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://www.sciencedirect.com/science/article/abs/pii/0965856495000044"},{"id":"paper-comprehensive-econometric-microsimulator-for-daily-activity-travel-patterns","type":"paper","name":"Comprehensive Econometric Microsimulator for Daily Activity-Travel Patterns","description":"CEMDAP: full-day activity-travel simulator; basis for large-scale urban demand models.","category":"Spatial & Geo > Mobility & Movement Patterns","url":"https://journals.sagepub.com/doi/10.3141/1894-01"}]}